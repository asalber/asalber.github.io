<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Estadística | Aprende con Alf</title><link>/category/estadistica/</link><atom:link href="/category/estadistica/index.xml" rel="self" type="application/rss+xml"/><description>Estadística</description><generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>es-es</language><lastBuildDate>Sun, 07 Nov 2021 00:00:00 +0000</lastBuildDate><image><url>/images/logo_hude38443eeb2faa5fa84365aba7d86a77_3514_300x300_fit_lanczos_3.png</url><title>Estadística</title><link>/category/estadistica/</link></image><item><title>Introducción</title><link>/docencia/estadistica/manual/introduccion/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/docencia/estadistica/manual/introduccion/</guid><description>&lt;h2 id="la-estadística-como-herramienta-científica">La estadística como herramienta científica&lt;/h2>
&lt;h3 id="qué-es-la-estadística">¿Qué es la estadística?&lt;/h3>
&lt;div class="alert alert-def">
&lt;div>
&lt;strong>Definición - Estadística&lt;/strong>. La &lt;em>estadística&lt;/em> es una rama de las matemáticas que se encarga de la recogida, análisis e interpretación de datos.
&lt;/div>
&lt;/div>
&lt;p>El papel de la Estadística es extraer información de los datos para adquirir el conocimiento necesario para tomar decisiones.&lt;/p>
&lt;img src="../img/introduccion/proposito_estadistica.svg" alt="Propósito de la Estadística" width="600px">
&lt;p>La estadística es imprescindible en cualquier disciplina científica o técnica donde se manejen datos, especialmente si son grandes volúmenes de datos, como por ejemplo en Física, Química, Medicina, Psicología, Economía o Ciencias Sociales.&lt;/p>
&lt;p>Pero, &lt;em>¿por qué es necesaria la Estadística?&lt;/em>&lt;/p>
&lt;h3 id="la-variabilidad-de-nuestro-mundo">La variabilidad de nuestro mundo&lt;/h3>
&lt;p>El científico trata de estudiar el mundo que le rodea; un mundo que está lleno de variaciones que dificultan la determinación del comportamiento de las cosas.&lt;/p>
&lt;p>La estadística actúa como disciplina puente entre la realidad del mundo y los modelos matemáticos que tratan de explicarla, proporcionando una metodología para evaluar las discrepancias entre la realidad y los modelos teóricos.&lt;/p>
&lt;p>Esto la convierte en una herramienta indispensable en las ciencias aplicadas que requieran el análisis de datos y el diseño de experimentos.&lt;/p>
&lt;h2 id="población-y-muestra">Población y muestra&lt;/h2>
&lt;h3 id="población-estadística">Población estadística&lt;/h3>
&lt;div class="alert alert-def">
&lt;div>
&lt;strong>Definición - Población&lt;/strong>. Una &lt;em>población&lt;/em> es un conjunto de elementos definido por una o más características que tienen todos los elementos, y sólo ellos. Cada elemento de la población se llama &lt;em>individuo&lt;/em>.
&lt;/div>
&lt;/div>
&lt;div class="alert alert-def">
&lt;div>
&lt;strong>Definición - Tamaño poblacional&lt;/strong>. El número de individuos de una población se conoce como &lt;em>tamaño poblacional&lt;/em> y se representa como $N$.
&lt;/div>
&lt;/div>
&lt;p>&lt;strong>Ejemplo&lt;/strong>. En unas elecciones generales a la presidencia del gobierno, la población serían todos los individuos del estado con derecho a voto. En el estudio de una enfermedad, la población sería todas las personas que tienen la enfermedad. Y en un proceso de control de calidad en la fabricación de un fármaco, la población estaría formada por todos los fármacos que se producen en la fábrica.&lt;/p>
&lt;p>A veces, no todos los elementos de la población están accesibles para su estudio. Entonces se distingue entre:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Población Teórica&lt;/strong>: Conjunto de elementos a los que se quiere extrapolar los resultados del estudio.&lt;/li>
&lt;li>&lt;strong>Población Estudiada&lt;/strong>: Conjunto de elementos realmente accesibles en el estudio.&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Ejemplo&lt;/strong>. En el caso del estudio de una enfermedad, la población teórica sería todas las personas que contraigan la enfermedad, incluso si aún no han nacido, mientras que la población estudiada se limitaría al número de personas enfermas que realmente podemos estudiar (obsérvese que incluso quedarían fuera las personas enfermas pero de las que no podemos conseguir información).&lt;/p>
&lt;h3 id="inconvenientes-en-el-estudio-de-la-población">Inconvenientes en el estudio de la población&lt;/h3>
&lt;p>El científico estudia un determinado fenómeno en una población para comprenderlo, obtener conocimiento sobre el mismo, y así poder controlarlo. Pero, para tener un conocimiento completo de la población &lt;em>es necesario estudiar todos los individuos de la misma&lt;/em>. Sin embargo, esto no siempre es posible por distintos motivos:&lt;/p>
&lt;ul>
&lt;li>El tamaño de la población es infinito, o bien es finito pero demasiado grande.&lt;/li>
&lt;li>Las pruebas a que se someten los individuos son destructivas.&lt;/li>
&lt;li>El coste, tanto de dinero como de tiempo, que supondría estudiar a todos los individuos es excesivo.&lt;/li>
&lt;/ul>
&lt;h3 id="muestra-estadística">Muestra estadística&lt;/h3>
&lt;p>Cuando no es posible o conveniente estudiar todos los individuos de la población, se estudia sólo una parte de la misma.&lt;/p>
&lt;div class="alert alert-def">
&lt;div>
&lt;strong>Definición - Muestra&lt;/strong>. Una &lt;em>muestra&lt;/em> es un subconjunto de la población.
&lt;/div>
&lt;/div>
&lt;div class="alert alert-def">
&lt;div>
&lt;strong>Definición - Tamaño muestral&lt;/strong>. Al número de individuos que componen la muestra se le llama &lt;em>tamaño muestral&lt;/em> y se representa por $n$.
&lt;/div>
&lt;/div>
&lt;p>Habitualmente, el estudio de una población se realiza a partir de muestras extraídas de dicha población.&lt;/p>
&lt;p>Generalmente, el estudio de la muestra sólo aporta conocimiento aproximado de la población. Pero en muchos casos es &lt;em>suficiente&lt;/em>.&lt;/p>
&lt;h3 id="determinación-del-tamaño-muestral">Determinación del tamaño muestral&lt;/h3>
&lt;p>Una de las preguntas más interesantes que surge inmediatamente es: &lt;em>¿cuántos individuos es necesario tomar en la muestra para tener un conocimiento aproximado pero suficiente de la población?&lt;/em>&lt;/p>
&lt;p>La respuesta depende de varios factores, como la variabilidad de la población o la fiabilidad deseada para las extrapolaciones que se hagan hacia la población.&lt;/p>
&lt;p>Por desgracia no se podrá responder hasta casi el final del curso, pero en general, cuantos más individuos haya en la muestra, más fiables serán las conclusiones sobre la población, pero también será más lento y costoso el estudio.&lt;/p>
&lt;p>&lt;strong>Ejemplo&lt;/strong>. Para entender a qué nos referimos cuando hablamos de un tamaño muestral suficiente para comprender lo que ocurre en la población, podemos utilizar el siguiente símil en que se trata de comprender el motivo que representa una fotografía.&lt;/p>
&lt;p>Una fotografía digital está formada por multitud de pequeños puntitos llamados pixels que se dispone en una enorme tabla de filas y columnas (cuantas más filas y columnas haya se habla de que la foto tiene más resolución). Aquí la población estaría formada por todos y cada uno de los píxeles que forman la foto. Por otro lado cada pixel tiene un color y es la variedad de colores a lo largo de los pixels la que permite formar la imagen de la fotografía.&lt;/p>
&lt;p>&lt;em>¿Cuántos píxeles debemos tomar en una muestra para averiguar la imagen de la foto?&lt;/em>&lt;/p>
&lt;p>La respuesta depende de la variabilidad de colores en la foto. Si todos los pixels de la foto son del mismo color, entonces un sólo pixel basta para desvelar la imagen. Pero, si la foto tiene mucha variabilidad de colores, necesitaremos muchos más pixels en la muestra para descubrir el motivo de la foto.&lt;/p>
&lt;p>La imagen siguiente contiene una muestra pequeña de píxeles de una foto. ¿Puedes averiguar el motivo de a foto?&lt;/p>
&lt;p>&lt;img src="../img/introduccion/muestra_molinos1.jpg" alt="Muestra pequeña de píxeles de una foto." title="Muestra pequeña de pixels de una foto">&lt;/p>
&lt;p>&lt;em>¡Con una muestra pequeña es difícil averiguar el contenido de la imagen!&lt;/em>&lt;/p>
&lt;p>Seguramente no has podido averiguar el motivo de la fotografía, porque en este caso el número de píxeles que hemos tomado en la muestra es insuficiente para comprender toda la variabilidad de colores que hay en la foto.&lt;/p>
&lt;p>La siguiente imagen contiene una muestra mayor de píxeles. ¿Eres capaz de adivinar el motivo de la foto ahora?&lt;/p>
&lt;p>&lt;img src="../img/introduccion/muestra_molinos2.jpg" alt="Muestra mayor de píxeles de una foto." title="Muestra mayor de pixels de una foto.">&lt;/p>
&lt;p>&lt;em>¡Con una muestra mayor es posible desvelar el motivo de la foto!&lt;/em>&lt;/p>
&lt;p>Y aquí está la población completa.&lt;/p>
&lt;p>&lt;img src="../img/introduccion/muestra_molinos3.jpg" alt="Población de píxeles de una foto." title="Población de pixels de una foto.">&lt;/p>
&lt;p>Lo importante es que &lt;em>¡No es necesario conocer todos los píxeles para averiguar la imagen!&lt;/em>&lt;/p>
&lt;h3 id="tipos-de-razonamiento">Tipos de razonamiento&lt;/h3>
&lt;p>Así pues, habitualmente realizaremos el estudio de la población a partir de muestras y luego trataremos de extrapolar lo observado en la muestra al resto de la población. A este tipo de razonamiento que saca conclusiones desde la muestra hacia la población se le conoce como &lt;em>razonamiento inductivo&lt;/em>.&lt;/p>
&lt;img src="../img/introduccion/tipos_razonamiento.svg" alt="Tipos de razonamiento" width="400px">
&lt;ul>
&lt;li>
&lt;p>&lt;em>Características de la deducción&lt;/em>: Si las premisas son ciertas, garantiza la certeza de las conclusiones (es decir, si algo se cumple en la población, también se cumple en la muestra). Sin embargo, &lt;em>¡no aporta conocimiento nuevo!&lt;/em>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;em>Características de la inducción&lt;/em>: No garantiza la certeza de las conclusiones (si algo se cumple en la muestra, puede que no se cumpla en la población, así que ¡cuidado con las extrapolaciones!), pero &lt;em>¡es la única forma de generar conocimiento nuevo!&lt;/em>&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>La estadística se apoya fundamentalmente en el razonamiento inductivo ya que utiliza la información obtenida a partir de muestras para sacar conclusiones sobre las poblaciones. A diferencia del razonamiento deductivo que va de lo general a lo particular, o en nuestro caso de la población a la muestra, el razonamiento inductivo no garantiza la certeza de las conclusiones, por lo que debemos ser cuidadosos a la hora de generalizar sobre la población lo observado en al muestra, ya que si la muestra no es representativa de la población o contiene sesgos, las conclusiones pueden ser erróneas.&lt;/p>
&lt;h2 id="muestreo">Muestreo&lt;/h2>
&lt;div class="alert alert-def">
&lt;div>
&lt;strong>Definición - Muestreo&lt;/strong>. El proceso de selección de los elementos que compondrán una muestra se conoce como &lt;em>muestreo&lt;/em>.
&lt;/div>
&lt;/div>
&lt;img src="../img/introduccion/muestreo.svg" alt="Muestreo" width="500px">
&lt;p>Para que una muestra refleje información fidedigna sobre la población global debe ser representativa de la misma, lo que significa que debe reproducir a pequeña escala la variabilidad de la población.&lt;/p>
&lt;p>&lt;em>El objetivo es obtener una muestra representativa de la población.&lt;/em>&lt;/p>
&lt;h3 id="modalidades-de-muestreo">Modalidades de muestreo&lt;/h3>
&lt;p>Existen muchas técnicas de muestreo pero se pueden agrupar en dos categorías:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>Muestreo Aleatorio&lt;/strong>: Elección aleatoria de los individuos de la muestra. Todos tienen la misma probabilidad de ser elegidos (&lt;em>equiprobabilidad&lt;/em>).&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Muestreo No Aleatorio&lt;/strong>: Los individuos se eligen de forma no aleatoria. Algunos individuos tienen más probabilidad de ser seleccionados que otros.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>Sólo las técnicas aleatorias evitan el sesgo de selección, y por tanto, garantizan la representatividad de la muestra extraída, y en consecuencia la validez de las conclusiones.&lt;/p>
&lt;p>Las técnicas no aleatorias no sirven para hacer generalizaciones, ya que no garantizan la representatividad de la muestra. Sin embargo, son menos costosas y pueden utilizarse en estudios exploratorios.&lt;/p>
&lt;h3 id="muestreo-aleatorio-simple">Muestreo aleatorio simple&lt;/h3>
&lt;p>Dentro de las modalidades de muestreo aleatorio, el tipo más conocido es el &lt;em>muestreo aleatorio simple&lt;/em>, caracterizado por:&lt;/p>
&lt;ul>
&lt;li>Todos los individuos de la población tienen la misma probabilidad de ser elegidos para la muestra.&lt;/li>
&lt;li>La selección de individuos es con reemplazamiento, es decir, cada individuo seleccionado es devuelto a la población antes de seleccionar al siguiente (y por tanto no se altera la población de partida).&lt;/li>
&lt;li>Las sucesivas selecciones de un individuo son independientes.&lt;/li>
&lt;/ul>
&lt;p>La única forma de realizar un muestreo aleatorio es asignar un número a cada individuo de la población (&lt;em>censo&lt;/em>) y realizar un sorteo aleatorio.&lt;/p>
&lt;h3 id="variables-estadísticas">Variables estadísticas&lt;/h3>
&lt;p>Todo estudio estadístico comienza por la identificación de las características que interesa estudiar en la población y que se medirán en los individuos de la muestra.&lt;/p>
&lt;div class="alert alert-def">
&lt;div>
&lt;p>&lt;strong>Definición - Variable estadística&lt;/strong>. Una &lt;em>variable estadística&lt;/em> es una propiedad o característica medida en los individuos de la población.&lt;/p>
&lt;p>Los &lt;em>datos&lt;/em> son los valores observados en las variables estadísticas.&lt;/p>
&lt;/div>
&lt;/div>
&lt;p>&lt;img src="../img/introduccion/variables_estadisticas.svg" alt="&amp;amp;ldquo;Variables estadísticas&amp;amp;rdquo;">&lt;/p>
&lt;p>Estas características pueden ser de distintos tipos de acuerdo a su naturaleza y su escala:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>Variables cualitativas o atributos&lt;/strong>: Miden cualidades no numéricas. Pueden ser:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>Nominales&lt;/strong>: No existe un orden entre las categorías.&lt;br>
Ejemplo: El color de pelo o el sexo.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Ordinales&lt;/strong>: Existe un orden entre las categorías.
Ejemplo: El nivel de estudios o la gravedad de una enfermedad.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Variables cuantitativas&lt;/strong>: Miden cantidades numéricas. Pueden ser:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>Discretas&lt;/strong>: Toman valores numéricos aislados (habitualmente números enteros).&lt;br>
Ejemplo: El número de hijos o el número de coches en una familia.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Continuas&lt;/strong>: Pueden tomar cualquier valor en un intervalo real.&lt;br>
Ejemplo: El peso o la estatura.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>Las variables cualitativas y discretas se conocen también con &lt;em>variables categóricas&lt;/em> y sus valores &lt;em>categorías&lt;/em>.&lt;/p>
&lt;img src="../img/introduccion/tipos_variables.svg" alt="Variables estadísticas" width="800px">
&lt;h4 id="elección-del-tipo-de-variable-más-apropiado">Elección del tipo de variable más apropiado&lt;/h4>
&lt;p>En ocasiones una característica puede medirse mediante variables de distinto tipo.&lt;/p>
&lt;p>&lt;strong>Ejemplo&lt;/strong>. Si una persona fuma o no podría medirse de diferentes formas:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Fuma: si/no. (Nominal)&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Nivel de fumador: No fuma / ocasional / moderado / bastante / empedernido. (Ordinal)&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Número de cigarros diarios: 0,1,2,&amp;hellip; (Discreta)&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>En estos casos es preferible usar variables cuantitativas a cualitativas. Dentro de las cuantitativas es preferible usar las continuas a las discretas y dentro de las cualitativas es preferible usar ordinales a nominales pues aportan más información.&lt;/p>
&lt;img src="../img/introduccion/informacion_variables.svg" alt="Cantidad de información de los tipos de variables estadísticas" width="600px">
&lt;p>De acuerdo al papel que juegan en el estudio las variables también pueden clasificarse como:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Variables independientes&lt;/strong>: Variables que supuestamente no dependen de otras variables en el estudio. Habitualmente son las variables manipuladas en el experimento para ver su efecto en las variables dependientes. Se conocen también como &lt;em>variables predictivas&lt;/em>.&lt;/li>
&lt;li>&lt;strong>Variables dependientes&lt;/strong>: Variables que supuestamente dependen de otras variables en el estudio. No son manipuladas en el experimento y también se conocen como &lt;em>variables respuesta&lt;/em>.&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Ejemplo&lt;/strong>. En un estudio sobre el rendimiento de los alumnos de un curso, la inteligencia de los alumnos y el número de horas de estudio diarias serían variables independientes y la nota del curso sería una variable dependiente.&lt;/p>
&lt;h3 id="tipos-de-estudios-estadísticos">Tipos de estudios estadísticos&lt;/h3>
&lt;p>Dependiendo de si se manipulan las variables independientes existen dos tipos de estudios:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Experimentales&lt;/strong>: Cuando las variables independientes son manipuladas para ver el efecto que producen en las variables dependientes.&lt;br>
&lt;strong>Ejemplo&lt;/strong>. En un estudio sobre el rendimiento de los estudiantes en un test, el profesor manipula la metodología de estudio para crear dos o más grupos con metodologías de estudio distintas.&lt;/li>
&lt;li>&lt;strong>No experimentales&lt;/strong>: Cuando las variables independientes no son manipuladas. Esto no significa que sea imposible hacerlo, sino que es difícil o poco ético hacerlo.&lt;br>
&lt;strong>Ejemplo&lt;/strong>. En un estudio un investigador puede estar interesado en el efecto de fumar sobre el cáncer de pulmón. Aunque es posible, no sería ético pedirle a los pacientes que fumasen para ver el efecto que tiene sobre sus pulmones. En este caso, el investigador podría estudiar dos grupos de pacientes, uno con cáncer de pulmón y otro sin cáncer, y observar en cada grupo cuántos fuman o no.&lt;/li>
&lt;/ul>
&lt;p>Los estudios experimentales permiten identificar causas y efectos entre las variables del estudio, mientras que los no experimentales sólo permiten identificar relaciones de asociación entre las variables.&lt;/p>
&lt;h3 id="la-tabla-de-datos">La tabla de datos&lt;/h3>
&lt;p>Las variables a estudiar se medirán en cada uno de los individuos de la muestra, obteniendo un conjunto de datos que suele organizarse en forma de matriz que se conoce como tabla de datos_.&lt;/p>
&lt;p>En esta tabla cada columna contiene la información de una variable y cada fila la información de un individuo.&lt;/p>
&lt;p>&lt;strong>Ejemplo&lt;/strong> La siguiente tabla contiene información de las variables Nombre, Edad, Sexo, Peso y Altura de una muestra de 6 personas.&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align:left">Nombre&lt;/th>
&lt;th style="text-align:center">Edad&lt;/th>
&lt;th style="text-align:center">Sexo&lt;/th>
&lt;th style="text-align:center">Peso(Kg)&lt;/th>
&lt;th style="text-align:center">Altura(cm)&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align:left">José Luis Martínez&lt;/td>
&lt;td style="text-align:center">18&lt;/td>
&lt;td style="text-align:center">H&lt;/td>
&lt;td style="text-align:center">85&lt;/td>
&lt;td style="text-align:center">179&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">Rosa Díaz&lt;/td>
&lt;td style="text-align:center">32&lt;/td>
&lt;td style="text-align:center">M&lt;/td>
&lt;td style="text-align:center">65&lt;/td>
&lt;td style="text-align:center">173&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">Javier García&lt;/td>
&lt;td style="text-align:center">24&lt;/td>
&lt;td style="text-align:center">H&lt;/td>
&lt;td style="text-align:center">71&lt;/td>
&lt;td style="text-align:center">181&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">Carmen López&lt;/td>
&lt;td style="text-align:center">35&lt;/td>
&lt;td style="text-align:center">M&lt;/td>
&lt;td style="text-align:center">65&lt;/td>
&lt;td style="text-align:center">170&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">Marisa López&lt;/td>
&lt;td style="text-align:center">46&lt;/td>
&lt;td style="text-align:center">M&lt;/td>
&lt;td style="text-align:center">51&lt;/td>
&lt;td style="text-align:center">158&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">Antonio Ruiz&lt;/td>
&lt;td style="text-align:center">68&lt;/td>
&lt;td style="text-align:center">H&lt;/td>
&lt;td style="text-align:center">66&lt;/td>
&lt;td style="text-align:center">174&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h3 id="fases-del-análisis-estadístico">Fases del análisis estadístico&lt;/h3>
&lt;p>Normalmente un estudio estadístico pasa por las siguientes etapas:&lt;/p>
&lt;ol>
&lt;li>
&lt;p>El estudio comienza por el diseño previo del mismo en el que se establezcan los objetivos del mismo, la población, las variables que se medirán y el tamaño muestral requerido.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>A continuación se seleccionará una muestra representativa del tamaño establecido y se medirán las variables en los individuos de la muestra obteniendo la tabla de datos. De esto se encarga el &lt;em>Muestreo&lt;/em>.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>El siguiente paso consiste en describir y resumir la información que contiene la muestra. De esto se encarga la &lt;em>Estadística Descriptiva&lt;/em>.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>La información obtenida es proyectada sobre un modelo matemático que intenta explicar el comportamiento de la población y el modelo se valida. De todo esto se encarga la &lt;em>Estadística Inferencial&lt;/em>.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Finalmente, el modelo validado nos permite hacer predicciones y sacar conclusiones sobre la población de partida con cierta confianza.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;h4 id="el-ciclo-estadístico">El ciclo estadístico&lt;/h4>
&lt;img src="../img/introduccion/ciclo_estadistico.svg" alt="El ciclo estadístico" width="600px"></description></item><item><title>Ejercicios de Estadística Descriptiva</title><link>/docencia/estadistica/ejercicios/descriptiva/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/docencia/estadistica/ejercicios/descriptiva/</guid><description>&lt;h2 id="ejercicio-1">Ejercicio 1&lt;/h2>
&lt;p>Titulación: Medicina, Farmacia&lt;/p>
&lt;p>En un grupo de personas sometidas a una anestesia general se ha medido la dosis de sustancia anestésica recibida (X) en mg y el tiempo que estuvieron dormidas (Y) en horas.
Las frecuencias observadas aparecen en la siguiente tabla:&lt;/p>
&lt;p>$$
\begin{array}{|c|ccc|c|}
\hline
X\backslash Y &amp;amp; [1,2) &amp;amp; [2,3) &amp;amp; [3,4) &amp;amp; n_x \newline
\hline
(20,30] &amp;amp; 14 &amp;amp; 10 &amp;amp; 0 &amp;amp; 24 \newline
(30,40] &amp;amp; 12 &amp;amp; 26 &amp;amp; 7 &amp;amp; 45 \newline
(40,50] &amp;amp; 2 &amp;amp; 12 &amp;amp; 17 &amp;amp; 31 \newline
\hline
n_y &amp;amp; 28 &amp;amp; 48 &amp;amp; 24 &amp;amp; 100 \newline
\hline
\end{array}
$$&lt;/p>
&lt;p>Se pide:&lt;/p>
&lt;ol>
&lt;li>¿En qué variable es más representativa la media? Justificar la respuesta&lt;/li>
&lt;li>¿Por encima de cuánto tiempo estarán dormidas el 10% de las personas que reciben una dosis entre 30 y 40 mg?&lt;/li>
&lt;li>¿En qué variable hay más asimetría? Justificar la respuesta.&lt;/li>
&lt;li>Según el modelo de regresión lineal, ¿cuánta sustancia anestésica será necesaria para domir a alguien durante al menos dos horas?
¿Es fiable la predicción?
Justificar la respuesta.&lt;/li>
&lt;/ol>
&lt;div class="spoiler " >
&lt;p>
&lt;a class="btn btn-primary" data-toggle="collapse" href="#spoiler-0" role="button" aria-expanded="false" aria-controls="spoiler-0">
Solución
&lt;/a>
&lt;/p>
&lt;div class="collapse card " id="spoiler-0">
&lt;div class="card-body">
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="spoiler " >
&lt;p>
&lt;a class="btn btn-primary" data-toggle="collapse" href="#spoiler-1" role="button" aria-expanded="false" aria-controls="spoiler-1">
Resolución
&lt;/a>
&lt;/p>
&lt;div class="collapse card " id="spoiler-1">
&lt;div class="card-body">
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe src="https://www.youtube.com/embed/q5j2ryj0oCQ" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video">&lt;/iframe>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div></description></item><item><title>Estadística Descriptiva</title><link>/docencia/estadistica/manual/estadistica-descriptiva/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/docencia/estadistica/manual/estadistica-descriptiva/</guid><description>&lt;p>La estadística descriptiva es la parte de la estadística encargada de representar, analizar y resumir la información contenida en la muestra.&lt;/p>
&lt;p>Tras el proceso de muestreo, es la siguiente etapa de todo estudio estadístico y suele consistir en:&lt;/p>
&lt;ol>
&lt;li>
&lt;p>Clasificar, agrupar y ordenar los datos de la muestra.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Tabular y representar gráficamente los datos de acuerdo a sus frecuencias.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Calcular medidas que resuman la información que contiene la muestra (&lt;em>estadísticos muestrales&lt;/em>).&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>No tiene poder inferencial por lo que &lt;em>nunca deben sacarse conclusiones sobre la población a partir de las medidas resumen que aporta la Estadística Descriptiva&lt;/em>.&lt;/p>
&lt;h2 id="distribución-de-frecuencias">Distribución de frecuencias&lt;/h2>
&lt;p>El estudio de una variable estadística comienza por medir la variable en los individuos de la muestra y clasificar los valores obtenidos.&lt;/p>
&lt;p>Existen dos formas de clasificar estos valores:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>Sin agrupar&lt;/strong>: Ordenar todos los valores obtenidos en la muestra de menor a mayor. Se utiliza con atributos y variables discretas con pocos valores diferentes.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Agrupados&lt;/strong>: Agrupar los valores en clases (intervalos) y ordenar dichas clases de menor a mayor. Se utiliza con variables continuas y con variables discretas con muchos valores diferentes.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h3 id="clasificación-de-la-muestra">Clasificación de la muestra&lt;/h3>
&lt;p>Consiste colocar juntos los valores iguales y ordenarlos si existe un orden entre ellos.&lt;/p>
&lt;img src="../img/descriptiva/clasificacion_muestra.png" alt="Clasificación de la muestra" width=400px>
&lt;h3 id="recuento-de-frecuencias">Recuento de frecuencias&lt;/h3>
&lt;img src="../img/descriptiva/recuento_frecuencias.png" alt="Recuento de frecuencias" width=400px>
&lt;h2 id="frecuencias-muestrales">Frecuencias muestrales&lt;/h2>
&lt;div class="alert alert-def">
&lt;div>
&lt;p>&lt;strong>Definición - Frecuencias muestrales&lt;/strong>. Dada una muestra de tamaño $n$ de una variable $X$, para cada valor de la variable $x_i$ observado en la muestra, se define&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Frecuencia Absoluta $n_i$&lt;/strong>: Es el número de veces que el valor $x_i$ aparece en la muestra.&lt;/li>
&lt;li>&lt;strong>Frecuencia Relativa $f_i$&lt;/strong>: Es la proporción de veces que el valor $x_i$ aparece en la muestra.
$$f_i = \frac{n_i}{n}$$&lt;/li>
&lt;li>&lt;strong>Frecuencia Absoluta Acumulada $N_i$&lt;/strong>: Es el número de valores en la muestra menores o iguales que $x_i$.
$$N_i = n_1 + \cdots + n_i = N_{i-1}+n_i$$&lt;/li>
&lt;li>&lt;strong>Frecuencia Relativa Acumulada $F_i$&lt;/strong>: Es la proporción de valores en la muestra menores o iguales que $x_i$.
$$F_i = \frac{N_i}{n}$$&lt;/li>
&lt;/ul>
&lt;/div>
&lt;/div>
&lt;h3 id="tabla-de-frecuencias">Tabla de frecuencias&lt;/h3>
&lt;p>Al conjunto de valores observados en la muestra junto a sus respectivas frecuencias se le denomina &lt;strong>distribución de frecuencias&lt;/strong> y suele representarse mediante una &lt;strong>tabla de frecuencias&lt;/strong>.&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align:center">Valores de $X$&lt;/th>
&lt;th style="text-align:center">Frecuencia Absoluta&lt;/th>
&lt;th style="text-align:center">Frecuencia Relativa&lt;/th>
&lt;th style="text-align:center">Frecuencia Absoluta Acumulada&lt;/th>
&lt;th style="text-align:center">Frecuencia Relativa Acumulada&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align:center">$x_1$&lt;/td>
&lt;td style="text-align:center">$n_1$&lt;/td>
&lt;td style="text-align:center">$f_1$&lt;/td>
&lt;td style="text-align:center">$N_1$&lt;/td>
&lt;td style="text-align:center">$F_1$&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">$\vdots$&lt;/td>
&lt;td style="text-align:center">$\vdots$&lt;/td>
&lt;td style="text-align:center">$\vdots$&lt;/td>
&lt;td style="text-align:center">$\vdots$&lt;/td>
&lt;td style="text-align:center">$\vdots$&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">$x_i$&lt;/td>
&lt;td style="text-align:center">$n_i$&lt;/td>
&lt;td style="text-align:center">$f_i$&lt;/td>
&lt;td style="text-align:center">$N_i$&lt;/td>
&lt;td style="text-align:center">$F_i$&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">$\vdots$&lt;/td>
&lt;td style="text-align:center">$\vdots$&lt;/td>
&lt;td style="text-align:center">$\vdots$&lt;/td>
&lt;td style="text-align:center">$\vdots$&lt;/td>
&lt;td style="text-align:center">$\vdots$&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">$x_k$&lt;/td>
&lt;td style="text-align:center">$n_k$&lt;/td>
&lt;td style="text-align:center">$f_k$&lt;/td>
&lt;td style="text-align:center">$N_k$&lt;/td>
&lt;td style="text-align:center">$F_k$&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>&lt;strong>Ejemplo - Variable cuantitativa y datos no agrupados&lt;/strong>. El número de hijos en 25 familias es:&lt;/p>
&lt;div style="text-align:center">
1, 2, 4, 2, 2, 2, 3, 2, 1, 1, 0, 2, 2, 0, 2, 2, 1, 2, 2, 3, 1, 2, 2, 1, 2
&lt;/div>
&lt;p>La tabla de frecuencias del número de hijos en esta muestra es&lt;/p>
&lt;p>$$ \begin{array}{rrrrr}
\hline
x_i &amp;amp; n_i &amp;amp; f_i &amp;amp; N_i &amp;amp; F_i\newline
\hline
0 &amp;amp; 2 &amp;amp; 0.08 &amp;amp; 2 &amp;amp; 0.08\newline
1 &amp;amp; 6 &amp;amp; 0.24 &amp;amp; 8 &amp;amp; 0.32\newline
2 &amp;amp; 14 &amp;amp; 0.56 &amp;amp; 22 &amp;amp; 0.88\newline
3 &amp;amp; 2 &amp;amp; 0.08 &amp;amp; 24 &amp;amp; 0.96\newline
4 &amp;amp; 1 &amp;amp; 0.04 &amp;amp; 25 &amp;amp; 1 \newline
\hline
\sum &amp;amp; 25 &amp;amp; 1 \newline
\hline
\end{array}
$$&lt;/p>
&lt;p>&lt;strong>Ejemplo - Variable cuantitativa y datos agrupados&lt;/strong>. Se ha medido la estatura (en cm) de 30 universitarios obteniendo:&lt;/p>
&lt;div style="text-align:center">
179, 173, 181, 170, 158, 174, 172, 166, 194, 185,&lt;br>
162, 187, 198, 177, 178, 165, 154, 188, 166, 171,&lt;br>
175, 182, 167, 169, 172, 186, 172, 176, 168, 187.
&lt;/div>
&lt;p>La tabla de frecuencias de la estatura en a esta muestra es&lt;/p>
&lt;p>$$ \begin{array}{crrrr}
\hline
x_i &amp;amp; n_i &amp;amp; f_i &amp;amp; N_i &amp;amp; F_i\newline
\hline
(150,160] &amp;amp; 2 &amp;amp; 0.07 &amp;amp; 2 &amp;amp; 0.07\newline
(160,170] &amp;amp; 8 &amp;amp; 0.27 &amp;amp; 10 &amp;amp; 0.34\newline
(170,180] &amp;amp; 11 &amp;amp; 0.36 &amp;amp; 21 &amp;amp; 0.70\newline
(180,190] &amp;amp; 7 &amp;amp; 0.23 &amp;amp; 28 &amp;amp; 0.93\newline
(190,200] &amp;amp; 2 &amp;amp; 0.07 &amp;amp; 30 &amp;amp; 1 \newline
\hline
\sum &amp;amp; 30 &amp;amp; 1 \newline
\hline
\end{array}
$$&lt;/p>
&lt;h3 id="construcción-de-clases">Construcción de clases&lt;/h3>
&lt;p>Cada intervalo de agrupación de datos se denomina &lt;strong>clase&lt;/strong> y el centro del intervalo se llama &lt;strong>marca de clase&lt;/strong>.&lt;/p>
&lt;p>A la hora de agrupar los datos en clases hay que tener en cuenta lo siguiente:&lt;/p>
&lt;ul>
&lt;li>El número de intervalos no debe ser muy grande ni muy pequeño. Una regla orientativa es tomar un número de intervalos próximo a $\sqrt{n}$ o $\log_2(n)$.&lt;/li>
&lt;li>Los intervalos no deben solaparse y deben cubrir todo el rango de valores. Es indiferente si se abren por la izquierda y se cierran por la derecha o al revés.&lt;/li>
&lt;li>El valor más pequeño debe caer dentro del primer intervalo y el más grande dentro del último.&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Ejemplo - Variable cualitativa&lt;/strong>. Los grupos sanguíneos de una muestra de 30 personas son:&lt;/p>
&lt;div style="text-align:center">
A, B, B, A, AB, 0, 0, A, B, B, A, A, A, A, AB, A, A, A, B, 0, B, B, B, A, A, A, 0, A, AB, 0.
&lt;/div>
&lt;p>La tabla de frecuencias del grupo sanguíneo en esta muestra es&lt;/p>
&lt;p>$$
\begin{array}{crr}
\hline
x_i &amp;amp; n_i &amp;amp; f_i \newline
\hline
\mbox{0} &amp;amp; 5 &amp;amp; 0.16 \newline
\mbox{A} &amp;amp; 14 &amp;amp; 0.47 \newline
\mbox{B} &amp;amp; 8 &amp;amp; 0.27 \newline
\mbox{AB} &amp;amp; 3 &amp;amp; 0.10 \newline
\hline
\sum &amp;amp; 30 &amp;amp; 1 \newline
\hline
\end{array}
$$&lt;/p>
&lt;p>&lt;em>Obsérvese que en este caso las frecuencias acumuladas no tienen sentido al no existir un orden entre los valores de la variable.&lt;/em>&lt;/p>
&lt;h2 id="representaciones-gráficas">Representaciones gráficas&lt;/h2>
&lt;p>La tabla de frecuencias también suele representarse gráficamente. Dependiendo del tipo de variable y de si se han agrupado o no los datos, se utilizan distintos tipos de gráficos:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Diagrama de barras&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Histograma&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Diagrama de líneas o polígonos.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Diagrama de sectores.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h3 id="diagrama-de-barras">Diagrama de barras&lt;/h3>
&lt;p>Un &lt;strong>diagrama de barras&lt;/strong> consiste en un conjunto de barras, una para cada valor o categoría de la variable, dibujadas sobre unos ejes cartesianos.&lt;/p>
&lt;p>Habitualmente los valores o categorías de la variable se representan en eje $X$, y las frecuencias en el eje $Y$.
Para cada valor o categoría se dibuja una barra con la altura correspondiente a su frecuencia. La anchura de la barra no es importante pero las barras deben aparecer claramente separadas unas de otras.&lt;/p>
&lt;p>Dependiendo del tipo de frecuencia representada en el eje $Y$ se tienen diferentes tipos de diagramas de barras.&lt;/p>
&lt;p>En ocasiones se dibuja un polígono, conocido como &lt;strong>polígono de frecuencias&lt;/strong>, uniendo mediante segmentos los puntos más altos de cada barra.&lt;/p>
&lt;p>&lt;strong>Ejemplo&lt;/strong>. El diagrama de barras que aparece a continuación muestra la distribución de frecuencias absolutas del número de hijos en la muestra anterior.&lt;/p>
&lt;div id="absolute-barchart" class="plotly" style="margin: 25px auto; width:80%">
&lt;/div>
&lt;script type="application/json" data-for="absolute-barchart">
{"x":{"data":[{"type":"bar","inherit":true,"x":[0,1,2,3,4],"y":[2,6,14,2,1], "marker":{"color":"rgba(137,211,243,1)"}}],"layout":{"title":"Distribución de frecuencias absolutas del número de hijos","xaxis":{"title":"Número de hijos"},"yaxis":{"title":"Frecuencia Absoluta"},"autosize":false, "width":600, "height":400, "bargap":0.5, "margin":{"b":40,"l":60,"t":25,"r":10}},"filename":"Distribución de frecuencias absolutas del número de hijos"},"evals":[]}
&lt;/script>
&lt;p>El diagrama de barras que aparece a continuación muestra la distribución de frecuencias relativas del número de hijos en la muestra anterior junto al polígono de frecuencias.&lt;/p>
&lt;div id="relative-barchart" class="plotly" style="margin: 25px auto; width:80%">
&lt;/div>
&lt;script type="application/json" data-for="relative-barchart">
{"x":{"data":[{"type":"bar","inherit":true,"x":[0,1,2,3,4],"y":[0.08,0.24,0.56,0.08,0.04],"name":"barra", "marker":{"color":"rgba(137,211,243,1)"}},{"type":"scatter","inherit":true,"x":[0,1,2,3,4],"y":[0.08,0.24,0.56,0.08,0.04],"name":"polígono", "marker":{"color":"rgba(238,50,36,1)"}}],"layout":{"title":"Distribución de frecuencias relativas del número de hijos","xaxis":{"title":"Número de hijos"},"yaxis":{"title":"Frecuencia Relativa"},"autosize":false,"width":600,"height":400,"bargap":0.5,"showlegend":false,"margin":{"b":40,"l":60,"t":25,"r":10}}, "filename":"Distribución de frecuencias relativas del número de hijos"},"evals":[]}
&lt;/script>
&lt;p>El diagrama de barras que aparece a continuación muestra la distribución de frecuencias absolutas acumuladas del número de hijos en la muestra anterior.&lt;/p>
&lt;div id="cumulative-absolute-barchart" class="plotly" style="margin: 25px auto; width:80%">
&lt;/div>
&lt;script type="application/json" data-for="cumulative-absolute-barchart">
{"x":{"data":[{"type":"bar","inherit":true,"x":[0,1,2,3,4],"y":[2,8,22,24,25], "marker":{"color":"rgba(137,211,243,1)"}}],"layout":{"title":"Distribución de frecuencias absolutas acumuladas del número de hijos","xaxis":{"title":"Número de hijos"},"yaxis":{"title":"Frecuencia Absoluta Acumulada"},"autosize":false, "width":600, "height":400,"barsgap":0.5,"bargap":0.5,"margin":{"b":40,"l":60,"t":25,"r":10}},"filename":"Distribución de frecuencias absolutas acumuladas del número de hijos"},"evals":[]}
&lt;/script>
&lt;p>Y el diagrama de barras que aparece a continuación muestra la distribución de frecuencias relativas acumuladas del número de hijos en la muestra anterior junto al polígono de frecuencias.&lt;/p>
&lt;div id="cumulative-relative-barchart" class="plotly" style="margin: 25px auto; width:80%">
&lt;/div>
&lt;script type="application/json" data-for="cumulative-relative-barchart">
{"x":{"data":[{"type":"bar","inherit":true,"x":[0,0,1,2,3,4],"y":[0,0.08,0.32,0.88,0.96,1],"name":"barra", "marker":{"color":"rgba(137,211,243,1)"}},{"type":"scatter","inherit":true,"x":[0,0,1,2,3,4],"y":[0,0.08,0.32,0.88,0.96,1],"name":"polígono","line":{"shape":"hv"}, "marker":{"color":"rgba(238,50,36,1)"}}],"layout":{"title":"Distribución de frecuencias relativas acumuladas del número de hijos","xaxis":{"title":"Número de hijos"},"yaxis":{"title":"Frecuencia Relativa Acumulada"},"autosize":false,"width":600,"height":400,"bargap":0.5,"showlegend":false,"margin":{"b":40,"l":60,"t":25,"r":10}}, "filename":"Distribución de frecuencias relativas acumuladas del número de hijos"},"evals":[]}
&lt;/script>
&lt;h3 id="histograma">Histograma&lt;/h3>
&lt;p>Un &lt;em>histograma&lt;/em> es similar a un diagrama de barras pero para datos agrupados.&lt;/p>
&lt;p>Habitualmente las clases o intervalos de agrupación se representan en el
eje $X$, y las frecuencias en el eje $Y$.
Para cada clase se dibuja una barra de altura la correspondiente
frecuencia. A diferencia del diagrama de barras, la anchura del la barra
coincide con la anchura de las clases y no hay separación entre dos
barras consecutivas.&lt;/p>
&lt;img src="../img/descriptiva/histogram_creation.gif" alt="Sample classification" width="400">
&lt;p>Dependiendo del tipo de frecuencia representada en el eje $Y$ existen
distintos tipos de histogramas.&lt;/p>
&lt;p>Al igual que con el diagrama de barras, se puede dibujar un &lt;em>polígono de frecuencias&lt;/em> uniendo los puntos centrales más altos de cada barra con segmentos.&lt;/p>
&lt;p>&lt;strong>Ejemplo&lt;/strong>. El siguiente histograma muestra la distribución de frecuencias absolutas de las estaturas.&lt;/p>
&lt;div id="absolute-histogram" class="plotly" style="margin: auto; width:80%">&lt;/div>
&lt;script type="application/json" data-for="absolute-histogram">{"x":{"data":[{"type":"histogram","inherit":true,"x":[179,173,181,169,158,174,172,166,194,185,162,187,198,177,178,165,154,188,166,171,175,182,167,169,172,186,172,176,168,187],"marker":{"line":{"width":1},"color":"rgba(137,211,243,1)"}}],"layout":{"title":"Distribución de frecuencias absolutas de estaturas","xaxis":{"title":"Estatura"},"yaxis":{"title":"Frecuencia absoluta"},"autosize":false,"width":600,"height":400,"margin":{"b":40,"l":60,"t":25,"r":10}},"url":null,"width":null,"height":null,"base_url":"https://plot.ly","layout.1":{"title":"Distribución de frecuencias absolutas de estaturas","xaxis":{"title":"Estatura"},"yaxis":{"title":"Frecuencia absoluta"},"autosize":false,"width":600,"height":400},"filename":"Distribución de frecuencias absolutas de estaturas"},"evals":[]}&lt;/script>
&lt;p>El siguiente histograma muestra la distribución de frecuencias relativas con el polígono de frecuencias.&lt;/p>
&lt;div id="relative-histogram" class="plotly" style="margin: auto; width:80%">&lt;/div>
&lt;script type="application/json" data-for="relative-histogram">{"x":{"data":[{"type":"histogram","inherit":true,"x":[179,173,181,169,158,174,172,166,194,185,162,187,198,177,178,165,154,188,166,171,175,182,167,169,172,186,172,176,168,187],"marker":{"line":{"width":1},"color":"rgba(137,211,243,1)"},"histnorm":"probability","name":"bar"},{"type":"scatter","inherit":true,"x":[155,165,175,185,195],"marker":{"line":{"width":1},"color":"rgba(238,50,36,1)"},"histnorm":"probability","name":"polygon","y":[0.0667,0.2667,0.3667,0.2333,0.0667]}],"layout":{"title":"Distribución de frequencias relativas de estaturas","xaxis":{"title":"Estatura"},"yaxis":{"title":"Frecuencia relativa"},"autosize":false,"width":600,"height":400,"showlegend":false,"margin":{"b":40,"l":60,"t":25,"r":10}},"url":null,"width":null,"height":null,"base_url":"https://plot.ly","layout.1":{"title":"Distribución de frequencias relativas de estaturas","xaxis":{"title":"Estatura"},"yaxis":{"title":"Frecuencia relativa"},"autosize":false,"width":600,"height":400,"showlegend":false},"filename":"Distribución de frequencias relativas de estaturas"},"evals":[]}&lt;/script>
&lt;p>El polígono de frecuencias acumuladas (absolutas o relativas) se conoce como &lt;strong>ojiva&lt;/strong>.&lt;/p>
&lt;p>&lt;strong>Example&lt;/strong>. El histograma y la ojiva siguientes muestran la distribución de frecuencias relativas acumuladas de estaturas.&lt;/p>
&lt;div id="ogive" class="plotly" style="margin: auto; width:80%">&lt;/div>
&lt;script type="application/json" data-for="ogive">{"x":{"data":[{"type":"bar","inherit":true,"x":[155,165,175,185,195],"y":[0.0666666666666667,0.333333333333333,0.7,0.933333333333333,1],"marker":{"line":{"width":1},"color":"rgba(137,211,243,1)"},"name":"bar"},{"type":"scatter","inherit":true,"x":[150,160,170,180,190,200],"y":[0,0.0666666666666667,0.333333333333333,0.7,0.933333333333333,1],"marker":{"line":{"width":1},"color":"rgba(238,50,36,1)"},"name":"ogive"}],"layout":{"title":"Distribución de frecuencias relativas acumuladas de estaturas","xaxis":{"title":"Estatura"},"yaxis":{"title":"Frecuencia relativa acumulada"},"autosize":false,"width":600,"height":400,"bargap":0,"showlegend":false,"margin":{"b":40,"l":60,"t":25,"r":10}},"url":null,"width":null,"height":null,"base_url":"https://plot.ly","layout.1":{"title":"Distribución de frecuencias relativas acumuladas de estaturas","xaxis":{"title":"Estatura"},"yaxis":{"title":"Frecuencia relativa acumulada"},"autosize":false,"width":600,"height":400,"bargap":0,"showlegend":false},"filename":"Distribución de frecuencias relativas acumuladas de estaturas"},"evals":[]}&lt;/script>
&lt;p>Obsérvese que en la ojiva se unen los vértices superiores derechos de cada barra con segmentos, en lugar de los puntos centrales, ya que no se consigue alcanzar la frecuencia acumulada correspondiente a la clase hasta que no se alcanza el final del intervalo.&lt;/p>
&lt;h3 id="diagrama-de-sectores">Diagrama de sectores&lt;/h3>
&lt;p>Un &lt;em>diagrama de sectores&lt;/em> consiste en un círculo divido en porciones, uno por cada valor o categoría de la variable.
Cada porción se conoce como &lt;em>sector&lt;/em> y su ángulo o área es proporcional a la correspondiente frecuencia del valor o categoría.&lt;/p>
&lt;p>Los diagramas de sectores pueden representar frecuencias absolutas o relativas, pero no pueden representar frecuencias acumuladas, y se utilizan sobre todo con atributos nominales.
Para atributos ordinales o variables cuantitativas es mejor utilizar diagramas de barras, ya es más fácil percibir las diferencias en una dimensión (altura de las barras) que en dos dimensiones (áreas de los sectores).&lt;/p>
&lt;p>&lt;strong>Example&lt;/strong>. El diagrama de sectores siguiente muestra la distribución de frecuencias relativas de los grupos sanguíneos.&lt;/p>
&lt;div id="piechart" class="plotly" style="margin: auto; width:80%">&lt;/div>
&lt;script type="application/json" data-for="piechart">{"x":{"data":[{"type":"pie","inherit":true,"labels":["0","A","AB","B"],"values":[5,14,3,8]}],"layout":{"title":"Distribución de frecuencias relativas de los grupos sanguíneos","autosize":false,"width":600,"height":400,"margin":{"b":40,"l":60,"t":25,"r":10}},"url":null,"width":null,"height":null,"base_url":"https://plot.ly","layout.1":{"title":"Distribución de frecuencias relativas de los grupos sanguíneos","autosize":false,"width":600,"height":400},"filename":"Distribución de frecuencias relativas de los grupos sanguíneos"},"evals":[]}&lt;/script>
&lt;h3 id="la-distribución-normal">La distribución Normal&lt;/h3>
&lt;p>Las distribuciones con diferentes propiedades presentan formas distintas.&lt;/p>
&lt;!-- TODO: Insertar histogramas con diferentes formas -->
&lt;h2 id="datos-atípicos">Datos atípicos&lt;/h2>
&lt;p>Uno de los principales problemas de las muestras son los &lt;strong>datos atípicos&lt;/strong>, que son valores de la variable que se diferencian mucho del resto de los valores en la muestra.&lt;/p>
&lt;img src="../img/descriptiva/dato_atipico.png" alt="Dato atípico" width="400">
&lt;p>Es muy importante detectar los datos atípicos antes de realizar cualquier análisis de los datos, pues suelen distorsionar los resultados.&lt;/p>
&lt;p>Aparecen siempre en los extremos de la distribución, y pueden detectarse con un diagrama de caja y bigotes (tal y como veremos más adelante).&lt;/p>
&lt;h3 id="tratamiento-de-los-datos-atípicos">Tratamiento de los datos atípicos&lt;/h3>
&lt;p>Cuando trabajemos con muestras grandes, los datos atípicos tienen menor influencia y pueden dejarse en la muestra.&lt;/p>
&lt;p>Cuando trabajemos con muestras pequeñas tenemos varias opciones:&lt;/p>
&lt;ul>
&lt;li>Eliminar el dato atípico si se trata de un error.&lt;/li>
&lt;li>Sustituir el dato atípico por el menor o el mayor valor de la distribución que no es atípico si no se trata de un error y el dato atípico no concuerda con la distribución teórica.&lt;/li>
&lt;li>Dejar el dato atípico si no es un error, y cambiar el modelo de distribución teórico para adecuarlo a los datos atípicos.&lt;/li>
&lt;/ul>
&lt;h2 id="estadísticos-muestrales">Estadísticos muestrales&lt;/h2>
&lt;p>La tabla de frecuencias sintetiza la información de la distribución de valores de la variable estudiada en la muestra, pero en muchas ocasiones es insuficiente para describir determinados aspectos de la distribución, como por ejemplo, cuáles son los valores más representativos de la muestra, cómo es la variabilidad de los datos, qué datos pueden considerarse atípicos, o cómo es la simetría de la distribución.&lt;/p>
&lt;p>Para describir esos aspectos de la distribución muestral se utilizan unas medidas resumen llamadas &lt;strong>estadísticos muestrales&lt;/strong>.&lt;/p>
&lt;p>De acuerdo al aspecto de las distribución que miden, existen diferentes tipos de estadísticos:&lt;/p>
&lt;p>&lt;strong>Estadísticos de Posición&lt;/strong>: Miden los valores en torno a los que se agrupan los datos o que dividen la distribución en partes iguales.&lt;/p>
&lt;p>&lt;strong>Estadísticos de Dispersión&lt;/strong>: Miden la heterogeneidad de los datos.&lt;/p>
&lt;p>&lt;strong>Estadísticos de Forma&lt;/strong>: Miden aspectos de la forma que tiene la distribución de los datos, como la simetría o el apuntamiento.&lt;/p>
&lt;h2 id="estadísticos-de-posición">Estadísticos de posición&lt;/h2>
&lt;p>Pueden ser de dos tipos:&lt;/p>
&lt;p>&lt;strong>Estadísticos de Tendencia Central&lt;/strong>: Determinan valores alrededor de los cuales se concentran los datos, habitualmente en el centro de la distribución. Estas medidas suelen utilizarse como valores representativos de la muestra. Las más importantes son:&lt;/p>
&lt;ul>
&lt;li>Media aritmética&lt;/li>
&lt;li>Mediana&lt;/li>
&lt;li>Moda&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Estadísticos de Posición no centrales&lt;/strong>: Dividen la distribución en partes con el mismo número de datos. Las más importantes son:&lt;/p>
&lt;ul>
&lt;li>Cuartiles.&lt;/li>
&lt;li>Deciles.&lt;/li>
&lt;li>Percentiles.&lt;/li>
&lt;/ul>
&lt;h3 id="media-aritmética">Media aritmética&lt;/h3>
&lt;div class="alert alert-def">
&lt;div>
&lt;p>&lt;strong>Definición - Media aritmética muestral $\bar{x}$&lt;/strong>. La &lt;em>media aritmética muestral&lt;/em> de una variable $X$ es la suma de los valores observados en la muestra dividida por el tamaño muestral&lt;/p>
&lt;p>$$\bar{x} = \frac{\sum x_i}{n}$$&lt;/p>
&lt;/div>
&lt;/div>
&lt;p>A partir de la tabla de frecuencias puede calcularse con la fórmula&lt;/p>
&lt;p>$$\bar{x} = \frac{\sum x_in_i}{n} = \sum x_i f_i$$&lt;/p>
&lt;p>En la mayoría de los casos, la media aritmética es la medida que mejor representa a la muestra.&lt;/p>
&lt;div class="alert alert-warning">
&lt;div>
No puede calcularse para variables cualitativas.
&lt;/div>
&lt;/div>
&lt;p>&lt;strong>Ejemplo - Datos no agrupados&lt;/strong>. Utilizando los datos de la muestra del número de hijos en las familias, la media aritmética es&lt;/p>
&lt;p>$$
\begin{aligned}
\bar{x} &amp;amp;= \frac{1+2+4+2+2+2+3+2+1+1+0+2+2}{25}+\newline
&amp;amp;+\frac{0+2+2+1+2+2+3+1+2+2+1+2}{25} = \frac{44}{25} = 1.76 \mbox{ hijos}.
\end{aligned}
$$&lt;/p>
&lt;p>o bien, desde la tabla de frecuencias&lt;/p>
&lt;p>$$
\begin{array}{rrrrr}
\hline
x_i &amp;amp; n_i &amp;amp; f_i &amp;amp; x_in_i &amp;amp; x_if_i\newline
\hline
0 &amp;amp; 2 &amp;amp; 0.08 &amp;amp; 0 &amp;amp; 0\newline
1 &amp;amp; 6 &amp;amp; 0.24 &amp;amp; 6 &amp;amp; 0.24\newline
2 &amp;amp; 14 &amp;amp; 0.56 &amp;amp; 28 &amp;amp; 1.12\newline
3 &amp;amp; 2 &amp;amp; 0.08 &amp;amp; 6 &amp;amp; 0.24\newline
4 &amp;amp; 1 &amp;amp; 0.04 &amp;amp; 4 &amp;amp; 0.16 \newline
\hline
\sum &amp;amp; 25 &amp;amp; 1 &amp;amp; 44 &amp;amp; 1.76 \newline
\hline
\end{array}
$$&lt;/p>
&lt;p>$$
\bar{x} = \frac{\sum x_in_i}{n} = \frac{44}{25}= 1.76 \mbox{ hijos}\qquad \bar{x}=\sum{x_if_i} = 1.76 \mbox{ hijos}.
$$&lt;/p>
&lt;p>Esto significa que el valor que mejor representa el número de hijos en las familias de la muestra es 1.76 hijos.&lt;/p>
&lt;p>&lt;strong>Ejemplo - Datos agrupados&lt;/strong>. Utilizando los datos de la muestra de estaturas, la media es&lt;/p>
&lt;p>$$
\bar{x} = \frac{179+173+\cdots+187}{30} = 175.07 \mbox{ cm}.
$$&lt;/p>
&lt;p>o bien, desde la tabla de frecuencias utilizando las marcas de clase $x_i$:&lt;/p>
&lt;p>$$
\begin{array}{crrrrr}
\hline
X &amp;amp; x_i &amp;amp; n_i &amp;amp; f_i &amp;amp; x_in_i &amp;amp; x_if_i\newline
\hline
(150,160] &amp;amp; 155 &amp;amp; 2 &amp;amp; 0.07 &amp;amp; 310 &amp;amp; 10.33\newline
(160,170] &amp;amp; 165 &amp;amp; 8 &amp;amp; 0.27 &amp;amp; 1320 &amp;amp; 44.00\newline
(170,180] &amp;amp; 175 &amp;amp; 11 &amp;amp; 0.36 &amp;amp; 1925 &amp;amp; 64.17\newline
(180,190] &amp;amp; 185 &amp;amp; 7 &amp;amp; 0.23 &amp;amp; 1295 &amp;amp; 43.17\newline
(190,200] &amp;amp; 195 &amp;amp; 2 &amp;amp; 0.07 &amp;amp; 390 &amp;amp; 13 \newline
\hline
\sum &amp;amp; &amp;amp; 30 &amp;amp; 1 &amp;amp; 5240 &amp;amp; 174.67 \newline
\hline
\end{array}
$$&lt;/p>
&lt;p>$$
\bar{x} = \frac{\sum x_in_i}{n} = \frac{5240}{30}= 174.67 \mbox{ cm} \qquad \bar{x}=\sum{x_if_i} = 174.67 \mbox{ cm}.
$$&lt;/p>
&lt;p>Obsérvese que al calcular la media desde la tabla de frecuencias el resultado difiere ligeramente del valor real obtenido directamente desde la muestra, ya que los valores usados en los cálculos no son los datos reales sino las marcas de clase.&lt;/p>
&lt;h4 id="media-ponderada">Media ponderada&lt;/h4>
&lt;p>En algunos casos, los valores de la muestra no tienen la misma importancia. En este caso la importancia o &lt;em>peso&lt;/em> de cada valor de la muestra debe tenerse en cuenta al calcular la media.&lt;/p>
&lt;div class="alert alert-def">
&lt;div>
&lt;p>&lt;strong>Definición - Media ponderada muestral $\bar x_p$&lt;/strong>. Dada una muestra de valores $x_1,\ldots, x_n$ donde cada valor $x_i$ tiene asociado un peso $p_i$, la &lt;em>media ponderada muestral&lt;/em> de la variable $X$ es la suma de los productos de cada valor observado en la muestra por su peso, dividida por la suma de todos los pesos&lt;/p>
&lt;p>$$\bar{x}_p = \frac{\sum x_ip_i}{\sum p_i}$$&lt;/p>
&lt;/div>
&lt;/div>
&lt;p>A partir de la tabla de frecuencias puede calcularse con la fórmula&lt;/p>
&lt;p>$$\bar{x}_p = \frac{\sum x_ip_in_i}{\sum p_i}$$&lt;/p>
&lt;p>&lt;strong>Ejemplo&lt;/strong>. Supóngase que un estudiante quiere calcular una medida que represente su rendimiento en el curso. La nota obtenida en cada asignatura y sus créditos son&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align:center">Asignatura&lt;/th>
&lt;th style="text-align:center">Créditos&lt;/th>
&lt;th style="text-align:left">Nota&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align:center">Matemáticas&lt;/td>
&lt;td style="text-align:center">6&lt;/td>
&lt;td style="text-align:left">5&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">Economía&lt;/td>
&lt;td style="text-align:center">4&lt;/td>
&lt;td style="text-align:left">3&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">Química&lt;/td>
&lt;td style="text-align:center">8&lt;/td>
&lt;td style="text-align:left">6&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>La media aritmética vale&lt;/p>
&lt;p>$$\bar{x} = \frac{\sum x_i}{n} = \frac{5+3+6}{3}= 4.67 \text{ puntos}.$$&lt;/p>
&lt;p>Sin embargo, esta nota no representa bien el rendimiento académico del alumno ya que no todas las asignaturas tienen la misma importancia ni requieren el mismo esfuerzo para aprobar. Las asignaturas con más créditos requieren más trabajo y deben tener más peso en el cálculo de la media.&lt;/p>
&lt;p>Es más lógico usar la media ponderada como medida del rendimiento del estudiante, tomando como pesos los créditos de cada asignatura&lt;/p>
&lt;p>$$
\bar{x}_p = \frac{\sum x_ip_i}{\sum p_i} = \frac{5\cdot 6+3\cdot 4+6\cdot 8}{6+4+8}= \frac{90}{18} = 5 \text{ puntos}.
$$&lt;/p>
&lt;h3 id="mediana">Mediana&lt;/h3>
&lt;div class="alert alert-def">
&lt;div>
&lt;strong>Definición - Mediana muestral $Me$&lt;/strong>. La &lt;em>mediana muestral&lt;/em> de una variable $X$ es el valor de la variable que está en el medio de la muestra ordenada.
&lt;/div>
&lt;/div>
&lt;p>La mediana divide la distribución de la muestra en dos partes iguales, es decir, hay el mismo número de valores por debajo y por encima de la mediana. Por tanto, tiene frecuencias acumuladas $N_{Me}= n/2$ y $F_{Me}= 0.5$.&lt;/p>
&lt;div class="alert alert-warning">
&lt;div>
No puede calcularse para variables nominales.
&lt;/div>
&lt;/div>
&lt;p>Con datos no agrupados pueden darse varios casos:&lt;/p>
&lt;ul>
&lt;li>Tamaño muestral impar: La mediana es el valor que ocupa la posición $\frac{n+1}{2}$.&lt;/li>
&lt;li>Tamaño muestral par: La mediana es la media de los valores que ocupan las posiciones $\frac{n}{2}$ y $\frac{n}{2}+1$.&lt;/li>
&lt;/ul>
&lt;img src="../img/descriptiva/mediana.svg" alt="Cálculo de la mediana con datos no agrupados" width="700">
&lt;p>&lt;strong>Ejemplo&lt;/strong>. Utilizando los datos del número de hijos de las familias, el tamaño muestral es 25, que es impar, y la mediana es el valor que ocupa la posición $\frac{25+1}{2} = 13$ de la muestra ordenada.&lt;/p>
&lt;p>$$0,0,1,1,1,1,1,1,2,2,2,2,\fbox{2},2,2,2,2,2,2,2,2,2,3,3,4$$&lt;/p>
&lt;p>y la mediana es 2 hijos.&lt;/p>
&lt;p>Si se trabaja con la tabla de frecuencias, la mediana es el valor más pequeño con una frecuencia acumulada mayor o igual a $13$, o con una frecuencia relativa acumulada mayor o igual que $0.5$.&lt;/p>
&lt;p>$$
\begin{array}{rrrrr}
\hline
x_i &amp;amp; n_i &amp;amp; f_i &amp;amp; N_i &amp;amp; F_i\newline
\hline
0 &amp;amp; 2 &amp;amp; 0.08 &amp;amp; 2 &amp;amp; 0.08\newline
1 &amp;amp; 6 &amp;amp; 0.24 &amp;amp; 8 &amp;amp; 0.32\newline
\color{red}2 &amp;amp; 14 &amp;amp; 0.56 &amp;amp; 22 &amp;amp; 0.88\newline
3 &amp;amp; 2 &amp;amp; 0.08 &amp;amp; 24 &amp;amp; 0.96\newline
4 &amp;amp; 1 &amp;amp; 0.04 &amp;amp; 25 &amp;amp; 1 \newline
\hline
\sum &amp;amp; 25 &amp;amp; 1 \newline
\hline
\end{array}
$$&lt;/p>
&lt;h4 id="cálculo-de-la-mediana-con-datos-agrupados">Cálculo de la mediana con datos agrupados&lt;/h4>
&lt;p>Con datos agrupados la mediana se calcula interpolando en el polígono de frecuencias relativas acumuladas para el valor 0.5.&lt;/p>
&lt;img src="../img/descriptiva/interpolacion.svg" alt="Cálculo de la mediana con datos agrupados" width="600">
&lt;p>Ambas expresiones son iguales ya que el ángulo $\alpha$ es el mismo, y resolviendo la ecuación se tiene la siguiente fórmula para calcular la mediana&lt;/p>
&lt;p>$$
Me=l_i+\frac{0.5-F_{i-1}}{F_i-F_{i-1}}(l_i-l_{i-1})=l_i+\frac{0.5-F_{i-1}}{f_i}a_i
$$&lt;/p>
&lt;p>&lt;strong>Ejemplo - Datos agrupados&lt;/strong>. Utilizando los datos de la muestra de las estaturas de estudiantes, la mediana cae en la clase (170,180].&lt;/p>
&lt;img src="../img/descriptiva/interpolacion_ejemplo_1.svg" alt="Ejemplo de cálculo de la mediana con datos agrupados" width="600">
&lt;p>Interpolando en el intervalo (170,180] se tiene&lt;/p>
&lt;img src="../img/descriptiva/interpolacion_ejemplo_2.svg" alt="Ejemplo de cálculo de la mediana con datos agrupados" width="600">
&lt;p>Igualando ambas expresiones y resolviendo la ecuación se obtiene&lt;/p>
&lt;p>$$
Me= 170+\frac{0.5-0.34}{0.7-0.34}(180-170)=170+\frac{0.16}{0.36}10=174.54 \mbox{ cm}.
$$&lt;/p>
&lt;p>Esto significa que la mitad de los estudiantes tienen estaturas menores o iguales que 174.54 cm y la otra mitad mayores o iguales.&lt;/p>
&lt;h3 id="moda">Moda&lt;/h3>
&lt;div class="alert alert-def">
&lt;div>
&lt;strong>Definición - Moda muestral $Mo$&lt;/strong>. La &lt;em>moda muestral&lt;/em> de una variable $X$ es el valor de la variable más frecuente en la muestra.
&lt;/div>
&lt;/div>
&lt;p>Con datos agrupados la &lt;em>clase modal&lt;/em> es la clase con mayor frecuencia en la muestra.&lt;/p>
&lt;p>Puede calcularse para todos los tipos de variables (cuantitativas y cualitativas).&lt;/p>
&lt;p>Las distribuciones pueden tener más de una moda.&lt;/p>
&lt;img src="../img/descriptiva/moda.png" alt="Cálculo de la moda" width="600">
&lt;p>&lt;strong>Ejemplo&lt;/strong>. Utilizando los datos de la muestra del número de hijos en las familias, el valor con mayor frecuencia es 2, y por tanto la moda es $Mo=2$.&lt;/p>
&lt;p>$$
\begin{array}{rr}
\hline
x_i &amp;amp; n_i \newline
\hline
0 &amp;amp; 2 \newline
1 &amp;amp; 6 \newline
\color{red} 2 &amp;amp; 14 \newline
3 &amp;amp; 2 \newline
4 &amp;amp; 1 \newline
\hline
\end{array}
$$&lt;/p>
&lt;p>Utilizando los datos de la muestra de estaturas de estudiantes, la clase con la mayor frecuencia es $(170,180]$, que es la clase modal $Mo=(170,180]$.&lt;/p>
&lt;p>$$
\begin{array}{cr}
\hline
X &amp;amp; n_i \newline
\hline
(150,160] &amp;amp; 2 \newline
(160,170] &amp;amp; 8 \newline
\color{red}{(170,180]} &amp;amp; 11 \newline
(180,190] &amp;amp; 7 \newline
(190,200] &amp;amp; 2 \newline
\hline
\end{array}
$$&lt;/p>
&lt;h3 id="qué-estadístico-de-tendencia-central-usar">¿Qué estadístico de tendencia central usar?&lt;/h3>
&lt;p>En general, siempre que puedan calcularse los estadísticos de tendencia central, es recomendable utilizarlos como valores representativos en el siguiente orden:&lt;/p>
&lt;ol>
&lt;li>
&lt;p>Media. La media utiliza más información que el resto ya que para calcularla se tiene en cuenta la magnitud de los datos.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Mediana. La mediana utiliza menos información que la media, pero más que la moda, ya que para calcularla se tiene en cuenta el orden de los datos.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Moda. La moda es la que menos información utiliza ya que para calcularla sólo se tienen en cuenta las frecuencias absolutas.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>Pero, &lt;em>hay que tener cuidado con los datos atípicos&lt;/em>, ya que la media puede distorsionarse cuando hay datos atípicos. En tal caso es mejor utilizar la mediana como valor más representativo.&lt;/p>
&lt;p>&lt;strong>Ejemplo&lt;/strong>. Si una muestra de número de hijos de 7 familias es&lt;/p>
&lt;div style="text-align:center">
0, 0, 1, 1, 2, 2, 15,
&lt;/div>
&lt;p>entonces, $\bar{x}=3$ hijos y $Me=1$ hijo.&lt;/p>
&lt;p>&lt;em>¿Qué medida representa mejor el número de hijos en la muestra?&lt;/em>&lt;/p>
&lt;h3 id="medidas-de-posición-no-centrales">Medidas de posición no centrales&lt;/h3>
&lt;p>Las medidas de posición no centrales o &lt;em>cuantiles&lt;/em> dividen la distribución en partes iguales.&lt;/p>
&lt;p>Los más utilizados son:&lt;/p>
&lt;p>&lt;strong>Cuartiles&lt;/strong>: Dividen la distribución en 4 partes iguales. Hay 3 cuartiles: $C_1$ (25% acumulado), $C_2$ (50% acumulado), $C_3$ (75% acumulado).&lt;/p>
&lt;p>&lt;strong>Deciles&lt;/strong>: Dividen la distribución en 10 partes iguales. Hay 9 deciles: $D_1$ (10% acumulado),&amp;hellip;, $D_9$ (90% acumulado).&lt;/p>
&lt;p>&lt;strong>Percentiles&lt;/strong>: Dividen la distribución en 100 partes iguales. Hay 99 percentiles: $P_1$ (1% acumulado),&amp;hellip;, $P_{99}$ (99% acumulado).&lt;/p>
&lt;img src="../img/descriptiva/cuantiles.svg" alt="Cuartiles, deciles y percentiles" width="600">
&lt;p>Obsérvese que hay una correspondencia entre los cuartiles, los deciles y los percentiles. Por ejemplo, el primer cuartil coincide con el percentil 25, y el cuarto decil coincide con el percentil 40.&lt;/p>
&lt;p>Los cuantiles se calculan de forma similar a la mediana. La única diferencia es la frecuencia relativa acumulada que corresponde a cada cuantil.&lt;/p>
&lt;img src="../img/descriptiva/cuantiles_calculo.svg" alt="Cálculo de los cuartiles, deciles y percentiles" width="600">
&lt;p>&lt;strong>Ejemplo&lt;/strong>. Utilizando los datos de la muestra del número de hijos de las familias, la frecuencia relativa acumulada era&lt;/p>
&lt;p>$$
\begin{array}{rr}
\hline
x_i &amp;amp; F_i \newline
\hline
0 &amp;amp; 0.08\newline
1 &amp;amp; 0.32\newline
2 &amp;amp; 0.88\newline
3 &amp;amp; 0.96\newline
4 &amp;amp; 1\newline
\hline
\end{array}
$$&lt;/p>
&lt;p>$$
\begin{aligned}
F_{C_1}=0.25 &amp;amp;\Rightarrow Q_1 = 1 \text{ hijos},\newline
F_{C_2}=0.5 &amp;amp;\Rightarrow Q_2 = 2 \text{ hijos},\newline
F_{C_3}=0.75 &amp;amp;\Rightarrow Q_3 = 2 \text{ hijos},\newline
F_{D_4}=0.4 &amp;amp;\Rightarrow D_4 = 2 \text{ hijos},\newline
F_{P_{92}}=0.92 &amp;amp;\Rightarrow P_{92} = 3 \text{ hijos}.
\end{aligned}$$&lt;/p>
&lt;h2 id="estadísticos-de-dispersión">Estadísticos de dispersión&lt;/h2>
&lt;p>La &lt;em>dispersión&lt;/em> se refiere a la heterogeneidad o variabilidad de los datos. Así pues, los estadísticos de dispersión mide la variabilidad global de los datos, o con respecto a una medida de tendencia central.&lt;/p>
&lt;p>Para las variables cuantitativas, las más empleadas son:&lt;/p>
&lt;ul>
&lt;li>Recorrido.&lt;/li>
&lt;li>Rango Intercuartílico.&lt;/li>
&lt;li>Varianza.&lt;/li>
&lt;li>Desviación Típica.&lt;/li>
&lt;li>Coeficiente de Variación.&lt;/li>
&lt;/ul>
&lt;h3 id="recorrido">Recorrido&lt;/h3>
&lt;div class="alert alert-def">
&lt;div>
&lt;p>&lt;strong>Recorrido muestral $Re$&lt;/strong>. El &lt;em>recorrido muestral&lt;/em> de una variable $X$ se define como la diferencia entre el máximo y el mínimo de los valores en la muestra.&lt;/p>
&lt;p>$$Re = \max_{x_i} -\min_{x_i}$$&lt;/p>
&lt;/div>
&lt;/div>
&lt;img src="../img/descriptiva/rango.svg" alt="Rango" width="600">
&lt;p>El recorrido mide la máxima variación que hay entre los datos muestrales. No obstante, es muy sensible a datos atípicos ya que suelen aparecer justo en los extremos de la distribución, por lo que no se suele utilizar mucho.&lt;/p>
&lt;h3 id="rango-intercuartílico">Rango intercuartílico&lt;/h3>
&lt;p>Para evitar el problema de los datos atípicos en el recorrido, se puede utilizar el primer y tercer cuartil en lugar del mínimo y el máximo.&lt;/p>
&lt;div class="alert alert-def">
&lt;div>
&lt;p>&lt;strong>Definición - Rango intercuartílico muestral $RI$&lt;/strong>. El &lt;em>rango intercuartílico muestral&lt;/em> de una variable $X$ se define como la diferencia entre el tercer y el primer cuartil de la muestra.&lt;/p>
&lt;p>$$RI = C_3 -C_1$$&lt;/p>
&lt;/div>
&lt;/div>
&lt;img src="../img/descriptiva/rango_intercuartilico.svg" alt="Rango intercuartílico" width="600">
&lt;p>El rango intercuartílico mide la dispersión del 50% de los datos centrales.&lt;/p>
&lt;h3 id="diagrama-de-caja-y-bigotes">Diagrama de caja y bigotes&lt;/h3>
&lt;p>La dispersión de una variable suele representarse gráficamente mediante un &lt;em>diagrama de caja y bigotes&lt;/em>, que representa cinco estadísticos descriptivos (mínimo, cuartiles y máximo) conocidos como los &lt;em>cinco números&lt;/em>. Consiste en una caja, dibujada desde el primer al tercer cuartil, que representa el rango intercuartílico, y dos segmentos, conocidos como &lt;em>bigotes&lt;/em> inferior y superior. A menudo la caja se divide en dos por la mediana.&lt;/p>
&lt;p>Este diagrama es muy útil y se utiliza para muchos propósitos:&lt;/p>
&lt;ul>
&lt;li>Sirve para medir la dispersión de los datos ya que representa el rango y el rango intercuartílico.&lt;/li>
&lt;li>Sirve para detectar datos atípicos, que son los valores que quedan fuera del intervalo definido por los bigotes.&lt;/li>
&lt;li>Sirve para medir la simetría de la distribución, comparando la longitud de las cajas y de los bigotes por encima y por debajo de la mediana.&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Ejemplo&lt;/strong>. El diagrama siguiente muestra el diagrama de caja y bigotes del peso de una muestra de recién nacidos.&lt;/p>
&lt;img src="../img/descriptiva/diagrama_caja.png" alt="Diagrama de caja y bigotes del peso de recien nacidos" width="600">
&lt;p>Para construir el diagrama de caja y bigotes hay que seguir los siguientes pasos:&lt;/p>
&lt;ol>
&lt;li>
&lt;p>Calcular los cuartiles.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Dibujar una caja de manera que el extremo inferior caiga sobre el primer cuartil y el extremo superior sobre el tercer cuartil.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Dividir la caja con una línea que caiga sobre el segundo cuartil.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Para los bigotes inicialmente se calculan dos valores llamados &lt;em>vallas&lt;/em> $v_1$ y $v_2$. La valla inferior es el primer cuartil menos una vez y media el rango intercuartílico, y la valla superior es el tercer cuartil más una vez y media el rango intercuartílico.&lt;/p>
&lt;p>$$
\begin{aligned}
v_1&amp;amp;=Q_1-1.5,\text{IQR}\newline
v_2&amp;amp;=Q_3+1.5,\text{IQR}
\end{aligned}
$$&lt;/p>
&lt;p>Las vallas definen el intervalo donde los datos se consideran normales. Cualquier valor fuera de ese intervalo se considera un dato atípico.&lt;br>
El bigote superior se dibuja desde el borde inferior de la caja hasta el menor valor de la muestra que es mayor o igual a la valla inferior, y el bigote superior se dibuja desde el borde superior de la caja hasta el mayor valor de la muestra que es menor o igual a la valla superior.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;div class="alert alert-warning">
&lt;div>
Los bigotes no son las vallas.
&lt;/div>
&lt;/div>
&lt;ol start="5">
&lt;li>Finalmente, si en la muestra hay algún dato atípico, se dibuja un punto para cada uno de ellos.&lt;/li>
&lt;/ol>
&lt;p>&lt;strong>Ejemplo&lt;/strong>. El diagrama de caja y bigotes de la muestra del número de hijos de las familias se muestra a continuación.&lt;/p>
&lt;img src="../img/descriptiva/diagrama_caja_hijos.png" alt="Diagrama de caja y bigotes del número de hijos" width="600">
&lt;h4 id="desviaciones-respecto-de-la-media">Desviaciones respecto de la media&lt;/h4>
&lt;p>Otra forma de medir la variabilidad de una variable es estudiar la concentración de los valores en torno a algún estadístico de tendencia central como por ejemplo la media.&lt;/p>
&lt;p>Para ello se suele medir la distancia de cada valor a la media. A ese valor se le llama &lt;strong>desviación de la media&lt;/strong>.&lt;/p>
&lt;img src="../img/descriptiva/desviaciones.svg" alt="Desviaciones de la media" width="400">
&lt;p>Si las desviaciones son grandes la media no será tan representativa como cuando la desviaciones sean pequeñas.&lt;/p>
&lt;p>&lt;strong>Example&lt;/strong>. La siguiente tabla contiene las notas de 3 estudiantes en un curso con las asignaturas $A$, $B$ y $C$.&lt;/p>
&lt;p>$$
\begin{array}{cccc}
\hline
A &amp;amp; B &amp;amp; C &amp;amp; \bar x \newline
0 &amp;amp; 5 &amp;amp; 10 &amp;amp; 5 \newline
4 &amp;amp; 5 &amp;amp; 6 &amp;amp; 5 \newline
5 &amp;amp; 5 &amp;amp; 5 &amp;amp; 5 \newline
\hline
\end{array}
$$&lt;/p>
&lt;p>Todos los estudiantes tienen la misma media, pero, en qué caso la media representa mejor el rendimiento en el curso?&lt;/p>
&lt;h3 id="varianza-y-desviación-típica">Varianza y desviación típica&lt;/h3>
&lt;div class="alert alert-def">
&lt;div>
&lt;p>&lt;strong>Definición - Varianza $s^2$&lt;/strong>. La &lt;em>varianza muestral&lt;/em> de una variable $X$ se define como el promedio del cuadrado de las desviaciones de los valores de la muestra respecto de la media muestral.&lt;/p>
&lt;p>$$s^2 = \frac{\sum (x_i-\bar x)^2n_i}{n} = \sum (x_i-\bar x)^2f_i$$&lt;/p>
&lt;/div>
&lt;/div>
&lt;p>También puede calcularse de manera más sencilla mediante la fórmula&lt;/p>
&lt;p>$$s^2 = \frac{\sum x_i^2n_i}{n} -\bar x^2= \sum x_i^2f_i-\bar x^2$$&lt;/p>
&lt;p>La varianza tiene las unidades de la variable al cuadrado, por lo que para facilitar su interpretación se suele utilizar su raíz cuadrada.&lt;/p>
&lt;div class="alert alert-def">
&lt;div>
&lt;p>&lt;strong>Definición - Desviación típica $s$&lt;/strong>. La &lt;em>desviación típica muestral&lt;/em> de una variable $X$ se define como la raíz cuadrada positiva de su varianza muestral.&lt;/p>
&lt;p>$$s = +\sqrt{s^2}$$&lt;/p>
&lt;/div>
&lt;/div>
&lt;div class="alert alert-int">
&lt;div>
&lt;p>Tanto la varianza como la desviación típica sirven para cuantificar la dispersión de los datos en torno a la media. Cuando la varianza o la desviación típica son pequeñas, los datos de la muestra están concentrados en torno a la media, y la media es una buena medida de representatividad. Por contra, cuando la varianza o la desviación típica son grandes, los datos de la muestra están alejados de la media, y la media ya no representa tan bien.&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align:left">&lt;/th>
&lt;th style="text-align:center">&lt;/th>
&lt;th style="text-align:left">&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align:left">Desviación típica pequeña&lt;/td>
&lt;td style="text-align:center">$\Rightarrow$&lt;/td>
&lt;td style="text-align:left">Media representativa&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">Desviación típica grande&lt;/td>
&lt;td style="text-align:center">$\Rightarrow$&lt;/td>
&lt;td style="text-align:left">Media no representativa&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;/div>
&lt;/div>
&lt;p>&lt;strong>Ejemplo&lt;/strong>. Las siguientes muestras contienen las notas de dos estudiantes en dos asignaturas.&lt;/p>
&lt;img src="../img/descriptiva/interpretacion_desviacion_tipica.svg" alt="Interpretación de la desviación típica" width="400">
&lt;p>&lt;em>¿Qué media es más representativa?&lt;/em>&lt;/p>
&lt;p>&lt;strong>Ejemplo - Datos no agrupados&lt;/strong>. Utilizando los datos de la muestra del número de hijos de las familias, con una media $\bar x=1.76$ hijos, y añadiendo una nueva columna a la tabla de frecuencias con los cuadrados de los valores,&lt;/p>
&lt;p>$$
\begin{array}{rrr}
\hline
x_i &amp;amp; n_i &amp;amp; x_i^2n_i \newline
\hline
0 &amp;amp; 2 &amp;amp; 0 \newline
1 &amp;amp; 6 &amp;amp; 6 \newline
2 &amp;amp; 14 &amp;amp; 56\newline
3 &amp;amp; 2 &amp;amp; 18\newline
4 &amp;amp; 1 &amp;amp; 16 \newline
\hline
\sum &amp;amp; 25 &amp;amp; 96 \newline
\hline
\end{array}$$&lt;/p>
&lt;p>$$s^2 = \frac{\sum x_i^2n_i}{n}-\bar x^2 = \frac{96}{25}-1.76^2= 0.7424 \mbox{ hijos}^2.$$&lt;/p>
&lt;p>y la desviación típica es $s=\sqrt{0.7424} = 0.8616$ hijos.&lt;/p>
&lt;p>Comparado este valor con el recorrido, que va de 0 a 4 hijos se observa que no es demasiado grande por lo que se puede concluir que no hay mucha dispersión y en consecuencia la media de $1.76$ hijos representa bien el número de hijos de las familias de la muestra.&lt;/p>
&lt;p>&lt;strong>Ejemplo - Datos agrupados&lt;/strong>. Utilizando los datos de la muestra de estaturas de los estudiantes y agrupando las estaturas en clases, se obtenía una media $\bar x = 174.67$ cm. El cálculo de la varianza se realiza igual que antes pero tomando como valores de la variable las marcas de clase.&lt;/p>
&lt;p>$$
\begin{array}{crrr}
\hline
X &amp;amp; x_i &amp;amp; n_i &amp;amp; x_i^2n_i \newline
\hline
(150,160] &amp;amp; 155 &amp;amp; 2 &amp;amp; 48050\newline
(160,170] &amp;amp; 165 &amp;amp; 8 &amp;amp; 217800\newline
(170,180] &amp;amp; 175 &amp;amp; 11 &amp;amp; 336875\newline
(180,190] &amp;amp; 185 &amp;amp; 7 &amp;amp; 239575\newline
(190,200] &amp;amp; 195 &amp;amp; 2 &amp;amp; 76050\newline
\hline
\sum &amp;amp; &amp;amp; 30 &amp;amp; 918350 \newline
\hline
\end{array}
$$&lt;/p>
&lt;p>$$s^2 = \frac{\sum x_i^2n_i}{n}-\bar x^2 = \frac{918350}{30}-174.67^2= 102.06 \mbox{ cm}^2,$$&lt;/p>
&lt;p>y la desviación típica es $s=\sqrt{102.06} = 10.1$ cm.&lt;/p>
&lt;p>Este valor es bastante pequeño, comparado con el recorrido de la variable, que va de 150 a 200 cm, por lo que la variable tiene poca dispersión y en consecuencia su media es muy representativa.&lt;/p>
&lt;h3 id="coeficiente-de-variación">Coeficiente de variación&lt;/h3>
&lt;p>Tanto la varianza como la desviación típica tienen unidades y eso dificulta a veces su interpretación, especialmente cuando se compara la dispersión de variables con diferentes unidades.&lt;/p>
&lt;p>Por este motivo, es también común utilizar la siguiente medida de dispersión que no tiene unidades.&lt;/p>
&lt;div class="alert alert-def">
&lt;div>
&lt;p>&lt;strong>Definición - Coeficiente de variación muestral $cv$&lt;/strong>. El &lt;em>coeficiente de variación muestral&lt;/em> de una variable $X$ se define como el cociente entre su desviación típica muestral y el valor absoluto de su media muestral.&lt;/p>
&lt;p>$$cv = \frac{s}{|\bar x|}$$&lt;/p>
&lt;/div>
&lt;/div>
&lt;div class="alert alert-int">
&lt;div>
&lt;p>El coeficiente de variación muestral mide la dispersión relativa de los valores de la muestra en torno a la media muestral.&lt;/p>
&lt;p>Como no tiene unidades, es muy sencillo de interpretar: Cuanto mayor sea, mayor será la dispersión relativa con respecto a la media y menos representativa será la media.&lt;/p>
&lt;/div>
&lt;/div>
&lt;p>El coeficiente de variación es muy útil para comparar la dispersión de distribuciones de variables diferentes, incluso si las variables tienen unidades diferentes.&lt;/p>
&lt;p>&lt;strong>Ejemplo&lt;/strong>. En la muestra del número de hijos, donde la media era $\bar x=1.76$ hijos y la desviación típica $s=0.8616$ hijos, el coeficiente de variación vale&lt;/p>
&lt;p>$$cv = \frac{s}{|\bar x|} = \frac{0.8616}{|1.76|} = 0.49.$$&lt;/p>
&lt;p>En la muestra de las estaturas, donde la media era $\bar x=174.67$ cm y la desviación típica $s=10.1$ cm, el coeficiente de variación vale&lt;/p>
&lt;p>$$cv = \frac{s}{|\bar x|} = \frac{10.1}{|174.67|} = 0.06.$$&lt;/p>
&lt;p>Esto significa que la dispersión relativa en la muestra de estaturas es mucho menor que en la del número de hijos, por lo que la media de las estaturas será más representativa que la media del número de hijos.&lt;/p>
&lt;h2 id="estadísticos-de-forma">Estadísticos de forma&lt;/h2>
&lt;p>Son medidas que describen la forma de la distribución.&lt;/p>
&lt;p>Los aspectos más relevantes son:&lt;/p>
&lt;p>&lt;strong>Simetría&lt;/strong> Mide la simetría de la distribución de frecuencias en torno a la media. El estadístico más utilizado es el &lt;em>Coeficiente de Asimetría de Fisher&lt;/em>.&lt;/p>
&lt;p>&lt;strong>Apuntamiento&lt;/strong> Mide el apuntamiento o el grado de concentración de valores en torno a la media de la distribución de frecuencias. El estadístico más utilizado es el &lt;em>Coeficiente de Apuntamiento o Curtosis&lt;/em>.&lt;/p>
&lt;h3 id="coeficiente-de-asimetría">Coeficiente de asimetría&lt;/h3>
&lt;div class="alert alert-def">
&lt;div>
&lt;p>&lt;strong>Definición - Coeficiente de asimetría muestral $g_1$&lt;/strong>. El &lt;em>coeficiente de asimetría muestral&lt;/em> de una variable $X$ es el promedio de las desviaciones de los valores de la muestra respecto de la media muestral, elevadas al cubo, dividido por la desviación típica al cubo.&lt;/p>
&lt;p>$$g_1 = \frac{\sum (x_i-\bar x)^3 n_i/n}{s^3} = \frac{\sum (x_i-\bar x)^3 f_i}{s^3}$$&lt;/p>
&lt;/div>
&lt;/div>
&lt;div class="alert alert-int">
&lt;div>
&lt;p>Mide el grado de simetría de los valores de la muestra con respecto a la media muestra, es decir, cuantos valores de la muestra están por encima o por debajo de la media y cómo de alejados de esta.&lt;/p>
&lt;ul>
&lt;li>$g_1=0$ indica que hay el mismo número de valores por encima y por debajo de la media e igualmente alejados de ella (simétrica).&lt;/li>
&lt;/ul>
&lt;img src="../img/descriptiva/distribucion_simetrica.svg" alt="Distribución simétrica" width="600">
&lt;ul>
&lt;li>$g_1&amp;lt;0$ indica que la mayoría de los valores son mayores que la media, pero los valores menores están más alejados de ella (asimétrica a la izquierda).&lt;/li>
&lt;/ul>
&lt;img src="../img/descriptiva/distribucion_asimetrica_izquierda.svg" alt="Distribución simétrica a la izquierda" width="600">
&lt;ul>
&lt;li>$g_1&amp;gt;0$ indica que la mayoría de los valores son menores que la media, pero los valores mayores están más alejados de ella (asimétrica a la derecha).&lt;/li>
&lt;/ul>
&lt;img src="../img/descriptiva/distribucion_asimetrica_derecha.svg" alt="Distribución simétrica a la derecha" width="600">
&lt;/div>
&lt;/div>
&lt;p>&lt;strong>Ejemplo - Datos agrupados&lt;/strong>. Utilizando la tabla de frecuencias de la muestra de estaturas y añadiendo una nueva columna con las desviaciones de la media $\bar x = 174.67$ cm al cubo, se tiene&lt;/p>
&lt;p>$$
\begin{array}{crrrr}
\hline
X &amp;amp; x_i &amp;amp; n_i &amp;amp; x_i-\bar x &amp;amp; (x_i-\bar x)^3 n_i \newline
\hline
(150,160] &amp;amp; 155 &amp;amp; 2 &amp;amp; -19.67 &amp;amp; -15221.00\newline
(160,170] &amp;amp; 165 &amp;amp; 8 &amp;amp; -9.67 &amp;amp; -7233.85\newline
(170,180] &amp;amp; 175 &amp;amp; 11 &amp;amp; 0.33 &amp;amp; 0.40\newline
(180,190] &amp;amp; 185 &amp;amp; 7 &amp;amp; 10.33 &amp;amp; 7716.12\newline
(190,200] &amp;amp; 195 &amp;amp; 2 &amp;amp; 20.33 &amp;amp; 16805.14\newline
\hline
\sum &amp;amp; &amp;amp; 30 &amp;amp; &amp;amp; 2066.81 \newline
\hline
\end{array}
$$&lt;/p>
&lt;p>$$g_1 = \frac{\sum (x_i-\bar x)^3n_i/n}{s^3} = \frac{2066.81/30}{10.1^3} = 0.07.$$&lt;/p>
&lt;p>Como está cerca de 0, eso significa que la distribución de las estaturas es casi simétrica.&lt;/p>
&lt;h3 id="coeficiente-de-apuntamiento-o-curtosis">Coeficiente de apuntamiento o curtosis&lt;/h3>
&lt;div class="alert alert-def">
&lt;div>
&lt;p>&lt;strong>Definición - Coeficiente de apuntamiento muestral $g_2$&lt;/strong>. El &lt;em>coeficiente de apuntamiento muestral&lt;/em> de una variable $X$ es el promedio de las desviaciones de
los valores de la muestra respecto de la media muestral, elevadas a la cuarta, dividido por la desviación típica a la
cuarta y al resultado se le resta 3.&lt;/p>
&lt;p>$$g_2 = \frac{\sum (x_i-\bar x)^4 n_i/n}{s^4}-3 = \frac{\sum (x_i-\bar x)^4 f_i}{s^4}-3$$&lt;/p>
&lt;/div>
&lt;/div>
&lt;div class="alert alert-int">
&lt;div>
&lt;p>El coeficiente de apuntamiento mide la concentración de valores en torno a la media y la longitud de las colas de la distribución.
Se toma como referencia la distribución normal (campana de Gauss).&lt;/p>
&lt;ul>
&lt;li>$g_2=0$ indica que la distribución tienen un apuntamiento normal, es decir, la concentración de valores en torno a la media es similar al de una campana de Gauss (&lt;em>mesocúrtica&lt;/em>).&lt;/li>
&lt;/ul>
&lt;img src="../img/descriptiva/distribucion_mesocurtica.svg" alt="Distribución mesocúrtica" width="600">
&lt;ul>
&lt;li>$g_2&amp;lt;0$ indica que la distribución tiene menos apuntamiento de lo normal, es decir, la concentración de valores en torno a la media es menor que en una campana de Gauss (&lt;em>platicúrtica&lt;/em>).&lt;/li>
&lt;/ul>
&lt;img src="../img/descriptiva/distribucion_platicurtica.svg" alt="Distribución platicúrtica" width="600">
&lt;ul>
&lt;li>$g_2&amp;gt;0$ indica que la distribución tiene más apuntamiento de lo normal, es decir, la concentración de valores en torno a la media es menor que en una campana de Gauss (&lt;em>leptocúrtica&lt;/em>).&lt;/li>
&lt;/ul>
&lt;img src="../img/descriptiva/distribucion_leptocurtica.svg" alt="Distribución leptocúrtica" width="600">
&lt;/div>
&lt;/div>
&lt;p>&lt;strong>Ejemplo - Datos agrupados&lt;/strong>. Utilizando la tabla de frecuencias de la muestra de estaturas y añadiendo una nueva columna con las desviaciones de la media $\bar x = 174.67$ cm a la cuarta, se tiene&lt;/p>
&lt;p>$$
\begin{array}{rrrrr}
\hline
X &amp;amp; x_i &amp;amp; n_i &amp;amp; x_i-\bar x &amp;amp; (x_i-\bar x)^4 n_i\newline
\hline
(150,160] &amp;amp; 155 &amp;amp; 2 &amp;amp; -19.67 &amp;amp; 299396.99\newline
(160,170] &amp;amp; 165 &amp;amp; 8 &amp;amp; -9.67 &amp;amp; 69951.31\newline
(170,180] &amp;amp; 175 &amp;amp; 11 &amp;amp; 0.33 &amp;amp; 0.13\newline
(180,190] &amp;amp; 185 &amp;amp; 7 &amp;amp; 10.33 &amp;amp; 79707.53\newline
(190,200] &amp;amp; 195 &amp;amp; 2 &amp;amp; 20.33 &amp;amp; 341648.49\newline
\hline
\sum &amp;amp; &amp;amp; 30 &amp;amp; &amp;amp; 790704.45 \newline
\hline
\end{array}
$$&lt;/p>
&lt;p>$$g_2 = \frac{\sum (x_i-\bar x)^4n_i/n}{s^4} - 3 = \frac{790704.45/30}{10.1^4}-3 = -0.47.$$&lt;/p>
&lt;p>Como se trata de un valor negativo, aunque cercano a 0, podemos decir que la distribución es ligeramente platicúrtica.&lt;/p>
&lt;p>Como se verá más adelante en la parte de inferencia, muchas de las pruebas estadísticas solo pueden aplicarse a poblaciones normales.&lt;/p>
&lt;p>Las poblaciones normales se caracterizan por ser simétricas y mesocúrticas, de manera que, tanto el coeficiente de asimetría como el de apuntamiento pueden utilizarse para contrastar si los datos de la muestra provienen de una población normal.&lt;/p>
&lt;div class="alert alert-int">
&lt;div>
En general, se suele rechazar la hipótesis de normalidad de la población cuando $g_1$ o $g_2$ estén fuera del intervalo $[-2,2]$.
&lt;/div>
&lt;/div>
&lt;p>En tal caso, lo habitual es aplicar alguna transformación a la variable para corregir la anormalidad.&lt;/p>
&lt;h3 id="distribuciones-no-normales">Distribuciones no normales&lt;/h3>
&lt;h4 id="distribución-asimétrica-a-la-derecha-no-normal">Distribución asimétrica a la derecha no normal&lt;/h4>
&lt;p>Un ejemplo de distribución asimétrica a la derecha es el ingreso de las familias.&lt;/p>
&lt;img src="../img/descriptiva/ejemplo_distribucion_asimetrica_derecha.svg" alt="Distribucion de los ingresos familiares de EEUU" width="600">
&lt;h4 id="distribución-asimétrica-a-la-izquierda-no-normal">Distribución asimétrica a la izquierda no normal&lt;/h4>
&lt;p>Un ejemplo de distribución asimétrica a la izquierda es la edad de fallecimiento.&lt;/p>
&lt;img src="../img/descriptiva/ejemplo_distribucion_asimetrica_izquierda.svg" alt="Distribucion de la esperanza de vida" width="600">
&lt;h4 id="distribución-bimodal-no-normal">Distribución bimodal no normal&lt;/h4>
&lt;p>Un ejemplo de distribución bimodal es la hora de llegada de los clientes de un restaurante.&lt;/p>
&lt;img src="../img/descriptiva/ejemplo_distribucion_bimodal.svg" alt="Distribucion de la hora de llegada de los clientes de un restaurante" width="600">
&lt;h2 id="transformaciones-de-variables">Transformaciones de variables&lt;/h2>
&lt;p>En muchas ocasiones se suelen transformar los datos brutos para corregir alguna anormalidad de la distribución o simplemente para trabajar con unas unidades más cómodas.&lt;/p>
&lt;p>Por ejemplo, si estamos trabajando con estaturas medidas en metros y tenemos los siguientes valores:&lt;/p>
&lt;p>$$
1.75 \mbox{ m}, 1.65 \mbox{ m}, 1.80 \mbox{ m},
$$&lt;/p>
&lt;p>podemos evitar los decimales multiplicando por 100, es decir, pasando de metros a centímetros:&lt;/p>
&lt;p>$$
175 \mbox{ cm}, 165 \mbox{ cm}, 180 \mbox{ cm},
$$&lt;/p>
&lt;p>Y si queremos reducir la magnitud de los datos podemos restarles a todos el menor de ellos, en este caso, 165cm:&lt;/p>
&lt;p>$$10\mbox{cm}, 0\mbox{cm}, 15\mbox{cm},$$&lt;/p>
&lt;p>Está claro que este conjunto de datos es mucho más sencillo que el original. En el fondo lo que se ha hecho es aplicar a los datos la transformación:&lt;/p>
&lt;p>$$Y= 100X-165$$&lt;/p>
&lt;h3 id="transformaciones-lineales">Transformaciones lineales&lt;/h3>
&lt;p>Una de las transformaciones más habituales es la &lt;em>transformación lineal&lt;/em>:&lt;/p>
&lt;p>$$Y=a+bX.$$&lt;/p>
&lt;p>Se puede comprobar fácilmente que la media y la desviación típica de la variable resultante cumplen:&lt;/p>
&lt;p>$$
\begin{aligned}
\bar y &amp;amp;= a+ b\bar x,\newline
s_{y} &amp;amp;= |b|s_{x}
\end{aligned}
$$&lt;/p>
&lt;p>Además, el coeficiente de curtosis no se altera y el de asimetría sólo cambia de signo si $b$ es negativo.&lt;/p>
&lt;h3 id="transformación-de-tipificación-y-puntuaciones-típicas">Transformación de tipificación y puntuaciones típicas&lt;/h3>
&lt;p>Una de las transformaciones lineales más habituales es la &lt;em>tipificación&lt;/em>:&lt;/p>
&lt;div class="alert alert-def">
&lt;div>
&lt;p>&lt;strong>Definición - Variable tipificada&lt;/strong>. La &lt;em>variable tipificada&lt;/em> de una variable estadística $X$ es la variable que resulta de restarle su media y dividir por su desviación típica.&lt;/p>
&lt;p>$$Z=\frac{X-\bar x}{s_{x}}$$&lt;/p>
&lt;p>Para cada valor $x_i$ de la muestra, la &lt;em>puntuación típica&lt;/em> es el valor que resulta de aplicarle la transformación de tipificación&lt;/p>
&lt;p>$$z_i=\frac{x_i-\bar x}{s_{x}}.$$&lt;/p>
&lt;/div>
&lt;/div>
&lt;div class="alert alert-int">
&lt;div>
La puntuación típica es el número de desviaciones típicas que un valor está por encima o por debajo de la media, y es útil para evitar la dependencia de una variable respecto de las unidades de medida empleadas. Esto es útil, por ejemplo, para comparar valores de variables o muestras distintas.
&lt;/div>
&lt;/div>
&lt;p>La variable tipificada siempre tiene media 0 y desviación típica 1.&lt;/p>
&lt;p>$$\bar z = 0 \qquad s_{z} = 1$$&lt;/p>
&lt;p>&lt;strong>Ejemplo&lt;/strong>. Las notas de 5 alumnos en dos asignaturas $X$ e $Y$ son&lt;/p>
&lt;p>$$
\begin{array}{rccccccccc}
\mbox{Alumno:} &amp;amp; 1 &amp;amp; 2 &amp;amp; 3 &amp;amp; 4 &amp;amp; 5\newline
\hline
X: &amp;amp; 2 &amp;amp; 5 &amp;amp; 4 &amp;amp; \color{red} 8 &amp;amp; 6 &amp;amp; \qquad &amp;amp; \bar x = 5 &amp;amp; \quad s_x = 2\newline
Y: &amp;amp; 1 &amp;amp; 9 &amp;amp; \color{red} 8 &amp;amp; 5 &amp;amp; 2 &amp;amp; \qquad &amp;amp; \bar y = 5 &amp;amp; \quad s_y = 3.16\newline
\hline
\end{array}
$$&lt;/p>
&lt;p>&lt;em>¿Ha tenido el mismo rendimiento el cuarto alumno en la asignatura $X$ que el tercero en la asignatura $Y$?&lt;/em>&lt;/p>
&lt;p>Podría parecer que ambos alumnos han tenido el mismo rendimiento puesto que tienen la misma nota, pero si queremos ver el rendimiento relativo al resto del grupo, tendríamos que tener en cuenta la dispersión de cada muestra y medir sus puntuaciones típicas:&lt;/p>
&lt;p>$$
\begin{array}{cccccc}
\mbox{Alumno:} &amp;amp; 1 &amp;amp; 2 &amp;amp; 3 &amp;amp; 4 &amp;amp; 5\newline
\hline
X: &amp;amp; -1.50 &amp;amp; 0.00 &amp;amp; -0.50 &amp;amp; \color{red}{1.50} &amp;amp; 0.50 \newline
Y: &amp;amp; -1.26 &amp;amp; 1.26 &amp;amp; \color{red}{0.95} &amp;amp; 0.00 &amp;amp; -0.95\newline
\hline
\end{array}
$$&lt;/p>
&lt;p>Es decir, el alumno que tiene un 8 en $X$ está $1.5$ veces la desviación típica por encima de la media de $X$, mientras que el alumno que tiene un 8 en $Y$ sólo está $0.95$ desviaciones típicas por encima de la media de $Y$. Así pues, el primer alumno tuvo un rendimiento superior al segundo.&lt;/p>
&lt;p>Siguiendo con el ejemplo anterior y considerando ambas asignaturas, &lt;em>¿cuál es el mejor alumno?&lt;/em>&lt;/p>
&lt;p>Si simplemente se suman las puntuaciones de cada asignatura se tiene:&lt;/p>
&lt;p>$$\begin{array}{rccccc}
\mbox{Alumno:} &amp;amp; 1 &amp;amp; 2 &amp;amp; 3 &amp;amp; 4 &amp;amp; 5\newline
\hline
X: &amp;amp; 2 &amp;amp; 5 &amp;amp; 4 &amp;amp; 8 &amp;amp; 6 \newline
Y: &amp;amp; 1 &amp;amp; 9 &amp;amp; 8 &amp;amp; 5 &amp;amp; 2 \newline
\hline
\sum &amp;amp; 3 &amp;amp; \color{red}{14} &amp;amp; 12 &amp;amp; 13 &amp;amp; 8
\end{array}
$$&lt;/p>
&lt;p>El mejor alumno sería el segundo.&lt;/p>
&lt;p>Pero si se considera el rendimiento relativo tomando las puntuaciones típicas se tiene&lt;/p>
&lt;p>$$
\begin{array}{rccccc}
\mbox{Alumno:} &amp;amp; 1 &amp;amp; 2 &amp;amp; 3 &amp;amp; 4 &amp;amp; 5\newline
\hline
X: &amp;amp; -1.50 &amp;amp; 0.00 &amp;amp; -0.50 &amp;amp; 1.50 &amp;amp; 0.50 \newline
Y: &amp;amp; -1.26 &amp;amp; 1.26 &amp;amp; 0.95 &amp;amp; 0.00 &amp;amp; -0.95\newline
\hline
\sum &amp;amp; -2.76 &amp;amp; 1.26 &amp;amp; 0.45 &amp;amp; \color{red}{1.5} &amp;amp; -0.45
\end{array}
$$&lt;/p>
&lt;p>Y el mejor alumno sería el cuarto.&lt;/p>
&lt;h4 id="transformaciones-no-lineales">Transformaciones no lineales&lt;/h4>
&lt;p>Las transformaciones no lineales son también habituales para corregir la anormalidad de las distribuciones.&lt;/p>
&lt;p>La transformación $Y=X^2$ comprime la escala para valores pequeños y la expande para valores altos, de manera que es muy útil para corregir asimetrías hacia la izquierda.&lt;/p>
&lt;img src="../img/descriptiva/transformacion_cuadratica.svg" alt="Transformación cuadrática" width="600">
&lt;p>Las transformaciones $Y=\sqrt x$, $Y= \log X$ y $Y=1/X$ comprimen la escala para valores altos y la expanden para valores pequeños, de manera que son útiles para corregir asimetrías hacia la derecha.&lt;/p>
&lt;img src="../img/descriptiva/transformacion_logaritmica.svg" alt="Trasformación logarítmica" width="600">
&lt;h3 id="variables-clasificadoras-o-factores">Variables clasificadoras o factores&lt;/h3>
&lt;p>En ocasiones interesa describir el comportamiento de una variable, no para toda la muestra, sino para distintos grupos de individuos correspondientes a las categorías de otra variable conocida como &lt;strong>variable clasificadora&lt;/strong> o &lt;strong>factor&lt;/strong>.&lt;/p>
&lt;p>&lt;strong>Ejemplo&lt;/strong>. Dividiendo la muestra de estaturas según el sexo se obtienen dos submuestras:&lt;/p>
&lt;p>$$
\begin{array}{lll}
\hline
\mbox{Mujeres} &amp;amp; &amp;amp; 173, 158, 174, 166, 162, 177, 165, 154, 166, 182, 169, 172, 170, 168. \newline
\mbox{Hombres} &amp;amp; &amp;amp; 179, 181, 172, 194, 185, 187, 198, 178, 188, 171, 175, 167, 186, 172, 176, 187. \newline
\hline
\end{array}
$$&lt;/p>
&lt;h5 id="comparación-de-distribuciones-según-los-niveles-de-un-factor">Comparación de distribuciones según los niveles de un factor&lt;/h5>
&lt;p>Habitualmente los factores se usan para comparar la distribución de la variable principal para cada categoría del factor.&lt;/p>
&lt;p>&lt;strong>Ejemplo&lt;/strong> Los siguientes diagramas permiten comparar la distribución de estaturas según el sexo.&lt;/p>
&lt;img src="../img/descriptiva/histograma_estatura_sexo.svg" alt="Histograma de estaturas por sexo" width="500">
&lt;img src="../img/descriptiva/diagrama_caja_estatura_sexo.svg" alt="Diagrama de cajas de estaturas por sexo" width="500"></description></item><item><title>Tipos de estudios estadísticos</title><link>/docencia/estadistica/tutoriales/tipos-estudios-estadisticos/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/docencia/estadistica/tutoriales/tipos-estudios-estadisticos/</guid><description>&lt;p>El tipo de estudio estadístico más apropiado en cada caso depende de varios factores:&lt;/p>
&lt;ul>
&lt;li>El objetivo del estudio.&lt;/li>
&lt;li>El número de variables que intervienen.&lt;/li>
&lt;li>El tipo de las variables dependientes e independientes.&lt;/li>
&lt;li>La naturaleza de las observaciones (independientes o emparejadas).&lt;/li>
&lt;/ul>
&lt;p>A continuación se presentan los estudios estadísticos más habituales en función de estos factores. La siguiente tabla puede ayudar a identificar el más apropiado en cada caso.&lt;/p>
&lt;table width="1054" cellspacing="0" cellpadding="5" border="1">
&lt;tbody>
&lt;tr>
&lt;td bgcolor="#6d9eeb" width="95">
&lt;p>&lt;strong>Variables independientes&lt;/strong>&lt;/p>
&lt;/td>
&lt;td bgcolor="#6d9eeb" width="88">
&lt;p>&lt;strong>Variable dependiente&lt;/strong>&lt;/p>
&lt;/td>
&lt;td bgcolor="#6d9eeb" width="315">
&lt;p>&lt;strong>Objetivo&lt;/strong>&lt;/p>
&lt;/td>
&lt;td bgcolor="#6d9eeb" width="330">
&lt;p>&lt;strong>Ejemplo&lt;/strong>&lt;/p>
&lt;/td>
&lt;td bgcolor="#6d9eeb" width="174">
&lt;p>&lt;strong>Contraste&lt;/strong>&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td rowspan="6" width="95" height="14">
&lt;p>Ninguna&lt;br /> (Una poblaci&amp;oacute;n)&lt;/p>
&lt;/td>
&lt;td rowspan="2" width="88">
&lt;p>Cuantitativa&lt;/p>
&lt;/td>
&lt;td rowspan="2" width="315">
&lt;p>Contrastar la normalidad de una variable&lt;/p>
&lt;/td>
&lt;td rowspan="2" width="330">
&lt;p>Comprobar si la nota de un examen tiene distribuci&amp;oacute;n normal (forma de campana de Gauss)&lt;/p>
&lt;/td>
&lt;td width="174">
&lt;p>Komogorov-Smirnov&lt;br /> (requiere muestras grandes)&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td width="174">
&lt;p>Shapiro-Willks&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td width="88">
&lt;p>Cuantitativa normal&lt;/p>
&lt;/td>
&lt;td width="315">
&lt;p>Contrastar si la media poblacional de una variable tiene un valor determinado&lt;/p>
&lt;/td>
&lt;td width="330">
&lt;p>Comprobar si la nota media de un examen es 5&lt;/p>
&lt;/td>
&lt;td width="174">
&lt;p>Test T para la media de una poblaci&amp;oacute;n&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td width="88">
&lt;p>Cuantitativa o cualitativa ordinal&lt;/p>
&lt;/td>
&lt;td width="315">
&lt;p>Contrastar si la mediana poblacional de una variable tiene un valor determinado&lt;/p>
&lt;/td>
&lt;td width="330">
&lt;p>Comprobar si la calificaci&amp;oacute;n mediana de un examen es Aprobado&lt;/p>
&lt;/td>
&lt;td width="174">
&lt;p>Test para la mediana de una poblaci&amp;oacute;n&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td width="88">
&lt;p>Cualitativa (2 categor&amp;iacute;as)&lt;/p>
&lt;/td>
&lt;td width="315">
&lt;p>Contrastar si la proporci&amp;oacute;n poblacional de una de las categor&amp;iacute;as tiene un valor determinado&lt;/p>
&lt;/td>
&lt;td width="330">
&lt;p>Comprobar si la proporci&amp;oacute;n de aprobados es de la mitad (o que el porcentaje es 50%)&lt;/p>
&lt;/td>
&lt;td width="174">
&lt;p>Test Binomial&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td width="88">
&lt;p>Cualitativa&lt;/p>
&lt;/td>
&lt;td width="315">
&lt;p>Contrastar si las proporciones de cada una de las categor&amp;iacute;as tienen un valor determinado&lt;/p>
&lt;/td>
&lt;td width="330">
&lt;p>Comprobar si las proporciones de alumnos matriculados en ciencias, letras o mixtas son 0.5, 0.2 y 0.3 respectivamente&lt;/p>
&lt;/td>
&lt;td width="174">
&lt;p>Test Chi-cuadrado de bondad de ajuste&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td rowspan="7" width="95" height="13">
&lt;p>Una cualitativa con dos categor&amp;iacute;as independientes &lt;br /> (Dos poblaciones independientes)&lt;/p>
&lt;/td>
&lt;td rowspan="3" width="88">
&lt;p>Cuantitativa normal&lt;/p>
&lt;/td>
&lt;td width="315">
&lt;p>Contrastar si hay diferencias entre las medias la variable dependiente en dos poblaciones independientes&lt;/p>
&lt;/td>
&lt;td width="330">
&lt;p>Comprobar si el grupo de ma&amp;ntilde;ana y el grupo de tarde han tenido notas medias diferentes&lt;/p>
&lt;/td>
&lt;td width="174">
&lt;p>Test T para la comparaci&amp;oacute;n de medias de poblaciones independientes&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td width="315">
&lt;p>Contrastar si hay diferencias entre las varianzas de la variable dependiente en dos poblaciones independientes&lt;/p>
&lt;/td>
&lt;td width="330">
&lt;p>Comprobar si hay diferencias entre la variabilidad de las notas del grupo de ma&amp;ntilde;ana y el de tarde&lt;/p>
&lt;/td>
&lt;td width="174">
&lt;p>Test F de Fisher&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td width="315">
&lt;p>Contrastar si hay concordancia o acuerdo entre las dos variables&lt;/p>
&lt;/td>
&lt;td width="330">
&lt;p>Comprobar si hay concordancia o acuerdo entre las notas que ponen dos profesores distintos para los mismos ex&amp;aacute;menes&lt;/p>
&lt;/td>
&lt;td width="174">
&lt;p>Correlaci&amp;oacute;n intraclase&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td rowspan="2" width="88">
&lt;p>Cuantitativa o cualitativa ordinal&lt;/p>
&lt;/td>
&lt;td width="315">
&lt;p>Contrastar si hay diferencias entre las distribuciones de la variable dependiente en dos poblaciones independientes&lt;/p>
&lt;/td>
&lt;td width="330">
&lt;p>Comprobar si el grupo de ma&amp;ntilde;ana y el grupo de tarde han tenido calificaciones diferentes&lt;/p>
&lt;/td>
&lt;td width="174">
&lt;p>Test de la U de Mann-Whitney&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td width="315">
&lt;p>Contrastar si hay concordancia o acuerdo entre las dos variables&lt;/p>
&lt;/td>
&lt;td width="330">
&lt;p>Comprobar si hay concordancia o acuerdo entre las calificaciones que ponen dos profesores distintos para los mismos ex&amp;aacute;menes&lt;/p>
&lt;/td>
&lt;td width="174">
&lt;p>Kappa de Cohen&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td rowspan="2" width="88">
&lt;p>Cualitativa&lt;/p>
&lt;/td>
&lt;td width="315">
&lt;p>Contrastar si hay relaci&amp;oacute;n entre las dos variables o bien si hay diferencias entre las proporciones de las categor&amp;iacute;as de la variable dependiente en las dos poblaciones definidas por las categor&amp;iacute;as de la variable independiente&lt;/p>
&lt;/td>
&lt;td width="330">
&lt;p>Comprobar si existe relaci&amp;oacute;n entre los aprobados en una asignatura y el grupo al que pertenecen los alumnos, es decir, si la proporci&amp;oacute;n de aprobados es diferente en dos grupos distintos.&lt;/p>
&lt;/td>
&lt;td width="174">
&lt;p>Test Chi-cuadrado &lt;br /> (si no ha m&amp;aacute;s del 20% de frecuencias esperadas menores que 5)&lt;br /> Test exacto de Fisher&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td width="315">
&lt;p>Contrastar si hay concordancia o acuerdo entre las dos variables&lt;/p>
&lt;/td>
&lt;td width="330">
&lt;p>Comprobar si hay concordancia o acuerdo entre la valoraci&amp;oacute;n (aprobado o suspenso) que hacen dos profesores distintos para los mismos ex&amp;aacute;menes&lt;/p>
&lt;/td>
&lt;td width="174">
&lt;p>Kappa de Cohen&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td rowspan="3" width="95" height="14">
&lt;p>Una cualitativa con dos categor&amp;iacute;as relacionadas o pareadas&lt;br /> (Dos poblaciones relacionadas o pareadas)&lt;/p>
&lt;/td>
&lt;td width="88">
&lt;p>Cuantitativa normal&lt;/p>
&lt;/td>
&lt;td width="315">
&lt;p>Contrastar si hay diferencias entre las medias de la variable dependiente en dos poblaciones relacionadas o pareadas&lt;/p>
&lt;/td>
&lt;td width="330">
&lt;p>Comprobar si las notas medias de dos asignaturas cursadas por los mismos alumnos han sido diferentes o si las notas medias de un examen realizado al comienzo del curso (antes) y otro al final (despu&amp;eacute;s) de una misma asignatura han sido diferentes&lt;/p>
&lt;/td>
&lt;td width="174">
&lt;p>Test T para la comparaci&amp;oacute;n de medias de poblaciones relacionadas o pareadas&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td width="88">
&lt;p>Cuantitativa o cualitativa ordinal&lt;/p>
&lt;/td>
&lt;td width="315">
&lt;p>Contrastar si hay diferencias entre las distribuciones de la variable dependiente en dos poblaciones relacionadas o pareadas&lt;/p>
&lt;/td>
&lt;td width="330">
&lt;p>Comprobar si las calificaciones de dos asignaturas cursadas por los mismos alumnos han sido diferentes&lt;/p>
&lt;/td>
&lt;td width="174">
&lt;p>Test de Wilcoxon&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td width="88">
&lt;p>Cualitativa con dos categor&amp;iacute;as&lt;/p>
&lt;/td>
&lt;td width="315">
&lt;p>Contrastar si hay diferencias entre las proporciones de las categor&amp;iacute;as de la variable dependiente en dos poblaciones relacionadas o pareadas&lt;/p>
&lt;/td>
&lt;td width="330">
&lt;p>Comprobar si la proporci&amp;oacute;n o el porcentaje de aprobados en un examen es distinta al comienzo y al final del curso&lt;/p>
&lt;/td>
&lt;td width="174">
&lt;p>Test de McNemar&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td rowspan="4" width="95" height="14">
&lt;p>Una cualitativa con dos o m&amp;aacute;s categor&amp;iacute;as&lt;/p>
&lt;p>independientes&lt;br /> (Dos o m&amp;aacute;s poblaciones independientes)&lt;/p>
&lt;/td>
&lt;td width="88">
&lt;p>Cuantitativa normal y homogeneidad de varianzas&lt;/p>
&lt;/td>
&lt;td width="315">
&lt;p>Contrastar si hay diferencias entre las medias la variable dependiente en cada una de las poblaciones definidas por las categor&amp;iacute;as de la variable independiente&lt;/p>
&lt;/td>
&lt;td width="330">
&lt;p>Comprobar si existen diferencias entre las notas medias de tres grupos distintos de clase.&lt;/p>
&lt;/td>
&lt;td width="174">
&lt;p>An&amp;aacute;lisis de la Varianza de un factor (ANOVA)&lt;br /> Si hay diferencias &amp;gt; Test de Tukey o Bonferroni para la diferencia por pares&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td width="88">
&lt;p>Cuantitativa normal&lt;/p>
&lt;/td>
&lt;td width="315">
&lt;p>Contrastar si hay diferencias entre las varianzas de la variable dependiente en cada una de las poblaciones definidas por las categor&amp;iacute;as de la variable independiente&lt;/p>
&lt;/td>
&lt;td width="330">
&lt;p>Comprobar si la variabilidad de las notas de una asignatura es distinta en tres grupos diferentes de clase&lt;/p>
&lt;/td>
&lt;td width="174">
&lt;p>Prueba de Levene para la homogeneidad de varianzas&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td width="88">
&lt;p>Cuantitativa o cualitativa ordinal&lt;/p>
&lt;/td>
&lt;td width="315">
&lt;p>Contrastar si hay diferencias entre las distribuciones de la variable dependiente en cada una de las poblaciones definidas por las categor&amp;iacute;as de la variable independiente&lt;/p>
&lt;/td>
&lt;td width="330">
&lt;p>Comprobar si existen diferencias entre las calificaciones de tres grupos distintos de clase&lt;/p>
&lt;/td>
&lt;td width="174">
&lt;p>Test de Kruskal Wallis&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td width="88">
&lt;p>Cualitativa&lt;/p>
&lt;/td>
&lt;td width="315">
&lt;p>Contrastar si hay relaci&amp;oacute;n entre las dos variables o bien si hay diferencias entre las proporciones de las categor&amp;iacute;as de la variable dependiente en cada una de las poblaciones definidas por las categor&amp;iacute;as de la variable independiente&lt;/p>
&lt;/td>
&lt;td width="330">
&lt;p>Comprobar si existe relaci&amp;oacute;n entre los aprobados en una asignatura y el grupo al que pertenecen los alumnos, es decir, si la proporci&amp;oacute;n de aprobados es diferente en los distintos grupos.&lt;/p>
&lt;/td>
&lt;td width="174">
&lt;p>Test Chi-cuadrado &lt;br /> (si no ha m&amp;aacute;s del 20% de frecuencias esperadas menores que 5)&lt;br /> Test exacto de Fisher&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td rowspan="3" width="95" height="14">
&lt;p>Una cualitativa con dos o m&amp;aacute;s categor&amp;iacute;as relacionadas &lt;br /> (medidas repetidas)&lt;/p>
&lt;/td>
&lt;td width="88">
&lt;p>Cuantitativa normal&lt;/p>
&lt;/td>
&lt;td width="315">
&lt;p>Contrastar si hay diferencias entre las medias repetidas de la variable dependiente&lt;/p>
&lt;/td>
&lt;td width="330">
&lt;p>Comprobar si hay diferencias entre las notas que otorgan varios profesores a un mismo examen&lt;/p>
&lt;/td>
&lt;td width="174">
&lt;p>An&amp;aacute;lisis de la Varianza (ANOVA) de medidas repetidas de un factor&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td width="88">
&lt;p>Cuantitativa o cualitativa ordinal&lt;/p>
&lt;/td>
&lt;td width="315">
&lt;p>Contrastar si hay diferencias entre las medidas repetidas de la variable dependiente&lt;/p>
&lt;/td>
&lt;td width="330">
&lt;p>Comprobar si hay diferencias entre las calificaciones que otorgan varios profesores a un mismo examen&lt;/p>
&lt;/td>
&lt;td width="174">
&lt;p>Test de Friedman&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td width="88">
&lt;p>Cualitativa&lt;/p>
&lt;/td>
&lt;td width="315">
&lt;p>Contrastar si hay diferencias entre las valoraciones repetidas de la variable dependiente&lt;/p>
&lt;/td>
&lt;td width="330">
&lt;p>Comprobar si hay diferencias entre la valoraci&amp;oacute;n (aprobado o suspenso) que hacen varios profesores de un mismo examen&lt;/p>
&lt;/td>
&lt;td width="174">
&lt;p>Regresi&amp;oacute;n log&amp;iacute;stica de medidas repetidas&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td rowspan="4" width="95" height="13">
&lt;p>Una cuantitativa normal&lt;/p>
&lt;/td>
&lt;td rowspan="2" width="88">
&lt;p>Cuantitativa normal&lt;/p>
&lt;/td>
&lt;td width="315">
&lt;p>Contrastar si existe relaci&amp;oacute;n lineal entre las dos variables&lt;/p>
&lt;/td>
&lt;td width="330">
&lt;p>Comprobar si existe relaci&amp;oacute;n entre las notas de dos asignaturas&lt;/p>
&lt;/td>
&lt;td width="174">
&lt;p>Correlaci&amp;oacute;n de Pearson&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td width="315">
&lt;p>Construir un modelo predictivo que explique la variable dependiente en funci&amp;oacute;n de la independiente&lt;/p>
&lt;/td>
&lt;td width="330">
&lt;p>Construir el modelo (funci&amp;oacute;n de regresi&amp;oacute;n) que mejor explique la relaci&amp;oacute;n entre la nota de un examen y las horas dedicadas a su estudio&lt;/p>
&lt;/td>
&lt;td width="174">
&lt;p>Regresi&amp;oacute;n simple (lineal o no lineal)&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td width="88">
&lt;p>Cuantitativa o cualitativa ordinal&lt;/p>
&lt;/td>
&lt;td width="315">
&lt;p>Contrastar si existe relaci&amp;oacute;n lineal entre las dos variables&lt;/p>
&lt;/td>
&lt;td width="330">
&lt;p>Comprobar si existe relaci&amp;oacute;n entre las calificaciones de dos asignaturas&lt;/p>
&lt;/td>
&lt;td width="174">
&lt;p>Correlaci&amp;oacute;n de Spearman&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td width="88">
&lt;p>Cualitativa&lt;/p>
&lt;/td>
&lt;td width="315">
&lt;p>Construir un modelo predictivo que explique la variable dependiente en funci&amp;oacute;n de la independiente&lt;/p>
&lt;/td>
&lt;td width="330">
&lt;p>Construir el modelo (funci&amp;oacute;n log&amp;iacute;stica) que mejor explique la relaci&amp;oacute;n entre el resultado de un examen (aprobado o suspenso) y las horas dedicadas a su estudio&lt;/p>
&lt;/td>
&lt;td width="174">
&lt;p>Regresi&amp;oacute;n log&amp;iacute;stica simple&lt;/p>
&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>Los ejemplos de los distintos test que se presentan a continuación se han realizado a partir del siguiente conjunto de datos que contiene las notas y calificaciones de un curso. El fichero con los datos puede descargarse aquí para reproducir los estudios:
&lt;a href="datos/datos-curso.csv">datos-curso.csv&lt;/a>&lt;/p>
&lt;pre>&lt;code class="language-r">library(tidyverse)
&lt;/code>&lt;/pre>
&lt;h2 id="una-variable-cuantitativa">Una variable cuantitativa&lt;/h2>
&lt;h3 id="estudios-descriptivos">Estudios descriptivos&lt;/h3>
&lt;h4 id="estadísticos">Estadísticos&lt;/h4>
&lt;ul>
&lt;li>Tamaño muestral&lt;/li>
&lt;li>Media&lt;/li>
&lt;li>Desviación típica&lt;/li>
&lt;li>Mínimo, Máximo&lt;/li>
&lt;li>Cuartiles&lt;/li>
&lt;li>Coeficiente de asimetría&lt;/li>
&lt;li>Coeficiente de apuntamiento&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-r"># Tamaño muestral
nrow(df)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## [1] 120
&lt;/code>&lt;/pre>
&lt;pre>&lt;code class="language-r"># Media
mean(df$notaA, na.rm = TRUE)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## [1] 6.028333
&lt;/code>&lt;/pre>
&lt;pre>&lt;code class="language-r"># Desviación típica
sd(df$notaA, na.rm = TRUE)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## [1] 1.340524
&lt;/code>&lt;/pre>
&lt;pre>&lt;code class="language-r"># Min, max
min(df$notaA, na.rm = TRUE)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## [1] 2.5
&lt;/code>&lt;/pre>
&lt;pre>&lt;code class="language-r">max(df$notaA, na.rm = TRUE)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## [1] 9.3
&lt;/code>&lt;/pre>
&lt;pre>&lt;code class="language-r"># Cuartiles
quantile(df$notaA, c(0.25, 0.5, 0.75), na.rm = TRUE)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## 25% 50% 75%
## 5.100 5.900 6.825
&lt;/code>&lt;/pre>
&lt;pre>&lt;code class="language-r"># Coef. asimetría
library(moments)
skewness(df$notaA, na.rm = TRUE)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## [1] 0.1373915
&lt;/code>&lt;/pre>
&lt;pre>&lt;code class="language-r"># Coef. apuntamiento
kurtosis(df$notaA, na.rm = TRUE) - 3
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## [1] -0.102287
&lt;/code>&lt;/pre>
&lt;h4 id="gráficos">Gráficos&lt;/h4>
&lt;ul>
&lt;li>Diagrama de barras (variables discretas)&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-r">df %&amp;gt;% ggplot(aes(x = asinaturas.aprobadas)) +
geom_bar(fill=&amp;quot;#00BFC4&amp;quot;) +
# Cambio de escala del eje X
scale_x_discrete(limits=0:5)
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="img/one-quantitative-variable-bar-chart-1.svg" alt="">&amp;lt;!&amp;ndash; &amp;ndash;&amp;gt;&lt;/p>
&lt;ul>
&lt;li>Histograma&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-r">library(ggplot2)
# Límites de los intervalos
breaks = 0:10
# Histograma de las notasA
df %&amp;gt;% ggplot(aes(x = notaA)) +
geom_histogram(breaks = breaks, fill=&amp;quot;#00BFC4&amp;quot;) +
# Cambio de escala del eje X
scale_x_continuous(limits=c(0, 10), breaks = 0:10)
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="img/one-quantitative-variable-histogram-1.svg" alt="">&amp;lt;!&amp;ndash; &amp;ndash;&amp;gt;&lt;/p>
&lt;pre>&lt;code class="language-r"># Histograma de notasE
df %&amp;gt;% ggplot(aes(x = notaE)) +
geom_histogram(breaks = breaks, fill=&amp;quot;#00BFC4&amp;quot;) +
# Cambio de escala del eje X
scale_x_continuous(limits=c(0, 10), breaks = 0:10)
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="img/one-quantitative-variable-histogram-2.svg" alt="">&amp;lt;!&amp;ndash; &amp;ndash;&amp;gt;&lt;/p>
&lt;ul>
&lt;li>Diagrama de líneas&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-r"># Variables discretas
df %&amp;gt;% count(asinaturas.aprobadas) %&amp;gt;%
ggplot(aes(x = asinaturas.aprobadas, y = n)) +
geom_line(col=&amp;quot;#00BFC4&amp;quot;) +
# Cambio de escala del eje X
scale_x_discrete(limits=0:5)
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="img/one-quantitative-variable-line-chart-1.svg" alt="">&amp;lt;!&amp;ndash; &amp;ndash;&amp;gt;&lt;/p>
&lt;pre>&lt;code class="language-r"># Agrupación de datos en intervalos
df %&amp;gt;% ggplot(aes(x = notaA)) +
geom_freqpoly(breaks = breaks, col=&amp;quot;#00BFC4&amp;quot;) +
# Cambio de escala del eje X
scale_x_continuous(limits=c(0, 10), breaks = 0:10)
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="img/one-quantitative-variable-line-chart-2.svg" alt="">&amp;lt;!&amp;ndash; &amp;ndash;&amp;gt;&lt;/p>
&lt;ul>
&lt;li>Diagrama de caja y bigotes&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-r">df %&amp;gt;% ggplot(aes(x = notaA)) +
geom_boxplot(fill=&amp;quot;#00BFC4&amp;quot;) +
# Cambio de escala del eje X
scale_x_continuous(limits=c(0, 10), breaks = 0:10)
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="img/one-quantitative-variable-box-plot-1.svg" alt="">&amp;lt;!&amp;ndash; &amp;ndash;&amp;gt;&lt;/p>
&lt;h3 id="estudios-inferenciales">Estudios inferenciales&lt;/h3>
&lt;h4 id="test-de-normalidad-de-shapiro-wilk">Test de normalidad de Shapiro-Wilk&lt;/h4>
&lt;p>&lt;strong>Objetivo&lt;/strong>: Comprobar la normalidad de la distribución.&lt;/p>
&lt;p>&lt;strong>Hipótesis nula&lt;/strong>: La distribución es normal.&lt;/p>
&lt;pre>&lt;code class="language-r">shapiro.test(df$notaA)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>##
## Shapiro-Wilk normality test
##
## data: df$notaA
## W = 0.99424, p-value = 0.907
&lt;/code>&lt;/pre>
&lt;pre>&lt;code class="language-r">shapiro.test(df$notaE)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>##
## Shapiro-Wilk normality test
##
## data: df$notaE
## W = 0.92264, p-value = 4.065e-06
&lt;/code>&lt;/pre>
&lt;h4 id="test-t-para-la-media-de-una-población">Test t para la media de una población&lt;/h4>
&lt;p>&lt;strong>Objetivo&lt;/strong>: Estimar la media de una variable o compararla con un valor
dado &lt;em>μ&lt;/em>&lt;sub>0&lt;/sub>.&lt;/p>
&lt;p>&lt;strong>Requisitos&lt;/strong>:&lt;/p>
&lt;ul>
&lt;li>Una variable cuantitativa.&lt;/li>
&lt;li>Distribución normal o tamaño muestral ≥ 30.&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Hipótesis nula&lt;/strong>: La media de la población es igual a &lt;em>μ&lt;/em>&lt;sub>0&lt;/sub>.&lt;/p>
&lt;p>&lt;strong>Ejemplo&lt;/strong>: Comprobar si la nota media de un examen es diferente de 5.&lt;/p>
&lt;pre>&lt;code class="language-r">t.test(df$notaA, mu = 5, alternative = &amp;quot;two.sided&amp;quot;)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>##
## One Sample t-test
##
## data: df$notaA
## t = 8.4033, df = 119, p-value = 1.08e-13
## alternative hypothesis: true mean is not equal to 5
## 95 percent confidence interval:
## 5.786023 6.270643
## sample estimates:
## mean of x
## 6.028333
&lt;/code>&lt;/pre>
&lt;h2 id="una-variable-cualitativa">Una variable cualitativa&lt;/h2>
&lt;h3 id="estudios-descriptivos-1">Estudios descriptivos&lt;/h3>
&lt;h4 id="estadísticos-1">Estadísticos&lt;/h4>
&lt;ul>
&lt;li>Tamaños muestral&lt;/li>
&lt;li>Frecuencias muestrales&lt;/li>
&lt;li>Proporciones/porcentajes muestrales&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-r"># Tamaño muestral sin datos perdidos
length(na.omit(df$calificacionB))
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## [1] 115
&lt;/code>&lt;/pre>
&lt;pre>&lt;code class="language-r"># Frecuencias
table(df$calificacionB)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>##
## Aprobado Suspenso
## 98 17
&lt;/code>&lt;/pre>
&lt;pre>&lt;code class="language-r"># Proporciones
table(df$calificacionB) / length(na.omit(df$calificacionB))
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>##
## Aprobado Suspenso
## 0.8521739 0.1478261
&lt;/code>&lt;/pre>
&lt;pre>&lt;code class="language-r"># Porcentajes
table(df$calificacionB) / length(na.omit(df$calificacionB)) * 100
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>##
## Aprobado Suspenso
## 85.21739 14.78261
&lt;/code>&lt;/pre>
&lt;h4 id="gráficos-1">Gráficos&lt;/h4>
&lt;ul>
&lt;li>Diagrama de sectores&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-r">df %&amp;gt;% ggplot(aes(x = &amp;quot;&amp;quot;, fill = calificacionA)) +
geom_bar() +
# Cambiar a coordenadas polares
coord_polar(theta = &amp;quot;y&amp;quot;) +
# Eliminar ejes
theme_void()
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="img/piechart-1.svg" alt="">&amp;lt;!&amp;ndash; &amp;ndash;&amp;gt;&lt;/p>
&lt;h3 id="estudios-inferenciales-1">Estudios inferenciales&lt;/h3>
&lt;h4 id="test-binomial-para-una-proporción-de-una-población">Test binomial para una proporción de una población&lt;/h4>
&lt;p>&lt;strong>Objetivo&lt;/strong>: Estimar la propoción de una categoría en una población o
compararla con un valor &lt;em>p&lt;/em>&lt;sub>0&lt;/sub>.&lt;/p>
&lt;p>&lt;strong>Requisitos&lt;/strong>:&lt;/p>
&lt;ul>
&lt;li>One variable cualitativa&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Hipótesis nula&lt;/strong>: La proporción poblacional es igual a
&lt;em>p&lt;/em>&lt;sub>0&lt;/sub>.&lt;/p>
&lt;p>&lt;strong>Ejemplo&lt;/strong>: Comprobar si la proporción de aprobados es mayor de 0.5.&lt;/p>
&lt;pre>&lt;code class="language-r">freq &amp;lt;- table(df$calificacionA)[&amp;quot;Aprobado&amp;quot;]
binom.test(freq, n, p = 0.7, alternative = &amp;quot;greater&amp;quot;)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>##
## Exact binomial test
##
## data: freq and n
## number of successes = 94, number of trials = 120, p-value = 0.02657
## alternative hypothesis: true probability of success is greater than 0.7
## 95 percent confidence interval:
## 0.7123183 1.0000000
## sample estimates:
## probability of success
## 0.7833333
&lt;/code>&lt;/pre>
&lt;h4 id="test-z-para-la-proporción-de-una-población">Test Z para la proporción de una población&lt;/h4>
&lt;p>&lt;strong>Objetivo&lt;/strong>: Estimar la propoción de una categoría en una población o
compararla con un valor &lt;em>p&lt;/em>&lt;sub>0&lt;/sub>.&lt;/p>
&lt;p>&lt;strong>Requisitos&lt;/strong>:&lt;/p>
&lt;ul>
&lt;li>Una variable cualitativa&lt;/li>
&lt;li>Tamaño muestral &amp;gt;= 30&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Observación&lt;/strong>: Utiliza la aproximación normal de la distribución
Binomal.&lt;/p>
&lt;p>&lt;strong>Ejemplo&lt;/strong>: Comprobar si la proporción de aprobados es mayor de 0.5.&lt;/p>
&lt;pre>&lt;code class="language-r">freq &amp;lt;- table(df$calificacionA)[&amp;quot;Aprobado&amp;quot;]
prop.test(freq, n, p = 0.7, alternative = &amp;quot;greater&amp;quot;)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>##
## 1-sample proportions test with continuity correction
##
## data: freq out of n, null probability 0.7
## X-squared = 3.5813, df = 1, p-value = 0.02922
## alternative hypothesis: true p is greater than 0.7
## 95 percent confidence interval:
## 0.7111099 1.0000000
## sample estimates:
## p
## 0.7833333
&lt;/code>&lt;/pre>
&lt;h2 id="dos-variables-variable-dependiente-cuantitativa-y-variable-independiente-culitativa-con-dos-categorías-o-grupos">Dos variables: Variable dependiente cuantitativa y variable independiente culitativa con dos categorías o grupos&lt;/h2>
&lt;h3 id="estudios-descriptivos-2">Estudios descriptivos&lt;/h3>
&lt;h4 id="estadísticos-2">Estadísticos&lt;/h4>
&lt;ul>
&lt;li>Tamaño muestral de cada grupo&lt;/li>
&lt;li>Media de cada grupo&lt;/li>
&lt;li>Desviación típica de cada grupo&lt;/li>
&lt;li>Mínimo, Máximo de cada grupo&lt;/li>
&lt;li>Cuartiles de cada grupo&lt;/li>
&lt;li>Coeficiente de asimetría de cada grupo&lt;/li>
&lt;li>Coeficiente de apuntamiento de cada grupo&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-r"># Tamaño muestral de notaA según el sexo
df %&amp;gt;% group_by(sexo) %&amp;gt;% group_size()
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## [1] 71 49
&lt;/code>&lt;/pre>
&lt;pre>&lt;code class="language-r"># Media, Desviación típica, Mín, Máx, Cuartiles, Coef. Asimetría y Coef. Apuntamiento
library(moments)
df %&amp;gt;% group_by(sexo) %&amp;gt;% summarize(Media = mean(notaA, na.rm=TRUE), Des.Tip = sd(notaA, na.rm = TRUE), Mín = min(notaA), Máx = max(notaA), C1 = quantile(notaA, 0.25, na.rm = TRUE), C2 = quantile(notaA, 0.5, na.rm = TRUE), C3 = quantile(notaA, 0.75, na.rm = TRUE), Coef.Asimetría = skewness(notaA, na.rm = TRUE), Coef.Apuntamiento = kurtosis(notaA, na.rm = TRUE) - 3)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## # A tibble: 2 x 10
## sexo Media Des.Tip Mín Máx C1 C2 C3 Coef.Asimetría
## &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1 Hombre 6.12 1.23 3.5 9.3 5.3 6.1 6.85 0.249
## 2 Mujer 5.89 1.49 2.5 9.3 5 5.7 6.8 0.135
## # … with 1 more variable: Coef.Apuntamiento &amp;lt;dbl&amp;gt;
&lt;/code>&lt;/pre>
&lt;h4 id="gráficos-2">Gráficos&lt;/h4>
&lt;ul>
&lt;li>Diagrama de cajas y bigotes&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-r">df %&amp;gt;% ggplot(aes(x = sexo, y = notaA, fill = sexo)) +
geom_boxplot() +
# Cambio de escala del eje X
scale_y_continuous(limits=c(0, 10), breaks = 0:10)
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="img/quantiative-vs-qualitative-box-plot-1.svg" alt="">&amp;lt;!&amp;ndash; &amp;ndash;&amp;gt;&lt;/p>
&lt;ul>
&lt;li>Diagrama de violín&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-r">df %&amp;gt;% ggplot(aes(x = sexo, y = notaA, fill = sexo)) +
geom_violin() +
# Cambio de escala del eje X
scale_y_continuous(limits=c(0, 10), breaks = 0:10)
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="img/quantiative-vs-qualitative-viol%C3%ADn-plot-1.svg" alt="">&amp;lt;!&amp;ndash; &amp;ndash;&amp;gt;&lt;/p>
&lt;h3 id="estudios-inferenciales-2">Estudios inferenciales&lt;/h3>
&lt;h4 id="test-de-normalidad-de-shapiro-wilks">Test de normalidad de Shapiro-Wilks&lt;/h4>
&lt;p>&lt;strong>Objetivo&lt;/strong>: Comprobar la normalidad de la distribución de cada
población.&lt;/p>
&lt;p>&lt;strong>Hipótesis nula&lt;/strong>: La distribución es normal.&lt;/p>
&lt;pre>&lt;code class="language-r">df %&amp;gt;% group_by(sexo) %&amp;gt;%
summarise(`Estadístico W` = shapiro.test(notaA)$statistic, `p-valor` = shapiro.test(notaA)$p.value)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## # A tibble: 2 x 3
## sexo `Estadístico W` `p-valor`
## &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1 Hombre 0.990 0.872
## 2 Mujer 0.990 0.942
&lt;/code>&lt;/pre>
&lt;h4 id="test-f-de-fisher-de-comparación-de-varianzas-de-dos-poblaciones-independientes">Test F de Fisher de comparación de varianzas de dos poblaciones independientes&lt;/h4>
&lt;p>&lt;strong>Objetivo&lt;/strong>: Comparar las varianzas de dos poblaciones independientes.&lt;/p>
&lt;p>&lt;strong>Requisitos&lt;/strong>:&lt;/p>
&lt;ul>
&lt;li>Variable dependiente cuantitativa.&lt;/li>
&lt;li>Una variable independiente cualitativa con dos categorías
(poblaciones)&lt;/li>
&lt;li>Distribución normal de la variable dependiente en ambas poblaciones
o tamaños de las muestras de cada población ≥ 30.&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Hipótesis nula&lt;/strong>: La varianzas poblacionales son iguales (no existe
una diferencia significativa entre las medias poblacionales).&lt;/p>
&lt;p>&lt;strong>Ejemplo&lt;/strong>: Comprobar si diferencias signicativas entre las notas
medias de hombres y mujeres.&lt;/p>
&lt;pre>&lt;code class="language-r"># Test de comparación de varianzas
var.test(notaA ~ sexo, data = df)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>##
## F test to compare two variances
##
## data: notaA by sexo
## F = 0.6769, num df = 70, denom df = 48, p-value = 0.1347
## alternative hypothesis: true ratio of variances is not equal to 1
## 95 percent confidence interval:
## 0.3953421 1.1293155
## sample estimates:
## ratio of variances
## 0.6769032
&lt;/code>&lt;/pre>
&lt;h4 id="test-t-de-comparación-de-medias-de-dos-poblaciones-independientes">Test t de comparación de medias de dos poblaciones independientes&lt;/h4>
&lt;p>&lt;strong>Objetivo&lt;/strong>: Estimar la diferencia de medias en las dos poblaciones o
comprobar si hay diferencias significativas entre ellas.&lt;/p>
&lt;p>&lt;strong>Requisitos&lt;/strong>:&lt;/p>
&lt;ul>
&lt;li>Variable dependiente cuantitativa.&lt;/li>
&lt;li>Una variable independiente cualitativa con dos categorías
(poblaciones)&lt;/li>
&lt;li>Distribución normal de la variable dependiente en ambas poblaciones
o tamaños de las muestras de cada población ≥ 30.&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Hipótesis nula&lt;/strong>: La medias poblacionales son iguales (no existe una
diferencia significativa entre las medias poblacionales).&lt;/p>
&lt;p>&lt;strong>Observación&lt;/strong>: El resultado del test depende de si las varianzas
poblacionales son iguales o no.&lt;/p>
&lt;p>&lt;strong>Ejemplo&lt;/strong>: Comprobar si diferencias signicativas entre las notas
medias de hombres y mujeres.&lt;/p>
&lt;pre>&lt;code class="language-r"># Test de comparación de varianzas
var.test(notaA ~ sexo, data = df)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>##
## F test to compare two variances
##
## data: notaA by sexo
## F = 0.6769, num df = 70, denom df = 48, p-value = 0.1347
## alternative hypothesis: true ratio of variances is not equal to 1
## 95 percent confidence interval:
## 0.3953421 1.1293155
## sample estimates:
## ratio of variances
## 0.6769032
&lt;/code>&lt;/pre>
&lt;pre>&lt;code class="language-r"># Test de comparación de medias asumiendo varianzas iguales
t.test (notaA ~ sexo, data = df, alternative = &amp;quot;two.sided&amp;quot;, var.equal = FALSE)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>##
## Welch Two Sample t-test
##
## data: notaA by sexo
## t = 0.89364, df = 89.873, p-value = 0.3739
## alternative hypothesis: true difference in means between group Hombre and group Mujer is not equal to 0
## 95 percent confidence interval:
## -0.2821809 0.7435779
## sample estimates:
## mean in group Hombre mean in group Mujer
## 6.122535 5.891837
&lt;/code>&lt;/pre>
&lt;pre>&lt;code class="language-r"># Test de comparación de medias asumiendo varianzas iguales
t.test (notaA ~ sexo, data = df, alternative = &amp;quot;two.sided&amp;quot;, var.equal = TRUE)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>##
## Two Sample t-test
##
## data: notaA by sexo
## t = 0.92608, df = 118, p-value = 0.3563
## alternative hypothesis: true difference in means between group Hombre and group Mujer is not equal to 0
## 95 percent confidence interval:
## -0.262615 0.724012
## sample estimates:
## mean in group Hombre mean in group Mujer
## 6.122535 5.891837
&lt;/code>&lt;/pre>
&lt;ul>
&lt;li>Diagrama de medias&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-r">df %&amp;gt;% ggplot(aes(x = sexo, y = notaA, colour = sexo)) +
# Puntos de medias
stat_summary(fun=&amp;quot;mean&amp;quot;, size=3, geom=&amp;quot;point&amp;quot;, position=position_dodge(width=0.25)) +
# Intervalos de confianza para la media
stat_summary(fun.data = function(x) mean_cl_normal(x, conf.int=0.95), geom = &amp;quot;pointrange&amp;quot;, position=position_dodge(width=0.25))
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="img/quantitative-vs-qualitative-means-plot-1.svg" alt="">&amp;lt;!&amp;ndash; &amp;ndash;&amp;gt;&lt;/p>
&lt;h4 id="test-u-de-mann-whitney-de-comparación-de-dos-poblaciones-independientes-no-paramétrico">Test U de Mann-Whitney de comparación de dos poblaciones independientes (no paramétrico)&lt;/h4>
&lt;p>&lt;strong>Objetivo&lt;/strong>: Comprobar si hay diferencias significativas entre entre
dos poblaciones independientes.&lt;/p>
&lt;p>&lt;strong>Requisitos&lt;/strong>:&lt;/p>
&lt;ul>
&lt;li>Variable dependiente cuantitativa.&lt;/li>
&lt;li>Una variable independiente cualitativa con dos categorías
(poblaciones)&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Hipótesis nula&lt;/strong>: La medianas poblacionales son iguales (no existe una
diferencia significativa entre las medianas poblacionales).&lt;/p>
&lt;p>&lt;strong>Ejemplo&lt;/strong>: Comprobar si diferencias signicativas entre las notas de
hombres y mujeres.&lt;/p>
&lt;pre>&lt;code class="language-r"># Test de rangos U the Mann-Whitney
wilcox.test(notaA ~ sexo, data = df, alternative = &amp;quot;two.sided&amp;quot;)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>##
## Wilcoxon rank sum test with continuity correction
##
## data: notaA by sexo
## W = 1917, p-value = 0.3445
## alternative hypothesis: true location shift is not equal to 0
&lt;/code>&lt;/pre>
&lt;h2 id="dos-variables-variable-dependiente-cuantitativa-y-variable-independiente-culitativa-con-dos-categorías-o-grupos-pareados">Dos variables: Variable dependiente cuantitativa y variable independiente culitativa con dos categorías o grupos pareados&lt;/h2>
&lt;p>Dos grupos o poblaciones están pareadas o emparejadas cuando los dos
poblaciones contienen los mismos individuos, es decir, se trata en
realidadad de una única población, pero la variable dependiente se mide
dos veces en cada individuo (normalmente antes y después de la algún
suceso) y por tanto cada individuo tiene asociado un par de valores.&lt;/p>
&lt;p>Este estudio puede realizarse también creando una nueva variable a
partir de la resta de las dos mediciones y planteando un estudio de una
sola variable cuantitativa.&lt;/p>
&lt;p>&lt;strong>Ejemplo&lt;/strong>: Creación de la diferencia de notas de las asignaturas A y
B.&lt;/p>
&lt;pre>&lt;code class="language-r"># Creamos la variable diferencia = notaA - notaB
df &amp;lt;- df %&amp;gt;% mutate(diferencia = notaA - notaB)
&lt;/code>&lt;/pre>
&lt;h3 id="estudios-descriptivos-3">Estudios descriptivos&lt;/h3>
&lt;h4 id="estadísticos-3">Estadísticos&lt;/h4>
&lt;ul>
&lt;li>Tamaño muestral del grupo&lt;/li>
&lt;li>Media de la diferencia&lt;/li>
&lt;li>Desviación típica de la diferencia&lt;/li>
&lt;li>Mínimo, Máximo de la diferencia&lt;/li>
&lt;li>Cuartiles de la diferencia&lt;/li>
&lt;li>Coeficiente de asimetría de la diferencia&lt;/li>
&lt;li>Coeficiente de apuntamiento de la diferencia&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Ejemplo&lt;/strong>: Estadísticos descriptivos de la diferencia entre las notas
de las asignaturas A y B de un mismo grupo de alumnos.&lt;/p>
&lt;pre>&lt;code class="language-r"># Tamaño muestral de sin contar los datos perdidos
length(na.omit(df$diferencia))
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## [1] 115
&lt;/code>&lt;/pre>
&lt;pre>&lt;code class="language-r"># Media, Desviación típica, Mín, Máx, Cuartiles, Coef. Asimetría y Coef. Apuntamiento
library(moments)
df %&amp;gt;% summarize(Media = mean(diferencia, na.rm=TRUE), Des.Tip = sd(diferencia, na.rm = TRUE), Mín = min(diferencia, na.rm = TRUE), Máx = max(diferencia, na.rm = TRUE), C1 = quantile(diferencia, 0.25, na.rm = TRUE), C2 = quantile(diferencia, 0.5, na.rm = TRUE), C3 = quantile(diferencia, 0.75, na.rm = TRUE), Coef.Asimetría = skewness(diferencia, na.rm = TRUE), Coef.Apuntamiento = kurtosis(diferencia, na.rm = TRUE) - 3)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## # A tibble: 1 x 9
## Media Des.Tip Mín Máx C1 C2 C3 Coef.Asimetría Coef.Apuntamiento
## &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1 -0.882 0.900 -3.2 1.10 -1.5 -0.8 -0.300 -0.430 -0.137
&lt;/code>&lt;/pre>
&lt;h4 id="gráficos-3">Gráficos&lt;/h4>
&lt;ul>
&lt;li>Diagrama de cajas y bigotes&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-r">df %&amp;gt;% ggplot(aes(x = diferencia)) +
geom_boxplot(fill=&amp;quot;#00BFC4&amp;quot;)
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="img/quantiative-vs-qualitative-paired-box-plot-1.svg" alt="">&amp;lt;!&amp;ndash; &amp;ndash;&amp;gt;&lt;/p>
&lt;h3 id="estudios-inferenciales-3">Estudios inferenciales&lt;/h3>
&lt;h4 id="test-de-normalidad-de-shapiro-wilks-1">Test de normalidad de Shapiro-Wilks&lt;/h4>
&lt;p>&lt;strong>Objetivo&lt;/strong>: Comprobar la normalidad de la distribución de la
diferencia.&lt;/p>
&lt;p>&lt;strong>Hipótesis nula&lt;/strong>: La distribución es normal.&lt;/p>
&lt;p>&lt;strong>Ejemplo&lt;/strong>: Comprobar la normalidad de la diferencia entre las notas de
las asignaturas A y B de un mismo grupo de alumnos.&lt;/p>
&lt;pre>&lt;code class="language-r">df %&amp;gt;% summarise(`Estadístico W` = shapiro.test(diferencia)$statistic, `p-valor` = shapiro.test(diferencia)$p.value)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## # A tibble: 1 x 2
## `Estadístico W` `p-valor`
## &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1 0.979 0.0737
&lt;/code>&lt;/pre>
&lt;h4 id="test-t-de-comparación-de-medias-de-dos-poblaciones-pareadas">Test t de comparación de medias de dos poblaciones pareadas&lt;/h4>
&lt;p>&lt;strong>Objetivo&lt;/strong>: Estimar la media de la diferencia o compararla con un
valor dado &lt;em>μ&lt;/em>&lt;sub>0&lt;/sub>.&lt;/p>
&lt;p>&lt;strong>Requisitos&lt;/strong>:&lt;/p>
&lt;ul>
&lt;li>Variable dependiente cuantitativa.&lt;/li>
&lt;li>Una variable independiente cualitativa con dos categorías
(poblaciones) pareadas&lt;/li>
&lt;li>Distribución normal de la variable diferencia o tamaño muestral
≥ 30.&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Hipótesis nula&lt;/strong>: La medias poblacionales son iguales (no existe una
diferencia significativa entre las medias poblacionales).&lt;/p>
&lt;p>&lt;strong>Ejemplo&lt;/strong>: Comprobar si hay una diferencia signicativa entre las notas
medias de las asinaturas A y B, o lo que es lo mismo, comprobar si la
media de la diferencia de las notas de A y B es distinta de 0.&lt;/p>
&lt;pre>&lt;code class="language-r">t.test (notaA, notaB, data = df, alternative = &amp;quot;two.sided&amp;quot;, paired = TRUE)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>##
## Paired t-test
##
## data: notaA and notaB
## t = -10.618, df = 114, p-value &amp;lt; 2.2e-16
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
## -1.0515337 -0.7208695
## sample estimates:
## mean of the differences
## -0.8862016
&lt;/code>&lt;/pre>
&lt;ul>
&lt;li>Diagrama de medias&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-r">df %&amp;gt;% ggplot(aes(x=&amp;quot;&amp;quot;, y = diferencia)) +
# Puntos de medias
stat_summary(fun=&amp;quot;mean&amp;quot;, size=3, geom=&amp;quot;point&amp;quot;) +
# Intervalos de confianza para la media
stat_summary(fun.data = function(x) mean_cl_normal(x, conf.int=0.95), geom = &amp;quot;pointrange&amp;quot;, position=position_dodge(width=0.25))
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="img/quantitative-vs-qualitative-paired-means-plot-1.svg" alt="">&amp;lt;!&amp;ndash; &amp;ndash;&amp;gt;&lt;/p>
&lt;h4 id="test-wilcoxon-de-comparación-de-dos-poblaciones-pareadas-no-paramétrico">Test Wilcoxon de comparación de dos poblaciones pareadas (no paramétrico)&lt;/h4>
&lt;p>&lt;strong>Objetivo&lt;/strong>: Comparar las medianas de las dos poblaciones.&lt;/p>
&lt;p>&lt;strong>Requisitos&lt;/strong>:&lt;/p>
&lt;ul>
&lt;li>Variable dependiente cuantitativa.&lt;/li>
&lt;li>Una variable independiente cualitativa con dos categorías
(poblaciones) pareadas.&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Hipótesis nula&lt;/strong>: La medianas poblacionales son iguales (no existe una
diferencia significativa entre las medianas poblacionales).&lt;/p>
&lt;p>&lt;strong>Ejemplo&lt;/strong>: Comprobar si hay una diferencia signicativa entre las notas
de las asignaturas A y B.&lt;/p>
&lt;pre>&lt;code class="language-r">wilcox.test(notaA, notaB, data = df, alternative = &amp;quot;two.sided&amp;quot;, paired = TRUE)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>##
## Wilcoxon signed rank test with continuity correction
##
## data: notaA and notaB
## V = 466, p-value = 1.192e-15
## alternative hypothesis: true location shift is not equal to 0
&lt;/code>&lt;/pre>
&lt;h2 id="dos-variables-variable-dependiente-cuantitativa-y-variable-independiente-culitativa-con-más-de-dos-categorías-o-grupos">Dos variables: Variable dependiente cuantitativa y variable independiente culitativa con más de dos categorías o grupos&lt;/h2>
&lt;h3 id="estudios-descriptivos-4">Estudios descriptivos&lt;/h3>
&lt;h4 id="estadísticos-4">Estadísticos&lt;/h4>
&lt;ul>
&lt;li>Tamaño muestral de cada grupo&lt;/li>
&lt;li>Media de cada grupo&lt;/li>
&lt;li>Desviación típica de cada grupo&lt;/li>
&lt;li>Mínimo, Máximo de cada grupo&lt;/li>
&lt;li>Cuartiles de cada grupo&lt;/li>
&lt;li>Coeficiente de asimetría de cada grupo&lt;/li>
&lt;li>Coeficiente de apuntamiento de cada grupo&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-r"># Tamaño muestral de notaA según el grupo
df %&amp;gt;% group_by(grupo) %&amp;gt;% group_size()
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## [1] 38 35 47
&lt;/code>&lt;/pre>
&lt;pre>&lt;code class="language-r"># Media, Desviación típica, Mín, Máx, Cuartiles, Coef. Asimetría y Coef. Apuntamiento
library(moments)
df %&amp;gt;% group_by(grupo) %&amp;gt;% summarize(Media = mean(notaA, na.rm=TRUE), Des.Tip = sd(notaA, na.rm = TRUE), Mín = min(notaA, na.rm = TRUE), Máx = max(notaA, na.rm = TRUE), C1 = quantile(notaA, 0.25, na.rm = TRUE), C2 = quantile(notaA, 0.5, na.rm = TRUE), C3 = quantile(notaA, 0.75, na.rm = TRUE), Coef.Asimetría = skewness(notaA, na.rm = TRUE), Coef.Apuntamiento = kurtosis(notaA, na.rm = TRUE) - 3)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## # A tibble: 3 x 10
## grupo Media Des.Tip Mín Máx C1 C2 C3 Coef.Asimetría
## &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1 A 6.54 0.998 4.3 8.6 5.93 6.6 7.15 -0.250
## 2 B 6.96 1.23 3.5 9.3 6.2 6.8 7.7 -0.141
## 3 C 4.92 0.771 2.5 5.9 4.5 5.1 5.5 -1.06
## # … with 1 more variable: Coef.Apuntamiento &amp;lt;dbl&amp;gt;
&lt;/code>&lt;/pre>
&lt;h4 id="gráficos-4">Gráficos&lt;/h4>
&lt;ul>
&lt;li>Diagrama de cajas y bigotes&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-r">df %&amp;gt;% ggplot(aes(x = grupo, y = notaA, fill = grupo)) +
geom_boxplot() +
# Cambio de escala del eje X
scale_y_continuous(limits=c(0, 10), breaks = 0:10)
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="img/quantiative-vs-qualitative-more-two-box-plot-1.svg" alt="">&amp;lt;!&amp;ndash; &amp;ndash;&amp;gt;&lt;/p>
&lt;ul>
&lt;li>Diagrama de violín&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-r">df %&amp;gt;% ggplot(aes(x = grupo, y = notaA, fill = grupo)) +
geom_violin() +
# Cambio de escala del eje X
scale_y_continuous(limits=c(0, 10), breaks = 0:10)
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="img/quantiative-vs-qualitative-more-two-viol%C3%ADn-plot-1.svg" alt="">&amp;lt;!&amp;ndash; &amp;ndash;&amp;gt;&lt;/p>
&lt;h3 id="estudios-inferenciales-4">Estudios inferenciales&lt;/h3>
&lt;h4 id="test-de-normalidad-de-shapiro-wilks-2">Test de normalidad de Shapiro-Wilks&lt;/h4>
&lt;p>&lt;strong>Objetivo&lt;/strong>: Comprobar la normalidad de la distribución de cada
población.&lt;/p>
&lt;p>&lt;strong>Hipótesis nula&lt;/strong>: La distribución es normal.&lt;/p>
&lt;p>&lt;strong>Ejemplo&lt;/strong>: Comprobar la normalidad de las distribuciones de la nota A
en los grupos A, B y C.&lt;/p>
&lt;pre>&lt;code class="language-r">df %&amp;gt;% group_by(grupo) %&amp;gt;%
summarise(`Estadístico W` = shapiro.test(notaA)$statistic, `p-valor` = shapiro.test(notaA)$p.value)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## # A tibble: 3 x 3
## grupo `Estadístico W` `p-valor`
## &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1 A 0.984 0.840
## 2 B 0.963 0.277
## 3 C 0.918 0.00280
&lt;/code>&lt;/pre>
&lt;p>&lt;strong>Interpretación&lt;/strong>: La distribución de la nota A en los grupos A y B es
normal (p-valores &amp;gt; 0.05) pero no en el grupo C (p-valor &amp;lt; 0.05)&lt;/p>
&lt;p>&lt;strong>Ejemplo&lt;/strong>: Comprobar la normalidad de las distribuciones de la nota A
en los grupos A, B y C.&lt;/p>
&lt;pre>&lt;code class="language-r">df %&amp;gt;% group_by(grupo) %&amp;gt;%
summarise(`Estadístico W` = shapiro.test(notaC)$statistic, `p-valor` = shapiro.test(notaC)$p.value)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## # A tibble: 3 x 3
## grupo `Estadístico W` `p-valor`
## &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1 A 0.989 0.961
## 2 B 0.965 0.343
## 3 C 0.976 0.442
&lt;/code>&lt;/pre>
&lt;p>&lt;strong>Interpretación&lt;/strong>: La distribución de la nota C en los tres grupos es
normal (p-valores &amp;gt; 0.05).&lt;/p>
&lt;h4 id="test-de-levene-de-comparación-de-varianzas-de-dos-o-más-poblaciones-independientes">Test de Levene de comparación de varianzas de dos o más poblaciones independientes&lt;/h4>
&lt;p>&lt;strong>Objetivo&lt;/strong>: Comparar las varianzas de dos o más poblaciones
independientes.&lt;/p>
&lt;p>&lt;strong>Requisitos&lt;/strong>:&lt;/p>
&lt;ul>
&lt;li>Variable dependiente cuantitativa.&lt;/li>
&lt;li>Una variable independiente cualitativa con dos o más categorías
(poblaciones)&lt;/li>
&lt;li>Distribución normal de la variable dependiente en todas las
poblaciones o tamaños de las muestras de cada población ≥ 30.&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Hipótesis nula&lt;/strong>: La varianzas poblacionales son iguales (no existe
una diferencia significativa entre las medias poblacionales).&lt;/p>
&lt;p>&lt;strong>Ejemplo&lt;/strong>: Comprobar si diferencias signicativas entre las varianzas
de las notas de la asignatura C de los grupos A, B y C.&lt;/p>
&lt;pre>&lt;code class="language-r"># El test de Levene está disponible en el paquete car
library(car)
# Test de comparación de varianzas
leveneTest(notaC ~ grupo, data = df)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## Levene's Test for Homogeneity of Variance (center = median)
## Df F value Pr(&amp;gt;F)
## group 2 0.3186 0.7278
## 116
&lt;/code>&lt;/pre>
&lt;p>&lt;strong>Interpretación&lt;/strong>: No existe diferencia significativa entre las
varianzas de la nota C en los grupos A, B y C (p-valor &amp;gt; 0.05).&lt;/p>
&lt;h4 id="anova-de-un-factor-para-la-comparación-medias-de-más-de-dos-poblaciones-independientes">ANOVA de un factor para la comparación medias de más de dos poblaciones independientes&lt;/h4>
&lt;p>&lt;strong>Objetivo&lt;/strong>: Comprobar si hay diferencias significativas entre las
medias de más de dos poblaciones independientes.&lt;/p>
&lt;p>&lt;strong>Requisitos&lt;/strong>:&lt;/p>
&lt;ul>
&lt;li>Variable dependiente cuantitativa.&lt;/li>
&lt;li>Una variable independiente cualitativa con más de dos categorías
(poblaciones)-&lt;/li>
&lt;li>Distribución normal de la variable dependiente en todas las
poblaciones o tamaños de las muestras de cada población ≥ 30.&lt;/li>
&lt;li>Homogeneidad de varianzas en las poblaciones.&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Hipótesis nula&lt;/strong>: La medias poblacionales son iguales (no existe una
diferencia significativa entre las medias poblacionales).&lt;/p>
&lt;p>&lt;strong>Ejemplo&lt;/strong>: Comprobar si diferencias signicativas entre las notas
medias de la asignatura C de los grupos A, B y C.&lt;/p>
&lt;pre>&lt;code class="language-r"># Análisis de la varianza de un factor
summary(aov(notaC ~ grupo, data = df))
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## Df Sum Sq Mean Sq F value Pr(&amp;gt;F)
## grupo 2 80.69 40.34 20.05 3.32e-08 ***
## Residuals 116 233.41 2.01
## ---
## Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 1 observation deleted due to missingness
&lt;/code>&lt;/pre>
&lt;p>&lt;strong>Interpretación&lt;/strong>: Existen diferencias significativas entre las medias
de la nota C entre al menos dos grupos (p-valor=3.32e-08 &amp;lt; 0.05).&lt;/p>
&lt;p>&lt;strong>Observación&lt;/strong>: Cuando se detectan diferencias significativas entre las
medias de al menos dos grupos conviene realizar un test de comparación
múltiple por pares para ver entre qué poblaciones hay diferencias y
entre cuáles no. Los test más habituales de comparación por pares son el
de Tukey y el de Bonferroni.&lt;/p>
&lt;pre>&lt;code class="language-r"># Test de comparación múltiple de Tukey
TukeyHSD(aov(notaC ~ grupo, data = df))
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## Tukey multiple comparisons of means
## 95% family-wise confidence level
##
## Fit: aov(formula = notaC ~ grupo, data = df)
##
## $grupo
## diff lwr upr p adj
## B-A 0.4312693 -0.3637573 1.2262960 0.4048482
## C-A -1.4455767 -2.1802858 -0.7108676 0.0000241
## C-B -1.8768461 -2.6350758 -1.1186163 0.0000001
&lt;/code>&lt;/pre>
&lt;p>&lt;strong>Interpretación&lt;/strong>: No existe una diferencia significativa entre las
notas medias de la asignatura C de los grupos A y B (p-valor=0.4048 &amp;gt;
0.05), pero si existe una diferencia significativa entre las notas
medias de los grupos A y C (p-valor=0.00002 &amp;lt; 0.05) y también entre las
notas medias de los grupos B y C (p-valor=0.0000001 &amp;lt; 0.05).&lt;/p>
&lt;ul>
&lt;li>Diagrama de medias&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-r">df %&amp;gt;% ggplot(aes(x = grupo, y = notaC, colour = grupo)) +
# Puntos de medias
stat_summary(fun=&amp;quot;mean&amp;quot;, size=3, geom=&amp;quot;point&amp;quot;, position=position_dodge(width=0.25)) +
# Intervalos de confianza para la media
stat_summary(fun.data = function(x) mean_cl_normal(x, conf.int=0.95), geom = &amp;quot;pointrange&amp;quot;, position=position_dodge(width=0.25))
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="img/quantitative-vs-qualitative-more-two-means-plot-1.svg" alt="">&amp;lt;!&amp;ndash; &amp;ndash;&amp;gt;&lt;/p>
&lt;h4 id="test-kruskal-wallis-de-comparación-de-más-de-dos-poblaciones-independientes-no-paramétrico">Test Kruskal-Wallis de comparación de más de dos poblaciones independientes (no paramétrico)&lt;/h4>
&lt;p>&lt;strong>Objetivo&lt;/strong>: Comprobar si hay diferencias significativas entre entre
más de dos poblaciones independientes.&lt;/p>
&lt;p>&lt;strong>Requisitos&lt;/strong>:&lt;/p>
&lt;ul>
&lt;li>Variable dependiente cuantitativa.&lt;/li>
&lt;li>Una variable independiente cualitativa con más de dos categorías
(poblaciones)&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Hipótesis nula&lt;/strong>: La medianas poblacionales son iguales (no existe una
diferencia significativa entre las medianas poblacionales).&lt;/p>
&lt;p>&lt;strong>Ejemplo&lt;/strong>: Comprobar si diferencias signicativas entre las notas de la
asignatura A de los grupos A, B y C.&lt;/p>
&lt;pre>&lt;code class="language-r"># Test de Kruskal-Wallis
kruskal.test(notaA ~ grupo, data = df)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>##
## Kruskal-Wallis rank sum test
##
## data: notaA by grupo
## Kruskal-Wallis chi-squared = 62.218, df = 2, p-value = 3.087e-14
&lt;/code>&lt;/pre>
&lt;p>&lt;strong>Interpretación&lt;/strong>: Existen diferencias significativas entre las notas
de la asignatura A de al menos dos de los grupos.&lt;/p>
&lt;p>&lt;strong>Observación&lt;/strong>: Cuando se detectan diferencias significativas entre al
menos dos grupos conviene realizar un test de comparación múltiple por
pares para ver entre qué poblaciones hay diferencias y entre cuáles no.
El test más habitual es el de Wilcoxon.&lt;/p>
&lt;pre>&lt;code class="language-r"># Test de comparación múltiple de Wilcoxon
pairwise.wilcox.test(df$notaA, df$grupo, p.adjust.method = &amp;quot;BH&amp;quot;)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>##
## Pairwise comparisons using Wilcoxon rank sum test with continuity correction
##
## data: df$notaA and df$grupo
##
## A B
## B 0.19 -
## C 4.2e-10 1.3e-11
##
## P value adjustment method: BH
&lt;/code>&lt;/pre>
&lt;p>&lt;strong>Interpretación&lt;/strong>: No existe una diferencia significativa entre las
notas de la asignatura A de los grupos A y B (p-valor=0.19 &amp;gt; 0.05),
pero si existe una diferencia significativa entre las notas de los
grupos A y C (p-valor=4.2e-10 &amp;lt; 0.05) y también entre las notas de los
grupos B y C (p-valor=1.3e-11 &amp;lt; 0.05).&lt;/p></description></item><item><title>Epidemiología</title><link>/docencia/estadistica/tutoriales/epidemiologia/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/docencia/estadistica/tutoriales/epidemiologia/</guid><description>&lt;h2 id="qué-es-la-epidemiología">¿Qué es la Epidemiología?&lt;/h2>
&lt;p>Epidemiología viene Griego: Epi (sobre), demos (gente) y logos (estudio), es decir, el estudio de lo que le ocurre a las poblaciones.&lt;/p>
&lt;blockquote>
&lt;p>En el ámbito de la salud pública, la &lt;strong>Epidemilogía&lt;/strong> es una rama de la Medicina que se encarga del estudio de la distribución y las causas de eventos relacionados con la salud (normalmente enfermedades) en las poblaciones, y la aplicación de este estudio para controlar problemas públicos de salud.&lt;/p>
&lt;/blockquote>
&lt;img src="img/detective.png" width=80% alt="Detective epidemiólogo">
&lt;p>Debido a la epidemia provocada por el coronavirus, la Epidemiología se ha convertido en una de las ramas de la medicina que más interés despiertan.&lt;/p>
&lt;p>&lt;img src="img/fernando-simon.jpg" alt="Fernando Simón">&lt;/p>
&lt;p>Sin embargo, antes de la COVID, la Epidemiología ya había servido en otros momentos históricos para solucionar o controlar algunos de los problemas de salud públicos más serios que ha enfrentado la humanidad.&lt;/p>
&lt;h3 id="algunos-descubrimientos-históricos">Algunos descubrimientos históricos&lt;/h3>
&lt;ul>
&lt;li>1854: John Snow determina que la causa de la epidemia de cólera que asolaba Lóndres era que el agua estaba contaminada con heces.&lt;/li>
&lt;li>1898: Ronald Ross averigua que el transmisor de la malaria es el el mosquito Anopheles.&lt;/li>
&lt;li>1950: Se descubre que fumar es el principal factor de riesgo de cáncer de pulmón.&lt;/li>
&lt;li>1954: Se valida la primera vacuna contra la poliomielitis (Jonas Salk’s).&lt;/li>
&lt;li>1970: Se observó que el ejercicio físico y una dieta sana reducían el riesgo de sufrir un infarto.&lt;/li>
&lt;li>1983: Robert Gallo, Luc Montagnier y Françoise Barré-Sinoussi identifican el virus que causa el SIDA. Poco después se se observó que el riesgo de contraer el HIV aumentaba con ciertas prácticas sexuales y con el consumo de algunos tipos de drogas.&lt;/li>
&lt;li>2020: Y llegó la COVID&amp;hellip;&lt;/li>
&lt;/ul>
&lt;p>En estos tiempos de pandemia un montón de términos técnicos de la Epidemiología se han convertido en lugares comunes gracias a los medios de comunicación.&lt;/p>
&lt;p>&lt;img src="img/wordcloud.png" alt="Términos epidemiología">&lt;/p>
&lt;p>Sin embargo, muchos de estos términos se utilizan de manera errónea, incluso por los propios medios de comunicación, y generan confusión para la población no experta. En este tutorial pretendo explicar los principales conceptos epidemiológicos usados en el control de enfermedades como la COVID e ilustrar su uso con ejemplos de aplicación.&lt;/p>
&lt;h2 id="índices-epidemiológicos">Índices epidemiológicos&lt;/h2>
&lt;p>&lt;strong>Riesgos&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>Prevalencia&lt;/li>
&lt;li>Incidencia&lt;/li>
&lt;li>Riesgo y Odds&lt;/li>
&lt;li>Riesgo/Odd relativo&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Test diagnósticos&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>Sensibilidad&lt;/li>
&lt;li>Especificidad&lt;/li>
&lt;li>Valores predictivos&lt;/li>
&lt;/ul>
&lt;p>Todos estos índices estan basados en el cálculo de probabilidades, por lo que comenzaremos introduciendo el concepto de probabilidad y sus principales propiedades.&lt;/p>
&lt;h2 id="el-concepto-de-probabilidad">El concepto de probabilidad&lt;/h2>
&lt;p>A lo largo de la historia ha habido diferentes intentos de definir matemáticamente el concepto de probabilidad. Quizá la más conocida y la primera que se enseña en las escuelas es la definición clásica de Laplace.&lt;/p>
&lt;div class="alert alert-def">
&lt;div>
&lt;strong>Definición clásica (Laplace)&lt;/strong> $$P(E)=\frac{|E|}{|\Omega|}=\frac{\mbox{Casos favorables a $E$}}{\mbox{Casos posibles}}$$
&lt;/div>
&lt;/div>
&lt;p>&lt;strong>Ejemplo&lt;/strong> Al tirar un dado equilibrado, la probabilidad de sacar un número par $E=\{2, 4, 6\}$ es
$$ P(E) = \frac{3}{6} = 0.5$$&lt;/p>
&lt;p>Sin embargo, esta definición tiene serios inconvenientes ya que, para poder usarla, todos los casos posibles de un experimento deben tener la misma probabilidad de ocurrir (&lt;em>equiprobabilidad&lt;/em>) y esto no suele ocurrir en la vida real (por ejemplo no todos los grupos sanguíneos tienen la misma probabilidad de ocurrir).&lt;/p>
&lt;p>Por este motivo, en el ámbito de las Ciencias es mucho más común utilizar la definición de probabilidad basada en el cálculo de frecuencias.&lt;/p>
&lt;div class="alert alert-def">
&lt;div>
&lt;strong>Definición frecuentista&lt;/strong> $$P(E)\approx f_E = \frac{n_E}{n}=\frac{\mbox{Frecuencia absoluta del evento}}{\mbox{Tamaño muestral}}$$
&lt;/div>
&lt;/div>
&lt;p>&lt;strong>Ejemplo&lt;/strong> Se ha aplicado un tratamiento a 100 personas y se han curado 75, entonces la probabilidad de curación del tratamiento es
$$P(E) = \frac{75}{100} = 0.75 \Rightarrow 75\%$$&lt;/p>
&lt;p>&lt;i class="fa fa-exclamation-triangle" style="color:#ff9900;">&lt;/i>Ojo, esta definición no permite calcular el valor exacto de la probabilidad de un suceso, tan solo una aproximación que será mejor cuanto mayor sea el tamaño de la muestra.&lt;/p>
&lt;h3 id="algunas-propiedades-de-la-probabilidad">Algunas propiedades de la probabilidad&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>Una probabilidad es un número real entre 0 y 1: $$0\leq P(E)\leq 1$$&lt;/p>
&lt;/li>
&lt;li>
&lt;p>La suma de las probabilidades de todos los casos posibles es 1: $$P(\Omega) = P(e_1) + P(e_2) + \cdots + P(e_n) = 1$$&lt;/p>
&lt;/li>
&lt;li>
&lt;p>La probabilidad de que ocurra lo contrario de un suceso es 1 menos la probabilidad del suceso: $$P(\overline E) = 1 - P(E)$$&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>De este modo, cuanto más probable es que ocurra un suceso, menos probable es que ocurra su contrario, y viceversa.&lt;/p>
&lt;h3 id="interpretación-de-una-probabilidad">Interpretación de una probabilidad&lt;/h3>
&lt;p>La probabilidad mide la verosimilitud de un suceso.&lt;/p>
&lt;p>De manera informal, se puede decir que la probabilidad mide la creencia o la confianza que tenemos en la ocurrencia de un suceso.&lt;/p>
&lt;ul>
&lt;li>$P(E) = 0 \Rightarrow$ Mínima verosimilitud&lt;/li>
&lt;li>$P(E) = 0.5 \Rightarrow$ Verosimilitud media (máxima incertidumbre)&lt;/li>
&lt;li>$P(E) = 1 \Rightarrow$ Máxima verosimilitud&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="img/balanza-probabilidad.png" alt="Balanza probabilidades">&lt;/p>
&lt;p>Aunque el concepto de probabilidad es el más extendido en aplicaciones que requieren cuantificar la incertidumbre sobre la ocurrencia de un suceso, existen otras formas de cuantificar esa incertidumbre como por ejemplo el &lt;em>odds&lt;/em>.&lt;/p>
&lt;h2 id="el-concepto-de-odds">El concepto de Odds&lt;/h2>
&lt;div class="alert alert-def">
&lt;div>
&lt;strong>Definición: Odds&lt;/strong> $$O(E)=\frac{\mbox{Nº casos con $E$}}{\mbox{Nº casos sin $E$}}=\frac{P(E)}{P(\overline E)}$$
&lt;/div>
&lt;/div>
&lt;p>&lt;strong>Ejemplo&lt;/strong> Se ha aplicado un tratamiento a 100 personas y se han curado 75, entonces el odds de curación del tratamiento es $$O(E) = \frac{75}{25} = 3$$&lt;/p>
&lt;p>&lt;i class="fa fa-exclamation-triangle" style="color:#ff9900;">&lt;/i> Un odds puede ser mayor que 1.&lt;/p>
&lt;h3 id="interpretación-de-un-odds">Interpretación de un Odds&lt;/h3>
&lt;p>Los odds también permiten cuantificar la verosimilitud de un suceso&amp;hellip;, pero en una escala diferente, ya que es una razón de probabilidades.&lt;/p>
&lt;ul>
&lt;li>$O(E) = 0 \Rightarrow$ Mínima verosimilitud&lt;/li>
&lt;li>$O(E) = 1 \Rightarrow$ Verosimilitud media (máxima incertidumbre)&lt;/li>
&lt;li>$O(E) = \infty \Rightarrow$ Máxima verosimilitud&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="img/balanza-odds.png" alt="Balanza probabilidades">&lt;/p>
&lt;h3 id="conversión-de-odds-en-probabilidades">Conversión de Odds en probabilidades&lt;/h3>
&lt;p>Es posible convertir un odds en una probabilidad aplicando la siguiente fórmula:&lt;/p>
&lt;p>$$ \frac{O(E)}{1 + O(E)} = \frac{\frac{P(E)}{P(\overline E)}}{1 + \frac{P(E)}{P(\overline E)}} = \frac{\frac{P(E)}{P(\overline E)}}{\frac{P(\overline E) + P(E)}{P(\overline E)}} = P(E)$$&lt;/p>
&lt;p>&lt;strong>Ejemplo&lt;/strong> Se ha aplicado un tratamiento a 100 personas y se han curado 75.
$$O(E) = \frac{75}{25} = 3 \Rightarrow P(E) = \frac{3}{1+3}=0.75$$&lt;/p>
&lt;h2 id="prevalencia">Prevalencia&lt;/h2>
&lt;div class="alert alert-def">
&lt;div>
&lt;strong>Definición: Prevalencia&lt;/strong>&lt;br>
La &lt;em>prevalencia&lt;/em> de una enfermedad $E$ es la proporción de personas que tienen la enfermedad en un momento concreto.
$$\mbox{Prevalencia}(E) = \frac{\mbox{Nº individuos afectados por $E$}}{\mbox{Tamaño poblacional}}$$
&lt;/div>
&lt;/div>
&lt;p>&lt;strong>Ejemplo&lt;/strong>. En una muestra de 1000 personas 150 tenían gripe. La prevalencia de la gripe es aproximadamente $$\frac{150}{1000}=0.15$$&lt;/p>
&lt;h2 id="incidencia-o-riesgo-absoluto">Incidencia o riesgo absoluto&lt;/h2>
&lt;div class="alert alert-def">
&lt;div>
&lt;strong>Definición: Incidencia&lt;/strong>&lt;br>
La &lt;em>incidencia&lt;/em> o &lt;em>riesgo absoluto&lt;/em> de una enfermedad $E$ es la proporción de nuevos casos durante un periodo determinado (por día, por semana, por mes, etc.)
$$R(E)=\frac{\mbox{Nº nuevos casos con $E$ en el periodo}}{\mbox{Tamaño población en riesgo al comienzo del periodo}}$$
&lt;/div>
&lt;/div>
&lt;p>&lt;strong>Ejemplo&lt;/strong>. Al comienzo del año se tomó una muestra de 1000 personas sin gripe y al finalizar el año 80 tuvieron gripe. La incidencia de la gripe ese año fue
$$ R(E) = \frac{80}{1000} = 0.08$$&lt;/p>
&lt;h3 id="prevalencia-vs-incidencia">Prevalencia vs Incidencia&lt;/h3>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>&lt;/th>
&lt;th style="text-align:center">Tiempo&lt;/th>
&lt;th style="text-align:center">Casos&lt;/th>
&lt;th style="text-align:center">Tipo estudio&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>Prevalencia&lt;/td>
&lt;td style="text-align:center">Puntual&lt;/td>
&lt;td style="text-align:center">Nuevos y existentes&lt;/td>
&lt;td style="text-align:center">Transversal&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Incidencia&lt;/td>
&lt;td style="text-align:center">Periodo&lt;/td>
&lt;td style="text-align:center">Solo nuevos&lt;/td>
&lt;td style="text-align:center">Longitudinal&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;ul>
&lt;li>La prevalencia muestra el número de personas afectadas (carga de la enfermedad).&lt;/li>
&lt;li>La incidencia muestra la evolución de la enfermedad y es más útil para detectar brotes y estudiar su causa.&lt;/li>
&lt;li>La incidencia depende sobre todo de la contagiosidad de la enfermedad, mientras que la prevalencia depende también de la duración de la enfermedad y de lo agresiva que sea.&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Ejemplo&lt;/strong> Una enfermedad crónica como la diabetes o la artrosis tiene una incidencia prácticamente constante al depender fundamentalmente de la edad y no ser contagiosas y una prevalencia alta ya que no existe cura para ellas y las personas tampoco mueren a causa de ellas sino que viven con ellas el resto de su vida.&lt;/p>
&lt;p>Por otro lado, una enfermedad como el ébola tiene una incidencia pequeña al no ser muy contagiosa y también una prevalencia pequeña al ser una enfermedad mortal ya que casi todas las personas que se contagian acaban muriendo.&lt;/p>
&lt;p>Finalmente, una enfermedad como la COVID tiene una incidencia muy alta al ser muy contagiosa y una prevalencia parecida a la incidencia ya que la enfermedad suele acabar en un periodo de dos semanas desde el contagio (salvo los casos que necesitan hospitalización).&lt;/p>
&lt;h3 id="algunas-consideraciones-en-el-caso-de-la-covid">Algunas consideraciones en el caso de la COVID&lt;/h3>
&lt;p>
&lt;a href="https://www.mscbs.gob.es/profesionales/saludPublica/ccayes/alertasActual/nCov/situacionActual.htm" target="_blank" rel="noopener">Datos del ministerio de sanidad&lt;/a>&lt;/p>
&lt;p>La incidencia de la COVID se suele dar sobre un periodo de dos semanas (14 días) aunque no siempre.&lt;/p>
&lt;p>Los datos son poco precisos y subestiman el riesgo de la COVID:&lt;/p>
&lt;ul>
&lt;li>Muchos asintomáticos no son detectados.&lt;/li>
&lt;li>La detección de casos es mediante test diagnósticos que tienen un margen de error (falsos positivos y falsos negativos).&lt;/li>
&lt;li>Se calcula dividiendo por el tamaño de la población (nuevos casos por cada 100000 habitantes) pero habría que dividir por el tamaño de la población en riesgo (sin contar ya infectados o inmunizados).&lt;/li>
&lt;/ul>
&lt;h2 id="comparación-de-riesgos">Comparación de riesgos&lt;/h2>
&lt;p>Tanto la prevalencia como la incidencia permiten estudiar la magnitud y la evolución de una enfermedad pero no permiten analizar las posibles causas. Cuando se quiere investigar si la exposición a un determinado factor puede influir en el desarrollo de una enfermedad hay que comparar los riesgos en dos grupos:&lt;/p>
&lt;ul>
&lt;li>Grupo tratamiento $T$: Individuos expuestos a un factor.&lt;/li>
&lt;li>Grupo control $C$: Individuos no expuestos al factor.&lt;/li>
&lt;/ul>
&lt;p>$$
\begin{array}{|l|cc|}
\hline
&amp;amp; E &amp;amp; \overline E\newline
\hline
T &amp;amp; a &amp;amp; b\newline
C &amp;amp; c &amp;amp; d\newline
\hline
\end{array}
$$&lt;/p>
&lt;h2 id="riesgo-relativo">Riesgo relativo&lt;/h2>
&lt;div class="alert alert-def">
&lt;div>
&lt;strong>Definición: Riesgo relativo&lt;/strong>
$$RR(E)=\frac{\mbox{Riesgo grupo tratamiento}}{\mbox{Riesgo grupo control}}=\frac{R_T(E)}{R_C(E)}=\frac{a/(a+b)}{c/(c+d)}$$
&lt;/div>
&lt;/div>
&lt;p>&lt;strong>Ejemplo&lt;/strong>.&lt;/p>
&lt;p>$$
\begin{array}{|l|cc|}
\hline
&amp;amp; \mbox{Gripe } G &amp;amp; \mbox{No gripe }\overline E\newline
\hline
\mbox{Vacunados } T &amp;amp; 20 &amp;amp; 480 \newline
\mbox{No vacunados } C &amp;amp; 80 &amp;amp; 420 \newline
\hline
\end{array}
$$&lt;/p>
&lt;p>$$RR(G) = \frac{20/(20+480)}{80/(80+420)} = 0.25$$&lt;/p>
&lt;h3 id="interpretación-del-riesgo-relativo">Interpretación del riesgo relativo&lt;/h3>
&lt;ul>
&lt;li>$RR=1$ $\Rightarrow$ No hay asociación entre el suceso y la exposición al factor.&lt;/li>
&lt;li>$RR&amp;lt;1$ $\Rightarrow$ La exposición al factor disminuye el riesgo del suceso.&lt;/li>
&lt;li>$RR&amp;gt;1$ $\Rightarrow$ La exposición al factor aumenta el riesgo del suceso.&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="img/escala-riesgo-relativo.png" alt="Interpretación riesgo relativo">&lt;/p>
&lt;h2 id="odds-ratio">Odds ratio&lt;/h2>
&lt;p>Del mismo modo que se pueden comparar los riesgos en los grupos tratamiento y control, se pueden comparar también los odds.&lt;/p>
&lt;div class="alert alert-def">
&lt;div>
&lt;strong>Definición: Odds ratio&lt;/strong>
$$OR(E)=\frac{\mbox{Odds grupo tratamiento}}{\mbox{Odds grupo control}}=\frac{O_T(E)}{O_C(E)}=\frac{a/b}{c/d}=\frac{ad}{bc}$$
&lt;/div>
&lt;/div>
&lt;p>&lt;strong>Ejemplo&lt;/strong>.&lt;/p>
&lt;p>$$
\begin{array}{|l|cc|}
\hline
&amp;amp; \mbox{Gripe } G &amp;amp; \mbox{No gripe }\overline E\newline
\hline
\mbox{Vacunados } T &amp;amp; 20 &amp;amp; 480 \newline
\mbox{No vacunados } C &amp;amp; 80 &amp;amp; 420 \newline
\hline
\end{array}
$$&lt;/p>
&lt;p>$$OR(G) = \frac{20/480}{80/420} = 0.22$$&lt;/p>
&lt;h3 id="interpretación-del-odds-ratio">Interpretación del odds ratio&lt;/h3>
&lt;ul>
&lt;li>$OR=1$ $\Rightarrow$ No existe asociación entre el suceso y la exposición al factor.&lt;/li>
&lt;li>$OR&amp;lt;1$ $\Rightarrow$ La exposición al factor disminuye el riesgo del suceso.&lt;/li>
&lt;li>$OR&amp;gt;1$ $\Rightarrow$ La exposición al factor aumenta el riesgo del suceso.&lt;/li>
&lt;/ul>
&lt;h3 id="riesgo-relativo-vs-odds-ratio">Riesgo relativo vs odds ratio&lt;/h3>
&lt;p>El riesgo relativo es una comparación de probabilidades pero depende de la incidencia de la enfermedad.&lt;/p>
&lt;p>La interpretación del odds ratio es más enrevesada porque es contrafactual, ya que da cuántas veces es más frecuente el suceso en el grupo tratamiento en comparación con el control, asumiendo que en el
grupo control es tan frecuente que ocurra el suceso como que no. Su ventaja es que no depende de la incidencia de la enfermedad.&lt;/p>
&lt;p>&lt;strong>Ejemplo&lt;/strong>. Para estudiar la asociación entre fumar y el cáncer de pulmón se han tomado dos muestras, la segunda con el doble de pacientes sanos que la primera.&lt;/p>
&lt;p>$$
\begin{array}{|l|cc|}
\hline
\textbf{Muestra 1} &amp;amp; \mbox{Cáncer } E &amp;amp; \mbox{No cáncer }\overline E\newline
\hline
\mbox{Fumadores } &amp;amp; 60 &amp;amp; 80 \newline
\mbox{No fumadores } C &amp;amp; 40 &amp;amp; 320 \newline
\hline
\end{array}
$$&lt;/p>
&lt;p>$$
\begin{aligned}
RR(E) &amp;amp;= \frac{60/(60+80)}{40/(40+320)} = 3.86
\newline
OR(E) &amp;amp;= \frac{60/80}{40/320} = 6
\end{aligned}
$$&lt;/p>
&lt;p>$$
\begin{array}{|l|cc|}
\hline
\textbf{Muestra 2} &amp;amp; \mbox{Cáncer } E &amp;amp; \mbox{No cáncer }\overline E\newline
\hline
\mbox{Fumadores } &amp;amp; 60 &amp;amp; 160 \newline
\mbox{No fumadores } C &amp;amp; 40 &amp;amp; 640 \newline
\hline
\end{array}
$$&lt;/p>
&lt;p>$$
\begin{aligned}
RR(E) &amp;amp;= \frac{60/(60+160)}{40/(40+640)} = 4.64
\newline
OR(E) &amp;amp;= \frac{60/160}{40/640} = 6
\end{aligned}
$$&lt;/p>
&lt;h3 id="aplicación-a-la-covid">Aplicación a la COVID&lt;/h3>
&lt;ul>
&lt;li>
&lt;a href="https://www.npr.org/sections/coronavirus-live-updates/2020/03/22/819846180/study-calculates-just-how-much-age-medical-conditions-raise-odds-of-severe-covid?t=1614095513052" target="_blank" rel="noopener">La edad aumenta la gravedad&lt;/a>&lt;/li>
&lt;li>
&lt;a href="https://www.aarp.org/espanol/salud/enfermedades-y-tratamientos/info-2020/tipo-de-sangre-y-riesgo-de-covid.html" target="_blank" rel="noopener">El riesgo de infección depende del grupo sanguíneo&lt;/a>&lt;/li>
&lt;li>
&lt;a href="https://medicalxpress.com/news/2021-01-vitamin-d-deficiency-covid-.html" target="_blank" rel="noopener">El déficit de vitamina D aumenta el riesgo de infección&lt;/a>&lt;/li>
&lt;li>
&lt;a href="https://www.sciencedaily.com/releases/2021/02/210209083524.htm" target="_blank" rel="noopener">Las personas con demencia tienen mayor riesgo de infectase&lt;/a>&lt;/li>
&lt;li>
&lt;a href="https://www.nejm.org/doi/full/10.1056/NEJMoa2007764" target="_blank" rel="noopener">El Remdesivir acelera la recuperación&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="tests-diagnósticos">Tests diagnósticos&lt;/h2>
&lt;p>Otra aplicación de la Epidemiología basado en el cálculo de probabilidades son los &lt;em>test diagnósticos&lt;/em>.&lt;/p>
&lt;blockquote>
&lt;p>Un test diagnóstico es un test usado para diagnosticar una enfermedad o descartarla.&lt;/p>
&lt;/blockquote>
&lt;p>Normalmente producen dos resultados: positivo (+) a favor de la enfermedad y negativo (-) en contra de ella.&lt;/p>
&lt;p>$$
\begin{array}{|l|cc|}
\hline
\mbox{Test} &amp;amp; E &amp;amp; \overline E\newline
\hline
\mbox{Positivo }+ &amp;amp; \color{green}{\mbox{Verdadero positivo }VP} &amp;amp; \color{red}{\mbox{Falso positivo }FP} \newline
\mbox{Negativo }- &amp;amp; \color{red}{\mbox{Falso negativo }FN} &amp;amp; \color{green}{\mbox{Verdadero negativo }VN}\newline
\hline
\end{array}
$$&lt;/p>
&lt;h2 id="sensibilidad-y-especificidad-de-un-test">Sensibilidad y especificidad de un test&lt;/h2>
&lt;p>La fiabilidad de un test diagnóstico depende de las siguientes probabilidades.&lt;/p>
&lt;div class="alert alert-def">
&lt;div>
&lt;strong>Definición: Sensibilidad&lt;/strong>&lt;br>
La &lt;em>sensibilidad&lt;/em> de un test diagnóstico es la proporción de resultados positivos del test en personas con la enfermedad,
$$P(+|E)=\frac{VP}{VP+FN}$$
&lt;/div>
&lt;/div>
&lt;div class="alert alert-def">
&lt;div>
&lt;strong>Definición: Especificidad&lt;/strong>&lt;br>
La &lt;em>especificidad&lt;/em> de un test diagnóstico es la proporción de resultados negativos del test en personas sin la enfermedad,
$$P(-|\overline{E})=\frac{VN}{VN+FP}$$
&lt;/div>
&lt;/div>
&lt;p>&lt;strong>Ejemplo&lt;/strong>. Un test de antígenos para detectar el SARS-COV-2 tiene una sensibilidad del 70% y una especificidad del 95%.&lt;/p>
&lt;ul>
&lt;li>Si aplicamos el test a 100 enfermos dará 70 positivos y 30 negativos.&lt;/li>
&lt;li>Si aplicamos el test a 100 sanos dará 95 negativos y 5 positivos.&lt;/li>
&lt;/ul>
&lt;p>La fiabilidad del test depende también de la prevalencia de la enfermedad.&lt;/p>
&lt;p>&lt;strong>Ejemplo&lt;/strong>. Utilizando el test del ejemplo anterior en una población de 1000 personas y suponiendo una prevalencia del 1% se tiene&lt;/p>
&lt;p>$$
\begin{array}{|l|cc|}
\hline
\mbox{Test} &amp;amp; E &amp;amp; \overline E\newline
\hline
\mbox{Positivo }+ &amp;amp; 7 &amp;amp; 50 \newline
\mbox{Negativo }- &amp;amp; 3 &amp;amp; 940\newline
\hline
\end{array}
$$&lt;/p>
&lt;p>&lt;img src="img/resultados-test0.01-0.7-0.95.svg" alt="Resultados de un test diagnóstico con una sensibilidad del 70%, una especidficidad del 95% y una prevalencia del 1%">&lt;/p>
&lt;p>Mientras que si la prevalencia es del 10% se tiene&lt;/p>
&lt;p>$$
\begin{array}{|l|cc|}
\hline
\mbox{Test} &amp;amp; E &amp;amp; \overline E\newline
\hline
\mbox{Positivo }+ &amp;amp; 70 &amp;amp; 45 \newline
\mbox{Negativo }- &amp;amp; 30 &amp;amp; 855\newline
\hline
\end{array}
$$&lt;/p>
&lt;p>&lt;img src="img/resultados-test0.1-0.7-0.95.svg" alt="Resultados de un test diagnóstico con una sensibilidad del 70%, una especidficidad del 95% y una prevalencia del 10%">&lt;/p>
&lt;p>Para ver los resultados de un test diagnóstico en función de la prevalencia, la sensibilidad y la especificidad se puede utilizar esta
&lt;a href="http://nube.aprendeconalf.es/shiny/diagnostic-test/" target="_blank" rel="noopener">aplicación para test diagnósticos&lt;/a>&lt;/p>
&lt;h3 id="cuándo-usar-un-test-más-sensible-o-más-específico">Cuándo usar un test más sensible o más específico&lt;/h3>
&lt;p>Una mayor sensibilidad aumenta el número de verdaderos positivos y disminuye el número de falsos negativos, mientras que una mayor especificidad aumenta el número de verdaderos negativos y disminuye el número de falsos positivos. Por tanto, utilizaremos un test más sensible cuando:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>La enfermedad es grave o muy contagiosa y es importante detectarla.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>La enfermedad es curable.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Los falsos positivos no provocan traumas serios.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>Y utilizaremos un test más específico cuando:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>La enfermedad es importante pero difícil o imposible de curar.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Los falsos positivos pueden provocar traumas serios.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>El tratamiento de los falsos positivos puede tener graves consecuencias.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>Tanto la sensibilidad como la especificidad son indicadores de la fiabilidad de un test a priori, es decir, antes de aplicar el test. Una vez que el test se ha aplicado y se conoce su resultado, a la hora de diagnosticar la enfermedad o rechazarla, es mejor utilizar los &lt;em>valores predictivos&lt;/em>.&lt;/p>
&lt;h2 id="valores-predictivos-de-un-test">Valores predictivos de un test&lt;/h2>
&lt;div class="alert alert-def">
&lt;div>
&lt;strong>Definición: Valor predictivo positivo&lt;/strong>&lt;br>
El &lt;em>valor predictivo positivo&lt;/em> de un test diagnóstico es la proporción de personas con la enfermedad entre las personas con resultado positivo en el test,
$$P(E|+) = \frac{VP}{VP+FP}$$
&lt;/div>
&lt;/div>
&lt;div class="alert alert-def">
&lt;div>
&lt;strong>Definición: Valor predictivo negativo&lt;/strong>&lt;br>
El &lt;em>valor predictivo negativo&lt;/em> de un test diagnóstico es la proporción de personas sin la enfermedad entre las personas con resultado negativo en el test,
$$P(\overline{E}|-) = \frac{VN}{VN+FN}$$
&lt;/div>
&lt;/div>
&lt;p>&lt;strong>Ejemplo&lt;/strong>. Siguiendo con el ejemplo anterior y suponiendo una prevalencia del 1%, se tiene&lt;/p>
&lt;p>$$
\begin{array}{|l|cc|}
\hline
\mbox{Test} &amp;amp; E &amp;amp; \overline E\newline
\hline
\mbox{Positivo }+ &amp;amp; 7 &amp;amp; 50 \newline
\mbox{Negativo }- &amp;amp; 3 &amp;amp; 940\newline
\hline
\end{array}
$$&lt;/p>
&lt;p>&lt;img src="img/resultados-test0.01-0.7-0.95.svg" alt="Resultados de un test diagnóstico con una sensibilidad del 70%, una especidficidad del 95% y una prevalencia del 1%">&lt;/p>
&lt;p>Mientras que si la prevalencia es del 10% se tiene&lt;/p>
&lt;p>$$
\begin{array}{|l|cc|}
\hline
\mbox{Test} &amp;amp; E &amp;amp; \overline E\newline
\hline
\mbox{Positivo }+ &amp;amp; 70 &amp;amp; 45 \newline
\mbox{Negativo }- &amp;amp; 30 &amp;amp; 855\newline
\hline
\end{array}
$$&lt;/p>
&lt;p>$$VPP = \frac{7}{7+50} = 0.123$$
$$VPN = \frac{940}{3+940} = 0.997$$&lt;/p>
&lt;p>Mientras que si la prevalencia es del 10% se tiene&lt;/p>
&lt;p>$$
\begin{array}{|l|cc|}
\hline
\mbox{Test} &amp;amp; E &amp;amp; \overline E\newline
\hline
\mbox{Positivo }+ &amp;amp; 70 &amp;amp; 45 \newline
\mbox{Negativo }- &amp;amp; 30 &amp;amp; 855\newline
\hline
\end{array}
$$&lt;/p>
&lt;p>$$VPP = \frac{70}{70+45} = 0.609$$
$$VPN = \frac{855}{30+855} = 0.966$$&lt;/p>
&lt;h3 id="interpretación-de-los-valores-predictivos">Interpretación de los valores predictivos&lt;/h3>
&lt;p>$$
\begin{array}{rcl}
VPP&amp;gt;0.5 &amp;amp; \Rightarrow &amp;amp; \mbox{Diagnosticar la enfermedad}\newline
VPN&amp;gt;0.5 &amp;amp; \Rightarrow &amp;amp; \mbox{Descartar la enfermedad}
\end{array}
$$&lt;/p>
&lt;h2 id="curva-roc">Curva ROC&lt;/h2>
&lt;p>En los test diagnósticos basado en la medición de una variable cuantitativa (como por ejemplo los test de antígenos para la COVID) la sensibilidad y la especificidad dependen el umbral fijado para dar un positivo.&lt;/p>
&lt;p>Para evaluar la fiabilidad de estos tests se suele utilizar la &lt;em>curva ROC&lt;/em>.&lt;/p>
&lt;div class="alert alert-def">
&lt;div>
&lt;strong>Definición: Curva ROC&lt;/strong>&lt;br>
La curva ROC (Receiver Operating Characteristic) de un test diagnóstico es la curva que resulta de representar la razón de verdaderos positivos (sensibilidad) frente a la razón de falsos positivos (1-especificidad) para los diferentes umbrales de positivo del test.
&lt;/div>
&lt;/div>
&lt;p>&lt;img src="img/curva-roc.png" alt="Curva ROC">&lt;/p>
&lt;h3 id="interpretación-de-la-curva-roc">Interpretación de la curva ROC&lt;/h3>
&lt;ul>
&lt;li>Cada punto de la curva corresponde a un umbral para el positivo.&lt;/li>
&lt;li>El mejor test es el que que se sitúa en la esquina superior izquierda de el espacio (sensibilidad 1 y especificidad 1).&lt;/li>
&lt;li>La diagonal representa un test con un diagnóstico aleatorio.&lt;/li>
&lt;/ul>
&lt;h3 id="area-debajo-de-la-curva-roc-auc">Area debajo de la curva ROC (AUC)&lt;/h3>
&lt;p>Para evaluar la fiabilidad de un test diagnóstico independientemente del umbral de positivos se suele medir el area bajo la curva ROC, también conocida como &lt;em>AUC&lt;/em> (&lt;em>area under the curve&lt;/em>). Según del valor de la AUC, se tiene&lt;/p>
&lt;ul>
&lt;li>0.5: Diagnóstico aleatorio.&lt;/li>
&lt;li>[0.5, 0.6): Test malo.&lt;/li>
&lt;li>[0.6, 0.75): Test regular.&lt;/li>
&lt;li>[0.75, 0.9): Test bueno.&lt;/li>
&lt;li>[0.9, 0.97): Test muy bueno.&lt;/li>
&lt;li>[0.97, 1): Test excelente.&lt;/li>
&lt;/ul>
&lt;h3 id="aplicaciones-a-la-covid">Aplicaciones a la COVID&lt;/h3>
&lt;ul>
&lt;li>
&lt;a href="https://www.rcpjournals.org/content/clinmedicine/20/6/e209" target="_blank" rel="noopener">Fiabilidad del diagnóstico por PCR&lt;/a>&lt;/li>
&lt;li>
&lt;a href="https://www.cdc.gov/mmwr/volumes/69/wr/mm695152a3.htm" target="_blank" rel="noopener">Fiabilidad del diagnóstico por el test de antígenos&lt;/a>&lt;/li>
&lt;li>
&lt;a href="https://academic.oup.com/ajcp/article/154/5/575/5898531" target="_blank" rel="noopener">Comparativa de test&lt;/a>&lt;/li>
&lt;li>
&lt;a href="https://www.dosfarma.com/salud/test-analisis/test-antigenos-covid/" target="_blank" rel="noopener">Test comerciales&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>Los test de antígenos son más rápidos que las PCR pero son menos fiables.&lt;/p>
&lt;p>Por un lado son menos sensibles que una prueba de PCR debido a que se se requiere una mayor cantidad de virus en las mucosas nasales o bucales para que se muestre un resultado positivo. Eso limita su efectividad cuando las personas llevan poco tiempo infectadas y el virus está empezando a reproducirse.&lt;/p>
&lt;p>Por otro lado también son menos específicos que la PCR, y por tanto, producen más falsos positivos.&lt;/p>
&lt;h2 id="referencias">Referencias&lt;/h2>
&lt;ul>
&lt;li>
&lt;a href="http://matematicas.uclm.es/cemat/covid19/" target="_blank" rel="noopener">Acción matemática contra el coronavirus&lt;/a>&lt;/li>
&lt;li>
&lt;a href="https://www.repidemicsconsortium.org/" target="_blank" rel="noopener">R Epidemic Consortium (RECON)&lt;/a>&lt;/li>
&lt;li>
&lt;a href="https://cran.r-project.org/doc/contrib/Epicalc_Book.pdf" target="_blank" rel="noopener">Analysis of epidemiological data using R and Epicalc&lt;/a>&lt;/li>
&lt;li>
&lt;a href="https://statsandr.com/blog/top-r-resources-on-covid-19-coronavirus/#coronavirus" target="_blank" rel="noopener">R resources about COVID-19&lt;/a>&lt;/li>
&lt;li>
&lt;a href="http://nube.aprendeconalf.es/shiny/diagnostic-test/" target="_blank" rel="noopener">Aplicación para el análisis de la fiabilidad de test diagnósticos&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>Regresión</title><link>/docencia/estadistica/manual/regresion/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/docencia/estadistica/manual/regresion/</guid><description>&lt;p>Hasta ahora se ha visto como describir el comportamiento de una variable, pero en los fenómenos naturales normalmente aparecen más de una variable que suelen estar relacionadas. Por ejemplo, en un estudio sobre el peso de las personas, deberíamos incluir todas las variables con las que podría tener relación: altura, edad, sexo, dieta, tabaco,
ejercicio físico, etc.&lt;/p>
&lt;p>Para comprender el fenómeno no basta con estudiar cada variable por separado y es preciso un estudio conjunto de todas las variables para ver cómo interactúan y qué relaciones se dan entre ellas. El objetivo de la estadística en este caso es dar medidas del grado y del tipo de relación entre dichas variables.&lt;/p>
&lt;p>Generalmente, en un &lt;em>estudio de dependencia&lt;/em> se considera una &lt;strong>variable dependiente&lt;/strong> $Y$ que se supone relacionada con otras variables $X_1,\ldots,X_n$ llamadas &lt;strong>variables independientes&lt;/strong>.&lt;/p>
&lt;p>El caso más simple es el de una sola variable independiente, y en tal caso se habla de &lt;em>estudio de dependencia simple&lt;/em>. Para más de una
variable independiente se habla de &lt;em>estudio de dependencia múltiple&lt;/em>.&lt;/p>
&lt;p>En este capítulo se verán los estudios de dependencia simple que son más sencillos.&lt;/p>
&lt;h2 id="distribución-de-frecuencias-conjunta">Distribución de frecuencias conjunta&lt;/h2>
&lt;h3 id="frecuencias-conjuntas">Frecuencias conjuntas&lt;/h3>
&lt;p>Al estudiar la dependencia simple entre dos variables $X$ e $Y$, no se pueden estudiar sus distribuciones por separado, sino que hay que estudiar la distribución conjunta de la &lt;strong>variable bidimensional&lt;/strong> $(X,Y)$, cuyos valores son los pares $(x_i,y_j)$ donde el primer elemento es un valor $X$ y el segundo uno de $Y$.&lt;/p>
&lt;div class="alert alert-def">
&lt;div>
&lt;p>&lt;strong>Definición - Frecuencias muestrales conjuntas&lt;/strong>. Dada una muestra de tamaño $n$ de una variable bidimensional $(X,Y)$, para cada valor de la variable $(x_i,y_j)$ observado en la muestra se define&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Frecuencia absoluta&lt;/strong> $n_{ij}$: Es el número de veces que el par $(x_i,y_j)$ aparece en la muestra.&lt;/li>
&lt;li>&lt;strong>Frecuencia relativa&lt;/strong> $f_{ij}$: Es la proporción de veces que el par $(x_i,y_j)$ aparece en la muestra.&lt;/li>
&lt;/ul>
&lt;p>$$f_{ij}=\frac{n_{ij}}{n}$$&lt;/p>
&lt;/div>
&lt;/div>
&lt;div class="alert alert-warning">
&lt;div>
Para las variables bidimensionales no tienen sentido las frecuencias acumuladas.
&lt;/div>
&lt;/div>
&lt;h3 id="distribución-de-frecuencias-bidimensional">Distribución de frecuencias bidimensional&lt;/h3>
&lt;p>Al conjunto de valores de la variable bidimensional y sus respectivas frecuencias muestrales se le denomina &lt;strong>distribución de frecuencias bidimensional&lt;/strong>, y se representa mediante una &lt;strong>tabla de frecuencias bidimensional&lt;/strong>.&lt;/p>
&lt;p>$$\begin{array}{|c|ccccc|}
\hline
X\backslash Y &amp;amp; y_1 &amp;amp; \cdots &amp;amp; y_j &amp;amp; \cdots &amp;amp; y_q\newline
\hline
x_1 &amp;amp; n_{11} &amp;amp; \cdots &amp;amp; n_{1j} &amp;amp; \cdots &amp;amp; n_{1q}\newline
\vdots &amp;amp; \vdots &amp;amp; \vdots &amp;amp; \vdots &amp;amp; \vdots &amp;amp; \vdots\newline
x_i &amp;amp; n_{i1} &amp;amp; \cdots &amp;amp; n_{ij} &amp;amp; \cdots &amp;amp; n_{iq}\newline
\vdots &amp;amp; \vdots &amp;amp; \vdots &amp;amp; \vdots &amp;amp; \vdots &amp;amp; \vdots\newline
x_p &amp;amp; n_{p1} &amp;amp; \cdots &amp;amp; n_{pj} &amp;amp; \cdots &amp;amp; n_{pq}\newline
\hline
\end{array}$$&lt;/p>
&lt;p>&lt;strong>Ejemplo (datos agrupados)&lt;/strong>. La estatura (en cm) y el peso (en Kg) de una muestra de 30 estudiantes es:&lt;/p>
&lt;div style="text-align:center">
(179,85), (173,65), (181,71), (170,65), (158,51), (174,66),&lt;br/>
(172,62), (166,60), (194,90), (185,75), (162,55), (187,78),&lt;br/>
(198,109), (177,61), (178,70), (165,58), (154,50), (183,93),&lt;br/>
(166,51), (171,65), (175,70), (182,60), (167,59), (169,62),&lt;br/>
(172,70), (186,71), (172,54), (176,68),(168,67), (187,80).
&lt;/div>
&lt;p>La tabla de frecuencias bidimensional es&lt;/p>
&lt;p>$$\begin{array}{|c||c|c|c|c|c|c|}
\hline
X/Y &amp;amp; [50,60) &amp;amp; [60,70) &amp;amp; [70,80) &amp;amp; [80,90) &amp;amp; [90,100) &amp;amp; [100,110) \newline
\hline\hline
(150,160] &amp;amp; 2 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \newline
\hline
(160,170] &amp;amp; 4 &amp;amp; 4 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \newline
\hline
(170,180] &amp;amp; 1 &amp;amp; 6 &amp;amp; 3 &amp;amp; 1 &amp;amp; 0 &amp;amp; 0 \newline
\hline
(180,190] &amp;amp; 0 &amp;amp; 1 &amp;amp; 4 &amp;amp; 1 &amp;amp; 1 &amp;amp; 0 \newline
\hline
(190,200] &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 1 &amp;amp; 1 \newline
\hline
\end{array}$$&lt;/p>
&lt;h3 id="diagrama-de-dispersión">Diagrama de dispersión&lt;/h3>
&lt;p>La distribución de frecuencias conjunta de una variable bidimensional puede representarse gráficamente mediante un &lt;strong>diagrama de dispersión&lt;/strong>, donde los datos se representan como una colección de puntos en un plano cartesiano.&lt;/p>
&lt;p>Habitualmente la variable independiente se representa en el eje $X$ y la variable dependiente en el eje $Y$. Por cada par de valores $(x_i,y_j)$ en la muestra se dibuja un punto en el plano con esas coordenadas.&lt;/p>
&lt;img src="../img/regresion/diagrama_dispersion.svg" alt="Diagrama de dispersión" width="300">
&lt;p>El resultado es un conjunto de puntos que se conoce como &lt;em>nube de puntos&lt;/em>.&lt;/p>
&lt;p>&lt;strong>Ejemplo&lt;/strong>. El siguiente diagrama de dispersión representa la distribución conjunta de estaturas y pesos de la muestra anterior.&lt;/p>
&lt;img src="../img/regresion/diagrama_dispersion_estatura_peso.svg" alt="Diagrama de dispersión de estaturas y pesos" width="600">
&lt;div class="alert alert-int">
&lt;div>
El diagrama de dispersión da información visual sobre el tipo de relación entre las variables.&lt;/p>
&lt;img src="../img/regresion/diagrama_dispersion_tipos_relaciones.svg" alt="Diagramas de dispersión de diferentes tipos de relaciones" width="700">
&lt;/div>
&lt;/div>
&lt;h3 id="distribuciones-marginales">Distribuciones marginales&lt;/h3>
&lt;p>A cada una de las distribuciones de las variables que conforman la
variable bidimensional se les llama .&lt;/p>
&lt;p>Las distribuciones marginales se pueden obtener a partir de la tabla de
frecuencias bidimensional, sumando las frecuencias por filas y columnas.&lt;/p>
&lt;p>$$
\begin{array}{|c|ccccc|c|}
\hline
X\backslash Y &amp;amp; y_1 &amp;amp; \cdots &amp;amp; y_j &amp;amp; \cdots &amp;amp; y_q &amp;amp; \color{red}{n_x}\newline
\hline
x_1 &amp;amp; n_{11} &amp;amp; \cdots &amp;amp; n_{1j} &amp;amp; \cdots &amp;amp; n_{1q} &amp;amp; \color{red}{n_{x_1}}\newline
\vdots &amp;amp; \vdots &amp;amp; \vdots &amp;amp; \downarrow + &amp;amp; \vdots &amp;amp; \vdots &amp;amp; \color{red}{\vdots} \newline
x_i &amp;amp; n_{i1} &amp;amp; \stackrel{+}{\rightarrow} &amp;amp; n_{ij} &amp;amp; \stackrel{+}{\rightarrow} &amp;amp; n_{iq} &amp;amp; \color{red}{n_{x_i}}\newline
\vdots &amp;amp; \vdots &amp;amp; \vdots &amp;amp; \downarrow + &amp;amp; \vdots &amp;amp; \vdots &amp;amp; \color{red}{\vdots}\newline
x_p &amp;amp; n_{p1} &amp;amp; \cdots &amp;amp; n_{pj} &amp;amp; \cdots &amp;amp; n_{pq} &amp;amp; \color{red}{n_{x_p}} \newline
\hline
\color{red}{n_y} &amp;amp; \color{red}{n_{y_1}} &amp;amp; \color{red}{\cdots} &amp;amp; \color{red}{n_{y_j}} &amp;amp; \color{red}{\cdots} &amp;amp; \color{red}{n_{y_q}} &amp;amp; n\newline
\hline
\end{array}
$$&lt;/p>
&lt;p>&lt;strong>Ejemplo&lt;/strong>. En el ejemplo anterior de las estaturas y los pesos, las distribuciones marginales son&lt;/p>
&lt;p>$$
\begin{array}{|c||c|c|c|c|c|c|c|}
\hline
X/Y &amp;amp; [50,60) &amp;amp; [60,70) &amp;amp; [70,80) &amp;amp; [80,90) &amp;amp; [90,100) &amp;amp; [100,110) &amp;amp; \color{red}{n_x}\newline
\hline\hline
(150,160] &amp;amp; 2 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; \color{red}{2}\newline
\hline
(160,170] &amp;amp; 4 &amp;amp; 4 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; \color{red}{8}\newline
\hline
(170,180] &amp;amp; 1 &amp;amp; 6 &amp;amp; 3 &amp;amp; 1 &amp;amp; 0 &amp;amp; 0 &amp;amp; \color{red}{11} \newline
\hline
(180,190] &amp;amp; 0 &amp;amp; 1 &amp;amp; 4 &amp;amp; 1 &amp;amp; 1 &amp;amp; 0 &amp;amp; \color{red}{7} \newline
\hline
(190,200] &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 1 &amp;amp; 1 &amp;amp; \color{red}{2}\newline
\hline
\color{red}{n_y} &amp;amp; \color{red}{7} &amp;amp; \color{red}{11} &amp;amp; \color{red}{7} &amp;amp; \color{red}{2} &amp;amp; \color{red}{2} &amp;amp; \color{red}{1} &amp;amp; 30\newline
\hline
\end{array}
$$&lt;/p>
&lt;p>y los estadísticos correspondientes son&lt;/p>
&lt;p>$$
\begin{array}{lllll}
\bar x = 174.67 \mbox{ cm} &amp;amp; \quad &amp;amp; s^2_x = 102.06 \mbox{ cm}^2 &amp;amp; \quad &amp;amp; s_x = 10.1 \mbox{ cm}\newline
\bar y = 69.67 \mbox{ Kg} &amp;amp; &amp;amp; s^2_y = 164.42 \mbox{ Kg}^2 &amp;amp; &amp;amp; s_y = 12.82 \mbox{ Kg}
\end{array}
$$&lt;/p>
&lt;h2 id="covarianza">Covarianza&lt;/h2>
&lt;p>Para analizar la relación entre dos variables cuantitativas es importante hacer un estudio conjunto de las desviaciones respecto de la media de cada variable.&lt;/p>
&lt;img src="../img/regresion/desviaciones_media.svg" alt="Desviaciones de las medias en un diagrama de dispersión" width="600">
&lt;p>Si dividimos la nube de puntos del diagrama de dispersión en 4 cuadrantes centrados en el punto de medias $(\bar x, \bar y)$, el signo de las desviaciones será:&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align:center">&lt;strong>Cuadrante&lt;/strong>&lt;/th>
&lt;th style="text-align:center">$(x_i-\bar x)$&lt;/th>
&lt;th style="text-align:center">$(y_j-\bar y)$&lt;/th>
&lt;th style="text-align:center">$(x_i-\bar x)(y_j-\bar y)$&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align:center">1&lt;/td>
&lt;td style="text-align:center">$+$&lt;/td>
&lt;td style="text-align:center">$+$&lt;/td>
&lt;td style="text-align:center">$+$&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">2&lt;/td>
&lt;td style="text-align:center">$-$&lt;/td>
&lt;td style="text-align:center">$+$&lt;/td>
&lt;td style="text-align:center">$-$&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">3&lt;/td>
&lt;td style="text-align:center">$-$&lt;/td>
&lt;td style="text-align:center">$-$&lt;/td>
&lt;td style="text-align:center">$+$&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">4&lt;/td>
&lt;td style="text-align:center">$+$&lt;/td>
&lt;td style="text-align:center">$-$&lt;/td>
&lt;td style="text-align:center">$-$&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;img src="../img/regresion/cuadrantes_diagrama_dispersion.svg" alt="Cuadrantes de un diagrama de dispersión" width="400">
&lt;p>Si la relación entre las variables es &lt;em>lineal y creciente&lt;/em>, entonces la mayor parte de los puntos estarán en los cuadrantes 1 y 3 y la suma de los productos de desviaciones será positiva.&lt;/p>
&lt;p>$$\sum(x_i-\bar x)(y_j-\bar y) &amp;gt; 0$$&lt;/p>
&lt;img src="../img/regresion/diagrama_dispersion_lineal_creciente.svg" alt="Diagrama de dispersión de una relación lineal creciente" width="500">
&lt;p>Si la relación entre las variables es &lt;em>lineal y decreciente&lt;/em>, entonces la mayor parte de los puntos estarán en los cuadrantes 2 y 4 y la suma de los productos de desviaciones será negativa.&lt;/p>
&lt;p>$$\sum(x_i-\bar x)(y_j-\bar y) = -$$&lt;/p>
&lt;img src="../img/regresion/diagrama_dispersion_lineal_decreciente.svg" alt="Diagrama de dispersión de una relación lineal decreciente" width="500">
&lt;p>Usando el producto de las desviaciones respecto de las medias surge el
siguiente estadístico.&lt;/p>
&lt;div class="alert alert-def">
&lt;div>
&lt;p>&lt;strong>Definición - Covarianza muestral&lt;/strong>. La &lt;em>covarianza muestral&lt;/em> de una variable aleatoria bidimensional $(X,Y)$ se define como el promedio de los productos de las respectivas desviaciones respecto de las medias de $X$ e $Y$.&lt;/p>
&lt;p>$$s_{xy}=\frac{\sum (x_i-\bar x)(y_j-\bar y)n_{ij}}{n}$$&lt;/p>
&lt;/div>
&lt;/div>
&lt;p>También puede calcularse de manera más sencilla mediante la fórmula&lt;/p>
&lt;p>$$s_{xy}=\frac{\sum x_iy_jn_{ij}}{n}-\bar x\bar y.$$&lt;/p>
&lt;div class="alert alert-int">
&lt;div>
&lt;p>La covarianza sirve para estudiar la relación lineal entre dos variables:&lt;/p>
&lt;ul>
&lt;li>Si $s_{xy}&amp;gt;0$ existe una relación lineal creciente.&lt;/li>
&lt;li>Si $s_{xy}&amp;lt;0$ existe una relación lineal decreciente.&lt;/li>
&lt;li>Si $s_{xy}=0$ no existe relación lineal.&lt;/li>
&lt;/ul>
&lt;/div>
&lt;/div>
&lt;p>&lt;strong>Ejemplo&lt;/strong>. Utilizando la tabla de frecuencias bidimensional de la muestra de estaturas y pesos&lt;/p>
&lt;p>$$
\begin{array}{|c||c|c|c|c|c|c|c|}
\hline
X/Y &amp;amp; [50,60) &amp;amp; [60,70) &amp;amp; [70,80) &amp;amp; [80,90) &amp;amp; [90,100) &amp;amp; [100,110) &amp;amp; n_x\newline
\hline\hline
(150,160] &amp;amp; 2 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 2\newline
\hline
(160,170] &amp;amp; 4 &amp;amp; 4 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 8\newline
\hline
(170,180] &amp;amp; 1 &amp;amp; 6 &amp;amp; 3 &amp;amp; 1 &amp;amp; 0 &amp;amp; 0 &amp;amp; 11 \newline
\hline
(180,190] &amp;amp; 0 &amp;amp; 1 &amp;amp; 4 &amp;amp; 1 &amp;amp; 1 &amp;amp; 0 &amp;amp; 7 \newline
\hline
(190,200] &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 1 &amp;amp; 1 &amp;amp; 2\newline
\hline
n_y &amp;amp; 7 &amp;amp; 11 &amp;amp; 7 &amp;amp; 2 &amp;amp; 2 &amp;amp; 1 &amp;amp; 30\newline
\hline
\end{array}
$$&lt;/p>
&lt;p>$$\bar x = 174.67 \mbox{ cm} \qquad \bar y = 69.67 \mbox{ Kg}$$&lt;/p>
&lt;p>la covarianza vale&lt;/p>
&lt;p>$$
\begin{aligned}
s_{xy} &amp;amp;=\frac{\sum x_iy_jn_{ij}}{n}-\bar x\bar y = \frac{155\cdot 55\cdot 2 + 165\cdot 55\cdot 4 + \cdots + 195\cdot 105\cdot 1}{30}-174.67\cdot 69.67 =\newline
&amp;amp; = \frac{368200}{30}-12169.26 = 104.07 \mbox{ cm$\cdot$ Kg}.
\end{aligned}
$$&lt;/p>
&lt;p>Esto indica que existe una relación lineal creciente entre la estatura y el peso.&lt;/p>
&lt;h2 id="regresión">Regresión&lt;/h2>
&lt;p>En muchos casos el objetivo de un estudio no es solo detectar una relación entre dos variables, sino explicarla mediante alguna función matemática $$y=f(x)$$ que permita predecir la variable dependiente para cada valor de la independiente.&lt;/p>
&lt;p>La &lt;strong>regresión&lt;/strong> es la parte de la Estadística encargada de construir esta función, que se conoce como &lt;strong>función de regresión&lt;/strong> o &lt;strong>modelo de regresión&lt;/strong>.&lt;/p>
&lt;h3 id="modelos-de-regresión-simple">Modelos de regresión simple&lt;/h3>
&lt;p>Dependiendo de la forma de función de regresión, existen muchos tipos de
regresión simple. Los más habituales son los que aparecen en la
siguiente tabla:&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align:left">&lt;strong>Modelo&lt;/strong>&lt;/th>
&lt;th style="text-align:center">&lt;strong>Ecuación&lt;/strong>&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align:left">Lineal&lt;/td>
&lt;td style="text-align:center">$y=a+bx$&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">Cuadrático&lt;/td>
&lt;td style="text-align:center">$y=a+bx+cx^2$&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">Cúbico&lt;/td>
&lt;td style="text-align:center">$y=a+bx+cx^2+dx^3$&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">Potencial&lt;/td>
&lt;td style="text-align:center">$y=a\cdot x^b$&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">Exponencial&lt;/td>
&lt;td style="text-align:center">$y=e^{a+bx}$&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">Logarítmico&lt;/td>
&lt;td style="text-align:center">$y=a+b\log x$&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">Inverso&lt;/td>
&lt;td style="text-align:center">$y=a+\frac{b}{x}$&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">Sigmoidal&lt;/td>
&lt;td style="text-align:center">$y=e^{a+\frac{b}{x}}$&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>La elección de un tipo u otro depende de la forma que tenga la nube de puntos del diagrama de dispersión.&lt;/p>
&lt;h3 id="residuos-o-errores-predictivos">Residuos o errores predictivos&lt;/h3>
&lt;p>Una vez elegida la familia de curvas que mejor se adapta a la nube de
puntos, se determina, dentro de dicha familia, la curva que mejor se
ajusta a la distribución, es decir, la función que mejor predice la variable dependiente.&lt;/p>
&lt;p>El objetivo es encontrar la función de regresión que haga mínimas las
distancias entre los valores de la variable dependiente observados en la
muestra, y los predichos por la función de regresión. Estas distancias
se conocen como &lt;em>residuos&lt;/em> o &lt;em>errores predictivos&lt;/em>.&lt;/p>
&lt;div class="alert alert-def">
&lt;div>
&lt;p>&lt;strong>Definición - Residuos o errores predictivos&lt;/strong>. Dado el modelo de regresión $y=f(x)$ para una variable bidimensional $(X,Y)$, el &lt;em>residuo&lt;/em> o &lt;em>error predictivo&lt;/em> de un valor $(x_i,y_j)$ observado en la muestra, es la diferencia entre el valor observado de la variable dependiente $y_j$ y el predicho por la función de regresión para $x_i$,&lt;/p>
&lt;p>$$e_{ij} = y_j-f(x_i).$$&lt;/p>
&lt;/div>
&lt;/div>
&lt;img src="../img/regresion/residuos_y.svg" alt="Residuos de un modelo de regresión" width="600">
&lt;h3 id="ajuste-de-mínimos-cuadrados">Ajuste de mínimos cuadrados&lt;/h3>
&lt;p>Una forma posible de obtener la función de regresión es mediante el método de &lt;em>mínimos cuadrados&lt;/em> que consiste en calcular la función que haga mínima la suma de los cuadrados de los residuos&lt;/p>
&lt;p>$$\sum e_{ij}^2.$$&lt;/p>
&lt;p>En el caso de un modelo de regresión lineal $f(x) = a + bx$, como la recta depende de dos parámetros (el término independiente $a$ y la pendiente $b$), la suma también dependerá de estos parámetros&lt;/p>
&lt;p>$$\theta(a,b) = \sum e_{ij}^2 =\sum (y_j - f(x_i))^2 =\sum (y_j-a-bx_i)^2.$$&lt;/p>
&lt;p>Así pues, todo se reduce a buscar los valores $a$ y $b$ que hacen mínima esta suma.&lt;/p>
&lt;p>Considerando la suma de los cuadrados de los residuos como una función de dos variables $\theta(a,b)$, se pueden calcular los valores de los parámetros del modelo que hacen mínima esta suma derivando e igualando a 0 las derivadas con respecto a $a$ y $b$.&lt;/p>
&lt;p>$$
\begin{aligned}
\frac{\partial \theta(a,b)}{\partial a} &amp;amp;= \frac{\partial \sum (y_j-a-bx_i)^2 }{\partial a} =0\newline
\frac{\partial \theta(a,b)}{\partial b} &amp;amp;= \frac{\partial \sum (y_j-a-bx_i)^2 }{\partial b} =0
\end{aligned}
$$&lt;/p>
&lt;p>Tras resolver el sistema se obtienen los valores&lt;/p>
&lt;p>$$a= \bar y - \frac{s_{xy}}{s_x^2}\bar x \qquad b=\frac{s_{xy}}{s_x^2}$$&lt;/p>
&lt;p>Estos valores hacen mínimos los residuos en $Y$ y por tanto dan la recta
de regresión óptima.&lt;/p>
&lt;h2 id="recta-de-regresión">Recta de regresión&lt;/h2>
&lt;div class="alert alert-def">
&lt;div>
&lt;p>&lt;strong>Definición - Recta de regresión&lt;/strong>. Dada una variable bidimensional $(X,Y)$, la &lt;em>recta de regresión&lt;/em> de $Y$ sobre $X$ es&lt;/p>
&lt;p>$$y = \bar y +\frac{s_{xy}}{s_x^2}(x-\bar x).$$&lt;/p>
&lt;/div>
&lt;/div>
&lt;div class="alert alert-int">
&lt;div>
La recta de regresión de $Y$ sobre $X$ es la recta que hace mínimos los errores predictivos en $Y$, y por tanto es la recta que hará mejores predicciones de $Y$ para cualquier valor de $X$.
&lt;/div>
&lt;/div>
&lt;p>&lt;strong>Ejemplo&lt;/strong>. Utilizando la muestra anterior de estaturas ($X$) y pesos ($Y$) con los siguientes estadísticos&lt;/p>
&lt;p>$$
\begin{array}{lllll}
\bar x = 174.67 \mbox{ cm} &amp;amp; \quad &amp;amp; s^2_x = 102.06 \mbox{ cm}^2 &amp;amp; \quad &amp;amp; s_x = 10.1 \mbox{ cm}\newline
\bar y = 69.67 \mbox{ Kg} &amp;amp; &amp;amp; s^2_y = 164.42 \mbox{ Kg}^2 &amp;amp; &amp;amp; s_y = 12.82 \mbox{ Kg}\newline
&amp;amp; &amp;amp; s_{xy} = 104.07 \mbox{ cm$\cdot$ Kg} &amp;amp; &amp;amp;
\end{array}
$$&lt;/p>
&lt;p>la recta de regresión del peso sobre la estatura es&lt;/p>
&lt;p>$$y = \bar y +\frac{s_{xy}}{s_x^2}(x-\bar x) = 69.67+\frac{104.07}{102.06}(x-174.67) = -108.49 + 1.02 x.$$&lt;/p>
&lt;p>De igual modo, si tomamos la estatura como variable dependiente, la
recta de regresión de la estatura sobre el peso es&lt;/p>
&lt;p>$$x = \bar x +\frac{s_{xy}}{s_y^2}(y-\bar y) = 174.67+\frac{104.07}{164.42}(y-69.67) = +130.78 + 0.63 y.$$&lt;/p>
&lt;div class="alert alert-warning">
&lt;div>
¡Obsérvese que ambas rectas de regresión son diferentes!
&lt;/div>
&lt;/div>
&lt;img src="../img/regresion/rectas_regresion.svg" alt="Rectas de regresión de estaturas y pesos" width="600">
&lt;h3 id="posición-relativa-de-las-rectas-de-regresión">Posición relativa de las rectas de regresión&lt;/h3>
&lt;p>Habitualmente, las rectas de regresión $Y$ sobre $X$ y de $X$ sobre $Y$ no coinciden, pero siempre se cortan en el punto de medias $(\bar x,\bar y)$.&lt;/p>
&lt;p>Si entre las variables la relación lineal es perfecta, entonces ambas rectas coinciden ya que esa recta hace tanto los residuos en $X$ como los residuos en $Y$ nulos.&lt;/p>
&lt;img src="../img/regresion/regresion_lineal_perfecta.svg" alt="Recta de regresión de una relación lineal perfecta" width="500">
&lt;p>Si no hay relación lineal, entonces las ecuaciones de las rectas son constantes e iguales a las respectivas medias,&lt;/p>
&lt;p>$$y = \bar y,\quad x = \bar x,$$&lt;/p>
&lt;p>y se cortan perpendicularmente.&lt;/p>
&lt;img src="../img/regresion/rectas_independencia_lineal.svg" alt="Rectas de regresión de dos variables linealmente independientes" width="500">
&lt;h3 id="coeficiente-de-regresión">Coeficiente de regresión&lt;/h3>
&lt;p>El parámetro más importante de una recta de regresión es su pendiente.&lt;/p>
&lt;div class="alert alert-def">
&lt;div>
&lt;p>&lt;strong>Definición - Coeficiente de regresión&lt;/strong> $b_{yx}$. Dada una variable bidimensional $(X,Y)$, el &lt;em>coeficiente de regresión&lt;/em> de la recta de regresión de $Y$ sobre $X$ es su pendiente,&lt;/p>
&lt;p>$$b_{yx} = \frac{s_{xy}}{s_x^2}$$&lt;/p>
&lt;/div>
&lt;/div>
&lt;div class="alert alert-warning">
&lt;div>
El coeficiente de regresión siempre tiene el mismo signo que la covarianza.
&lt;/div>
&lt;/div>
&lt;div class="alert alert-int">
&lt;div>
Refleja el crecimiento de la variable dependiente en relación a la independiente según la recta de regresión. En concreto da el número de unidades que aumenta o disminuye la variable dependiente por cada unidad que aumenta la variable independiente.
&lt;/div>
&lt;/div>
&lt;p>&lt;strong>Ejemplo&lt;/strong>. En el ejemplo de las estaturas y los pesos, la recta de regresión del
peso sobre la estatura era&lt;/p>
&lt;p>$$y=-108.49 +1.02 x,$$&lt;/p>
&lt;p>de manera que el coeficiente de regresión del peso sobre la estatura es&lt;/p>
&lt;p>$$b_{yx}= 1.02 \mbox{Kg/cm.}$$&lt;/p>
&lt;p>Esto significa que, según la recta de regresión del peso sobre la estatura, por cada cm más de estatura, la persona pesará $1.02$ Kg más.&lt;/p>
&lt;h3 id="predicciones-con-las-rectas-de-regresión">Predicciones con las rectas de regresión&lt;/h3>
&lt;p>Las rectas de regresión, y en general cualquier modelo de regresión, suele utilizarse con fines predictivos.&lt;/p>
&lt;p>&lt;strong>Ejemplo&lt;/strong>. En la muestra de las estaturas y los pesos, si se quiere predecir
el peso de una persona que mide 180 cm, se debe utilizar la recta de regresión del peso sobre la estatura,&lt;/p>
&lt;p>$$y = 1.02 \cdot 180 -108.49 = 75.11 \mbox{ Kg}.$$&lt;/p>
&lt;p>Y si se quiere predecir la estatura de una persona que pesa 79 Kg, se debe utilizar la recta de regresión de la estatura sobre el peso,&lt;/p>
&lt;p>$$x = 0.63\cdot 79+ 130.78 = 180.55 \mbox{ cm}.$$&lt;/p>
&lt;p>&lt;em>Ahora bien, ¿qué fiabilidad tienen estas predicciones?&lt;/em>&lt;/p>
&lt;h2 id="correlación">Correlación&lt;/h2>
&lt;p>Una vez construido un modelo de regresión, para saber si se trata de un buen modelo predictivo, se tiene que analizar el grado de dependencia entre las variables según el tipo de dependencia planteada en el modelo.
De ello se encarga la parte de la estadística conocida como &lt;strong>correlación&lt;/strong>.&lt;/p>
&lt;p>La correlación se basa en el estudio de los residuos: cuanto menores sean éstos, más se ajustará la curva de regresión a los puntos, y más intensa será la correlación.&lt;/p>
&lt;h3 id="varianza-residual-muestral">Varianza residual muestral&lt;/h3>
&lt;p>Una medida de la bondad del ajuste del modelo de regresión es la
&lt;em>varianza residual&lt;/em>.&lt;/p>
&lt;div class="alert alert-def">
&lt;div>
&lt;p>&lt;strong>Definición - Varianza residual muestral&lt;/strong> $s_{ry}^2$. Dado un modelo de regresión simple $y=f(x)$ de una variable bidimensional $(X,Y)$, su &lt;em>varianza residual muestral&lt;/em> es el promedio de los cuadrados de los residuos para los valores de la muestra,&lt;/p>
&lt;p>$$s_{ry}^2 = \frac{\sum e_{ij}^2n_{ij}}{n} = \frac{\sum (y_j - f(x_i))^2n_{ij}}{n}.$$&lt;/p>
&lt;/div>
&lt;/div>
&lt;div class="alert alert-int">
&lt;div>
&lt;p>Cuanto más alejados estén los puntos de la curva de regresión, mayor será la varianza residual y menor la dependencia.&lt;/p>
&lt;p>Cuando la relación lineal es perfecta los residuos se anulan y la varianza residual vale cero. Por contra, cuando no existe relación, los residuos coinciden con las desviaciones de la media, y la varianza residual es igual a la varianza de la variable dependiente.&lt;/p>
&lt;p>$$0\leq s_{ry}^2\leq s_y^2$$&lt;/p>
&lt;/div>
&lt;/div>
&lt;h3 id="descomposición-de-la-variabilidad-total-variabilidad-explicada-y-no-explicada">Descomposición de la variabilidad total: Variabilidad explicada y no explicada&lt;/h3>
&lt;img src="../img/regresion/variation_decomposition.gif" alt="Descomposición de la variabilidad de un modelo de regresión" width="600">
&lt;h3 id="coeficiente-de-determinación">Coeficiente de determinación&lt;/h3>
&lt;p>A partir de la varianza residual se puede definir otro estadístico más sencillo de interpretar.&lt;/p>
&lt;div class="alert alert-def">
&lt;div>
&lt;p>&lt;strong>Definición - Coeficiente de determinación muestral $r^2$&lt;/strong>. Dado un modelo de regresión simple $y=f(x)$ de una variable bidimensional $(X,Y)$, su &lt;em>coeficiente de determinación muestral&lt;/em> es&lt;/p>
&lt;p>$$r^2 = 1- \frac{s_{ry}^2}{s_y^2}$$&lt;/p>
&lt;/div>
&lt;/div>
&lt;div class="alert alert-warning">
&lt;div>
&lt;p>Como la varianza residual puede tomar valores entre 0 y $s_y^2$, se tiene que&lt;/p>
&lt;p>$$0\leq r^2\leq 1$$&lt;/p>
&lt;/div>
&lt;/div>
&lt;div class="alert alert-int">
&lt;div>
&lt;p>Cuanto mayor sea $r^2$, mejor explicará el modelo de regresión la relación entre las variables, en particular:&lt;/p>
&lt;ul>
&lt;li>Si $r^2 =0$ entonces no existe relación del tipo planteado por el modelo.&lt;/li>
&lt;li>Si $r^2=1$ entonces la relación que plantea el modelo es perfecta.&lt;/li>
&lt;/ul>
&lt;/div>
&lt;/div>
&lt;div class="alert alert-warning">
&lt;div>
&lt;p>En el caso de las rectas de regresión, el coeficiente de determinación puede calcularse con esta fórmula&lt;/p>
&lt;p>$$ r^2 = \frac{s_{xy}^2}{s_x^2s_y^2}.$$&lt;/p>
&lt;/div>
&lt;/div>
&lt;div class="spoiler " >
&lt;p>
&lt;a class="btn btn-primary" data-toggle="collapse" href="#spoiler-18" role="button" aria-expanded="false" aria-controls="spoiler-18">
Demostración
&lt;/a>
&lt;/p>
&lt;div class="collapse card " id="spoiler-18">
&lt;div class="card-body">
&lt;p>Cuando el modelo ajustado es la recta de regresión la varianza residual vale&lt;/p>
&lt;p>$$
\begin{aligned}
s_{ry}^2 &amp;amp; = \sum e_{ij}^2f_{ij} = \sum (y_j - f(x_i))^2f_{ij} = \sum \left(y_j - \bar y -\frac{s_{xy}}{s_x^2}(x_i-\bar x) \right)^2f_{ij}=\newline
&amp;amp; = \sum \left((y_j - \bar y)^2 +\frac{s_{xy}^2}{s_x^4}(x_i-\bar x)^2 - 2\frac{s_{xy}}{s_x^2}(x_i-\bar x)(y_j -\bar y)\right)f_{ij} =\newline
&amp;amp; = \sum (y_j - \bar y)^2f_{ij} +\frac{s_{xy}^2}{s_x^4}\sum (x_i-\bar x)^2f_{ij}- 2\frac{s_{xy}}{s_x^2}\sum (x_i-\bar x)(y_j -\bar y)f_{ij}=\newline
&amp;amp; = s_y^2 + \frac{s_{xy}^2}{s_x^4}s_x^2 - 2 \frac{s_{xy}}{s_x^2}s_{xy} = s_y^2 - \frac{s_{xy}^2}{s_x^2}.
\end{aligned}
$$&lt;/p>
&lt;p>y, por tanto, el coeficiente de determinación lineal vale&lt;/p>
&lt;p>$$
\begin{aligned}
r^2 &amp;amp;= 1- \frac{s_{ry}^2}{s_y^2} = 1- \frac{s_y^2 - \frac{s_{xy}^2}{s_x^2}}{s_y^2} = 1 - 1 + \frac{s_{xy}^2}{s_x^2s_y^2} = \frac{s_{xy}^2}{s_x^2s_y^2}.
\end{aligned}
$$&lt;/p>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;p>&lt;strong>Ejemplo&lt;/strong>. En el ejemplo de las estaturas y pesos se tenía&lt;/p>
&lt;p>$$
\begin{array}{lll}
\bar x = 174.67 \mbox{ cm} &amp;amp; \quad &amp;amp; s^2_x = 102.06 \mbox{ cm}^2\newline
\bar y = 69.67 \mbox{ Kg} &amp;amp; &amp;amp; s^2_y = 164.42 \mbox{ Kg}^2\newline
s_{xy} = 104.07 \mbox{ cm$\cdot$ Kg}
\end{array}
$$&lt;/p>
&lt;p>De modo que el coeficiente de determinación lineal vale&lt;/p>
&lt;p>$$r^2 = \frac{s_{xy}^2}{s_x^2s_y^2} = \frac{(104.07 \mbox{ cm\cdot Kg})^2}{102.06 \mbox{ cm}^2 \cdot 164.42 \mbox{ Kg}^2} = 0.65.$$&lt;/p>
&lt;p>Esto indica que la recta de regresión del peso sobre la estatura explica el 65% de la variabilidad del peso, y de igual modo, la recta de regresión de la estatura sobre el peso explica el 65% de la variabilidad de la estatura.&lt;/p>
&lt;h3 id="coeficiente-de-correlación-lineal">Coeficiente de correlación lineal&lt;/h3>
&lt;div class="alert alert-def">
&lt;div>
&lt;p>&lt;strong>Definición - Coeficiente de correlación lineal muestral&lt;/strong>. Dada una variable bidimensional $(X,Y)$, el &lt;em>coeficiente de correlación lineal muestral&lt;/em> es la raíz cuadrada de su coeficiente de determinación lineal, con signo el de la covarianza&lt;/p>
&lt;p>$$r = \sqrt{r^2} = \dfrac{s_{xy}}{s_xs_y}.$$&lt;/p>
&lt;/div>
&lt;/div>
&lt;div class="alert alert-warning">
&lt;div>
&lt;p>Como $r^2$ toma valores entre 0 y 1, $r$ tomará valores entre -1 y 1,&lt;/p>
&lt;p>$$-1\leq r\leq 1$$&lt;/p>
&lt;/div>
&lt;/div>
&lt;div class="alert alert-int">
&lt;div>
&lt;p>El coeficiente de correlación lineal no sólo mide mide el grado de dependencia
lineal sino también su dirección (creciente o decreciente):&lt;/p>
&lt;ul>
&lt;li>Si $r =0$ entonces no existe relación lineal.&lt;/li>
&lt;li>Si $r=1$ entonces existe una relación lineal creciente perfecta.&lt;/li>
&lt;li>Si $r=-1$ entonces existe una relación lineal decreciente perfecta.&lt;/li>
&lt;/ul>
&lt;/div>
&lt;/div>
&lt;p>&lt;strong>Ejemplo&lt;/strong>. En el ejemplo de las estaturas y los pesos se tenía&lt;/p>
&lt;p>$$
\begin{array}{lll}
\bar x = 174.67 \mbox{ cm} &amp;amp; \quad &amp;amp; s^2_x = 102.06 \mbox{ cm}^2\newline
\bar y = 69.67 \mbox{ Kg} &amp;amp; &amp;amp; s^2_y = 164.42 \mbox{ Kg}^2\newline
s_{xy} = 104.07 \mbox{ cm$\cdot$ Kg}
\end{array}
$$&lt;/p>
&lt;p>De manera que el coeficiente de correlación lineal es&lt;/p>
&lt;p>$$r = \frac{s_{xy}}{s_xs_y} = \frac{104.07 \mbox{ cm\cdot Kg}}{10.1 \mbox{ cm} \cdot 12.82 \mbox{ Kg}} = +0.8.$$&lt;/p>
&lt;p>Esto indica que la relación lineal entre el peso y la estatura es fuerte, y además creciente.&lt;/p>
&lt;h3 id="distintos-grados-de-correlación">Distintos grados de correlación&lt;/h3>
&lt;p>Los siguientes diagramas de dispersión muestran modelos de regresión lineales con diferentes grados de correlación.&lt;/p>
&lt;img src="../img/regresion/grados_correlacion.svg" alt="Modelos de regresión lineales con diferentes grados de correlación" width="700">
&lt;h3 id="fiabilidad-de-las-predicciones-de-un-modelo-de-regresión">Fiabilidad de las predicciones de un modelo de regresión&lt;/h3>
&lt;p>Aunque el coeficiente de determinación o el de correlación determinan la bondad de ajuste de un modelo de regresión, existen otros factores que influyen en la fiabilidad de las predicciones de un modelo de regresión:&lt;/p>
&lt;ul>
&lt;li>El coeficiente de determinación: Cuanto mayor sea, menores serán los errores predictivos y mayor la fiabilidad de las predicciones.&lt;/li>
&lt;li>La variabilidad de la población: Cuanto más variable es una población, más difícil es predecir y por tanto menos fiables serán las predicciones.&lt;/li>
&lt;li>El tamaño muestral: Cuanto mayor sea, más información tendremos y, en consecuencia, más fiables serán las predicciones.&lt;/li>
&lt;/ul>
&lt;div class="alert alert-warning">
&lt;div>
Además, hay que tener en cuenta que un modelo de regresión es válido únicamente para el rango de valores observados en la muestra. Fuera de ese rango no hay información del tipo de relación entre las variables, por lo que no deben hacerse predicciones para valores lejos de los observados en la muestra.
&lt;/div>
&lt;/div>
&lt;h2 id="regresión-no-lineal">Regresión no lineal&lt;/h2>
&lt;p>El ajuste de un modelo de regresión no lineal es similar al del modelo lineal y también puede realizarse mediante la técnica de mínimos cuadrados.&lt;/p>
&lt;p>No obstante, en determinados casos un ajuste no lineal puede convertirse en un ajuste lineal mediante una sencilla transformación de alguna de las variables del modelo.&lt;/p>
&lt;h3 id="transformación-de-modelos-de-regresión-no-lineales">Transformación de modelos de regresión no lineales&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>Logarítmico&lt;/strong>: Un modelo logarítmico $y = a+b \log x$ se convierte en un modelo lineal haciendo el cambio $t=\log x$:&lt;/p>
&lt;p>$$y=a+b\log x = a+bt.$$&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Exponencial&lt;/strong>: Un modelo exponencial $y = ae^{bx}$ se convierte en un modelo
lineal haciendo el cambio $z = \log y$:&lt;/p>
&lt;p>$$z = \log y = \log(ae^{bx}) = \log a + \log e^{bx} = a^\prime +bx.$$&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Potencial&lt;/strong>: Un modelo potencial $y = ax^b$ se convierte en un modelo lineal
haciendo los cambios $t=\log x$ y $z=\log y$:&lt;/p>
&lt;p>$$z = \log y = \log(ax^b) = \log a + b \log x = a^\prime+bt.$$&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Inverso&lt;/strong>: Un modelo inverso $y = a+b/x$ se convierte en un modelo lineal
haciendo el cambio $t=1/x$:&lt;/p>
&lt;p>$$y = a + b(1/x) = a+bt.$$&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Sigmoidal&lt;/strong>: Un modelo curva S $y = e^{a+b/x}$ se convierte en un modelo lineal haciendo los cambios $t=1/x$ y $z=\log y$:&lt;/p>
&lt;p>$$z = \log y = \log (e^{a+b/x}) = a+b(1/x) = a+bt.$$&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h3 id="relación-exponencial">Relación exponencial&lt;/h3>
&lt;p>&lt;strong>Ejemplo&lt;/strong> El número de bacterias de un cultivo evoluciona con el tiempo según la
siguiente tabla:&lt;/p>
&lt;p>$$\begin{array}{c|c}
\mbox{Horas} &amp;amp; \mbox{Bacterias}\newline
\hline
0 &amp;amp; 25 \newline
1 &amp;amp; 28 \newline
2 &amp;amp; 47\newline
3 &amp;amp; 65 \newline
4 &amp;amp; 86\newline
5 &amp;amp; 121\newline
6 &amp;amp; 190\newline
7 &amp;amp; 290\newline
8 &amp;amp; 362
\end{array}
$$&lt;/p>
&lt;p>El diagrama de dispersión asociado es&lt;/p>
&lt;img src="../img/regresion/evolucion_bacterias.svg" alt="Diagrama de dispersión de la evolución de bacterias" width="500">
&lt;p>Si realizamos un ajuste lineal, obtenemos la siguiente recta de regresión&lt;/p>
&lt;p>$$\mbox{Bacterias} = -30.18+41,27,\mbox{Horas, with } r^2=0.85.$$&lt;/p>
&lt;img src="../img/regresion/regresion_lineal_bacterias.svg" alt="Regresión lineal de la evolución de un cultivo de bacterias" width="500">
&lt;p>&lt;em>¿Es un buen modelo?&lt;/em>&lt;/p>
&lt;p>Aunque el modelo lineal no es malo, de acuerdo al diagrama de dispersión es más lógico construir un modelo exponencial o cuadrático.&lt;/p>
&lt;p>Para construir el modelo exponencial $y = ae^{bx}$ hay que realizar la
transformación $z=\log y$, es decir, aplicar el logaritmo a la variable dependiente.&lt;/p>
&lt;p>$$\begin{array}{c|c|c}
\mbox{Horas} &amp;amp; \mbox{Bacterias} &amp;amp; \mbox{$\log$(Bacterias)}\newline
\hline
0 &amp;amp; 25 &amp;amp; 3.22\newline
1 &amp;amp; 28 &amp;amp; 3.33\newline
2 &amp;amp; 47 &amp;amp; 3.85\newline
3 &amp;amp; 65 &amp;amp; 4.17\newline
4 &amp;amp; 86 &amp;amp; 4.45\newline
5 &amp;amp; 121 &amp;amp; 4.80\newline
6 &amp;amp; 190 &amp;amp; 5.25\newline
7 &amp;amp; 290 &amp;amp; 5.67\newline
8 &amp;amp; 362 &amp;amp; 5.89
\end{array}
$$&lt;/p>
&lt;img src="../img/regresion/evolucion_log_bacterias.svg" alt="Diagrama de dispersión de la evolución del logarítmo de las bacterias de un cultivo" width="500">
&lt;p>Ahora sólo queda calcular la recta de regresión del logaritmo de Bacterias sobre Horas&lt;/p>
&lt;p>$$\mbox{Log Bacterias} = 3.107 + 0.352, \mbox{Horas}.$$&lt;/p>
&lt;p>Y, deshaciendo el cambio de variable, se obtiene el modelo exponencial&lt;/p>
&lt;p>$$\mbox{Bacterias} = e^{3.107+0.352,\textrm{Horas}}, \mbox{ con } r^2=0.99.$$&lt;/p>
&lt;img src="../img/regresion/regresion_exponencial_bacterias.svg" alt="Regresión exponencial de la evolución de las bacterias de un cultivo" width="500">
&lt;p>Como se puede apreciar, el modelo exponencial se ajusta mucho mejor que el modelo lineal.&lt;/p>
&lt;h2 id="riesgos-de-la-regresión">Riesgos de la regresión&lt;/h2>
&lt;h3 id="la-falta-de-ajuste-no-significa-independencia">La falta de ajuste no significa independencia&lt;/h3>
&lt;p>Es importante señalar que cada modelo de regresión tiene su propio coeficiente de determinación.&lt;/p>
&lt;div class="alert alert-warning">
&lt;div>
Así, un coeficiente de determinación cercano a cero significa que no existe relación entre las variables del tipo planteado por el modelo, pero &lt;em>eso no quiere decir que las variables sean independientes&lt;/em>, ya que puede existir relación de otro tipo.
&lt;/div>
&lt;/div>
&lt;img src="../img/regresion/regresion_lineal_relacion_cuadratica.svg" alt="Modelo de regresión lineal en una relación cuadrática" width="500">
&lt;img src="../img/regresion/regresion_cuadratica.svg" alt="Modelo de regresión cuadrático en una relación cuadrática" width="500">
&lt;h3 id="datos-atípicos-en-regresión">Datos atípicos en regresión&lt;/h3>
&lt;p>Los &lt;em>datos atípicos&lt;/em> en un estudio de regresión son los puntos que claramente no siguen la tendencia del resto de los puntos en el diagrama de dispersión, incluso si los valores del par no se pueden considerar atípicos para cada variable por separado.&lt;/p>
&lt;img src="../img/regresion/diagrama_dispersion_con_datos_atipicos.svg" alt="Diagrama de dispersión con un dato atípico" width="500">
&lt;div class="alert alert-warning">
&lt;div>
Los datos atípicos en regresión suelen provocar cambios drásticos en el ajuste de los modelos de regresión, y por tanto, habrá que tener mucho cuidado con ellos.
&lt;/div>
&lt;/div>
&lt;div class="center">
&lt;img src="../img/regresion/regresion_lineal_con_datos_atipicos.svg" alt="Modelo de regresión lineal con datos atípicos" width="500"> &lt;img src="../img/regresion/regresion_lineal_sin_datos_atipicos.svg" alt="Modelo de regresión lineal sin datos atípicos" width="500">
&lt;/div>
&lt;h3 id="la-paradoja-de-simpson">La paradoja de Simpson&lt;/h3>
&lt;p>A veces, una tendencia desaparece o incluso se revierte cuando se divide la muestra en grupos de acuerdo a una variable cualitativa que está relacionada con la variable dependiente.
Esto se conoce como la &lt;em>paradoja de Simpson&lt;/em>.&lt;/p>
&lt;p>&lt;strong>Ejemplo&lt;/strong>. El siguiente diagrama de dispersión muestra una relación inversa entre entre las horas de estudio preparando un examen y la nota del examen.&lt;/p>
&lt;div class="center">
&lt;img src="../img/regresion/paradoja_simpson_1.svg" alt="Paradoja de Simpson. Relación inversa entre las horas de estudio para un examen y la nota obtenida." width="500">
&lt;/div>
&lt;p>Pero si se divide la muestra en dos grupos (buenos y malos estudiantes) se obtienen diferentes tendencias y ahora la relación es directa, lo que tiene más lógica.&lt;/p>
&lt;div class="center">
&lt;img src="../img/regresion/paradoja_simpson_2.svg" alt="Paradoja de Simpson. Relación directa entre las horas de estudio para un examen y la nota obtenida." width="500">
&lt;/div></description></item><item><title>Ejercicios de Regresión Lineal</title><link>/docencia/estadistica/ejercicios/regresion-lineal/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/docencia/estadistica/ejercicios/regresion-lineal/</guid><description>&lt;h2 id="ejercicio-1">Ejercicio 1&lt;/h2>
&lt;p>Titulación: Todas&lt;/p>
&lt;p>Al realizar un estudio de regresión lineal de dos variables X e Y, se sabe que
las rectas de regresión se cortan en el punto (5,15), que el coeficiente de
correlación lineal es -0.85 y que la pendiente de la recta de regresión de X
sobre Y es el doble que la de la recta de Y sobre X. Se pide:&lt;/p>
&lt;ol>
&lt;li>Calcular las ecuaciones de las rectas de regresión de Y sobre X y de X sobre Y.&lt;/li>
&lt;li>¿Qué porcentaje de la variabilidad de Y queda explicado por el modelo lineal?&lt;/li>
&lt;/ol>
&lt;p>&lt;strong>SOLUCIÓN&lt;/strong>&lt;/p>
&lt;iframe src="http://www.slideshare.net/slideshow/embed_code/35214709" width="640" height="449" frameborder="0" marginwidth="0" marginheight="0" scrolling="no">&lt;/iframe>
&lt;iframe src="//www.youtube.com/embed/XKrRifxAfDg" width="640" height="360" frameborder="0"> &lt;/iframe></description></item><item><title>Relaciones entre variables cualitativas</title><link>/docencia/estadistica/manual/relaciones-cualitativas/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/docencia/estadistica/manual/relaciones-cualitativas/</guid><description>&lt;p>Los modelos de regresión vistos sólo pueden aplicarse cuando las variables estudiadas son cuantitativas.&lt;/p>
&lt;p>Cuando se desea estudiar la relación entre atributos, tanto ordinales como nominales, es necesario recurrir a otro tipo de medidas de relación o de asociación. En este capítulo veremos tres de ellas:&lt;/p>
&lt;ul>
&lt;li>Coeficiente de correlación de Spearman.&lt;/li>
&lt;li>Coeficiente chi-cuadrado.&lt;/li>
&lt;li>Coeficiente de contingencia.&lt;/li>
&lt;/ul>
&lt;h2 id="relación-entre-atributos-ordinales">Relación entre atributos ordinales&lt;/h2>
&lt;h3 id="coeficiente-de-correlación-de-spearman">Coeficiente de correlación de Spearman&lt;/h3>
&lt;p>Cuando se tengan atributos ordinales es posible ordenar sus categorías y asignarles valores ordinales, de manera que se puede calcular el coeficiente de correlación lineal entre estos valores ordinales.&lt;/p>
&lt;p>Esta medida de relación entre el orden que ocupan las categorías de dos atributos ordinales se conoce como &lt;em>coeficiente de correlación de Spearman&lt;/em>.&lt;/p>
&lt;div class="alert alert-def">
&lt;div>
&lt;p>&lt;strong>Definición - Coeficiente de correlación de Spearman&lt;/strong>. Dada una muestra de $n$ individuos en los que se han medido dos atributos ordinales $X$ e $Y$, el coeficiente de correlación de Spearman se define como&lt;/p>
&lt;p>$$r_s = 1-\frac{6\sum d_i^2}{n(n^2-1)}$$&lt;/p>
&lt;p>donde $d_i$ es la diferencia entre el valor ordinal de $X$ y el valor ordinal de $Y$ del individuo $i$.&lt;/p>
&lt;/div>
&lt;/div>
&lt;div class="alert alert-warning">
&lt;div>
&lt;p>Como el coeficiente de correlación de Spearman es en el fondo el coeficiente de correlación lineal aplicado a los órdenes, se tiene que&lt;/p>
&lt;p>$$-1\leq r_s\leq 1,$$&lt;/p>
&lt;/div>
&lt;/div>
&lt;div class="alert alert-int">
&lt;div>
&lt;ul>
&lt;li>Si $r_s=0$ entonces no existe relación entre los atributos ordinales.&lt;/li>
&lt;li>Si $r_s=1$ entonces los órdenes de los atributos coinciden y existe una relación directa perfecta.&lt;/li>
&lt;li>Si $r_s=-1$ entonces los órdenes de los atributos están invertidos y existe una relación inversa perfecta.&lt;/li>
&lt;/ul>
&lt;p>En general, cuanto más cerca de $1$ o $-1$ esté $r_s$, mayor será la relación entre los atributos, y cuanto más cerca de $0$, menor será la relación.
&lt;/div>
&lt;/div>
&lt;p>&lt;strong>Ejemplo&lt;/strong>. Una muestra de 5 alumnos realizaron dos tareas diferentes $X$ e $Y$, y se ordenaron de acuerdo a la destreza que manifestaron en cada tarea:&lt;/p>
&lt;p>$$
\begin{array}{lrrrr}
\hline
\text{Alumnos} &amp;amp; X &amp;amp; Y &amp;amp; d_i &amp;amp; d_i^2\newline
\hline
\text{Alumno 1} &amp;amp; 2 &amp;amp; 3 &amp;amp; -1 &amp;amp; 1\newline
\text{Alumno 2} &amp;amp; 5 &amp;amp; 4 &amp;amp; 1 &amp;amp; 1 \newline
\text{Alumno 3} &amp;amp; 1 &amp;amp; 2 &amp;amp; -1 &amp;amp; 1\newline
\text{Alumno 4} &amp;amp; 3 &amp;amp; 1 &amp;amp; 2 &amp;amp; 4\newline
\text{Alumno 5} &amp;amp; 4 &amp;amp; 5 &amp;amp; -1 &amp;amp; 1\newline
\hline
\sum &amp;amp; &amp;amp; &amp;amp; 0 &amp;amp; 8 \newline
\hline
\end{array}
$$&lt;/p>
&lt;p>El coeficiente de correlación de Spearman para esta muestra es&lt;/p>
&lt;p>$$r_s = 1-\frac{6\sum d_i^2}{n(n^2-1)} = 1- \frac{6\cdot 8}{5(5^2-1)} = 0.6.$$&lt;/p>
&lt;p>Esto indica que existe bastante relación directa entre las destrezas manifestadas en ambas tareas.&lt;/p>
&lt;p>&lt;strong>Ejemplo con empates&lt;/strong>.&lt;/p>
&lt;p>Cuando hay empates en el orden de las categorías se atribuye a cada valor empatado la media aritmética de los valores ordinales que hubieran ocupado esos individuos en caso de no haber estado empatados.&lt;/p>
&lt;p>Si en el ejemplo anterior los alumnos 4 y 5 se hubiesen comportado igual en la primera tarea y los alumnos 3 y 4 se hubiesen comportado igual en la segunda tarea, entonces se tendría&lt;/p>
&lt;p>$$
\begin{array}{lrrrr}
\hline
\text{Alumnos} &amp;amp; X &amp;amp; Y &amp;amp; d_i &amp;amp; d_i^2\newline
\hline
\text{Alumno 1} &amp;amp; 2 &amp;amp; 3 &amp;amp; -1 &amp;amp; 1\newline
\text{Alumno 2} &amp;amp; 5 &amp;amp; 4 &amp;amp; 1 &amp;amp; 1 \newline
\text{Alumno 3} &amp;amp; 1 &amp;amp; 1.5 &amp;amp; -0.5 &amp;amp; 0.25\newline
\text{Alumno 4} &amp;amp; 3.5 &amp;amp; 1.5 &amp;amp; 2 &amp;amp; 4\newline
\text{Alumno 5} &amp;amp; 3.5 &amp;amp; 5 &amp;amp; -1.5 &amp;amp; 2.25\newline
\hline
\sum &amp;amp; &amp;amp; &amp;amp; 0 &amp;amp; 8.5 \newline
\hline
\end{array}
$$&lt;/p>
&lt;p>El coeficiente de correlación de Spearman para esta muestra es&lt;/p>
&lt;p>$$r_s = 1-\frac{6\sum d_i^2}{n(n^2-1)} = 1- \frac{6\cdot 8.5}{5(5^2-1)} = 0.58.$$&lt;/p>
&lt;h2 id="relación-entre-atributos-nominales">Relación entre atributos nominales&lt;/h2>
&lt;p>Cuando se quiere estudiar la relación entre atributos nominales no tiene sentido calcular el coeficiente de correlación de Spearman ya que las categorías no pueden ordenarse.&lt;/p>
&lt;p>Para estudiar la relación entre atributos nominales se utilizan medidas basadas en las frecuencias de la tabla de frecuencias bidimensional, que para atributos se suele llamar &lt;em>tabla de contingencia&lt;/em>.&lt;/p>
&lt;p>&lt;strong>Ejemplo&lt;/strong>. En un estudio para ver si existe relación entre el sexo y el hábito de fumar se ha tomado una muestra de 100 personas. La tabla de contingencia resultante es&lt;/p>
&lt;p>$$
\begin{array}{|l|rr|r|}
\hline
\text{Sexo}\backslash\text{Fuma} &amp;amp; \text{Si} &amp;amp; \text{No} &amp;amp; n_i\newline
\hline
\text{Mujer} &amp;amp; 12 &amp;amp; 28 &amp;amp; 40 \newline
\text{Hombre} &amp;amp; 26 &amp;amp; 34 &amp;amp; 60 \newline
\hline
n_j &amp;amp; 38 &amp;amp; 62 &amp;amp; 100\newline
\hline
\end{array}
$$&lt;/p>
&lt;p>Si el hábito de fumar fuese independiente del sexo, la proporción de fumadores en mujeres y hombres sería la misma.&lt;/p>
&lt;h3 id="frecuencias-teóricas-o-esperadas">Frecuencias teóricas o esperadas&lt;/h3>
&lt;p>En general, dada una tabla de contingencia para dos atributos $X$ e $Y$,&lt;/p>
&lt;p>$$
\begin{array}{|c|ccccc|c|}
\hline
X\backslash Y &amp;amp; y_1 &amp;amp; \cdots &amp;amp; y_j &amp;amp; \cdots &amp;amp; y_q &amp;amp; n_x\newline
\hline
x_1 &amp;amp; n_{11} &amp;amp; \cdots &amp;amp; n_{1j} &amp;amp; \cdots &amp;amp; n_{1q} &amp;amp; n_{x_1}\newline
\vdots &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots &amp;amp; \vdots \newline
x_i &amp;amp; n_{i1} &amp;amp; \cdots &amp;amp; n_{ij} &amp;amp; \cdots &amp;amp; n_{iq} &amp;amp; n_{x_i}\newline
\vdots &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots &amp;amp; \vdots\newline
x_p &amp;amp; n_{p1} &amp;amp; \cdots &amp;amp; n_{pj} &amp;amp; \cdots &amp;amp; n_{pq} &amp;amp; n_{x_p} \newline
\hline
n_y &amp;amp; n_{y_1} &amp;amp; \cdots &amp;amp; n_{y_j} &amp;amp; \cdots &amp;amp; n_{y_q} &amp;amp; n\newline
\hline
\end{array}
$$&lt;/p>
&lt;p>si $X$ e $Y$ fuesen independientes, para cualquier valor $y_j$ se tendría&lt;/p>
&lt;p>$$\frac{n_{1j}}{n_{x_1}} = \frac{n_{2j}}{n_{x_2}} = \cdots = \frac{n_{pj}}{n_{x_p}} = \frac{n_{1j}+\cdots
+n_{pj}}{n_{x_1}+\cdots+n_{x_p}} = \frac{n_{y_j}}{n},$$ de donde se deduce que $$n_{ij} = \frac{n_{x_i}n_{y_j}}{n}.$$&lt;/p>
&lt;p>A esta última expresión se le llama &lt;em>frecuencia teórica&lt;/em> o &lt;em>frecuencia esperada&lt;/em> del par $(x_i,y_j)$.&lt;/p>
&lt;h3 id="coeficiente-chi-cuadrado-chi2">Coeficiente chi-cuadrado $\chi^2$&lt;/h3>
&lt;p>Es posible estudiar la relación entre dos atributos $X$ e $Y$ comparando las frecuencias reales con las esperadas:&lt;/p>
&lt;div class="alert alert-def">
&lt;div>
&lt;p>&lt;strong>Definición - Coeficiente Chi-cuadrado $\chi^2$&lt;/strong>. Dada una muestra de tamaño $n$ en la que se han medido dos atributos $X$ e $Y$, se define el coeficiente $\chi^2$ como&lt;/p>
&lt;p>$$\chi^2 = \sum_{i=1}^p\sum_{j=1}^q \frac{\left(n_{ij}-\frac{n_{x_i}n_{y_j}}{n}\right)^2}{\frac{n_{x_i}n_{y_j}}{n}},$$&lt;/p>
&lt;p>donde $p$ es el número de categorías de $X$ y $q$ el número de categorías de $Y$.&lt;/p>
&lt;/div>
&lt;/div>
&lt;div class="alert alert-warning">
&lt;div>
&lt;p>Por ser suma de cuadrados, se cumple que&lt;/p>
&lt;p>$$\chi^2 \geq 0.$$&lt;/p>
&lt;/div>
&lt;/div>
&lt;div class="alert alert-int">
&lt;div>
$\chi^2=0$ cuando los atributos son independientes, y crece a medida que aumenta la dependencia entre las variables.
&lt;/div>
&lt;/div>
&lt;p>&lt;strong>Ejemplo&lt;/strong>. Siguiendo con el ejemplo anterior, a partir de la tabla de contingencia&lt;/p>
&lt;p>$$
\begin{array}{|l|rr|r|}
\hline
\text{Sexo}\backslash\text{Fuma} &amp;amp; \text{Si} &amp;amp; \text{No} &amp;amp; n_i\newline
\hline
\text{Mujer} &amp;amp; 12 &amp;amp; 28 &amp;amp; 40 \newline
\text{Hombre} &amp;amp; 26 &amp;amp; 34 &amp;amp; 60 \newline
\hline
n_j &amp;amp; 38 &amp;amp; 62 &amp;amp; 100\newline
\hline
\end{array}
$$&lt;/p>
&lt;p>se obtienen las siguientes frecuencias esperadas&lt;/p>
&lt;p>$$
\renewcommand{\arraystretch}{1.5}
\begin{array}{|l|rr|r|}
\hline
\mbox{Sexo\backslash Fuma} &amp;amp; \mbox{Si} &amp;amp; \mbox{No} &amp;amp; n_i\newline
\hline
\text{Mujer} &amp;amp; \frac{40\cdot 38}{100}=15.2 &amp;amp; \frac{40\cdot 62}{100}=24.8 &amp;amp; 40 \newline
\text{Hombre} &amp;amp; \frac{60\cdot 38}{100}=22.8 &amp;amp; \frac{60\cdot 62}{100}=37.2 &amp;amp; 60 \newline
\hline
n_j &amp;amp; 38 &amp;amp; 62 &amp;amp; 100\newline
\hline
\end{array}
$$&lt;/p>
&lt;p>y el coeficiente $\chi^2$ vale&lt;/p>
&lt;p>$$\chi^2 = \frac{(12-15.2)^2}{15.2}+\frac{(28-24.8)^2}{24.8}+\frac{(26-22.8)^2}{22.8}+\frac{(34-37.2)^2}{37.2} = 1.81.$$&lt;/p>
&lt;p>Esto indica que no existe gran relación entre el sexo y el hábito de fumar.&lt;/p>
&lt;h3 id="coeficiente-de-contingencia">Coeficiente de contingencia&lt;/h3>
&lt;p>El coeficiente $\chi^2$ depende del tamaño muestral, ya que al multiplicar por una constante las frecuencias de todas las casillas, su valor queda multiplicado por dicha constante, lo que podría llevarnos al equívoco de pensar que ha aumentado la relación, incluso cuando las proporciones se mantienen. En consecuencia el valor de $\chi^2$ no está acotado superiormente y resulta difícil de interpretar.&lt;/p>
&lt;p>Para evitar estos problemas se suele utilizar el siguiente estadístico.&lt;/p>
&lt;div class="alert alert-def">
&lt;div>
&lt;p>&lt;strong>Definición - Coeficiente de contingencia&lt;/strong>. Dada una muestra de tamaño $n$ en la que se han medido dos atributos $X$ e $Y$, se define el &lt;em>coeficiente de contingencia&lt;/em> como&lt;/p>
&lt;p>$$C = \sqrt{\frac{\chi^2}{\chi^2+n}}$$&lt;/p>
&lt;/div>
&lt;/div>
&lt;div class="alert alert-warning">
&lt;div>
&lt;p>De la definición anterior se deduce que&lt;/p>
&lt;p>$$0\leq C\leq 1,$$&lt;/p>
&lt;/div>
&lt;/div>
&lt;div class="alert alert-int">
&lt;div>
$C=0$ cuando las variables son independientes, y crece a medida que aumenta la relación.
&lt;/div>
&lt;/div>
&lt;div class="alert alert-warning">
&lt;div>
Aunque $C$ nunca puede llegar a valer 1, se puede demostrar que para tablas de contingencia con $k$ filas y $k$ columnas, el valor máximo que puede alcanzar $C$ es $\sqrt{(k-1)/k}$.
&lt;/div>
&lt;/div>
&lt;p>&lt;strong>Ejemplo&lt;/strong>. En el ejemplo anterior el coeficiente de contingencia vale&lt;/p>
&lt;p>$$C = \sqrt{\frac{1.81}{1.81+100}} = 0.13.$$&lt;/p>
&lt;p>Como se trata de una tabla de contingencia de $2\times 2$, el valor máximo que podría tomar el coeficiente de contingencia es $\sqrt{(2-1)/2}=\sqrt{1/2}=0.707$, y como $0.13$ está bastante lejos de este valor, se puede concluir que no existe demasiada relación entre el hábito de fumar y el sexo.&lt;/p></description></item><item><title>Probabilidad</title><link>/docencia/estadistica/manual/probabilidad/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/docencia/estadistica/manual/probabilidad/</guid><description>&lt;p>La estadística descriptiva permite describir el comportamiento y las relaciones entre las variables en la muestra, pero no permite sacar conclusiones sobre el resto de la población.&lt;/p>
&lt;p>Ha llegado el momento de dar el salto de la muestra a la población y pasar de la estadística descriptiva a la inferencia estadística, y el puente que lo permite es la &lt;strong>Teoría de la Probabilidad&lt;/strong>.&lt;/p>
&lt;p>Hay que tener en cuenta que el conocimiento que se puede obtener de la población a partir de la muestra es limitado, y que para obtener conclusiones válidas para la población la muestra debe ser
representativa de esta. Por esta razón, para garantizar la representatividad de la muestra, esta debe extraerse &lt;em>aleatoriamente&lt;/em>, es decir, al &lt;em>azar&lt;/em>.&lt;/p>
&lt;p>La teoría de la probabilidad precisamente se encarga de controlar ese azar para saber hasta qué punto son fiables las conclusiones obtenidas a partir de una muestra.&lt;/p>
&lt;h2 id="experimentos-y-sucesos-aleatorios">Experimentos y sucesos aleatorios&lt;/h2>
&lt;h3 id="experimentos-aleatorios">Experimentos aleatorios&lt;/h3>
&lt;p>El estudio de una característica en una población se realiza a través de experimentos aleatorios.&lt;/p>
&lt;div class="alert alert-def">
&lt;div>
&lt;p>&lt;strong>Definición - Experimento aleatorio&lt;/strong>. Un &lt;em>experimento aleatorio&lt;/em> es un experimento que cumple dos condiciones:&lt;/p>
&lt;ol>
&lt;li>El conjunto de posibles resultados es conocido.&lt;/li>
&lt;li>No se puede predecir con absoluta certeza el resultado del experimento.&lt;/li>
&lt;/ol>
&lt;/div>
&lt;/div>
&lt;p>&lt;strong>Ejemplo&lt;/strong>. Un ejemplo típico de experimentos aleatorios son los juegos
de azar. El lanzamiento de un dado, por ejemplo, es un experimento
aleatorio ya que:&lt;/p>
&lt;ul>
&lt;li>Se conoce el conjunto posibles de resultados $\{1,2,3,4,5,6\}$.&lt;/li>
&lt;li>Antes de lanzar el dado, es imposible predecir con absoluta certeza el valor que saldrá.&lt;/li>
&lt;/ul>
&lt;p>Otro ejemplo de experimento aleatorio sería la selección de un individuo de una población al azar y la determinación de su grupo sanguíneo.&lt;/p>
&lt;p>En general, la obtención de cualquier muestra mediante procedimientos aleatorios será un experimento
aleatorio.&lt;/p>
&lt;h3 id="espacio-muestral">Espacio muestral&lt;/h3>
&lt;div class="alert alert-def">
&lt;div>
&lt;strong>Definición - Espacio muestral&lt;/strong>. Al conjunto $\Omega$ de todos los posibles resultados de un
experimento aleatorio se le llama &lt;em>espacio muestral&lt;/em>.
&lt;/div>
&lt;/div>
&lt;p>Algunos ejemplos de espacios muestrales son:&lt;/p>
&lt;ul>
&lt;li>Lanzamiento de una moneda: $\Omega=\{c,x\}$.&lt;/li>
&lt;li>Lanzamiento de un dado: $\Omega=\{1,2,3,4,5,6\}$.&lt;/li>
&lt;li>Grupo sanguíneo de un individuo seleccionado al azar:
$\Omega=\{\mbox{A},\mbox{B},\mbox{AB},\mbox{0}\}$.&lt;/li>
&lt;li>Estatura de un individuo seleccionado al azar:
$\Omega=\mathbb{R}^+$.&lt;/li>
&lt;/ul>
&lt;h3 id="diagrama-de-árbol">Diagrama de árbol&lt;/h3>
&lt;p>En experimentos donde se mide más de una variable, la determinación del espacio muestral puede resultar compleja. En tales casos es recomendable utilizar un para construir el espacio muestral.&lt;/p>
&lt;p>En un diagrama de árbol cada variable se representa en un nivel del árbol y cada posible valor de la variable como una rama.&lt;/p>
&lt;p>&lt;strong>Ejemplo&lt;/strong> El siguiente diagrama de árbol representa el espacio muestral de un experimento aleatorio en el que se mide el sexo y el grupo sanguineo de un individuo al azar.&lt;/p>
&lt;img src="../img/probabilidad/espacio_muestral.svg" alt="Diagrama de árbol del espacio muestral del sexo y el grupo sanguineo" width="500">
&lt;h3 id="sucesos-aleatorios">Sucesos aleatorios&lt;/h3>
&lt;div class="alert alert-def">
&lt;div>
&lt;strong>Definición - Suceso aleatorio&lt;/strong>. Un &lt;em>suceso aleatorio&lt;/em> es cualquier subconjunto del espacio muestral $\Omega$ de un experimento aleatorio.
&lt;/div>
&lt;/div>
&lt;p>Existen distintos tipos de sucesos:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Suceso imposible&lt;/strong>: Es el suceso vacío $\emptyset$. Este suceso nunca ocurre.&lt;/li>
&lt;li>&lt;strong>Sucesos elementales&lt;/strong>: Son los sucesos formados por un solo elemento.&lt;/li>
&lt;li>&lt;strong>Sucesos compuestos&lt;/strong>: Son los sucesos formados por dos o más elementos.&lt;/li>
&lt;li>&lt;strong>Suceso seguro&lt;/strong>: Es el suceso que contiene el propio espacio muestral $\Omega$. Este suceso siempre ocurre.&lt;/li>
&lt;/ul>
&lt;h2 id="teoría-de-conjuntos">Teoría de conjuntos&lt;/h2>
&lt;h3 id="espacio-de-sucesos">Espacio de sucesos&lt;/h3>
&lt;div class="alert alert-def">
&lt;div>
&lt;strong>Definición - Espacio de sucesos&lt;/strong>. Dado un espacio muestral $\Omega$ de un experimento aleatorio, el conjunto formado por todos los posibles sucesos de $\Omega$ se llama &lt;em>espacio de sucesos de $\Omega$&lt;/em> y se denota $\mathcal{P}(\Omega)$.
&lt;/div>
&lt;/div>
&lt;p>&lt;strong>Ejemplo&lt;/strong>. Dado el espacio muestral $\Omega=\{a,b,c\}$, su espacio de sucesos es&lt;/p>
&lt;p>$$\mathcal{P}(\Omega)=\left\{\emptyset, \{a\},\{b\},\{c\},\{a,b\},\{a,c\},\{b,c\},\{a,b,c\}\right\}$$&lt;/p>
&lt;h3 id="operaciones-entre-sucesos">Operaciones entre sucesos&lt;/h3>
&lt;p>Puesto que los sucesos son conjuntos, por medio de la teoría de
conjuntos se pueden definir las siguientes operaciones entre sucesos:&lt;/p>
&lt;ul>
&lt;li>Unión.&lt;/li>
&lt;li>Intersección.&lt;/li>
&lt;li>Complementario.&lt;/li>
&lt;li>Diferencia.&lt;/li>
&lt;/ul>
&lt;h3 id="unión-de-sucesos">Unión de sucesos&lt;/h3>
&lt;div class="alert alert-def">
&lt;div>
&lt;p>&lt;strong>Definición - Suceso unión&lt;/strong>. Dados dos sucesos $A,B\subseteq \Omega$, se llama &lt;em>suceso unión&lt;/em> de $A$ y $B$, y se denota $A\cup B$, al suceso formado por los elementos de $A$ junto a los elementos de $B$, es decir,&lt;/p>
&lt;p>$$A\cup B = \{x\,|\, x\in A\textrm{ o }x\in B\}.$$&lt;/p>
&lt;/div>
&lt;/div>
&lt;img src="../img/probabilidad/union.svg" alt="Union de dos sucesos" width="300">
&lt;p>El suceso unión $A\cup B$ ocurre siempre que ocurre $A$ &lt;span style="color:red;">o&lt;/span> $B$.&lt;/p>
&lt;h3 id="intersección-de-sucesos">Intersección de sucesos&lt;/h3>
&lt;div class="alert alert-def">
&lt;div>
&lt;p>&lt;strong>Definición - Suceso intersección&lt;/strong>. Dados dos sucesos $A,B\subseteq \Omega$, se llama &lt;em>suceso intersección&lt;/em> de $A$ y $B$, y se denota $A\cap B$, al suceso formado por los elementos comunes de $A$ y $B$, es decir,&lt;/p>
&lt;p>$$A\cap B = \{x\,|\, x\in A\textrm{ y }x\in B\}.$$&lt;/p>
&lt;/div>
&lt;/div>
&lt;img src="../img/probabilidad/interseccion.svg" alt="Intersección de dos sucesos" width="300">
&lt;p>El suceso intersección $A\cap B$ ocurre siempre que ocurren $A$ &lt;span style="color:red;">y&lt;/span> $B$.&lt;/p>
&lt;p>Diremos que dos sucesos son &lt;strong>incompatibles&lt;/strong> si su intersección es vacía.&lt;/p>
&lt;h3 id="contrario-de-un-suceso">Contrario de un suceso&lt;/h3>
&lt;div class="alert alert-def">
&lt;div>
&lt;p>&lt;strong>Definición - Suceso contrario&lt;/strong>. Dado suceso $A\subseteq \Omega$, se llama &lt;em>suceso contrario o complementario&lt;/em> de $A$, y se denota $\overline A$, al suceso formado por los elementos de $\Omega$ que no pertenecen a $A$, es decir,&lt;/p>
&lt;p>$$\overline A = \{x\,|\, x\not\in A\}.$$&lt;/p>
&lt;/div>
&lt;/div>
&lt;img src="../img/probabilidad/contrario.svg" alt="Contrario de un suceso" width="300">
&lt;p>El suceso contrario $\overline A$ ocurre siempre que &lt;span style="color:red;">no&lt;/span> ocurre $A$.&lt;/p>
&lt;h3 id="diferencia-de-sucesos">Diferencia de sucesos&lt;/h3>
&lt;div class="alert alert-def">
&lt;div>
&lt;p>&lt;strong>Definición - Suceso diferencia&lt;/strong>. Dados dos sucesos $A,B\subseteq \Omega$, se llama &lt;em>suceso diferencia&lt;/em> de $A$ y $B$, y se denota $A-B$, al suceso formado por los elementos de $A$ que no pertenecen a $B$, es decir,&lt;/p>
&lt;p>$$A-B = \{x\,|\, x\in A\mbox{ y }x\not\in B\} = A \cap \overline B.$$&lt;/p>
&lt;/div>
&lt;/div>
&lt;img src="../img/probabilidad/diferencia.svg" alt="Diferencia de sucesos" width="300">
&lt;p>El suceso diferencia $A-B$ ocurre siempre que ocurre $A$ pero no ocurre $B$, y también puede expresarse como $A\cap \bar B$.&lt;/p>
&lt;p>&lt;strong>Ejemplo&lt;/strong>. Dado el espacio muestral correspondiente al lanzamiento de un dado
$\Omega=\{1,2,3,4,5,6\}$ y los sucesos $A=\{2,4,6\}$ y $B=\{1,2,3,4\}$,&lt;/p>
&lt;ul>
&lt;li>La unión de $A$ y $B$ es $A\cup B=\{1,2,3,4,6\}$.&lt;/li>
&lt;li>La intersección de $A$ y $B$ es $A\cap B=\{2,4\}$.&lt;/li>
&lt;li>El contrario de $A$ es $\overline A=\{1,3,5\}$.&lt;/li>
&lt;li>Los eventos $A$ y $\overline A$ son incompatibles.&lt;/li>
&lt;li>La diferencia de $A$ y $B$ es $A-B=\{6\}$, y la diferencia de $B$ y $A$ es $B-A=\{1,3\}$.&lt;/li>
&lt;/ul>
&lt;h3 id="álgebra-de-sucesos">Álgebra de sucesos&lt;/h3>
&lt;p>Dados los sucesos $A,B,C\in \mathcal{P}(\Omega)$, se cumplen las
siguientes propiedades:&lt;/p>
&lt;ol>
&lt;li>$A\cup A=A$, $A\cap A=A$ (idempotencia).&lt;/li>
&lt;li>$A\cup B=B\cup A$, $A\cap B = B\cap A$ (conmutativa).&lt;/li>
&lt;li>$(A\cup B)\cup C = A\cup (B\cup C)$, $(A\cap B)\cap C = A\cap (B\cap C)$ (asociativa).&lt;/li>
&lt;li>$(A\cup B)\cap C = (A\cap C)\cup (B\cap C)$, $(A\cap B)\cup C = (A\cup C)\cap (B\cup C)$ (distributiva).&lt;/li>
&lt;li>$A\cup \emptyset=A$, $A\cap E=A$ (elemento neutro).&lt;/li>
&lt;li>$A\cup E=E$, $A\cap \emptyset=\emptyset$ (elemento absorbente).&lt;/li>
&lt;li>$A\cup \overline A = E$, $A\cap \overline A= \emptyset$ (elemento simétrico complementario).&lt;/li>
&lt;li>$\overline{\overline A} = A$ (doble contrario).&lt;/li>
&lt;li>$\overline{A\cup B} = \overline A\cap \overline B$, $\overline{A\cap B} = \overline A\cup \overline B$ (leyes de Morgan).&lt;/li>
&lt;li>$A\cap B\subseteq A\cup B$.&lt;/li>
&lt;/ol>
&lt;h2 id="definición-de-probabilidad">Definición de probabilidad&lt;/h2>
&lt;h3 id="definición-clásica-de-probabilidad">Definición clásica de probabilidad&lt;/h3>
&lt;div class="alert alert-def">
&lt;div>
&lt;p>Dado un espacio muestral $\Omega$ de un experimento aleatorio donde todos los elementos de $\Omega$ son equiprobables, la &lt;em>probabilidad&lt;/em> de un suceso $A\subseteq \Omega$ es el cociente entre el número de elementos de $A$ y el número de elementos de $\Omega$&lt;/p>
&lt;p>$$P(A) = \frac{|A|}{|\Omega|} = \frac{\mbox{nº casos favorables a A}}{\mbox{nº casos posibles}}$$&lt;/p>
&lt;/div>
&lt;/div>
&lt;p>Esta definición es ampliamente utilizada, aunque tiene importantes
restricciones:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Es necesario que todos los elementos del espacio muestral tengan la
misma probabilidad de ocurrir (&lt;em>equiprobabilidad&lt;/em>).&lt;/p>
&lt;/li>
&lt;li>
&lt;p>No puede utilizarse con espacios muestrales infinitos, o de los que
no se conoce el número de casos posibles.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>&lt;span class="alert">&lt;em>¡Ojo! Esto no se cumple en muchos experimentos
aleatorios reales.&lt;/em>&lt;/span>&lt;/p>
&lt;p>&lt;strong>Ejemplo&lt;/strong>. Dado el espacio muestral correspondiente al lanzamiento de un dado $\Omega=\{1,2,3,4,5,6\}$ y el suceso $A=\{2,4,6\}$, la probabilidad de $A$ es&lt;/p>
&lt;p>$$P(A) = \frac{|A|}{|\Omega|} = \frac{3}{6} = 0.5.$$&lt;/p>
&lt;p>Sin embargo, si se considera el espacio muestral correspondiente a observar el grupo sanguíneo de un individuo al azar, $\Omega=\{O,A,B,AB\}$, no se puede usar la definición clásica de probabilidad para calcular la probabilidad de que tenga grupo sanguíneo $A$,&lt;/p>
&lt;p>$$P(A) \neq \frac{|A|}{|\Omega|} = \frac{1}{4} = 0.25,$$&lt;/p>
&lt;p>ya que los grupos sanguíneos no son igualmente probables en las poblaciones humanas.&lt;/p>
&lt;h3 id="definición-frecuentista-de-probabilidad">Definición frecuentista de probabilidad&lt;/h3>
&lt;div class="alert alert-theo">
&lt;div>
&lt;strong>Teorema - Ley de los grandes números&lt;/strong>.Cuando un experimento aleatorio se repite un gran número de veces, las frecuencias relativas de los sucesos del experimento tienden a estabilizarse en torno a cierto número, que es precisamente su probabilidad.
&lt;/div>
&lt;/div>
&lt;p>De acuerdo al teorema anterior, podemos dar la siguiente definición&lt;/p>
&lt;div class="alert alert-def">
&lt;div>
&lt;p>&lt;strong>Definición - Probabilidad frecuentista&lt;/strong>. Dado un espacio muestral $\Omega$ de un experimento aleatorio
reproducible, la &lt;em>probabilidad&lt;/em> de un suceso $A\subseteq \Omega$ es la frecuencia relativa del suceso $A$ en infinitas repeticiones del experimento&lt;/p>
&lt;p>$$P(A) = lim_{n\rightarrow \infty}\frac{n_{A}}{n}$$&lt;/p>
&lt;/div>
&lt;/div>
&lt;p>Aunque esta definición es muy útil en experimentos científicos reproducibles, también tiene serios inconvenientes, ya que&lt;/p>
&lt;ul>
&lt;li>Sólo se calcula una aproximación de la probabilidad real.&lt;/li>
&lt;li>La repetición del experimento debe ser en las mismas condiciones.&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Ejemplo&lt;/strong>. Dado el espacio muestral correspondiente al lanzamiento de una moneda $\Omega=\{C,X\}$, si después de lanzar la moneda 100 veces obtenemos 54 caras, entonces la probabilidad de $C$ es aproximadamente&lt;/p>
&lt;p>$$P(C) = \frac{n_C}{n} = \frac{54}{100} = 0.54.$$&lt;/p>
&lt;p>Si se considera el espacio muestral correspondiente a observar el grupo sanguíneo de un individuo al azar, $\Omega=\{O,A,B,AB\}$, si se toma una muestra aleatoria de 1000 personas y se observa que 412 tienen grupo sanguíneo $A$, entonces la probabilidad del grupo sanguíneo $A$ es aproximadamente&lt;/p>
&lt;p>$$P(A) = \frac{n_A}{n} = \frac{412}{1000} = 0.412.$$&lt;/p>
&lt;h3 id="definición-axiomática-de-probabilidad">Definición axiomática de probabilidad&lt;/h3>
&lt;div class="alert alert-def">
&lt;div>
&lt;p>&lt;strong>Definición - Probabilidad (Kolmogórov)&lt;/strong>.Dado un espacio muestral $\Omega$ de un experimento aleatorio, una función de &lt;em>probabilidad&lt;/em> es una aplicación que asocia a cada suceso $A\subseteq \Omega$ un número real $P(A)$, conocido como probabilidad de $A$, que cumple los siguientes axiomas:&lt;/p>
&lt;ol>
&lt;li>
&lt;p>La probabilidad de un suceso cualquiera es positiva o nula,
$$P(A)\geq 0.$$&lt;/p>
&lt;/li>
&lt;li>
&lt;p>La probabilidad del suceso seguro es igual a la unidad,
$$P(\Omega)=1.$$&lt;/p>
&lt;/li>
&lt;li>
&lt;p>La probabilidad de la unión de dos sucesos incompatibles
($A\cap B=\emptyset$) es igual a la suma de las probabilidades de
cada uno de ellos,
$$P(A\cup B) = P(A)+P(B).$$&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;/div>
&lt;h3 id="consecuencias-de-los-axiomas-de-probabilidad">Consecuencias de los axiomas de probabilidad&lt;/h3>
&lt;p>A partir de los axiomas de la definición de probabilidad se pueden
deducir los siguientes resultados:&lt;/p>
&lt;ol>
&lt;li>
&lt;p>$P(\overline A) = 1-P(A)$.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>$P(\emptyset)= 0$.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Si $A\subseteq B$ entonces $P(A)\leq P(B)$.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>$P(A) \leq 1$.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Si $A$ y $B$ son sucesos compatibles, es decir, su intersección no es vacía, entonces&lt;/p>
&lt;p>$$P(A\cup B)= P(A) + P(B) - P(A\cap B).$$&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Si el suceso $A$ está compuesto por los sucesos elementales
$e_1,e_2,&amp;hellip;,e_n$, entonces&lt;/p>
&lt;p>$$P(A)=\sum_{i=1}^n P(e_i).$$&lt;/p>
&lt;/li>
&lt;/ol>
&lt;div class="spoiler " >
&lt;p>
&lt;a class="btn btn-primary" data-toggle="collapse" href="#spoiler-12" role="button" aria-expanded="false" aria-controls="spoiler-12">
Demostración
&lt;/a>
&lt;/p>
&lt;div class="collapse card " id="spoiler-12">
&lt;div class="card-body">
&lt;ol>
&lt;li>
&lt;p>$\overline A = \Omega \Rightarrow P(A\cup \overline A) = P(\Omega) \Rightarrow P(A)+P(\overline A) = 1 \Rightarrow P(\overline A)=1-P(A)$.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>$\emptyset = \overline \Omega \Rightarrow P(\emptyset) = P(\overline \Omega) = 1-P(\Omega) = 1-1 = 0.$&lt;/p>
&lt;/li>
&lt;li>
&lt;p>$B = A\cup (B-A)$. Como $A$ y $B-A$ son incompatibles, $P(B) = P(A\cup (B-A)) = P(A)+P(B-A) \geq P(A).$&lt;/p>
&lt;p>Si pensamos en probabilidades como áreas, es fácil de ver gráficamente,
&lt;img src="../img/probabilidad/probabilidad_inclusion.svg" alt="Probabilidad de un suceso incluido en otro" width="300">&lt;/p>
&lt;/li>
&lt;li>
&lt;p>$A\subseteq \Omega \Rightarrow P(A)\leq P(\Omega)=1.$&lt;/p>
&lt;/li>
&lt;li>
&lt;p>$A=(A-B)\cup (A\cap B)$. Como $A-B$ y $A\cap B$ son incompatibles, $P(A)=P(A-B)+P(A\cap B) \Rightarrow P(A-B)=P(A)-P(A\cap B)$.&lt;/p>
&lt;p>Si pensamos en probabilidades como áreas, es fácil de ver gráficamente,&lt;/p>
&lt;img src="../img/probabilidad/probabilidad_diferencia.svg" alt="Probabilidad de la diferencia de dos sucesos" width="300">
&lt;/li>
&lt;li>
&lt;p>$A\cup B= (A-B) \cup (B-A) \cup (A\cap B)$. Como $A-B$, $B-A$ y $A\cap B$ son incompatibles, $P(A\cup
B)=P(A-B)+P(B-A)+P(A\cap B) = P(A)-P(A\cap B)+P(B)-P(A\cap B)+P(A\cap B)= P(A)+P(B)-P(A\cup B)$.&lt;/p>
&lt;p>Si pensamos en probabilidades como áreas, es fácil de ver gráficamente,&lt;/p>
&lt;img src="../img/probabilidad/probabilidad_union.svg" alt="Probabilidad de la unión de dos sucesos" width="300">
&lt;/li>
&lt;li>
&lt;p>$A=\{e_1,\cdots,e_n\} = \{e_1\}\cup \cdots \cup \{e_n\} \Rightarrow$ $P(A)=P(\{e_1\}\cup \cdots \cup \{e_n\}) = P(\{e_1\})+ \cdots P(\{e_n\}).$&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;h3 id="interpretación-de-la-probabilidad">Interpretación de la probabilidad&lt;/h3>
&lt;p>Como ha quedado claro en los axiomas anteriores, la probabilidad de un evento $A$ es un número real $P(A)$ que está siempre entre 0 y 1.&lt;/p>
&lt;p>En cierto modo, este número expresa la verosimilitud del evento, es decir, la confianza que hay en que ocurra $A$ en el experimento. Por tanto, también nos da una medida de la incertidumbre sobre el suceso.&lt;/p>
&lt;ul>
&lt;li>
&lt;p>La mayor incertidumbre corresponde a $P(A)=0.5$ (Es tan probable que ocurra $A$ como que no ocurra).&lt;/p>
&lt;/li>
&lt;li>
&lt;p>La menor incertidumbre corresponde a $P(A)=1$ ($A$ sucederá con absoluta certeza) y $P(A)=0$ ($A$ no sucederá con absoluta certeza).&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>Cuando $P(A)$ está más próximo a 0 que a 1, la confianza en que no ocurra $A$ es mayor que la de que ocurra $A$. Por el contrario, cuando $P(A)$ está más próximo a 1 que a 0, la confianza en que ocurra
$A$ es mayor que la de que no ocurra $A$.&lt;/p>
&lt;h2 id="probabilidad-condicionada">Probabilidad condicionada&lt;/h2>
&lt;h3 id="experimentos-condicionados">Experimentos condicionados&lt;/h3>
&lt;p>En algunas ocasiones, es posible que tengamos alguna información sobre el experimento antes de su realización. Habitualmente esa información se da en forma de un suceso $B$ del mismo espacio muestral que sabemos que es cierto antes de realizar el experimento.&lt;/p>
&lt;p>En tal caso se dice que el suceso $B$ es un suceso &lt;em>condicionante&lt;/em>, y la probabilidad de otro suceso $A$ se conoce como y se expresa $$P(A|B).$$&lt;/p>
&lt;p>Esto debe leerse como &lt;em>probabilidad de $A$ dado $B$&lt;/em> o &lt;em>probabilidad de $A$ bajo la condición de $B$&lt;/em>.&lt;/p>
&lt;p>Los condicionantes suelen cambiar el espacio muestral del experimento y por tanto las probabilidades de sus sucesos.&lt;/p>
&lt;p>&lt;strong>Ejemplo&lt;/strong>. Supongamos que tenemos una muestra de 100 hombres y 100 mujeres con las siguientes frecuencias&lt;/p>
&lt;p>$$
\begin{array}{|c|c|c|}
\hline
&amp;amp; \mbox{No fumadores} &amp;amp; \mbox{Fumadores} \newline
\hline
\mbox{Mujeres} &amp;amp; 80 &amp;amp; 20 \newline
\hline
\mbox{Hombres} &amp;amp; 60 &amp;amp; 40 \newline
\hline
\end{array}
$$&lt;/p>
&lt;p>Entonces, usando la definición frecuentista de probabilidad, la probabilidad de que una persona elegida al azar sea fumadora es&lt;/p>
&lt;p>$$P(\mbox{Fumadora})= \frac{60}{200}=0.3.$$&lt;/p>
&lt;p>Sin embargo, si se sabe que la persona elegida es mujer, entonces la muestra se reduce a la primera fila, y la probabilidad de ser fumadora es&lt;/p>
&lt;p>$$P(\mbox{Fumadora}|\mbox{Mujer})=\frac{20}{100}=0.2.$$&lt;/p>
&lt;h3 id="probabilidad-condicionada-1">Probabilidad condicionada&lt;/h3>
&lt;div class="alert alert-def">
&lt;div>
&lt;p>&lt;strong>Definición - Probabilidad condicionada&lt;/strong>. Dado un espacio muestral $\Omega$ de un experimento aleatorio, y dos dos sucesos $A,B\subseteq \Omega$, la probabilidad de $A$ &lt;em>condicionada&lt;/em> por $B$ es&lt;/p>
&lt;p>$$P(A|B) = \frac{P(A\cap B)}{P(B)},$$&lt;/p>
&lt;p>siempre y cuando, $P(B)\neq 0$.&lt;/p>
&lt;/div>
&lt;/div>
&lt;p>Esta definición permite calcular probabilidades sin tener que alterar el espacio muestral original del experimento.&lt;/p>
&lt;p>&lt;strong>Ejemplo&lt;/strong>. En el ejemplo anterior&lt;/p>
&lt;p>$$P(\mbox{Fumadora}|\mbox{Mujer})= \frac{P(\mbox{Fumadora}\cap \mbox{Mujer})}{P(\mbox{Mujer})} = \frac{20/200}{100/200}=\frac{20}{100}=0.2.$$&lt;/p>
&lt;h3 id="probabilidad-del-suceso-intersección">Probabilidad del suceso intersección&lt;/h3>
&lt;p>A partir de la definición de probabilidad condicionada es posible obtener la fórmula para calcular la probabilidad de la intersección de dos sucesos.&lt;/p>
&lt;p>$$P(A\cap B) = P(A)P(B|A) = P(B)P(A|B).$$&lt;/p>
&lt;p>&lt;strong>Ejemplo&lt;/strong>. En una población hay un 30% de fumadores y se sabe que el 40% de los fumadores tiene cáncer de pulmón. La probabilidad de que una persona elegida al azar sea fumadora y tenga cáncer de pulmón es&lt;/p>
&lt;p>$$P(\mbox{Fumadora}\cap \mbox{Cáncer})= P(\mbox{Fumadora})P(\mbox{Cáncer}|\mbox{Fumadora}) = 0.3\times 0.4 = 0.12.$$&lt;/p>
&lt;h3 id="independencia-de-sucesos">Independencia de sucesos&lt;/h3>
&lt;p>En ocasiones, la ocurrencia del suceso condicionante no cambia la
probabilidad original del suceso principal.&lt;/p>
&lt;div class="alert alert-def">
&lt;div>
&lt;p>&lt;strong>Definición - Sucesos independientes&lt;/strong>. Dado un espacio muestral $\Omega$ de un experimento aleatorio, dos
sucesos $A,B\subseteq \Omega$ son &lt;em>independientes&lt;/em> si la probabilidad de $A$ no se ve alterada al condicionar por $B$, y viceversa, es decir,&lt;/p>
&lt;p>$$P(A|B) = P(A) \quad \mbox{and} \quad P(B|A)=P(B),$$&lt;/p>
&lt;p>si $P(A)\neq 0$ y $P(B)\neq 0$.&lt;/p>
&lt;/div>
&lt;/div>
&lt;p>Esto significa que la ocurrencia de uno evento no aporta información relevante para cambiar la incertidumbre sobre el otro.&lt;/p>
&lt;p>Cuando dos eventos son independientes, la probabilidad de su intersección es igual al producto de sus probabilidades,&lt;/p>
&lt;p>$$P(A\cap B) = P(A)P(B).$$&lt;/p>
&lt;h2 id="espacio-probabilístico">Espacio probabilístico&lt;/h2>
&lt;div class="alert alert-def">
&lt;div>
&lt;p>&lt;strong>Definición - Espacio probabilístico&lt;/strong>. Un &lt;em>espacio probabilístico&lt;/em> de un experimento aleatorio es una terna $(\Omega,\mathcal{F},P)$ donde&lt;/p>
&lt;ul>
&lt;li>$\Omega$ es el espacio muestral del experimento.&lt;/li>
&lt;li>$\mathcal{F}$ es un un conjunto de sucesos del experimento.&lt;/li>
&lt;li>$P$ es una función de probabilidad.&lt;/li>
&lt;/ul>
&lt;/div>
&lt;/div>
&lt;p>Si conocemos la probabilidad de todos los elementos de $\Omega$, entonces podemos calcular la probabilidad de cualquier suceso en $\mathcal{F}$ y se puede construir fácilmente el espacio probabilístico.&lt;/p>
&lt;h3 id="construcción-del-espacio-probabilístico">Construcción del espacio probabilístico&lt;/h3>
&lt;p>Para determinar la probabilidad de cada suceso elemental se puede utilizar un diagrama de árbol, mediante las siguientes reglas:&lt;/p>
&lt;ol>
&lt;li>
&lt;p>Para cada nodo del árbol, etiquetar la rama que conduce hasta él con la probabilidad de que la variable en ese nivel tome el valor del nodo, condicionada por los sucesos correspondientes a sus nodos
antecesores en el árbol.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>La probabilidad de cada suceso elemental en las hojas del árbol es el producto de las probabilidades de las ramas que van desde la raíz a la hoja del árbol.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;img src="../img/probabilidad/espacio_probabilistico.svg" alt="Diagrama de árbol de un espacio probabilístico" width="600">
&lt;h3 id="árboles-de-probabilidad-con-variables-dependientes">Árboles de probabilidad con variables dependientes&lt;/h3>
&lt;p>&lt;strong>Ejemplo&lt;/strong>. Sea una población en la que el 30% de las personas fuman, y que la incidencia del cáncer de pulmón en fumadores es del 40% mientras que en los no fumadores es del 10%.&lt;/p>
&lt;p>El espacio probabilístico del experimento aleatorio que consiste en elegir una persona al azar y medir las variables Fumar y Cáncer de pulmón se muestra a continuación.&lt;/p>
&lt;img src="../img/probabilidad/espacio_probabilistico_fumar_cancer.svg" alt="Diagrama de árbol del espacio probabilístico de fumar y tener cáncer de pulmón" width="550">
&lt;h3 id="árboles-de-probabilidad-con-variables-independientes">Árboles de probabilidad con variables independientes&lt;/h3>
&lt;p>&lt;strong>Ejemplo&lt;/strong> El árbol de probabilidad asociado al experimento aleatorio que consiste en el lanzamiento de dos monedas se muestra a continuación.&lt;/p>
&lt;img src="../img/probabilidad/espacio_probabilistico_monedas.svg" alt="Diágrama de árbol del espacio probabilístico del lanzamiento de dos monedas" width="550">
&lt;h3 id="árboles-de-probabilidad-con-variables-independientes-1">Árboles de probabilidad con variables independientes&lt;/h3>
&lt;p>&lt;strong>Ejemplo&lt;/strong>. Dada una población en la que hay un 40% de hombres y un 60% de mujeres, el experimento aleatorio que consiste en tomar una muestra aleatoria de tres personas tiene el árbol de probabilidad que se muestra a continuación.&lt;/p>
&lt;img src="../img/probabilidad/espacio_probabilistico_muestra.svg" alt="Diagrama de árbol del espacio probabilístico del sexo de tres individuos elegidos al azar" width="600">
&lt;h2 id="teorema-de-la-probabilidad-total">Teorema de la probabilidad total&lt;/h2>
&lt;h3 id="sistema-completo-de-sucesos">Sistema completo de sucesos&lt;/h3>
&lt;p>Una colección de sucesos $A_1,A_2,\ldots,A_n$ de un mismo espacio muestral $\Omega$ es un &lt;em>sistema completo&lt;/em> si cumple las siguientes condiciones:&lt;/p>
&lt;ol>
&lt;li>
&lt;p>La unión de todos es el espacio muestral:
$A_1\cup \cdots\cup A_n =\Omega$.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Son incompatibles dos a dos: $A_i\cap A_j = \emptyset$
$\forall i\neq j$.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;img src="../img/probabilidad/particion_espacio_muestral.svg" alt="Partición del espacio muestral en un sistema completo de sucesos" width="300">
&lt;p>En realidad un sistema completo de sucesos es una partición del espacio muestral de acuerdo a algún atributo, como por ejemplo el sexo o el grupo sanguíneo.&lt;/p>
&lt;h3 id="teorema-de-la-probabilidad-total-1">Teorema de la probabilidad total&lt;/h3>
&lt;p>Conocer las probabilidades de un determinado suceso en cada una de las partes de un sistema completo puede ser útil para calcular su probabilidad.&lt;/p>
&lt;div class="alert alert-def">
&lt;div>
&lt;p>&lt;strong>Definición - Teorema de la probabilidad total&lt;/strong>. Dado un sistema completo de sucesos $A_1,\ldots,A_n$ y un suceso $B$ de un espacio muestral $\Omega$, la probabilidad de cualquier suceso $B$ del espacio muestral se puede calcular mediante la fórmula&lt;/p>
&lt;p>$$P(B) = \sum_{i=1}^n P(A_i\cap B) = \sum_{i=1}^n P(A_i)P(B|A_i).$$&lt;/p>
&lt;/div>
&lt;/div>
&lt;div class="spoiler " >
&lt;p>
&lt;a class="btn btn-primary" data-toggle="collapse" href="#spoiler-17" role="button" aria-expanded="false" aria-controls="spoiler-17">
Demostración
&lt;/a>
&lt;/p>
&lt;div class="collapse card " id="spoiler-17">
&lt;div class="card-body">
&lt;p>La demostración del teorema es sencilla, ya que al ser $A_1,\ldots,A_n$ un sistema completo tenemos&lt;/p>
&lt;p>$$B = B\cap E = B\cap (A_1\cup \cdots \cup A_n) = (B\cap A_1)\cup \cdots \cup (B\cap A_n)$$&lt;/p>
&lt;p>y como estos sucesos son incompatibles entre sí, se tiene&lt;/p>
&lt;p>$$
\begin{aligned}
P(B) &amp;amp;= P((B\cap A_1)\cup \cdots \cup (B\cap A_n)) = P(B\cap A_1)+\cdots + P(B\cap A_n) =\newline
&amp;amp;= P(A_1)P(B/A_1)+\cdots + P(A_n)P(B/A_n) = \sum_{i=1}^n P(A_i)P(B/A_i).
\end{aligned}
$$&lt;/p>
&lt;img src="../img/probabilidad/probabilidad_total.svg" alt="Teorema de la probabilidad total" width="400">
&lt;/div>
&lt;/div>
&lt;/div>
&lt;p>&lt;strong>Ejemplo&lt;/strong>. Un determinado síntoma $S$ puede ser originado por una enfermedad $E$ pero también lo pueden presentar las personas sin la enfermedad.
Sabemos que la prevalencia de la enfermedad $E$ es $0.2$. Además, se sabe que el $90%$ de las personas con la enfermedad presentan el síntoma, mientras que sólo el $40%$ de las personas sin la enfermedad lo presentan. Si se toma una persona al azar de la población, &lt;em>¿qué probabilidad hay de que tenga el síntoma?&lt;/em>&lt;/p>
&lt;p>Para responder a la pregunta se puede aplicar el teorema de la probabilidad total usando el sistema completo $\{E,\overline{E}\}$:&lt;/p>
&lt;p>$$P(S) = P(E)P(S|E)+P(\overline E)P(S|\overline E) = 0.2\cdot 0.9 + 0.8\cdot 0.4 = 0.5.$$&lt;/p>
&lt;p>Es decir, la mitad de la población tendrá el síntoma.&lt;/p>
&lt;p>&lt;em>¡En el fondo se trata de una media ponderada de probabilidades!&lt;/em>&lt;/p>
&lt;p>La respuesta a la pregunta anterior es evidente a la luz del árbol de probabilidad del espacio probabilístico del experimento.&lt;/p>
&lt;img src="../img/probabilidad/espacio_probabilistico_total.svg" alt="Aplicación del teorema de la probabilidad total en un espacio probabilístico" width="600">
&lt;p>$$
\begin{aligned}
P(S) &amp;amp;= P(E,S) + P(\overline E,S) = P(E)P(S|E)+P(\overline E)P(S|\overline E)\newline
&amp;amp; = 0.2\cdot 0.9+ 0.8\cdot 0.4 = 0.18 + 0.32 = 0.5.
\end{aligned}
$$&lt;/p>
&lt;h2 id="teorema-de-bayes">Teorema de Bayes&lt;/h2>
&lt;p>Los sucesos de un sistema completo de sucesos $A_1,\cdots,A_n$ también pueden verse como las distintas hipótesis ante un determinado hecho $B$.&lt;/p>
&lt;p>En estas condiciones resulta útil poder calcular las probabilidades a posteriori $P(A_i|B)$ de cada una de las hipótesis.&lt;/p>
&lt;div class="alert alert-def">
&lt;div>
&lt;p>&lt;strong>Definición - Teorema de Bayes&lt;/strong>. Dado un sistema completo de sucesos $A_1,\ldots,A_n$ y un suceso $B$
de un espacio muestral $\Omega$ y otro suceso $B$ del mismo espacio muestral, la probabilidad de cada suceso $A_i$ $i=1,\ldots,n$ condicionada por $B$ puede calcularse con la siguiente fórmula&lt;/p>
&lt;p>$$P(A_i|B) = \frac{P(A_i\cap B)}{P(B)} = \frac{P(A_i)P(B|A_i)}{\sum_{i=1}^n P(A_i)P(B|A_i)}.$$&lt;/p>
&lt;/div>
&lt;/div>
&lt;p>&lt;strong>Ejemplo&lt;/strong>. En el ejemplo anterior, una pregunta más interesante es qué diagnosticar a una persona que presenta el síntoma.&lt;/p>
&lt;p>En este caso se puede interpretar $E$ y $\overline{E}$ como las dos posibles hipótesis para el síntoma $S$. Las probabilidades a priori para ellas son $P(E)=0.2$ y $P(\overline E)=0.8$. Esto quiere decir que si no se dispone de información sobre el síntoma, el diagnóstico será que la persona no tiene la enfermedad.&lt;/p>
&lt;p>Sin embargo, si al reconocer a la persona se observa que presenta el síntoma, dicha información condiciona a las hipótesis, y para decidir entre ellas es necesario calcular sus probabilidades a posteriori, es
decir, $P(E|S)$ y P(\overline{E}|S)$.&lt;/p>
&lt;p>Para calcular las probabilidades a posteriori se puede utilizar el teorema de Bayes:&lt;/p>
&lt;p>$$
\begin{aligned}
P(E|S) &amp;amp;= \frac{P(E)P(S|E)}{P(E)P(S|E)+P(\overline{E})P(S|\overline{E})} = \frac{0.2\cdot 0.9}{0.2\cdot 0.9 + 0.8\cdot 0.4} = \frac{0.18}{0.5}=0.36,\newline
P(\overline{E}|S) &amp;amp;= \frac{P(\overline{E})P(S|\overline{E})}{P(E)P(S|E)+P(\overline{E})P(S|\overline{E})} = \frac{0.8\cdot 0.4}{0.2\cdot 0.9 + 0.8\cdot 0.4} = \frac{0.32}{0.5}=0.64.
\end{aligned}
$$&lt;/p>
&lt;p>Como se puede ver la probabilidad de tener la enfermedad ha aumentado.
No obstante, la probabilidad de no tener la enfermedad sigue siendo mayor que la de tenerla, y por esta razón el diagnóstico seguirá siendo que no tiene la enfermedad.&lt;/p>
&lt;p>En este caso se dice que el síntoma $S$ &lt;em>no es determinante&lt;/em> a la hora de diagnosticar la enfermedad.&lt;/p>
&lt;h2 id="epidemiología">Epidemiología&lt;/h2>
&lt;p>Una de las ramas de la Medicina que hace un mayor uso de la probabilidad es la , que estudia la distribución y las causas de las enfermedades en las poblaciones, identificando factores de riesgos para las enfermedades de cara a la atención médica preventiva.&lt;/p>
&lt;p>En Epidemiología interesa la frecuencia de un &lt;em>suceso médico&lt;/em> $E$ (típicamente una enfermedad como la gripe, un factor de riesgo como fumar o un factor de protección como vacunarse) que se mide mediante una
variable nominal con dos categorías (ocurrencia o no del suceso).&lt;/p>
&lt;p>Hay diferentes medidas relativas a la frecuencia de un suceso médico. Las más importantes son:&lt;/p>
&lt;ul>
&lt;li>Prevalencia&lt;/li>
&lt;li>Incidencia&lt;/li>
&lt;li>Riesgo relativo&lt;/li>
&lt;li>Odds ratio&lt;/li>
&lt;/ul>
&lt;h3 id="prevalencia">Prevalencia&lt;/h3>
&lt;div class="alert alert-def">
&lt;div>
&lt;p>&lt;strong>Definición - Prevalencia&lt;/strong>. La &lt;em>prevalencia&lt;/em> de un suceso médico $E$ es la proporción de una población que está afectada por el suceso.&lt;/p>
&lt;p>$$\mbox{Prevalencia}(E) = \frac{\mbox{Nº individuos afectados por $E$}}{\mbox{Tamaño poblacional}}$$&lt;/p>
&lt;/div>
&lt;/div>
&lt;p>A menudo, la prevalencia se estima mediante una muestra como la frecuencia relativa de los individuos afectados por el suceso en la muestra. Es también común expresarla esta frecuencia como un porcentaje.&lt;/p>
&lt;p>&lt;strong>Ejemplo&lt;/strong>. Para estimar la prevalencia de la gripe se estudió una muestra de 1000 personas de las que 150 presentaron gripe. Así, la prevalencia de la gripe es aproximadamente 150/1000=0.15, es decir, un
15%.&lt;/p>
&lt;h3 id="incidencia">Incidencia&lt;/h3>
&lt;p>La mide la probabilidad de ocurrencia de un suceso médico en una población durante un periodo de tiempo específico. La incidencia puede medirse como una proporción acumulada o como una tasa.&lt;/p>
&lt;div class="alert alert-def">
&lt;div>
&lt;p>&lt;strong>Definición - Incidencia acumulada&lt;/strong>. La &lt;em>incidencia acumulada&lt;/em> de un suceso médico $E$ es la proporción de individuos que experimentaron el evento en un periodo de tiempo, es decir, el número de nuevos casos afectados por el evento en el periodo de tiempo, divido por el tamaño de la población inicialmente en riesgo de verse afectada.&lt;/p>
&lt;p>$$R(E)=\frac{\mbox{Nº de nuevos casos con $E$}}{\mbox{Tamaño de la población en riesgo}}$$&lt;/p>
&lt;/div>
&lt;/div>
&lt;p>&lt;strong>Ejemplo&lt;/strong>. Una población contenía inicialmente $1000$ personas sin gripe y después de dos años se observó que 160 de ellas sufrieron gripe. La incidencia acumulada de la gripe es 160 casos pro 1000 personas por dos años, es decir, 16% en dos años.&lt;/p>
&lt;h3 id="tasa-de-incidencia-o-riesgo-absoluto">Tasa de incidencia o Riesgo absoluto&lt;/h3>
&lt;div class="alert alert-def">
&lt;div>
&lt;p>&lt;strong>Definición - Riesgo absoluto&lt;/strong>.La &lt;em>tasa de incidencia&lt;/em> o &lt;em>riesgo absoluto&lt;/em> de un suceso médico $E$ es el número de nuevos casos afectados por el evento divido por la población en riesgo y por el número de unidades temporales del periodo considerado.&lt;/p>
&lt;p>$$R(E)=\frac{\mbox{Nº nuevos casos con $E$}}{\mbox{Tamaño población en riesgo}\times \mbox{Nº unidades de tiempo}}$$&lt;/p>
&lt;/div>
&lt;/div>
&lt;p>&lt;strong>Ejemplo&lt;/strong>. Una población contenía inicialmente $1000$ personas sin gripe y después de dos años se observó que 160 de ellas sufrieron gripe. Si se considera el año como intervalo de tiempo, la tasa de incidencia de la gripe es 160 casos dividida por 1000 personas y por dos años, es decir, 80 casos por 1000 personas-año o 8% de personas al año.&lt;/p>
&lt;h3 id="prevalencia-vs-incidencia">Prevalencia vs Incidencia&lt;/h3>
&lt;p>La prevalencia no debe confundirse con la incidencia. La prevalencia indica cómo de extendido está el suceso médico en una población, sin preocuparse por cuándo los sujetos se han expuesto al riesgo o durante
cuánto tiempo, mientras que la incidencia se fija en el riesgo de verse afectado por el suceso en un periodo concreto de tiempo.&lt;/p>
&lt;p>Así, la prevalencia se calcula en estudios transversales en un momento temporal puntual, mientras que para medir la incidencia se necesita un estudio longitudinal que permita observar a los individuos durante un
periodo de tiempo.&lt;/p>
&lt;p>La incidencia es más útil cuando se pretende entender la causalidad del suceso: por ejemplo, si la incidencia de una enfermedad en una población aumenta, seguramente hay un factor de riesgo que lo está promoviendo.&lt;/p>
&lt;p>Cuando la tasa de incidencia es aproximadamente constante en la duración del suceso, la prevalencia es aproximadamente el producto de la incidencia por la duración media del suceso, es decir,&lt;/p>
&lt;p>$$ \mbox{Prevalencia} = \mbox{Incidencia} \times \mbox{duración}$$&lt;/p>
&lt;h3 id="comparación-de-riesgos">Comparación de riesgos&lt;/h3>
&lt;p>Para determinar si un factor o característica está asociada con el suceso médico es necesario comparar el riesgo del suceso en dos poblaciones, una expuesta al factor y la otra no. El grupo expuesto al factor se conoce como &lt;em>grupo tratamiento&lt;/em> o &lt;em>grupo experimental&lt;/em> $T$ y el grupo no expuesto como &lt;em>grupo control&lt;/em> $C$.&lt;/p>
&lt;p>Habitualmente los casos observados para cada grupo se representan en una tabla de 2$\times$2 como la siguiente:&lt;/p>
&lt;table>
&lt;thead>
&lt;tr class="header">
&lt;th style="text-align: left;">&lt;/th>
&lt;th style="text-align: center;">Suceso $E$&lt;/th>
&lt;th style="text-align: center;">No suceso $\overline E$&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr class="odd">
&lt;td style="text-align: left;">Grupo tratamiento $T$&lt;/td>
&lt;td style="text-align: center;">$a$&lt;/td>
&lt;td style="text-align: center;">$b$&lt;/td>
&lt;/tr>
&lt;tr class="even">
&lt;td style="text-align: left;">Grupo control $C$&lt;/td>
&lt;td style="text-align: center;">$c$&lt;/td>
&lt;td style="text-align: center;">$d$&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h3 id="riesgo-atribuible-o-diferencia-de-riesgos-ra">Riesgo atribuible o diferencia de riesgos $RA$&lt;/h3>
&lt;div class="alert alert-def">
&lt;div>
&lt;p>&lt;strong>Definición - Riesgo atribuible&lt;/strong>. El &lt;em>riesgo atribuible&lt;/em> o &lt;em>diferencia de riesgo&lt;/em> de un suceso médico
$E$ para los individuos expuestos a un factor es la diferencia entre los riesgos absolutos de los grupos tratamiento y control.&lt;/p>
&lt;p>$$RA(E)=R_T(E)-R_C(E)=\frac{a}{a+b}-\frac{c}{c+d}.$$&lt;/p>
&lt;/div>
&lt;/div>
&lt;p>El riesgo atribuible es el riesgo de un suceso que es debido específicamente al factor de interés.&lt;/p>
&lt;p>Obsérvese que el riesgo atribuible puede ser positivo, cuando el riesgo del grupo tratamiento es mayor que el del grupo control, o negativo, de lo contrario.&lt;/p>
&lt;p>&lt;strong>Ejemplo&lt;/strong>. Para determinar la efectividad de una vacuna contra la gripe, una muestra de 1000 personas sin gripe fueron seleccionadas al comienzo del año. La mitad de ellas fueron vacunadas (grupo tratamiento) y la otra mitad recibieron un placebo (grupo control). La tabla siguiente resume los resultados al final del año.&lt;/p>
&lt;table>
&lt;thead>
&lt;tr class="header">
&lt;th style="text-align: left;">&lt;/th>
&lt;th style="text-align: center;">Gripe $E$&lt;/th>
&lt;th style="text-align: center;">No gripe $\overline E$&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr class="odd">
&lt;td style="text-align: left;">Grupo tratamiento (vacunados)&lt;/td>
&lt;td style="text-align: center;">20&lt;/td>
&lt;td style="text-align: center;">480&lt;/td>
&lt;/tr>
&lt;tr class="even">
&lt;td style="text-align: left;">Grupo control (No vacunados)&lt;/td>
&lt;td style="text-align: center;">80&lt;/td>
&lt;td style="text-align: center;">420&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>El riesgo atribuible de contraer la gripe cuando se es vacunado es&lt;/p>
&lt;p>$$AR(D) = \frac{20}{20+480}-\frac{80}{80+420} = -0.12.$$&lt;/p>
&lt;p>Esto quiere decir que el riesgo de contraer la gripe es un 12% menor en vacunados
que en no vacunados.&lt;/p>
&lt;h3 id="riesgo-relativo-rr">Riesgo relativo $RR$&lt;/h3>
&lt;div class="alert alert-def">
&lt;div>
&lt;p>&lt;strong>Definición - Teorema de Bayes&lt;/strong>. El &lt;em>riesgo relativo&lt;/em> de un suceso médico $E$ para los individuos expuestos a un factor es el cociente entre las proporciones de individuos afectados por el suceso en un periodo de tiempo de los grupos tratamiento y control. Es decir, el cociente entre las incidencias de
grupo tratamiento y el grupo control.&lt;/p>
&lt;p>$$RR(D)=\frac{\mbox{Riesgo grupo tratamiento}}{\mbox{Riesgo grupo control}}=\frac{R_T(E)}{R_C(E)}=\frac{a/(a+b)}{c/(c+d)}$$&lt;/p>
&lt;/div>
&lt;/div>
&lt;p>El riesgo relativo compara el riesgo de desarrollar un suceso médico entre el grupo tratamiento y el grupo control.&lt;/p>
&lt;ul>
&lt;li>$RR=1$ $\Rightarrow$ No hay asociación entre el suceso y la exposición al factor.&lt;/li>
&lt;li>$RR&amp;lt;1$ $\Rightarrow$ La exposición al factor disminuye el riesgo del suceso.&lt;/li>
&lt;li>$RR&amp;gt;1$ $\Rightarrow$ La exposición al factor aumenta el riesgo del suceso.&lt;/li>
&lt;/ul>
&lt;p>Cuanto más lejos de 1, más fuerte es la asociación.&lt;/p>
&lt;p>&lt;strong>Ejemplo&lt;/strong>. Para determinar la efectividad de una vacuna contra la gripe, una muestra de 1000 personas sin gripe fueron seleccionadas al comienzo del año. La mitad de ellas fueron vacunadas (grupo tratamiento) y la otra mitad recibieron un placebo (grupo control). La tabla siguiente resume los resultados al final del año.&lt;/p>
&lt;table>
&lt;thead>
&lt;tr class="header">
&lt;th style="text-align: left;">&lt;/th>
&lt;th style="text-align: center;">Gripe $E$&lt;/th>
&lt;th style="text-align: center;">No gripe $\overline E$&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr class="odd">
&lt;td style="text-align: left;">Grupo tratamiento (vacunados)&lt;/td>
&lt;td style="text-align: center;">20&lt;/td>
&lt;td style="text-align: center;">480&lt;/td>
&lt;/tr>
&lt;tr class="even">
&lt;td style="text-align: left;">Grupo control (No vacunados)&lt;/td>
&lt;td style="text-align: center;">80&lt;/td>
&lt;td style="text-align: center;">420&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>El riesgo relativo de contraer la gripe cuando se es vacunado es&lt;/p>
&lt;p>$$RR(D) = \frac{20/(20+480)}{80/(80+420)} = 0.25.$$&lt;/p>
&lt;p>Así, la probabilidad de contraer la gripe en los individuos vacunados fue la cuarta parte de
la de contraerla en el caso de no haberse vacunado, es decir, la vacuna reduce el riesgo de gripe un 75%.&lt;/p>
&lt;h3 id="odds">Odds&lt;/h3>
&lt;p>Una forma alternativa de medir el riesgo de un suceso médico es el &lt;em>odds&lt;/em>.&lt;/p>
&lt;p>El &lt;em>odds&lt;/em> de un suceso médico $E$ en una población es el cociente entre el número de individuos que adquirieron el suceso y los que no en un periodo de tiempo.&lt;/p>
&lt;p>$$ODDS(E)=\frac{\mbox{Nº nuevos casos con $E$}}{\mbox{Nº casos sin $E$}}=\frac{P(E)}{P(\overline E)}$$&lt;/p>
&lt;p>A diferencia de la incidencia, que es una proporción menor o igual que 1, el odds puede ser mayor que 1. No obstante es posible convertir el odds en una probabilidad con al fórmula&lt;/p>
&lt;p>$$P(E) = \frac{ODDS(E)}{ODDS(E)+1}$$&lt;/p>
&lt;p>&lt;strong>Ejemplo&lt;/strong> Una población contenía inicialmente $1000$ personas sin gripe. Después de un año 160 de ellas tuvieron gripe. Entonces el odds de la gripe es 160/840.&lt;/p>
&lt;p>Obsérvese que la incidencia es 160/1000.&lt;/p>
&lt;h3 id="odds-ratio-or">Odds ratio $OR$&lt;/h3>
&lt;div class="alert alert-def">
&lt;div>
&lt;p>&lt;strong>Definición - Odds ratio&lt;/strong>. El &lt;em>odds ratio&lt;/em> o la &lt;em>oportunidad relativa&lt;/em> de un suceso médico $E$
para los individuos expuestos a un factor es el cociente entre los odds del sucesos de los grupos tratamiento y control.&lt;/p>
&lt;p>$$OR(E)=\frac{\mbox{Odds en grupo tratamiento}}{\mbox{Odds en grupo control}}=\frac{a/b}{c/d}=\frac{ad}{bc}$$&lt;/p>
&lt;/div>
&lt;/div>
&lt;p>El odds ratio compara los odds de un suceso médico entre el grupo tratamiento y control. La interpretación es similar a la del riesgo relativo:&lt;/p>
&lt;ul>
&lt;li>$OR=1$ $\Rightarrow$ No existe asociación entre el suceso y la exposición al factor.&lt;/li>
&lt;li>$OR&amp;lt;1$ $\Rightarrow$ La exposición al factor disminuye el riesgo del suceso.&lt;/li>
&lt;li>$OR&amp;gt;1$ $\Rightarrow$ La exposición al factor aumenta el riesgo del suceso.&lt;/li>
&lt;/ul>
&lt;p>Cuanto más lejos de 1, más fuerte es la asociación.&lt;/p>
&lt;p>&lt;strong>Ejemplo&lt;/strong>. Para determinar la efectividad de una vacuna contra la gripe, una muestra de 1000 personas sin gripe fueron seleccionadas al comienzo del año. La mitad de ellas fueron vacunadas (grupo tratamiento) y la otra mitad recibieron un placebo (grupo control). La tabla siguiente resume los resultados al final del año.&lt;/p>
&lt;table>
&lt;thead>
&lt;tr class="header">
&lt;th style="text-align: left;">&lt;/th>
&lt;th style="text-align: center;">Gripe $E$&lt;/th>
&lt;th style="text-align: center;">No gripe $\overline E$&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr class="odd">
&lt;td style="text-align: left;">Grupo tratamiento (vacunados)&lt;/td>
&lt;td style="text-align: center;">20&lt;/td>
&lt;td style="text-align: center;">480&lt;/td>
&lt;/tr>
&lt;tr class="even">
&lt;td style="text-align: left;">Grupo control (No vacunados)&lt;/td>
&lt;td style="text-align: center;">80&lt;/td>
&lt;td style="text-align: center;">420&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>El odds ratio de sufrir la gripe para los individuos vacunados es&lt;/p>
&lt;p>$$OR(D) = \frac{20/480}{80/420} = 0.21875.$$&lt;/p>
&lt;p>Esto quiere decir que el odds de sufrir la gripe frente a no sufrirla en los vacunados es casi un quinto del de los no vacunados, es decir, que aproximadamente por cada 22 personas vacunadas con gripe habrá 100 personas no vacunadas con gripe.&lt;/p>
&lt;h3 id="riesgo-relativo-vs-odds-ratio">Riesgo relativo vs Odds ratio&lt;/h3>
&lt;p>El riesgo relativo y el odds ratio son dos medidas de asociación pero su interpretación es ligeramente diferente. Mientras que el riesgo relativo expresa una comparación de riesgos entre los grupos tratamiento y control, el odds ratio expresa una comparación de odds, que no es lo mismo que el riesgo. Así, un odds ratio de 2 &lt;em>no&lt;/em> significa que el grupo tratamiento tiene el doble de riesgo de adquirir el suceso.&lt;/p>
&lt;p>La interpretación del odds ratio es un poco más enrevesada porque es contrafactual, y nos da cuántas veces es más frecuente el suceso en el grupo tratamiento en comparación con el control, asumiendo que en el
grupo control es tan frecuente que ocurra el suceso como que no.&lt;/p>
&lt;p>La ventaja del odds ratio es que no depende de la prevalencia o la incidencia del suceso, y debe usarse siempre que el número de individuos que presenta el suceso se selecciona arbitrariamente en ambos grupos,
como ocurre en los estudios casos-control.&lt;/p>
&lt;p>&lt;strong>Ejemplo&lt;/strong>. Para determinar la asociación entre el cáncer de pulmón y fumar se tomaron dos muestras (la segunda con el doble de individuos sin cáncer) obteniendo los siguientes resultados:&lt;/p>
&lt;p>&lt;strong>Sample 1&lt;/strong>&lt;/p>
&lt;table>
&lt;thead>
&lt;tr class="header">
&lt;th style="text-align: left;">&lt;/th>
&lt;th style="text-align: center;">Cáncer&lt;/th>
&lt;th style="text-align: center;">No cáncer&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr class="odd">
&lt;td style="text-align: left;">Fumadores&lt;/td>
&lt;td style="text-align: center;">60&lt;/td>
&lt;td style="text-align: center;">80&lt;/td>
&lt;/tr>
&lt;tr class="even">
&lt;td style="text-align: left;">No fumadores&lt;/td>
&lt;td style="text-align: center;">40&lt;/td>
&lt;td style="text-align: center;">320&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>$$
\begin{aligned}
RR(D) &amp;amp;= \frac{60/(60+80)}{40/(40+320)} = 3.86.\newline
OR(D) &amp;amp;= \frac{60/80}{40/320} = 6.
\end{aligned}
$$&lt;/p>
&lt;p>&lt;strong>Sample 2&lt;/strong>&lt;/p>
&lt;table>
&lt;thead>
&lt;tr class="header">
&lt;th style="text-align: left;">&lt;/th>
&lt;th style="text-align: center;">Cáncer&lt;/th>
&lt;th style="text-align: center;">No cáncer&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr class="odd">
&lt;td style="text-align: left;">Fumadores&lt;/td>
&lt;td style="text-align: center;">60&lt;/td>
&lt;td style="text-align: center;">160&lt;/td>
&lt;/tr>
&lt;tr class="even">
&lt;td style="text-align: left;">No fumadores&lt;/td>
&lt;td style="text-align: center;">40&lt;/td>
&lt;td style="text-align: center;">640&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>$$
\begin{aligned}
RR(D) &amp;amp;= \frac{60/(60+160)}{40/(40+640)} = 4.64.\newline
OR(D) &amp;amp;= \frac{60/160}{40/640} = 6.
\end{aligned}
$$&lt;/p>
&lt;p>Así, cuando cambia la incidencia o prevalencia de un suceso (cáncer de pulmón) el riesgo relativo cambia, mientras que el odds ratio no.&lt;/p>
&lt;h3 id="riesgo-relativo-vs-odds-ratio-1">Riesgo relativo vs Odds ratio&lt;/h3>
&lt;p>La relación entre el riesgo relativo y el odds ratio viene dada por la siguiente fórmula&lt;/p>
&lt;p>$$RR = \frac{OR}{1-R_0+R_0\cdot OR} = OR \frac{1-R_1}{1-R_0},$$&lt;/p>
&lt;p>donde $R_C$ and $R_T$ son la prevalencia o la incidencia en los grupos control y tratamiento respectivamente.&lt;/p>
&lt;p>El odds ratio siempre sobrestima el riesgo relativo cuando este es mayor que 1 y lo subestima cuando es menor que 1. No obstante, con sucesos médicos raros (con una prevalencia o incidencia baja) el riesgo
relativo y el odds ratio son casi iguales.&lt;/p>
&lt;img src="../img/probabilidad/odds_ratio_vs_riesgo_relativo.svg" alt="Odss ratio versus riesgo relativo" width="600">
&lt;h2 id="tests-diagnósticos">Tests diagnósticos&lt;/h2>
&lt;p>En Epidemiología es común el uso de test para diagnosticar enfermedades.&lt;/p>
&lt;p>Generalmente estos test no son totalmente fiables, sino que hay cierta probabilidad de acierto o fallo en el diagnóstico, que suele representarse en la siguiente tabla:&lt;/p>
&lt;table>
&lt;thead>
&lt;tr class="header">
&lt;th style="text-align: left;">&lt;/th>
&lt;th style="text-align: center;">Presencia enfermedad $E$&lt;/th>
&lt;th style="text-align: center;">Ausencia enfermedad $\overline E$&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr class="odd">
&lt;td style="text-align: left;">Test positivo $+$&lt;/td>
&lt;td style="text-align: center;">&lt;span style="color: green">Verdadero positivo &lt;/span>$VP$&lt;/td>
&lt;td style="text-align: center;">&lt;span style="color: red">Falso positivo &lt;/span>$FP$&lt;/td>
&lt;/tr>
&lt;tr class="even">
&lt;td style="text-align: left;">Test negativo $−$&lt;/td>
&lt;td style="text-align: left;">&lt;span style="color: red">Falso negativo &lt;/span>$FN$&lt;/td>
&lt;td style="text-align: left;">&lt;span style="color: green">Verdadero Negativo &lt;/span>$VN$&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h3 id="sensibilidad-y-especificidad-de-un-test-diagnóstico">Sensibilidad y especificidad de un test diagnóstico&lt;/h3>
&lt;p>La fiabilidad de un test diagnóstico depende de las siguientes probabilidades.&lt;/p>
&lt;div class="alert alert-def">
&lt;div>
&lt;p>&lt;strong>Definición - Sensibilidad&lt;/strong>. La &lt;em>sensibilidad&lt;/em> de un test diagnóstico es la proporción de resultados positivos del test en personas con la enfermedad,&lt;/p>
&lt;p>$$P(+|E)=\frac{VP}{VP+FN}$$&lt;/p>
&lt;/div>
&lt;/div>
&lt;div class="alert alert-def">
&lt;div>
&lt;p>&lt;strong>Definición - Especificidad&lt;/strong>. La &lt;em>especificidad&lt;/em> de un test diagnóstico es la proporción de resultados
negativos del test en personas sin la enfermedad,&lt;/p>
&lt;p>$$P(-|\overline{E})=\frac{VN}{VN+FP}$$&lt;/p>
&lt;/div>
&lt;/div>
&lt;p>Normalmente existe un balance entre la sensibilidad y la especificidad.&lt;/p>
&lt;p>Un test con una alta sensibilidad detectará la enfermedad en la mayoría de las personas enfermas, pero también dará más falsos positivos que un test menos sensible. De este modo, un resultado positivo en un test con una gran sensibilidad no es muy útil para confirmar la enfermedad, pero un resultado negativo es útil para descartar la enfermedad, ya que raramente da resultados negativos en personas con la enfermedad.&lt;/p>
&lt;p>Por otro lado, un test con una alta especificidad descartará la enfermedad en la mayoría de las personas sin la enfermedad, pero también producirá más falsos negativos que un test menos específico. Así, un
resultado negativo en un test con una gran especificidad no es útil para descartar la enfermedad, pero un resultado positivo es muy útil para confirmar la enfermedad, ya que raramente da resultados positivos en
personas sin la enfermedad.&lt;/p>
&lt;p>Decidir entre un test con una gran sensibilidad o un test con una gran especificidad depende del tipo de enfermedad y el objetivo del test. En general, utilizaremos un test sensible cuando:&lt;/p>
&lt;ul>
&lt;li>La enfermedad es grave y es importante detectarla.&lt;/li>
&lt;li>La enfermedad es curable.&lt;/li>
&lt;li>Los falsos positivos no provocan traumas serios.&lt;/li>
&lt;/ul>
&lt;p>Y utilizaremos un test específico cuando:&lt;/p>
&lt;ul>
&lt;li>La enfermedad es importante pero difícil o imposible de curar.&lt;/li>
&lt;li>Los falsos positivos pueden provocar traumas serios.&lt;/li>
&lt;li>El tratamiento de los falsos positivos puede tener graves consecuencias.&lt;/li>
&lt;/ul>
&lt;h3 id="valores-predictivos-de-un-test-diagnóstico">Valores predictivos de un test diagnóstico&lt;/h3>
&lt;p>Pero el aspecto más importante de un test diagnóstico es su poder predictivo, que se mide con las siguientes probabilidades a posteriori.&lt;/p>
&lt;div class="alert alert-def">
&lt;div>
&lt;p>&lt;strong>Definición - Valor predictivo positivo&lt;/strong>. El &lt;em>valor predictivo positivo&lt;/em> de un test diagnóstico es la proporción de personas con la enfermedad entre las personas con resultado positivo
en el test,&lt;/p>
&lt;p>$$P(E|+) = \frac{VP}{VP+FP}$$&lt;/p>
&lt;/div>
&lt;/div>
&lt;div class="alert alert-def">
&lt;div>
&lt;p>&lt;strong>Definición - Valor predictivo negativo&lt;/strong>. El &lt;em>valor predictivo negativo&lt;/em> de un test diagnóstico es la proporción de personas sin la enfermedad entre las personas con resultado negativo en el test,&lt;/p>
&lt;p>$$P(\overline{E}|-) = \frac{VN}{VN+FN}$$&lt;/p>
&lt;/div>
&lt;/div>
&lt;p>Los valores predictivos positivo y negativo permiten confirmar o descartar la enfermedad, respectivamente, si alcanzan al menos el umbral de $0.5$.&lt;/p>
&lt;p>$$
\begin{array}{rcl}
VPP&amp;gt;0.5 &amp;amp; \Rightarrow &amp;amp; \mbox{Diagnosticar la enfermedad}\newline
VPN&amp;gt;0.5 &amp;amp; \Rightarrow &amp;amp; \mbox{Diagnosticar la no enfermedad}
\end{array}
$$&lt;/p>
&lt;p>No obstante, estas probabilidades dependen de la proporción de personas con la enfermedad en la población $P(E)$ que se conoce como de la enfermedad. Pueden calcularse a partir de la sensibilidad y la especificidad del test diagnóstico usando el teorema de Bayes.&lt;/p>
&lt;p>$$
\begin{aligned}
VPP=P(E|+) &amp;amp;= \frac{P(E)P(+|E)}{P(E)P(+|E)+P(\overline{E})P(+|\overline{E})}\newline
VPN=P(\overline{E}|-) &amp;amp;= \frac{P(\overline{E})P(-|\overline{E})}{P(E)P(-|E)+P(\overline{E})P(-|\overline{E})}
\end{aligned}
$$&lt;/p>
&lt;p>Así, con enfermedades frecuentes, el valor predictivo positivo aumenta, y con enfermedades raras, el valor predictivo negativo aumenta.&lt;/p>
&lt;p>&lt;strong>Ejemplo&lt;/strong> Un test diagnóstico para la gripe se ha aplicado a una muestra aleatoria de 1000 personas. Los resultados aparecen resumidos en la siguiente
tabla.&lt;/p>
&lt;table>
&lt;thead>
&lt;tr class="header">
&lt;th style="text-align: left;">&lt;/th>
&lt;th style="text-align: center;">Presencia de gripe $E$&lt;/th>
&lt;th style="text-align: center;">Ausencia de gripe $\overline E$&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr class="odd">
&lt;td style="text-align: left;">Test $+$&lt;/td>
&lt;td style="text-align: center;">95&lt;/td>
&lt;td style="text-align: center;">90&lt;/td>
&lt;/tr>
&lt;tr class="even">
&lt;td style="text-align: left;">Test $−$&lt;/td>
&lt;td style="text-align: center;">5&lt;/td>
&lt;td style="text-align: center;">810&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>Según esta muestra, la prevalencia de la gripe puede estimarse como&lt;/p>
&lt;p>$$P(E) = \frac{95+5}{1000} = 0.1.$$&lt;/p>
&lt;p>La sensibilidad del test diagnóstico es&lt;/p>
&lt;p>$$P(+|E) = \frac{95}{95+5}= 0.95.$$&lt;/p>
&lt;p>Y la especificidad es&lt;/p>
&lt;p>$$P(-|\overline{E}) = \frac{810}{90+810}=0.9.$$&lt;/p>
&lt;p>El valor predictivo positivo del test es&lt;/p>
&lt;p>$$VPP = P(E|+) = \frac{95}{95+90} = 0.5135.$$&lt;/p>
&lt;p>Como este valor es mayor que $0.5$, eso significa que se diagnosticará la gripe si el resultado del test es positivo. No obstante, la confianza en el diagnóstico será baja, ya que el valor es poco mayor que $0.5$.&lt;/p>
&lt;p>Por otro lado, el valor predictivo negativo es&lt;/p>
&lt;p>$$VPN = P(\overline{E}|-) = \frac{810}{5+810} = 0.9939.$$&lt;/p>
&lt;p>Como este valor es casi 1, eso significa que es casi seguro que no se tiene la gripe cuando el resultado del test es negativo.&lt;/p>
&lt;p>Así, se puede concluir que este test es muy potente para descartar la gripe, pero no lo est tanto para confirmarla.&lt;/p>
&lt;h3 id="razón-de-verosimilitud-de-un-test-diagnóstico">Razón de verosimilitud de un test diagnóstico&lt;/h3>
&lt;p>La siguientes medidas también se derivan de la sensibilidad y la especificidad de un test diagnóstico.&lt;/p>
&lt;div class="alert alert-def">
&lt;div>
&lt;p>&lt;strong>Definición - Razón de verosimilitud positiva&lt;/strong>. La &lt;em>razón de verosimilitud positiva&lt;/em> de un test diagnóstico es el cociente entre la probabilidad de un resultado positivo en personas con
la enfermedad y personas sin la enfermedad, respectivamente.&lt;/p>
&lt;p>$$RV+=\frac{P(+|E)}{P(+|\overline{E})} = \frac{\mbox{Sensibilidad}}{1-\mbox{Especificidad}}$$&lt;/p>
&lt;/div>
&lt;/div>
&lt;div class="alert alert-def">
&lt;div>
&lt;p>&lt;strong>Definición - Razón de verosimilitud negativa&lt;/strong>. La &lt;em>razón de verosimilitud negativa&lt;/em> de un test diagnóstico es el cociente entre la probabilidad de un resultado negativo en personas con la enfermedad y personas sin la enfermedad, respectivamente.&lt;/p>
&lt;p>$$RV-=\frac{P(-|E)}{P(-|\overline{E})} = \frac{1-\mbox{Sensibilidad}}{\mbox{Especificidad}}$$&lt;/p>
&lt;/div>
&lt;/div>
&lt;p>La razón de verosimilitud positiva puede interpretarse como el número de veces que un resultado positivo es más probable en personas con la enfermedad que en personas sin la enfermedad.&lt;/p>
&lt;p>Por otro lado, la razón de verosimilitud negativa puede interpretarse como el número de veces que un resultado negativo es más probable en personas con la enfermedad que en personas sin la enfermedad.&lt;/p>
&lt;p>Las probabilidades a posteriori pueden calculares a partir de las probabilidades a priori usando las razones de verosimilitud&lt;/p>
&lt;p>$$P(E|+) = \frac{P(E)P(+|E)}{P(E)P(+|E)+P(\overline{E})P(+|\overline{E})} = \frac{P(E)RV+}{1-P(E)+P(E)RV+}$$&lt;/p>
&lt;p>Así,&lt;/p>
&lt;ul>
&lt;li>Una razón de verosimilitud positiva mayor que 1 aumenta la probabilidad de la enfermedad.&lt;/li>
&lt;li>Una razón de verosimilitud positiva menor que 1 disminuye la probabilidad de la enfermedad.&lt;/li>
&lt;li>Una razón de verosimilitud 1 no cambia la probabilidad a priori de la de tener la enfermedad.&lt;/li>
&lt;/ul>
&lt;img src="../img/probabilidad/razon_verosimilitud.svg" alt="Razón de verosimilitud" width="600"></description></item><item><title>Ejercicios de Regresión No Lineal</title><link>/docencia/estadistica/ejercicios/regresion-no-lineal/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/docencia/estadistica/ejercicios/regresion-no-lineal/</guid><description>&lt;h2 id="ejercicio-1">Ejercicio 1&lt;/h2>
&lt;p>Titulación: Química, Biotecnología&lt;/p>
&lt;p>Se sometió a una persona a unas sesiones de entrenamiento para el manejo de una máquina de análisis químicos y se valoró la destreza en el manejo en diversas ocasiones, valorandola en una escala de 0 a 100.
Los resultados obtenidos aparecen en la siguiente tabla&lt;/p>
&lt;p>Sesiones | 2 | 5 | 7 | 10 | 12 | 16
Destreza | 15 | 40 | 62 | 86 | 92 | 95&lt;/p>
&lt;p>Se pide:&lt;/p>
&lt;ol>
&lt;li>Calcular la destreza alcanzada al cabo de 8 sesiones empleando el modelo logarítmico.&lt;/li>
&lt;li>Calcular el número de sesiones necesarias para alcanzar una destreza de 80 empleando el modelo exponencial.&lt;/li>
&lt;li>Justificar razonadamente cuál de las predicciones anteriores es más fiable.&lt;/li>
&lt;/ol>
&lt;p>&lt;strong>SOLUCIÓN&lt;/strong>&lt;/p>
&lt;iframe src="http://www.slideshare.net/slideshow/embed_code/35215217" width="640" height="449" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" style="border:1px solid #CCC; border-width:1px 1px 0; margin-bottom:5px; max-width: 100%;" allowfullscreen> &lt;/iframe>
&lt;iframe src="//www.youtube.com/embed/Jx8R4fTFjoE" width="640" height="360" frameborder="0"> &lt;/iframe></description></item><item><title>Ejercicios de Probabilidad</title><link>/docencia/estadistica/ejercicios/probabilidad/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/docencia/estadistica/ejercicios/probabilidad/</guid><description>&lt;h2 id="ejercicio-1">Ejercicio 1&lt;/h2>
&lt;p>Titulación: Farmacia&lt;/p>
&lt;p>Un grupo de 50 alumnos tiene 3 asignaturas A, B y C en un curso.
El número de aprobados en la convocatoria ordinaria y extraordinaria aparece en la siguiente tabla (se supone que quien
ha aprobado en la convocatoria ordinaria no se presenta a la extraordinaria):&lt;/p>
&lt;p>|Asignatura | Ordinaria | Extraordinaria|
|A | 25 | 12 |
|B | 14 | 10 |
|C | 32 | 8|&lt;/p>
&lt;p>Suponiendo que el aprobado en cada asignatura es independiente de las demás, se pide:&lt;/p>
&lt;ol>
&lt;li>¿Cuál es la probabilidad de aprobar alguna asignatura en la convocatoria ordinaria?&lt;/li>
&lt;li>¿Cuál es la probabilidad de aprobar las tres asignaturas?&lt;/li>
&lt;li>Si un alumno ha aprobado la asignatura A, ¿cuál es la probabilidad de que hubiese aprobado en la convocatoria ordinaria?&lt;/li>
&lt;/ol>
&lt;p>&lt;strong>SOLUCIÓN&lt;/strong>&lt;/p>
&lt;iframe src="http://www.slideshare.net/slideshow/embed_code/35219100" width="640" height="449" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" style="border:1px solid #CCC; border-width:1px 1px 0; margin-bottom:5px; max-width: 100%;" allowfullscreen> &lt;/iframe>
&lt;iframe src="//www.youtube.com/embed/lsMNzMM3-GI" width="640" height="360" frameborder="0"> &lt;/iframe></description></item><item><title>Ejercicios de Tests Diagnósticos</title><link>/docencia/estadistica/ejercicios/tests-diagnosticos/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/docencia/estadistica/ejercicios/tests-diagnosticos/</guid><description>&lt;h2 id="ejercicio-1">Ejercicio 1&lt;/h2>
&lt;p>Titulación: Farmacia, Medicina&lt;/p>
&lt;p>Para detectar el parásito del paludismo existe un test de respuesta inmediata que produce un 2 % de falsos
positivos y un 4 % de falsos negativos.
En una determinada región de África se sabe que hay un 32 % de personas con paludismo.
Se pide:&lt;/p>
&lt;ol>
&lt;li>¿Cuál es la probabilidad de que el test de un diagnóstico acertado?&lt;/li>
&lt;li>¿Cuál es el poder predictivo negativo del test?&lt;/li>
&lt;li>¿Cuánto debería valer la sensibilidad del test para que el poder predictivo negativo fuese de al menos el 99 %?&lt;/li>
&lt;/ol>
&lt;p>&lt;strong>SOLUCIÓN&lt;/strong>&lt;/p>
&lt;iframe src="http://www.slideshare.net/slideshow/embed_code/35218906" width="640" height="449" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" style="border:1px solid #CCC; border-width:1px 1px 0; margin-bottom:5px; max-width: 100%;" allowfullscreen> &lt;/iframe>
&lt;iframe src="//www.youtube.com/embed/Py7ciwGGvqg" width="640" height="360" frameborder="0"> &lt;/iframe></description></item><item><title>Ejercicios de Variables Aleatorias Discretas</title><link>/docencia/estadistica/ejercicios/variables-aleatorias-discretas/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/docencia/estadistica/ejercicios/variables-aleatorias-discretas/</guid><description>&lt;h2 id="ejercicio-1">Ejercicio 1&lt;/h2>
&lt;p>Titulación: Farmacia, Biotecnología&lt;/p>
&lt;p>Se sabe que el 0.1 % de los comprimidos fabricados en un laboratorio no supera los controles de calidad.
Se pide:&lt;/p>
&lt;ol>
&lt;li>Calcular la probabilidad de que en un envase de 500 comprimidos haya más de 2 comprimidos que no superan los controles de calidad.&lt;/li>
&lt;li>Calcular la probabilidad de que en un lote de 10 envases haya más de 7 envases en los que todos sus comprimidos superen los controles de calidad.&lt;/li>
&lt;/ol>
&lt;p>&lt;strong>SOLUCIÓN&lt;/strong>&lt;/p>
&lt;iframe src="http://www.slideshare.net/slideshow/embed_code/35218677" width="640" height="449" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" style="border:1px solid #CCC; border-width:1px 1px 0; margin-bottom:5px; max-width: 100%;" allowfullscreen> &lt;/iframe>
&lt;iframe src="//www.youtube.com/embed/49i-So_DvbY" width="640" height="360" frameborder="0"> &lt;/iframe></description></item><item><title>Contrastes de Hipótesis</title><link>/docencia/estadistica/manual/contrastes/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/docencia/estadistica/manual/contrastes/</guid><description>&lt;h2 id="hipótesis-estadísticas-y-tipos-de-contrastes-de-hipótesis">Hipótesis estadísticas y tipos de contrastes de hipótesis&lt;/h2>
&lt;h3 id="hipótesis-estadística">Hipótesis estadística&lt;/h3>
&lt;p>En muchos estudios estadísticos, el objetivo, más que estimar el valor de un parámetro desconocido en la población, es comprobar la veracidad de una hipótesis formulada sobre la población objeto de estudio.&lt;/p>
&lt;p>El investigador, de acuerdo a su experiencia o a estudios previos, suele tener conjeturas sobre la población estudiada que expresa en forma de hipótesis.&lt;/p>
&lt;div class="alert alert-def">
&lt;div>
&lt;strong>Definición - Hipótesis estadística&lt;/strong>. Una &lt;em>hipótesis estadística&lt;/em> es cualquier afirmación o conjetura que determina, total o parcialmente, la distribución de una o varias variables de la población.
&lt;/div>
&lt;/div>
&lt;p>&lt;strong>Ejemplo&lt;/strong>. Para contrastar el rendimiento académico de un grupo de alumnos en una determinada asignatura, podríamos platear la hipótesis de si el porcentaje de aprobados es mayor del 50%.&lt;/p>
&lt;h3 id="contraste-de-hipótesis">Contraste de hipótesis&lt;/h3>
&lt;p>En general nunca se sabrá con absoluta certeza si una hipótesis estadística es cierta o falsa, ya que para ello habría que estudiar a todos los individuos de la población.&lt;/p>
&lt;p>Para comprobar la veracidad o falsedad de estas hipótesis hay que contrastarlas con los resultados empíricos obtenidos de las muestras. Si los resultados observados en las muestras coinciden, dentro del margen de error admisible debido al azar, con lo que cabría esperar en caso de que la hipótesis fuese cierta, la hipótesis se aceptará como verdadera, mientras que en caso contrario se rechazará como falsa y se buscarán nuevas hipótesis capaces de explicar los datos observados.&lt;/p>
&lt;p>Como las muestras se obtienen aleatoriamente, &lt;em>la decisión de aceptar o rechazar una hipótesis estadística se tomará sobre una base de probabilidad&lt;/em>.&lt;/p>
&lt;p>La metodología que se encarga de contrastar la veracidad de las hipótesis estadísticas se conoce como &lt;em>contraste de hipótesis&lt;/em>.&lt;/p>
&lt;h3 id="tipos-de-contrastes-de-hipótesis">Tipos de contrastes de hipótesis&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>Contrastes de bondad de ajuste&lt;/strong>: El objetivo es comprobar una hipótesis sobre la forma de la distribución de la población.&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Ejemplo&lt;/strong>. Contrastar si las notas de un grupo de alumnos siguen una distribución normal.&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>Contrastes de conformidad&lt;/strong>: El objetivo es comprobar una hipótesis sobre alguno de los parámetros de la población.&lt;/p>
&lt;p>&lt;strong>Ejemplo&lt;/strong>. Contrastar si las nota media en un grupo de alumnos es igual a 5.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Contrastes de homogeneidad&lt;/strong> : El objetivo es comparar dos poblaciones con respecto a alguno de sus parámetros.&lt;/p>
&lt;p>&lt;strong>Ejemplo&lt;/strong>. Contrastar si el rendimiento de dos grupos de alumnos es el mismo comparando sus notas medias.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Contrastes de independencia&lt;/strong>: El objetivo es comprobar si existe relación entre dos variables de la población.&lt;/p>
&lt;p>&lt;strong>Ejemplo&lt;/strong>. Contrastar si existe relación entre la notas de dos asignaturas diferentes.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>Cuando las hipótesis se plantean sobre parámetros de la población, también se habla de &lt;strong>contrastes paramétricos&lt;/strong>.&lt;/p>
&lt;h2 id="planteamiento-de-un-contraste-de-hipótesis">Planteamiento de un contraste de hipótesis&lt;/h2>
&lt;h3 id="hipótesis-nula-e-hipótesis-alternativa">Hipótesis nula e hipótesis alternativa&lt;/h3>
&lt;p>En la mayoría de los casos un contraste supone tomar una decisión entre dos hipótesis antagonistas:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>Hipótesis nula&lt;/strong>: Es la hipótesis conservadora, ya que se mantendrá mientras que los datos de las muestras no reflejen claramente su falsedad. Se representa como $H_0$.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Hipótesis alternativa&lt;/strong>: Es la negación de la hipótesis nula y generalmente representa la afirmación que se pretende probar. Se representa como $H_1$.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>Ambas hipótesis se eligen de acuerdo con el principio de simplicidad científica:&lt;/p>
&lt;blockquote>
&lt;p>&lt;em>“Solamente se debe abandonar un modelo simple por otro más complejo cuando la evidencia a favor del último sea fuerte.”&lt;/em> (Navaja de Occam)&lt;/p>
&lt;/blockquote>
&lt;h3 id="elección-de-las-hipótesis-nula-y-alternativa">Elección de las hipótesis nula y alternativa&lt;/h3>
&lt;h4 id="analogía-con-un-juicio">Analogía con un juicio&lt;/h4>
&lt;p>En el caso de un juicio, en el que el juez debe decidir si el acusado es culpable o inocente, la elección de hipótesis debería ser&lt;/p>
&lt;p>$$
\begin{align*}
H_0: &amp;amp; \mbox{ Inocente}\newline
H_1: &amp;amp; \mbox{ Culpable}
\end{align*}
$$&lt;/p>
&lt;p>ya que la inocencia se asume, mientras que la culpabilidad hay que demostrarla.&lt;/p>
&lt;p>Según esto, el juez sólo aceptaría la hipótesis alternativa cuando hubiese pruebas significativas de la culpabilidad del acusado.&lt;/p>
&lt;p>El investigador jugaría el papel del fiscal, ya que su objetivo consistiría en intentar rechazar la hipótesis nula, es decir, demostrar culpabilidad del acusado.&lt;/p>
&lt;div class="alert alert-warning">
&lt;div>
¡Esta metodología siempre favorece a la hipótesis nula!
&lt;/div>
&lt;/div>
&lt;h3 id="contrastes-de-hipótesis-paramétricos">Contrastes de hipótesis paramétricos&lt;/h3>
&lt;p>En muchos contrastes, sobre todo en las pruebas de conformidad y de homogeneidad, las hipótesis se formulan sobre parámetros desconocidos de la población como puede ser una media, una varianza o una proporción.&lt;/p>
&lt;p>En tal caso, la hipótesis nula siempre asigna al parámetro un valor concreto, mientras que la alternativa suele ser una hipótesis abierta que, aunque opuesta a la hipótesis nula, no fija el valor del parámetro.&lt;/p>
&lt;p>Esto da lugar a tres tipos de contrastes:&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align:center">Bilateral&lt;/th>
&lt;th style="text-align:center">Unilateral menor&lt;/th>
&lt;th style="text-align:left">Unilateral mayor&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align:center">$H_0$: $\theta = \theta_0$&lt;/td>
&lt;td style="text-align:center">$H_0$: $\theta = \theta_0$&lt;/td>
&lt;td style="text-align:left">$H_0$: $\theta = \theta_0$&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">$H_1$: $\theta \neq \theta_0$&lt;/td>
&lt;td style="text-align:center">$H_1$: $\theta &amp;lt; \theta_0$&lt;/td>
&lt;td style="text-align:left">$H_1$: $\theta &amp;gt; \theta_0$&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h3 id="elección-del-tipo-de-contraste">Elección del tipo de contraste&lt;/h3>
&lt;p>&lt;strong>Ejemplo&lt;/strong>. Supóngase que existen sospechas de que en una población hay menos hombres que mujeres.&lt;/p>
&lt;p>¿Qué tipo de contraste debería plantearse para validar o refutar esta sospecha?&lt;/p>
&lt;ol>
&lt;li>
&lt;p>Las sospechas se refieren al porcentaje o la proporción $p$ de hombres en la población, por lo que se trata de un &lt;em>contraste paramétrico&lt;/em>.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>El objetivo es averiguar el valor de $p$, por lo que se trata de una &lt;em>prueba de conformidad&lt;/em>. En la hipótesis nula el valor de $p$ se fijará a $0.5$ ya que, de acuerdo a las leyes de la genética, en la población debería haber la misma proporción de hombres que de mujeres.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Finalmente, existen sospechas de que el porcentaje de hombres es menor que el de mujeres, por lo que la hipótesis alternativa será de menor $p&amp;lt;0.5$.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>Así pues, el contraste que debería plantearse es el siguiente:&lt;/p>
&lt;p>$$
\begin{align*}
H_0: &amp;amp; p=0.5\newline
H_1: &amp;amp; p&amp;lt;0.5
\end{align*}
$$&lt;/p>
&lt;h3 id="estadístico-del-contraste">Estadístico del contraste&lt;/h3>
&lt;p>La aceptación o rechazo de la hipótesis nula depende, en última instancia, de lo que se observe en la muestra.&lt;/p>
&lt;p>La decisión se tomará según el valor que presente algún estadístico de la muestra relacionado con el parámetro o característica que se esté contrastando, y cuya distribución de probabilidad debe ser conocida suponiendo cierta la hipótesis nula y una vez fijado el tamaño de la muestra. Este estadístico recibe el nombre de &lt;strong>estadístico del contraste&lt;/strong>.&lt;/p>
&lt;p>Para cada muestra, el estadístico dará una estimación a partir de la cual se tomará la decisión: &lt;em>si la estimación difiere demasiado del valor esperado bajo la hipótesis $H_0$, entonces se rechazará, y en caso contrario se aceptará.&lt;/em>&lt;/p>
&lt;p>La lógica que guía la decisión es la de mantener la hipótesis nula a no ser que en la muestra haya pruebas contundentes de su falsedad. Siguiendo con el símil del juicio, se trataría de mantener la inocencia mientras no haya pruebas claras de culpabilidad.&lt;/p>
&lt;p>&lt;strong>Ejemplo&lt;/strong>. Volviendo al ejemplo del contraste sobre la proporción de hombres de una población&lt;/p>
&lt;p>$$
\begin{align*}
H_0: &amp;amp; p=0.5\newline
H_1: &amp;amp; p&amp;lt;0.5
\end{align*}
$$&lt;/p>
&lt;p>Si para resolver el contraste se toma una muestra aleatoria de 10 personas, podría tomarse como estadístico del contraste $X$ el número de hombres en la muestra.&lt;/p>
&lt;p>Suponiendo cierta la hipótesis nula, el estadístico del contraste seguiría una distribución binomial $X\sim B(10,,0.5)$, de manera que el número esperado de hombres en la muestra sería 5.&lt;/p>
&lt;p>Así pues, es lógico aceptar la hipótesis nula si en la muestra se obtiene un número de hombres próximo a 5 y rechazarla cuando el número de hombres sea muy inferior a 5. Pero, &lt;em>¿dónde poner el límite entre los valores $X$ que lleven a la aceptación y los que lleven al rechazo?&lt;/em>&lt;/p>
&lt;h3 id="regiones-de-aceptación-y-de-rechazo">Regiones de aceptación y de rechazo&lt;/h3>
&lt;p>Una vez elegido el estadístico del contraste, lo siguiente es decidir para qué valores de este estadístico se decidirá aceptar la hipótesis nula y para que valores se rechazará. Esto divide del conjunto de valores posibles del estadístico en dos regiones:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>Región de aceptación&lt;/strong>: Es el conjunto de valores del estadístico del contraste a partir de los cuales se decidirá aceptar la hipótesis nula.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Región de rechazo&lt;/strong>: Es el conjunto de valores del estadístico del contraste a partir de los cuales se decidirá rechazar la hipótesis nula, y por tanto, aceptar la hipótesis alternativa.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>Dependiendo de la dirección del contraste, la región de rechazo quedará a un lado u otro del valor esperado del estadístico del contraste según la hipótesis nula:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Contraste bilateral $H_0:\ \theta=\theta_0$ $H_1:\ \theta\neq\theta_0$.
&lt;img src="../img/contrastes/regiones_bilateral.svg" alt="Regiones de un contraste bilateral" width="700">&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Contraste unilateral de menor $H_0:\ \theta=\theta_0$ &amp;amp;H_1:\ \theta&amp;lt;\theta_0$.
&lt;img src="../img/contrastes/regiones_unilateral_menor.svg" alt="Regiones de un contraste unilateral de menor" width="700">&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Contraste unilateral de mayor $H_0:\ \theta=\theta_0$ $H_1:\ \theta&amp;gt;\theta_0$.
&lt;img src="../img/contrastes/regiones_unilateral_mayor.svg" alt="Regiones de un contraste unilateral de mayor" width="700">&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Ejemplo&lt;/strong>. Siguiendo con el ejemplo del contraste sobre la proporción de hombres de una población&lt;/p>
&lt;p>$$
\begin{align*}
H_0: &amp;amp; p=0.5\newline
H_1: &amp;amp; p&amp;lt;0.5
\end{align*}
$$&lt;/p>
&lt;p>Como el estadístico del contraste tenía una distribución binomial $X\sim B(10,,0.5)$ suponiendo cierta la hipótesis nula, su recorrido será de 0 a 10 y su valor esperado 5, por lo que, al tratarse de un contraste unilateral de menor, la región de rechazo quedará por debajo del 5. Pero, &lt;em>¿dónde poner el límite entre las regiones de aceptación y de rechazo?&lt;/em>&lt;/p>
&lt;img src="../img/contrastes/regiones_contraste_proporcion_hombres.svg" alt="Regiones de un contraste sobre la proporción de hombres en una muestra de tamño 10." width="700">
&lt;h3 id="errores-en-un-contraste-de-hipótesis">Errores en un contraste de hipótesis&lt;/h3>
&lt;p>Hemos visto que un contraste de hipótesis se realiza mediante una regla de decisión que permite aceptar o rechazar la hipótesis nula dependiendo del valor que tome el estadístico del contraste.&lt;/p>
&lt;p>Al final el contraste se resuelve tomando una decisión de acuerdo a esta regla. El problema es que nunca se conocerá con absoluta certeza la veracidad o falsedad de una hipótesis, de modo que al aceptarla o rechazarla es posible que se esté tomando una decisión equivocada.&lt;/p>
&lt;p>Los errores que se pueden cometer en un contraste de hipótesis son de dos tipos:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>Error de tipo I&lt;/strong>: Se comete cuando se rechaza la hipótesis nula siendo esta verdadera.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Error de tipo II&lt;/strong>: Se comete cuando se acepta la hipótesis nula siendo esta falsa.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>$$
\begin{array}{|c|c|c|}
\hline
\mbox{Decisión} &amp;amp; H_0 \mbox{ cierta} &amp;amp; H_1 \mbox{ cierta}\newline
\hline
\mbox{Aceptar } H_0 &amp;amp; \color{green}{\mbox{Decisión correcta}} &amp;amp; \color{red}{\mbox{Error de tipo II}}\newline
\hline
\mbox{Rechazar }H_0 &amp;amp; \color{red}{\mbox{Error de tipo I}} &amp;amp; \color{green}{\mbox{Decisión correcta}}\newline
\hline
\end{array}
$$&lt;/p>
&lt;h3 id="riesgos-de-los-errores-de-un-contraste-de-hipótesis">Riesgos de los errores de un contraste de hipótesis&lt;/h3>
&lt;p>Los riesgos de cometer cada tipo de error se cuantifican mediante probabilidades:&lt;/p>
&lt;div class="alert alert-def">
&lt;div>
&lt;p>&lt;strong>Definición - Riesgos $\alpha$ y $\beta$&lt;/strong>. En un contraste de hipótesis, se define el &lt;em>riesgo&lt;/em> $\alpha$ como la máxima probabilidad de cometer un error de tipo I, es decir,&lt;/p>
&lt;p>$$P(\mbox{Rechazar }H_0|H_0) \leq \alpha,$$&lt;/p>
&lt;p>y se define el &lt;em>riesgo&lt;/em> $\beta$ como la máxima probabilidad de cometer un error de tipo II, es decir,&lt;/p>
&lt;p>$P(\mbox{Aceptar }H_0|H_1) \leq \beta.$$&lt;/p>
&lt;/div>
&lt;/div>
&lt;h3 id="interpretación-del-riesgo-alpha">Interpretación del riesgo $\alpha$&lt;/h3>
&lt;div class="alert alert-warning">
&lt;div>
En principio, puesto que esta metodología favorece a la hipótesis nula, el error del tipo I suele ser más grave que el error del tipo II, y por tanto, el riesgo $\alpha$ suele fijarse a niveles bajos de $0.1$, $0.05$ o $0.01$, siendo $0.05$ lo más habitual.
&lt;/div>
&lt;/div>
&lt;div class="alert alert-int">
&lt;div>
&lt;p>Debe tenerse cuidado al interpretar el riesgo $\alpha$ ya que se trata de una probabilidad condicionada a que la hipótesis nula sea cierta. Por tanto, cuando se rechace la hipótesis nula con un riesgo $\alpha=0.05$, es erróneo decir 5 de cada 100 veces nos equivocaremos, ya que esto sería cierto sólo si la hipótesis nula fuese siempre verdadera.&lt;/p>
&lt;p>Tampoco tiene sentido hablar de la probabilidad de haberse equivocado una vez tomada una decisión a partir de una muestra concreta, pues en tal caso, si se ha tomado la decisión acertada, la probabilidad de error es 0 y si se ha tomado la decisión equivocada, la probabilidad de error es 1.&lt;/p>
&lt;/div>
&lt;/div>
&lt;h3 id="determinación-de-las-regiones-de-aceptación-y-de-rechazo-en-función-del-riesgo-alpha">Determinación de las regiones de aceptación y de rechazo en función del riesgo $\alpha$&lt;/h3>
&lt;p>Una vez fijado el riesgo $\alpha$ que se está dispuesto a tolerar, es posible delimitar las regiones de aceptación y de rechazo para el estadístico del contraste de manera que la probabilidad acumulada en la región de rechazo sea $\alpha$, suponiendo cierta la hipótesis nula.&lt;/p>
&lt;img src="../img/contrastes/regiones_bilateral_normal.svg" alt="Regiones de un contraste bilateral en una distribución normal" width="600">
&lt;img src="../img/contrastes/regiones_unilateral_mayor_normal.svg" alt="Regiones de un contraste unilateral de mayor en una distribución normal" width="600">
&lt;p>&lt;strong>Ejemplo&lt;/strong>. Siguiendo con el contraste sobre la proporción de hombres de una población, como el estadístico del contraste sigue una distribución binomial $X\sim B(10,0.5)$, si se decide rechazar la hipótesis nula
cuando en la muestra haya 2 o menos hombres, la probabilidad de cometer un error de tipo I será&lt;/p>
&lt;p>$$P(X\leq 2)= f(0)+f(1)+f(2)= 0.0010 + 0.0098 + 0.0439 = 0.0547.$$&lt;/p>
&lt;p>Si riesgo máximo de error de tipo I que se está dispuesto a tolerar es $\alpha=0.05$, ¿qué valores del estadístico permitirán rechazar la hipótesis nula? $$P(X\leq 1)= f(0)+f(1) = 0.0010 + 0.0098 = 0.0107.$$ Es
decir, sólo se podría rechazar la hipótesis nula con 0 o 1 hombres en la muestra.&lt;/p>
&lt;img src="../img/contrastes/regiones_contraste_proporcion_hombres_2.svg" alt="Regiones de un contraste sobre la proporción de hombres en una muestra de tamño 10." width="700">
&lt;h3 id="riesgo-beta-y-tamaño-del-efecto">Riesgo $\beta$ y tamaño del efecto&lt;/h3>
&lt;p>Aunque el error de tipo II pueda parecer menos grave, también interesa que el riesgo $\beta$ sea bajo, ya que de lo contrario será difícil rechazar la hipótesis nula (que es lo que se persigue la mayoría de las veces), aunque haya pruebas muy claras de su falsedad.&lt;/p>
&lt;p>El problema, en el caso de contrastes paramétricos, es que la hipótesis alternativa es una hipótesis abierta en la que no se fija el valor del parámetro a contrastar, de modo que, para poder calcular el riesgo $\beta$ es necesario fijar dicho valor.&lt;/p>
&lt;p>Lo normal es fijar el valor del parámetro del contraste a la mínima cantidad para admitir diferencias significativas desde un punto de vista práctico o clínico. Esa mínima diferencia que se considera clínicamente significativa se conoce como &lt;strong>tamaño del efecto&lt;/strong> y se representa por $\delta$.&lt;/p>
&lt;h3 id="potencia-de-un-contraste">Potencia de un contraste&lt;/h3>
&lt;p>Puesto que el objetivo del investigador suele ser rechazar la hipótesis nula, a menudo, lo más interesante de un contraste es su capacidad para detectar la falsedad de la hipótesis nula cuando realmente hay diferencias mayores que $\delta$ entre el verdadero valor del parámetro y el que establece la hipótesis nula.&lt;/p>
&lt;div class="alert alert-def">
&lt;div>
&lt;p>&lt;strong>Definición - Potencia de un contraste&lt;/strong>. La &lt;em>potencia&lt;/em> de un contraste de hipótesis se define como&lt;/p>
&lt;p>$$\mbox{Potencia} = P(\mbox{Rechazar }H_0|H_1) = 1 - P(\mbox{Aceptar }H_0|H_1) = 1-\beta.$$&lt;/p>
&lt;/div>
&lt;/div>
&lt;p>Así pues, al reducir el riesgo $\beta$ se aumentará la potencia del contraste.&lt;/p>
&lt;p>Un contraste poco potente no suele ser interesante ya que no permitirá rechazar la hipótesis nula aunque haya evidencias en su contra.&lt;/p>
&lt;h3 id="cálculo-del-riesgo-beta-y-de-la-potencia-1-beta">Cálculo del riesgo $\beta$ y de la potencia $1-\beta$&lt;/h3>
&lt;p>&lt;strong>Ejemplo&lt;/strong> Supóngase que en el contraste sobre la proporción de hombres no se considera importante una diferencia de menos de un 10% con respecto al valor que establece la hipótesis nula, es decir, $\delta=0.1$.&lt;/p>
&lt;p>Esto permite fijar la hipótesis alternativa&lt;/p>
&lt;p>$$H_1:\ p=0.5-0.1=0.4.$$&lt;/p>
&lt;p>Suponiendo cierta esta hipótesis el estadístico del contraste seguiría una distribución binomial $X\sim B(10,,0.4)$.&lt;/p>
&lt;p>En tal caso, el riesgo $\beta$ para las regiones de aceptación y rechazo fijadas antes será&lt;/p>
&lt;p>$$\beta = P(\mbox{Aceptar }H_0|H_1) = P(X\geq 2) = 1 - P(X&amp;lt;2) = 1-0.0464 = 0.9536.$$&lt;/p>
&lt;p>Como puede apreciarse, se trata de un riesgo $\beta$ muy alto, por lo que la potencia del contraste sería sólo de&lt;/p>
&lt;p>$$1-\beta = 1-0.9536 = 0.0464,$$&lt;/p>
&lt;p>lo que indica que no se trataría de un buen contraste para detectar diferencias de un 10% en el valor del parámetro.&lt;/p>
&lt;h3 id="relación-del-riesgo-beta-y-el-tamaño-del-efecto-delta">Relación del riesgo $\beta$ y el tamaño del efecto $\delta$&lt;/h3>
&lt;p>El riesgo $\beta$ depende directamente de la mínima diferencia $\delta$ que se desea detectar con respecto al valor del parámetro que establece la hipótesis nula.&lt;/p>
&lt;img src="../img/contrastes/riesgo_beta_tamaño_efecto_pequeño.svg" alt="Riesgo beta para un tamaño del efecto pequeño." width="600">
&lt;img src="../img/contrastes/riesgo_beta_tamaño_efecto_grande.svg" alt="Riesgo beta para un tamaño del efecto grande." width="600">
&lt;p>&lt;strong>Ejemplo&lt;/strong>. Si en el contraste sobre la proporción de hombres se desease detectar una diferencia de al menos un 20% con respecto al valor que establece la hipótesis nula, es decir, $\delta=0.2$, entonces la hipótesis alternativa se fijaría a&lt;/p>
&lt;p>$$H_1:\ p=0.5-0.2=0.3,$$&lt;/p>
&lt;p>y bajo esta hipótesis el estadístico del contraste seguiría una distribución binomial $X\sim B(10,,0.3)$.&lt;/p>
&lt;p>En tal caso, el riesgo $\beta$ para las regiones de aceptación y rechazo fijadas antes sería&lt;/p>
&lt;p>$$\beta = P(\mbox{Aceptar }H_0|H_1) = P(X\geq 2) = 1 - P(X&amp;lt;2) = 1-0.1493 = 0.8507,$$&lt;/p>
&lt;p>por lo que el riesgo riesgo $\beta$ disminuiría y la potencia del contraste aumentaría&lt;/p>
&lt;p>$$1-\beta = 1-0.8507 = 0.1493,$$&lt;/p>
&lt;p>aunque seguiría siendo un contraste poco potente.&lt;/p>
&lt;h3 id="relación-entre-los-riesgos-alpha-y-beta">Relación entre los riesgos $\alpha$ y $\beta$&lt;/h3>
&lt;p>Los riesgos $\alpha$ y $\beta$ están enfrentados, es decir, cuando uno aumenta el otro disminuye y viceversa.&lt;/p>
&lt;img src="../img/contrastes/relacion_riesgos_alpha_pequeño.svg" alt="Riesgo beta para un tamaño del efecto pequeño." width="600">
&lt;img src="../img/contrastes/relacion_riesgos_alpha_grande.svg" alt="Riesgo beta para un tamaño del efecto grande." width="600">
&lt;p>&lt;strong>Ejemplo&lt;/strong>. Si en el contraste sobre la proporción de hombres toma como riesgo $\alpha=0.1,$ entonces la región de rechazo sería $X\leq 2$ ya que, suponiendo cierta la hipótesis nula, $X\sim B(10,, 0.5)$, y&lt;/p>
&lt;p>$$P(X\leq 2) = 0.0547 \leq 0.1=\alpha.$$&lt;/p>
&lt;p>Entonces, para una diferencia mínima $\delta=0.1$ y suponiendo cierta la hipótesis alternativa,
$X\sim B(10,,0.4)$, el riesgo $\beta$ será&lt;/p>
&lt;p>$$\beta = P(\mbox{Aceptar }H_0|H_1) = P(X\geq 3) = 1- P(X&amp;lt;3) = 1-0.1673 = 0.8327,$$&lt;/p>
&lt;p>y ahora la potencia ha subido hasta&lt;/p>
&lt;p>$$1-\beta = 1-0.8327 = 0.1673.$$&lt;/p>
&lt;h3 id="relación-de-los-riesgos-de-error-y-el-tamaño-muestral">Relación de los riesgos de error y el tamaño muestral&lt;/h3>
&lt;p>Los riesgos de error también dependen el tamaño de la muestra, ya que al aumentar el tamaño de la muestra, la dispersión del estadístico del contraste disminuye y con ello también lo hacen los riesgos de error.&lt;/p>
&lt;img src="../img/contrastes/relacion_riesgos_tamaño_muestral_pequeño.svg" alt="Riesgo beta para un tamaño del efecto grande." width="600">
&lt;img src="../img/contrastes/relacion_riesgos_tamaño_muestral_grande.svg" alt="Riesgo beta para un tamaño del efecto grande." width="600">
&lt;p>&lt;strong>Ejemplo&lt;/strong>. Si para realizar el contraste sobre la proporción de hombres se hubiese
tomado una muestra de tamaño 100, en lugar de 10, entonces, bajo la suposición de certeza de la hipótesis nula, el estadístico del contraste seguiría una distribución binomial $B(100,,0.5)$, y ahora la región de rechazo sería $X\leq 41$, ya que&lt;/p>
&lt;p>$$P(X\leq 41) = 0.0443 \leq 0.05 =\alpha.$$&lt;/p>
&lt;p>Entonces, para $\delta=0.1$ y suponiendo cierta la hipótesis alternativa, $X\sim B(100,,0.4)$, el
riesgo $\beta$ sería&lt;/p>
&lt;p>$$\beta = P(\mbox{Aceptar }H_0|H_1) = P(X\geq 42) = 0.3775,$$&lt;/p>
&lt;p>y ahora la potencia habría aumentado considerablemente&lt;/p>
&lt;p>$$1-\beta = 1-0.3775 = 0.6225.$$&lt;/p>
&lt;p>Este contraste sería mucho más útil para detectar una diferencia de al menos un 10% con respecto al valor del parámetro que establece la hipótesis nula.&lt;/p>
&lt;h3 id="curva-de-potencia">Curva de potencia&lt;/h3>
&lt;p>La potencia de un contraste depende del valor del parámetro que establezca la hipótesis alternativa y, por tanto, es una función de este&lt;/p>
&lt;p>$$\mbox{Potencia}(x)= P(\mbox{Rechazar }H_0|\theta=x).$$&lt;/p>
&lt;p>Esta función da la probabilidad de rechazar la hipótesis nula para cada valor del parámetro y se conoce como &lt;strong>curva de potencia&lt;/strong>.&lt;/p>
&lt;p>Cuando no se puede fijar el valor concreto del parámetro en la hipótesis alternativa, resulta útil representar esta curva para ver la bondad del contraste cuando no se rechaza la hipótesis nula. También es útil cuando sólo de dispone de un número determinado de individuos en la muestra, para ver si merece la pena hacer el estudio.&lt;/p>
&lt;div class="alert alert-int">
&lt;div>
Un contraste será mejor cuanto mayor sea el área encerrada por debajo de la curva de potencia.
&lt;/div>
&lt;/div>
&lt;p>&lt;strong>Ejemplo&lt;/strong>. La curva de potencia correspondiente al contraste sobre la proporción de hombres en la población es la siguiente&lt;/p>
&lt;img src="../img/contrastes/potencia.svg" alt="Curva de potencia para muestras de distinto tamaño." width="600">
&lt;h3 id="p-valor-de-un-contraste-de-hipótesis">$p$-valor de un contraste de hipótesis&lt;/h3>
&lt;p>En general, siempre que la estimación del estadístico caiga dentro de la región de rechazo, rechazaremos la hipótesis nula, pero evidentemente, si dicha estimación se aleja bastante de la región de aceptación tendremos más confianza en el rechazo que si la estimación está cerca del límite entre las regiones de aceptación y rechazo.&lt;/p>
&lt;p>Por este motivo, al realizar un contraste, también se calcula la probabilidad de obtener una discrepancia mayor o igual a la observada entre la estimación del estadístico del contraste y su valor esperado según la hipótesis nula.&lt;/p>
&lt;div class="alert alert-def">
&lt;div>
&lt;p>&lt;strong>Definición- $p$-valor&lt;/strong>. En un contraste de hipótesis, para cada estimación $x_0$ del estadístico del contraste $X$, dependiendo del tipo de contraste, se define el $p$-valor del contraste como&lt;/p>
&lt;p>$$
\begin{array}{lc}
\mbox{Contraste bilateral}: &amp;amp; 2P(X\geq x_0|H_0)\newline
\mbox{Contraste unilateral de menor}: &amp;amp; P(X\leq x_0|H_0)\newline
\mbox{Contraste unilateral de mayor}: &amp;amp; P(X\geq x_0|H_0)
\end{array}
$$&lt;/p>
&lt;/div>
&lt;/div>
&lt;div class="alert alert-int">
&lt;div>
En cierto modo, el $p$-valor expresa la confianza que se tiene al tomar la decisión de rechazar la hipótesis nula. Cuanto más próximo esté el $p$-valor a 1, mayor confianza existe al aceptar la hipótesis nula, y cuanto más próximo esté a 0, mayor confianza hay al rechazarla.
&lt;/div>
&lt;/div>
&lt;p>Una vez fijado el riesgo $\alpha$, la regla de decisión para realizar un contraste también puede expresarse de la siguiente manera:&lt;/p>
&lt;div class="alert alert-warning">
&lt;div>
&lt;p>&lt;strong>Regla de decisión de un contraste&lt;/strong>&lt;/p>
&lt;p>$$
\begin{array}{ccc}
\mbox{Si $p$-valor $\leq \alpha$} &amp;amp; \rightarrow &amp;amp; \mbox{Rechazar $H_0$}\newline
\mbox{Si $p$-valor $&amp;gt; \alpha$} &amp;amp; \rightarrow &amp;amp; \mbox{Aceptar $H_0$}.
\end{array}
$$&lt;/p>
&lt;/div>
&lt;/div>
&lt;p>De este modo, el $p$-valor nos da información de para qué niveles de significación puede rechazarse la hipótesis nula y para cuales no.&lt;/p>
&lt;p>&lt;strong>Ejemplo&lt;/strong>. Si el contraste sobre la proporción de hombres se toma una muestra de tamaño 10 y se observa 1 hombre, entonces el $p$-valor, bajo a supuesta certeza de la hipótesis nula, $X\sim B(10,, 0.5)$, será&lt;/p>
&lt;p>$$p = P(X\leq 1)= 0.0107,$$&lt;/p>
&lt;p>mientras que si en la muestra se observan 0 hombres, entonces el $p$-valor será&lt;/p>
&lt;p>$$p = P(X\leq 0)= 0.001.$$&lt;/p>
&lt;p>En el primer caso se rechazaría la hipótesis nula para un riesgo $\alpha=0.05$, pero no podría rechazarse par un riesgo $\alpha=0.01$, mientas que en el segundo caso también se rechazaría para $\alpha=0.01$. Es evidente que en el segundo la decisión de rechazar la hipótesis nula se tomaría con mayor confianza.&lt;/p>
&lt;h3 id="pasos-para-la-realización-de-un-contraste-de-hipótesis">Pasos para la realización de un contraste de hipótesis&lt;/h3>
&lt;ol>
&lt;li>Formular la hipótesis nula $H_0$ y la alternativa $H_1$.&lt;/li>
&lt;li>Fijar los riesgos $\alpha$ y $\beta$ deseados.&lt;/li>
&lt;li>Seleccionar el estadístico del contraste.&lt;/li>
&lt;li>Fijar la mínima diferencia clínicamente significativa (tamaño del efecto) $\delta$.&lt;/li>
&lt;li>Calcular el tamaño muestral necesario $n$.&lt;/li>
&lt;li>Delimitar las regiones de aceptación y rechazo.&lt;/li>
&lt;li>Tomar una muestra de tamaño $n$.&lt;/li>
&lt;li>Calcular el estadístico del contraste en la muestra.&lt;/li>
&lt;li>Rechazar la hipótesis nula si la estimación cae en la región de rechazo o bien si el $p$-valor es menor que el riesgo $\alpha$ y aceptarla en caso contrario.&lt;/li>
&lt;/ol>
&lt;h2 id="contrastes-paramétricos-más-importantes">Contrastes paramétricos más importantes&lt;/h2>
&lt;p>Pruebas de conformidad:&lt;/p>
&lt;ul>
&lt;li>Contraste para la media de una población normal con varianza conocida.&lt;/li>
&lt;li>Contraste para la media de una población normal con varianza desconocida.&lt;/li>
&lt;li>Contraste para la media de una población con varianza desconocida a partir de muestras grandes.&lt;/li>
&lt;li>Contraste para la varianza de una población normal.&lt;/li>
&lt;li>Contraste para un proporción de una población.&lt;/li>
&lt;/ul>
&lt;p>Pruebas de homogeneidad:&lt;/p>
&lt;ul>
&lt;li>Contraste de comparación de medias de dos poblaciones normales con varianzas conocidas.&lt;/li>
&lt;li>Contraste de comparación de medias de dos poblaciones normales con varianzas desconocidas pero iguales.&lt;/li>
&lt;li>Contraste de comparación de medias de dos poblaciones normales con varianzas desconocidas y diferentes.&lt;/li>
&lt;li>Contraste de comparación de varianzas de dos poblaciones normales.&lt;/li>
&lt;li>Contraste de comparación de proporciones de dos poblaciones.&lt;/li>
&lt;/ul>
&lt;h2 id="pruebas-de-conformidad">Pruebas de conformidad&lt;/h2>
&lt;h3 id="contraste-para-la-media-de-una-población-normal-con-varianza-conocida">Contraste para la media de una población normal con varianza conocida&lt;/h3>
&lt;p>Sea $X$ una variable aleatoria que cumple las siguientes condiciones:&lt;/p>
&lt;ul>
&lt;li>Su distribución es normal $X\sim N(\mu,\sigma)$.&lt;/li>
&lt;li>La media $\mu$ es desconocida, pero su varianza $\sigma^2$ es conocida.&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Contraste&lt;/strong>:&lt;/p>
&lt;p>$$
\begin{aligned}
H_0 &amp;amp;: \mu=\mu_0\newline
H_1 &amp;amp;: \mu\neq \mu_0\end{aligned}
$$&lt;/p>
&lt;p>&lt;strong>Estadístico del contraste&lt;/strong>:&lt;/p>
&lt;p>$$
\bar x\sim N\left(\mu_0,\frac{\sigma}{\sqrt{n}}\right) \Rightarrow Z=\frac{\bar x-\mu_0}{\sigma/\sqrt{n}}\sim N(0,1).
$$&lt;/p>
&lt;p>&lt;strong>Región de aceptación&lt;/strong>: $z_{\alpha/2}&amp;lt; Z &amp;lt; z_{1-\alpha/2}$.&lt;br>
&lt;strong>Región de rechazo&lt;/strong>: $Z\leq z_{\alpha/2}$ y $Z\geq z_{1-\alpha/2}$.&lt;/p>
&lt;h3 id="contraste-para-la-media-de-una-población-normal-con-varianza-desconocida">Contraste para la media de una población normal con varianza desconocida&lt;/h3>
&lt;p>Sea $X$ una variable aleatoria que cumple las siguientes condiciones:&lt;/p>
&lt;ul>
&lt;li>Su distribución es normal $X\sim N(\mu,\sigma)$.&lt;/li>
&lt;li>Tanto su media $\mu$ como su varianza $\sigma^2$ son desconocidas.&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Contraste&lt;/strong>:&lt;/p>
&lt;p>$$
\begin{aligned}
H_0 &amp;amp;: \mu=\mu_0\newline
H_1 &amp;amp;: \mu\neq \mu_0\end{aligned}
$$&lt;/p>
&lt;p>&lt;strong>Estadístico del contraste&lt;/strong>: Utilizando la cuasivarianza como estimador de la varianza poblacional se tiene&lt;/p>
&lt;p>$$
\bar x\sim N\left(\mu_0,\frac{\sigma}{\sqrt{n}}\right) \Rightarrow T=\frac{\bar x-\mu_0}{\hat s/\sqrt{n}}\sim T(n-1).
$$&lt;/p>
&lt;p>&lt;strong>Región de aceptación&lt;/strong>: $t^{n-1}_{\alpha/2} &amp;lt; T &amp;lt; t^{n-1}_{1-\alpha/2}$.&lt;br>
&lt;strong>Región de rechazo&lt;/strong>: $T\leq t^{n-1}_{\alpha/2}$ y $T\geq t^{n-1}_{1-\alpha/2}$.&lt;/p>
&lt;p>&lt;strong>Ejemplo&lt;/strong>. En un grupo de alumnos se quiere contrastar si la nota media de estadística es mayor que 5 puntos. Para ello se toma la siguiente muestra:&lt;/p>
&lt;div style="text-align:center">
6.3, 5.4, 4.1, 5.0, 8.2, 7.6, 6.4, 5.6, 4.3, 5.2
&lt;/div>
&lt;p>El contraste que se plantea es&lt;/p>
&lt;p>$$H_0: \mu=5 \quad H_1: \mu&amp;gt;5$$&lt;/p>
&lt;p>Para realizar el contraste se tiene:&lt;/p>
&lt;ul>
&lt;li>$\bar x = \frac{6.3+\cdots+5.2}{10}=\frac{58.1}{10}=5.81$ puntos.&lt;/li>
&lt;li>$\hat s^2 = \frac{(6.3-5.56)^2+\cdots+(5.2-5.56)^2}{9} = \frac{15.949}{9}=1.7721$ puntos$^2$, y $\hat s=1.3312$ puntos.&lt;/li>
&lt;/ul>
&lt;p>Y el estadístico del contraste vale&lt;/p>
&lt;p>$$
T=\frac{\bar x-\mu_0}{\hat s/\sqrt{n}} = \frac{5.81-5}{1.3312/\sqrt{10}}= 1.9246.
$$&lt;/p>
&lt;p>El $p$-valor del contraste es $P(T(9)\geq 1.9246) = 0.04323$, lo que indica que se rechazaría la hipótesis nula para $\alpha=0.05$.&lt;/p>
&lt;p>La región de rechazo es&lt;/p>
&lt;p>$$
T=\frac{\bar x-5}{1.3312/\sqrt{10}} \geq t^9_{0.95} = 1.8331 \Leftrightarrow \bar x \geq 5+1.8331\frac{1.3312}{\sqrt
10} = 5.7717,
$$&lt;/p>
&lt;p>de modo que se rechazará la hipótesis nula siempre que la media de la muestra sea mayor que $5.7717$ y se aceptará en caso contrario.&lt;/p>
&lt;p>Suponiendo que en la práctica la mínima diferencia importante en la nota media fuese de un punto $\delta=1$, entonces bajo la hipótesis alternativa $H_1:\mu=6$, si se decidiese rechazar la hipótesis nula, el riesgo $\beta$ sería&lt;/p>
&lt;p>$$
\beta = P\left(T(9)\leq \frac{5.7717-6}{1.3312\sqrt 10}\right) = P(T(9)\leq -0.5424) = 0.3004,
$$&lt;/p>
&lt;p>de manera que la potencia del contraste para detectar una diferencia de $\delta=1$ punto sería $1-\beta=1-0.3004 = 0.6996$.&lt;/p>
&lt;h3 id="determinación-del-tamaño-muestral-en-un-contraste-para-la-media">Determinación del tamaño muestral en un contraste para la media&lt;/h3>
&lt;p>Se ha visto que para un riesgo $\alpha$ la región de rechazo era&lt;/p>
&lt;p>$$
T=\frac{\bar x-\mu_0}{\hat s/\sqrt{n}} \geq t^{n-1}&lt;em>{1-\alpha} \approx z&lt;/em>{1-\alpha}\quad \mbox{para } n\geq 30.
$$&lt;/p>
&lt;p>o lo que es equivalente&lt;/p>
&lt;p>$$
\bar x \geq \mu_0+z_{1-\alpha}\frac{\hat s}{\sqrt n}.
$$&lt;/p>
&lt;p>Si el tamaño del efecto es $\delta$, para una hipótesis alternativa $H_1:\mu=\mu_0+\delta$, el riesgo $\beta$ es&lt;/p>
&lt;p>$$
\beta = P\left(Z&amp;lt; \frac{\mu_0+z_{1-\alpha}\frac{\hat s}{\sqrt n}-(\mu_0+\delta)}{\frac{\hat s}{\sqrt n}} \right) = P\left(Z&amp;lt; \frac{z_{1-\alpha}\frac{\hat s}{\sqrt n}-\delta}{\frac{\hat s}{\sqrt n}} \right).
$$&lt;/p>
&lt;p>de modo que&lt;/p>
&lt;p>$$
z_\beta = \frac{z_{1-\alpha}\frac{\hat s}{\sqrt n}-\delta}{\frac{\hat s}{\sqrt n}} \Leftrightarrow \delta = (z_{1-\alpha}-z_\beta)\frac{\hat s}{\sqrt n} \Leftrightarrow n = (z_{1-\alpha}-z_\beta)^2\frac{\hat s^2}{\delta^2} = (z_\alpha+z_\beta)^2\frac{\hat s^2}{\delta^2}.
$$&lt;/p>
&lt;p>&lt;strong>Ejemplo&lt;/strong>. Se ha visto en el ejemplo anterior que la potencia del contraste para detectar una diferencia en la nota media de 1 punto era del $69.96%$.
Para aumentar la potencia del test hasta un $90%$, ¿cuántos alumnos habría que tomar en la muestra?&lt;/p>
&lt;p>Como se desea una potencia $1-\beta=0.9$, el riesgo $\beta=0.1$ y mirando en la tabla de la normal estándar se puede comprobar que $z_\beta = z_{0.1}=1.2816$.&lt;/p>
&lt;p>Aplicando la fórmula anterior para determinar el tamaño muestral necesario, se tiene&lt;/p>
&lt;p>$$
n = (z_\alpha+z_\beta)^2\frac{\hat s^2}{\delta^2} = (1.6449+1.2816)^2\frac{1.7721}{1^2} = 15.18,
$$&lt;/p>
&lt;p>de manera que habría que haber tomado al menos 16 alumnos.&lt;/p>
&lt;h3 id="contraste-para-la-media-de-una-población-con-varianza-desconocida-y-muestras-grandes-ngeq-30">Contraste para la media de una población con varianza desconocida y muestras grandes $n\geq 30$&lt;/h3>
&lt;p>Sea $X$ una variable aleatoria que cumple las siguientes condiciones:&lt;/p>
&lt;ul>
&lt;li>Su distribución puede ser de cualquier tipo.&lt;/li>
&lt;li>Tanto su media $\mu$ como su varianza $\sigma^2$ son desconocidas.&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Contraste&lt;/strong>:&lt;/p>
&lt;p>$$
\begin{aligned}
H_0 &amp;amp;: \mu=\mu_0\newline
H_1 &amp;amp;: \mu\neq \mu_0
\end{aligned}
$$&lt;/p>
&lt;p>&lt;strong>Estadístico del contraste&lt;/strong>: Utilizando la cuasivarianza como estimador de la varianza poblacional y gracias al teorema central del límite por tratarse de muestras grandes ($n\geq 30)$ se tiene&lt;/p>
&lt;p>$$
\bar x\sim N\left(\mu_0,\frac{\sigma}{\sqrt{n}}\right) \Rightarrow Z=\frac{\bar x-\mu_0}{\hat s/\sqrt{n}}\sim N(0,1).
$$&lt;/p>
&lt;p>&lt;strong>Región de aceptación&lt;/strong>: $-z_{\alpha/2}&amp;lt; Z &amp;lt; z_{\alpha/2}$.&lt;br>
&lt;strong>Región de rechazo&lt;/strong>: $Z\leq -z_{\alpha/2}$ y $Z\geq z_{\alpha/2}$.&lt;/p>
&lt;h3 id="contraste-para-la-varianza-de-una-población-normal">Contraste para la varianza de una población normal&lt;/h3>
&lt;p>Sea $X$ una variable aleatoria que cumple las siguientes hipótesis:&lt;/p>
&lt;ul>
&lt;li>Su distribución es normal $X\sim N(\mu,\sigma)$.&lt;/li>
&lt;li>Tanto su media $\mu$ como su varianza $\sigma^2$ son desconocidas.&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Contraste&lt;/strong>:&lt;/p>
&lt;p>$$
\begin{aligned}
H_0 &amp;amp;: \sigma=\sigma_0\newline
H_1 &amp;amp;: \sigma\neq \sigma_0
\end{aligned}
$$&lt;/p>
&lt;p>&lt;strong>Estadístico del contraste&lt;/strong>: Partiendo de la cuasivarianza muestral como estimador de la varianza poblacional, se tiene&lt;/p>
&lt;p>$$
J=\frac{nS^2}{\sigma_0^2} = \frac{(n-1)\hat{S}^2}{\sigma_0^2}\sim \chi^2(n-1),
$$&lt;/p>
&lt;p>que sigue una distribución chi-cuadrado de $n-1$ grados de libertad.&lt;/p>
&lt;p>&lt;strong>Región de aceptación&lt;/strong>: $\chi_{\alpha/2}^{n-1} &amp;lt; J &amp;lt; \chi_{1-\alpha/2}^{n-1}$.&lt;br>
&lt;strong>Región de rechazo&lt;/strong>: $J\leq \chi_{\alpha/2}^{n-1}$ y $J\geq \chi_{1-\alpha/2}^{n-1}$.&lt;/p>
&lt;p>&lt;strong>Ejemplo&lt;/strong>. En un grupo de alumnos se quiere contrastar si la desviación típica de la nota es mayor de 1 punto. Para ello se toma la siguiente muestra:&lt;/p>
&lt;div style="text-align:center">
6.3, 5.4, 4.1, 5.0, 8.2, 7.6, 6.4, 5.6, 4.3, 5.2
&lt;/div>
&lt;p>El contraste que se plantea es&lt;/p>
&lt;p>$$
H_0: \sigma=1 \quad H_1: \sigma&amp;gt;1
$$&lt;/p>
&lt;p>Para realizar el contraste se tiene:&lt;/p>
&lt;ul>
&lt;li>$\bar x = \frac{6.3+\cdots+5.2}{10}=\frac{58.1}{10}=5.81$ puntos.&lt;/li>
&lt;li>$\hat s^2 = \frac{(6.3-5.56)^2+\cdots+(5.2-5.56)^2}{9} = \frac{15.949}{9}=1.7721$ puntos$^2$.&lt;/li>
&lt;/ul>
&lt;p>El estadístico del contraste vale&lt;/p>
&lt;p>$$
J= \frac{(n-1)\hat{S}^2}{\sigma_0^2} = \frac{9\cdot1.7721}{1^2} = 15.949,
$$&lt;/p>
&lt;p>y el $p$-valor del contraste es $P(\chi(9)\geq 15.949) = 0.068$, por lo que no se puede rechazar la hipótesis nula para $\alpha=0.05$.&lt;/p>
&lt;h3 id="contraste-para-proporción-de-una-población">Contraste para proporción de una población&lt;/h3>
&lt;p>Sea $p$ la proporción de individuos de una población que tienen una determinada característica.&lt;/p>
&lt;p>&lt;strong>Contraste&lt;/strong>:&lt;/p>
&lt;p>$$
\begin{aligned}
H_0 &amp;amp;: p=p_0\newline
H_1 &amp;amp;: p\neq p_0
\end{aligned}
$$&lt;/p>
&lt;p>&lt;strong>Estadístico del contraste&lt;/strong>: La variable que mide el número de individuos con la característica en una muestra aleatoria de tamaño $n$ sigue una distribución binomial $X\sim B(n,p_0)$. De acuerdo al teorema central del límite, para muestras grandes ($np\geq 5$ y $n(1-p)\geq 5$), $X\sim N(np_0,\sqrt{np_0(1-p_0)})$, y se cumple&lt;/p>
&lt;p>$$
\hat{p}=\frac{X}{n} \sim N\left(p_0,\sqrt{\frac{p_0(1-p_0)}{n}}\right) \Rightarrow Z = \frac{\hat
p-p_0}{\sqrt{p_0(1-p_0)/n}}\sim N(0,1).
$$&lt;/p>
&lt;p>&lt;strong>Región de aceptación&lt;/strong>: $z_{\alpha/2}&amp;lt; Z &amp;lt; z_{1-\alpha/2}$.&lt;br>
&lt;strong>Región de rechazo&lt;/strong>: $Z\leq z_{\alpha/2}$ y $Z\geq z_{1-\alpha/2}$.&lt;/p>
&lt;p>&lt;strong>Ejemplo&lt;/strong>. En un grupo de alumnos se desea estimar si el porcentaje de aprobados es mayor del $50%$. Para ello se toma una muestra de 80 alumnos entre los que hay 50 aprobados.&lt;/p>
&lt;p>El contraste que se plantea es&lt;/p>
&lt;p>$$
\begin{aligned}
H_0 &amp;amp;: p=0.5\newline
H_1 &amp;amp;: p&amp;gt;0.5
\end{aligned}
$$&lt;/p>
&lt;p>Para realizar el contraste se tiene que $\hat p= 50/80 = 0.625$ y como se cumple $n\hat p=80\cdot 0.625 = 50\geq 5$ y $n(1-\hat p)=80(1-0.625)=30\geq 5$, el estadístico del contraste vale&lt;/p>
&lt;p>$$
Z = \frac{\hat p-p_0}{\sqrt{p_0(1-p_0)/n}} = \frac{0.625-0.5}{\sqrt{0.5(1-0.5)/80}} = 2.2361.
$$&lt;/p>
&lt;p>y el $p$-valor del contraste es $P(Z\geq 2.2361)=0.0127$, por lo que se rechaza la hipótesis nula para $\alpha=0.05$ y se concluye que el porcentaje de aprobados es mayor de la mitad.&lt;/p>
&lt;h2 id="pruebas-de-homogeneidad">Pruebas de homogeneidad&lt;/h2>
&lt;h3 id="contraste-de-comparación-de-medias-de-dos-poblaciones-normales-con-varianzas-conocidas">Contraste de comparación de medias de dos poblaciones normales con varianzas conocidas&lt;/h3>
&lt;p>Sean $X_1$ y $X_2$ dos variables aleatorias que cumplen las siguientes condiciones:&lt;/p>
&lt;ul>
&lt;li>Su distribución es normal $X_1\sim N(\mu_1,\sigma_1)$
$X_2\sim N(\mu_2,\sigma_2)$.&lt;/li>
&lt;li>Sus medias $\mu_1$ y $\mu_2$ son desconocidas, pero sus varianzas $\sigma^2_1$ y $\sigma^2_2$ son conocidas.&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Contraste&lt;/strong>:&lt;/p>
&lt;p>$$
\begin{aligned}
H_0 &amp;amp;: \mu_1=\mu_2\newline
H_1 &amp;amp;: \mu_1\neq \mu_2
\end{aligned}
$$&lt;/p>
&lt;p>&lt;strong>Estadístico del contraste&lt;/strong>:&lt;/p>
&lt;p>$$
\left.
\begin{array}{l}
\bar{X}_1\sim N\left(\mu_1,\frac{\sigma_1}{\sqrt{n_1}} \right)\newline
\bar{X}_2\sim N\left(\mu_2,\frac{\sigma_2}{\sqrt{n_2}} \right)
\end{array}
\right\}
\Rightarrow
$$
$$
\Rightarrow
\bar{X}_1-\bar{X}_2 \sim N\left(\mu_1-\mu_2,\sqrt{\frac{\sigma^2_1}{n_1}+\frac{\sigma^2_2}{n_2}}\right)
\Rightarrow Z= \frac{\bar{X}_1-\bar{X}_2}{\sqrt{\frac{\sigma^2_1}{n_1}+\frac{\sigma^2_2}{n_2}}}\sim
N(0,1).
$$&lt;/p>
&lt;p>&lt;strong>Región de aceptación&lt;/strong>: $-z_{\alpha/2}&amp;lt; Z &amp;lt; z_{\alpha/2}$.&lt;br>
&lt;strong>Región de rechazo&lt;/strong>: $Z\leq -z_{\alpha/2}$ y $Z\geq z_{\alpha/2}$.&lt;/p>
&lt;h3 id="contraste-de-comparación-de-medias-de-dos-poblaciones-normales-con-varianzas-desconocidas-e-iguales">Contraste de comparación de medias de dos poblaciones normales con varianzas desconocidas e iguales&lt;/h3>
&lt;p>Sean $X_1$ y $X_2$ dos variables aleatorias que cumplen las siguientes condiciones:&lt;/p>
&lt;ul>
&lt;li>Su distribución es normal $X_1\sim N(\mu_1,\sigma_1)$ y $X_2\sim N(\mu_2,\sigma_2)$.&lt;/li>
&lt;li>Sus medias $\mu_1$ y $\mu_2$ son desconocidas y sus varianzas también, pero son iguales $\sigma^2_1=\sigma^2_2=\sigma^2$.&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Contraste&lt;/strong>:&lt;/p>
&lt;p>$$
\begin{aligned}
H_0 &amp;amp;: \mu_1=\mu_2\newline
H_1 &amp;amp;: \mu_1\neq \mu_2
\end{aligned}
$$&lt;/p>
&lt;p>&lt;strong>Estadístico del contraste&lt;/strong>:&lt;/p>
&lt;p>$$
\left.
\begin{array}{l}
\bar{X}_1-\bar{X}_2\sim N\left(\mu_1-\mu_2,\sigma\sqrt{\frac{n_1+n_2}{n_1n_2}} \right)\newline
\displaystyle \frac{n_1S_1^2+n_2S_2^2}{\sigma^2} \sim \chi^2(n_1+n_2-2)
\end{array}
\right\}
\Rightarrow
T=\frac{\bar{X}_1-\bar{X}_2}{\hat{S}_p\sqrt{\frac{n_1+n_2}{n_1n_2}}} \sim T(n_1+n_2-2).
$$&lt;/p>
&lt;p>&lt;strong>Región de aceptación&lt;/strong>: $-t_{\alpha/2}^{n_1+n_2-2} &amp;lt; T &amp;lt; t_{\alpha/2}^{n_1+n_2-2}$.&lt;br>
&lt;strong>Región de rechazo&lt;/strong>: $T\leq -t_{\alpha/2}^{n_1+n_2-2}$ y $T\geq t_{\alpha/2}^{n_1+n_2-2}$.&lt;/p>
&lt;p>&lt;strong>Ejemplo&lt;/strong>. Se quiere comparar el rendimiento académico de dos grupos de alumnos, uno con 10 alumnos y otro con 12, que han seguido metodologías diferentes. Para ello se les realiza un examen y se obtienen las siguientes puntuaciones:&lt;/p>
&lt;p>$$
\begin{aligned}
X_1 &amp;amp;: 4 - 6 - 8 - 7 - 7 - 6 - 5 - 2 - 5 - 3 \newline
X_2 &amp;amp;: 8 - 9 - 5 - 3 - 8 - 7 - 8 - 6 - 8 - 7 - 5 - 7
\end{aligned}
$$&lt;/p>
&lt;p>El contraste que se plantea es&lt;/p>
&lt;p>$$
H_0: \mu_1=\mu_2\qquad H_1: \mu_1\neq \mu_2
$$&lt;/p>
&lt;p>Para realizar el contraste, se tiene&lt;/p>
&lt;ul>
&lt;li>$\bar{X}_1 = \frac{4+\cdots +3}{10}=5.3$ puntos y $\bar{X}_2=\frac{8+\cdots +7}{12}=6.75$ puntos.&lt;/li>
&lt;li>$S_1^2= \frac{(4^2+\cdots + 3^2}{10}-5.3^2=3.21$ puntos$^2$ y $S_2^2= \frac{8^2+\cdots +3^2}{12}-6.75^2=2.69$ puntos$^2$.&lt;/li>
&lt;li>$\hat{S}_p^2 = \frac{10\cdot 3.21+12\cdot 2.6875}{10+12-2}= 3.2175$ puntos$^2$, y $\hat S_p=1.7937$.&lt;/li>
&lt;/ul>
&lt;p>Si se suponen varianzas iguales, el estadístico del contraste vale&lt;/p>
&lt;p>$$
T=\frac{\bar{X}_1-\bar{X}_2}{\hat{S}_p\sqrt{\frac{n_1+n_2}{n_1n_2}}} = \frac{5.3-6.75}{1.7937\sqrt{\frac{10+12}{10\cdot 12}}} = -1.8879,
$$&lt;/p>
&lt;p>y el $p$-valor del contraste es $2P(T(20)\leq -1.8879) = 0.0736$, de modo que no se puede rechazar la hipótesis nula y se concluye que no hay diferencias significativas entre las notas medias de los grupos.&lt;/p>
&lt;h3 id="contraste-de-comparación-de-medias-de-dos-poblaciones-normales-con-varianzas-desconocidas">Contraste de comparación de medias de dos poblaciones normales con varianzas desconocidas&lt;/h3>
&lt;p>Sean $X_1$ y $X_2$ dos variables aleatorias que cumplen las siguientes condiciones:&lt;/p>
&lt;ul>
&lt;li>Su distribución es normal $X_1\sim N(\mu_1,\sigma_1)$ y $X_2\sim N(\mu_2,\sigma_2)$.&lt;/li>
&lt;li>Sus medias $\mu_1$, $\mu_2$ y varianzas $\sigma_1^2$, $\sigma_2^2$, son desconocidas, pero $\sigma^2_1\not = \sigma^2_2$.&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Contraste&lt;/strong>:&lt;/p>
&lt;p>$$
\begin{aligned}
H_0 &amp;amp;: \mu_1=\mu_2\newline
H_1 &amp;amp;: \mu_1\neq \mu_2
\end{aligned}
$$&lt;/p>
&lt;p>&lt;strong>Estadístico del contraste&lt;/strong>:&lt;/p>
&lt;p>$$
T=\frac{(\bar{X}_1-\bar{X}_2)-(\mu_1-\mu_2)}{\sqrt{\frac{\hat{S}^2_1}{n_1}+\frac{\hat{S}^2_2}{n_2}}} \sim T(g),
$$&lt;/p>
&lt;p>con $g=n_1+n_2-2-\Delta$ y&lt;/p>
&lt;p>$$\Delta = \frac{(\frac{n_2-1}{n_1}\hat{S}_1^2-\frac{n_1-1}{n_2}\hat{S}_2^2)^2}{\frac{n_2-1}{n_1^2}\hat{S}_1^4+\frac{n_1-1}{n_2^2}\hat{S}_2^4}.
$$&lt;/p>
&lt;p>&lt;strong>Región de aceptación&lt;/strong>: $-t_{\alpha/2}^{g} &amp;lt; T &amp;lt; t_{\alpha/2}^{g}$.&lt;br>
&lt;strong>Región de rechazo&lt;/strong>: $T\leq -t_{\alpha/2}^{g}$ y $T\geq t_{\alpha/2}^{g}$.&lt;/p>
&lt;h3 id="contraste-de-comparación-de-varianzas-de-dos-poblaciones-normales">Contraste de comparación de varianzas de dos poblaciones normales&lt;/h3>
&lt;p>Sean $X_1$ y $X_2$ dos variables aleatorias que cumplen las siguientes condiciones:&lt;/p>
&lt;ul>
&lt;li>Su distribución es normal $X_1\sim N(\mu_1,\sigma_1)$ y $X_2\sim N(\mu_2,\sigma_2)$.&lt;/li>
&lt;li>Sus medias $\mu_1$, $\mu_2$ y varianzas $\sigma_1^2$, $\sigma_2^2$ son desconocidas.&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Contraste&lt;/strong>:&lt;/p>
&lt;p>$$
\begin{aligned}
H_0 &amp;amp;: \sigma_1=\sigma_2\newline
H_1 &amp;amp;: \sigma_1\neq \sigma_2
\end{aligned}
$$&lt;/p>
&lt;p>&lt;strong>Estadístico del contraste&lt;/strong>:
$$\left.
\begin{array}{l}
\displaystyle \frac{(n_1-1)\hat{S}_1^2}{\sigma_1^2}\sim \chi^2(n_1-1) \newline
\displaystyle \frac{(n_2-1)\hat{S}_2^2}{\sigma_2^2}\sim \chi^2(n_2-1)
\end{array}
\right\}
\Rightarrow
F= \frac{\frac{\frac{(n_1-1)\hat{S}_1^2}{\sigma_1^2}}{n_1-1}}{\frac{\frac{(n_2-1)\hat{S}_2^2}{\sigma_2^2}}{n_2-1}} =
\frac{\sigma_2^2}{\sigma_1^2}\frac{\hat{S}_1^2}{\hat{S}_2^2}\sim F(n_1-1,n_2-1).
$$&lt;/p>
&lt;p>&lt;strong>Región de aceptación&lt;/strong>: $F_{\alpha/2}^{n_1-1,n_2-1} &amp;lt; F &amp;lt; F_{1-\alpha/2}^{n_1-1,n_2-1}$.&lt;br>
&lt;strong>Región de rechazo&lt;/strong>: $F\leq F_{\alpha/2}^{n_1-1,n_2-1}$ y $F\geq F_{1-\alpha/2}^{n_1-1,n_2-1}$.&lt;/p>
&lt;p>&lt;strong>Ejemplo&lt;/strong>. Siguiendo con el ejemplo de las puntuaciones en dos grupos:&lt;/p>
&lt;p>$$
\begin{aligned}
X_1 &amp;amp;: 4 - 6 - 8 - 7 - 7 - 6 - 5 - 2 - 5 - 3 \newline
X_2 &amp;amp;: 8 - 9 - 5 - 3 - 8 - 7 - 8 - 6 - 8 - 7 - 5 - 7
\end{aligned}
$$&lt;/p>
&lt;p>Si se desea comparar las varianzas, el contraste que se plantea es&lt;/p>
&lt;p>$$
H_0: \sigma_1=\sigma_2\qquad H_1: \sigma_1\neq \sigma_2
$$&lt;/p>
&lt;p>Para realizar el contraste, se tiene&lt;/p>
&lt;ul>
&lt;li>$\bar{X}_1 = \frac{4+\cdots +3}{10}=5.3$ puntos y $\bar{X}_2=\frac{8+\cdots +7}{12}=6.75$ puntos.&lt;/li>
&lt;li>$\hat{S}_1^2= \frac{(4-5.3)^2+\cdots + (3-5.3)^2}{9}=3.5667$ y $\hat{S}_2^2= \frac{(8-6.75)^2+\cdots + (3-6.75)^2}{11}=2.9318$ puntos$^2$.&lt;/li>
&lt;/ul>
&lt;p>El estadístico del contraste vale&lt;/p>
&lt;p>$$
F = \frac{\hat{S}_1^2}{\hat{S}_2^2} = \frac{3.5667}{2.9318}=1.2165,
$$&lt;/p>
&lt;p>y el $p$-valor del contraste es $2P(F(9,11)\leq 1.2165)=0.7468$, por lo que se mantiene la hipótesis de igualdad de varianzas.&lt;/p>
&lt;h3 id="contraste-de-comparación-de-proporciones-de-dos-poblaciones">Contraste de comparación de proporciones de dos poblaciones&lt;/h3>
&lt;p>Sean $p_1$ y $p_2$ las respectivas proporciones de individuos que presentan una determinada característica en dos poblaciones.&lt;/p>
&lt;p>&lt;strong>Contraste&lt;/strong>:&lt;/p>
&lt;p>$$
H_0: p_1=p_2\qquad H_1: p_1\neq p_2
$$&lt;/p>
&lt;p>&lt;strong>Estadístico del contraste&lt;/strong>: Las variables que miden el número de individuos con la característica en dos muestras aleatorias de tamaños $n_1$ y $n_2$ respectivamente, siguen distribuciones binomiales
$X_1\sim B(n_1,p_1)$ y $X_2\sim B(n_2,p_2)$. Si las muestras son grandes ($n_ip_i\geq 5$ y $n_i(1-p_i)\geq 5$), de acuerdo al teorema central del límite, $X_1\sim N(np_1,\sqrt{np_1(1-p_1)})$ y $X_2\sim N(np_2,\sqrt{np_2(1-p_2)})$, y se cumple&lt;/p>
&lt;p>$$
\left.
\begin{array}{l}
\hat{p}_1=\frac{X_1}{n_1} \sim N\left(p_1,\sqrt{\frac{p_1(1-p_1)}{n_1}}\right)\newline
\hat{p}_2=\frac{X_2}{n_2} \sim N\left(p_2,\sqrt{\frac{p_2(1-p_2)}{n_2}}\right)
\end{array}
\right\}
\Rightarrow Z = \frac{\hat{p}_1-\hat{p_2}}{\sqrt{\frac{p_1(1-p_1)}{n_1}+\frac{p_2(1-p_2)}{n_2}}}\sim N(0,1)
$$&lt;/p>
&lt;p>&lt;strong>Región de aceptación&lt;/strong>: $z_{\alpha/2}&amp;lt; Z &amp;lt; z_{1-\alpha/2}$.&lt;br>
&lt;strong>Región de rechazo&lt;/strong>: $z\leq z_{\alpha/2}$ y $z\geq z_{1-\alpha/2}$.&lt;/p>
&lt;p>&lt;strong>Ejemplo&lt;/strong>. Se quiere comparar los porcentajes de aprobados en dos grupos que han seguido metodologías distintas. En el primer grupo han aprobado 24 alumnos de un total de 40, mientras que en el segundo han aprobado 48 de 60.&lt;/p>
&lt;p>El contraste que se plantea es&lt;/p>
&lt;p>$$
H_0: p_1=p_2\qquad H_1: p_1\neq p_2
$$&lt;/p>
&lt;p>Para realizar el contraste, se tiene $\hat{p}_1=24/40= 0.6$ y $\hat{p}_2=48/60=0.8$, de manera que se cumplen las condiciones $n_1\hat{p}_1=40\cdot 0.6=24\geq 5$,
$n_1(1-\hat{p}_1)=40(1-0.6)=26\geq 5$,
$n_2\hat{p}_2=60\cdot 0.8=48\geq 5$ y
$n_2(1-\hat{p}_2)=60(1-0.8)=12\geq 5$, y el estadístico del contraste vale&lt;/p>
&lt;p>$$
Z = \frac{\hat{p}_1-\hat{p_2}}{\sqrt{\frac{p_1(1-p_1)}{n_1}+\frac{p_2(1-p_2)}{n_2}}} = \frac{0.6-0.8}{\sqrt{\frac{0.6(1-0.6)}{40}+\frac{0.8(1-0.8)}{60}}} = -2.1483,
$$&lt;/p>
&lt;p>y el $p$-valor del contraste es $2P(Z\leq -2.1483)= 0.0317$, de manera que se rechaza la hipótesis nula para $\alpha=0.05$ y se concluye que hay diferencias.&lt;/p>
&lt;h2 id="realización-de-contrastes-mediante-intervalos-de-confianza">Realización de contrastes mediante intervalos de confianza&lt;/h2>
&lt;p>Una interesante alternativa a la realización de un contraste&lt;/p>
&lt;p>$$
H_0: \theta=\theta_0\qquad H_1: \theta\neq \theta_0
$$&lt;/p>
&lt;p>con un riesgo $\alpha$, es calcular el intervalo de confianza para $\theta$ con un nivel de confianza
$1-\alpha$, ya que este intervalo se puede interpretar como el conjunto aceptable de hipótesis para $\theta$, de manera que si $\theta_0$ está fuera del intervalo, la hipótesis nula es poco creíble y puede rechazarse, mientras que si está dentro la hipótesis es creíble y se
acepta.&lt;/p>
&lt;p>Cuando el contraste sea unilateral de menor, el contraste se realizaría comparando $\theta_0$ con el límite superior del intervalo de confianza para $\theta$ con un nivel de confianza $1-2\alpha$, mientras que si el
contraste es unilateral de mayor, se comparará con el límite inferior del intervalo.&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align:center">Contraste&lt;/th>
&lt;th style="text-align:center">Intervalo de confianza&lt;/th>
&lt;th style="text-align:center">Decisión&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align:center">Bilateral&lt;/td>
&lt;td style="text-align:center">$[l_i,l_s]$ con nivel de confianza $1-\alpha$&lt;/td>
&lt;td style="text-align:center">Rechazar $H_0$ si $\theta_0\not \in [l_i,l_s]$&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">Unilateral menor&lt;/td>
&lt;td style="text-align:center">$[-\infty,l_s]$ con nivel de confianza $1-2\alpha$&lt;/td>
&lt;td style="text-align:center">Rechazar $H_0$ si $\theta_0\geq l_s$&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">Unilateral mayor&lt;/td>
&lt;td style="text-align:center">$[l_i,\infty]$ con nivel de confianza $1-2\alpha$&lt;/td>
&lt;td style="text-align:center">Rechazar $H_0$ si $\theta_0\leq l_i$&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>&lt;strong>Ejemplo&lt;/strong>. Volviendo al contraste para comparar el rendimiento académico de dos grupos de alumnos que han obtenido las siguientes puntuaciones:&lt;/p>
&lt;p>$$
\begin{aligned}
X_1 &amp;amp;: 4 - 6 - 8 - 7 - 7 - 6 - 5 - 2 - 5 - 3 \newline
X_2 &amp;amp;: 8 - 9 - 5 - 3 - 8 - 7 - 8 - 6 - 8 - 7 - 5 - 7
\end{aligned}
$$&lt;/p>
&lt;p>El contraste que se planteaba era&lt;/p>
&lt;p>$$
H_0: \mu_1=\mu_2\qquad H_1: \mu_1\neq \mu_2
$$&lt;/p>
&lt;p>Como se trata de un contraste bilateral, el intervalo de confianza para la diferencia de medias $\mu_1-\mu_2$ con nivel de confianza $1-\alpha=0.95$, suponiendo
varianzas iguales, vale $[-3.0521, 0.1521]$ puntos. Y como según la hipótesis nula $\mu_1-\mu_2=0$, y el 0 cae dentro del intervalo, se acepta la hipótesis nula.&lt;/p>
&lt;p>La ventaja del intervalo es que, además de permitirnos realizar el contraste, nos da una idea de la magnitud de la diferencia entre las medias de los grupos.&lt;/p></description></item><item><title>Ejercicios de Variables Aleatorias Continuas</title><link>/docencia/estadistica/ejercicios/variables-aleatorias-continuas/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/docencia/estadistica/ejercicios/variables-aleatorias-continuas/</guid><description>&lt;h2 id="ejercicio-1">Ejercicio 1&lt;/h2>
&lt;p>Titulación: Todas&lt;/p>
&lt;p>En una población se sabe que las estaturas de los hombres y de las mujeres siguen una distribución
normal con la misma desviación típica y que la media de los hombres es 5 cm mayor que la de las mujeres.
También se sabe que el 75 % de los hombres miden menos de 178 cm y que el 10 % de las mujeres miden más de 176.8 cm.
Se pide:&lt;/p>
&lt;ol>
&lt;li>Calcular las medias y las desviaciones típicas de las distribuciones de estaturas de los hombres y de las mujeres.&lt;/li>
&lt;li>Calcular la probabilidad de que un hombre mida entre 170 y 180 cm.&lt;/li>
&lt;li>Calcular el percentil 90 de la estatura de los hombres.&lt;/li>
&lt;/ol>
&lt;p>&lt;strong>SOLUCIÓN&lt;/strong>&lt;/p>
&lt;iframe src="http://www.slideshare.net/slideshow/embed_code/35218982" width="640" height="449" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" style="border:1px solid #CCC; border-width:1px 1px 0; margin-bottom:5px; max-width: 100%;" allowfullscreen> &lt;/iframe>
&lt;iframe src="//www.youtube.com/embed/UwH4yRqutHY" width="640" height="360" frameborder="0"> &lt;/iframe></description></item><item><title>Epidemiología para tiempos de pandemia</title><link>/post/epidemiologia-tiempos-pandemias/</link><pubDate>Sun, 07 Nov 2021 00:00:00 +0000</pubDate><guid>/post/epidemiologia-tiempos-pandemias/</guid><description>&lt;p>Debido a la epidemia provocada por el coronavirus, la Epidemiología se ha convertido en una de las ramas de la medicina que más interés despiertan.&lt;/p>
&lt;p>En estos tiempos de pandemia un montón de términos técnicos de la Epidemiología se han convertido en lugares comunes gracias a los medios de comunicación. Sin embargo, muchos de estos términos se utilizan de manera errónea, incluso por los propios medios de comunicación, y generan confusión para la población no experta.&lt;/p>
&lt;p>Por ello, y con motivo de la
&lt;a href="http://www.madrimasd.org/semanacienciaeinnovacion/" target="_blank" rel="noopener">Semana de la Ciencia y la Innovación de Madrid 2021&lt;/a>, he preparado un tutorial para explicar al público en general los principales conceptos epidemiológicos usados en el control de enfermedades como la COVID e ilustrar su uso con ejemplos de aplicación.&lt;/p>
&lt;p>Podéis acceder a él en el siguiente enlace:
&lt;a href="/docencia/estadistica/tutoriales/epidemiologia/#valores-predictivos-de-un-test">Tutorial de Epidemiología&lt;/a>&lt;/p>
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe src="https://www.youtube.com/embed/R_Z_atAXoXA" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video">&lt;/iframe>
&lt;/div></description></item><item><title>Tipos de estudios estadísticos</title><link>/post/estudios-estadisticos-r/</link><pubDate>Wed, 21 Jul 2021 00:00:00 +0000</pubDate><guid>/post/estudios-estadisticos-r/</guid><description>&lt;p>Acabo de publicar una
&lt;a href="https://aprendeconalf.es/docencia/r/estudios-estadisticos/" target="_blank" rel="noopener">guía básica con los principales tipos de estudios estadísticos&lt;/a> y ejemplos realizados con el programa de análisis de datos R.&lt;/p>
&lt;p>Una de las preguntas más recurrentes de suelen hacerme mis compañeros cuando están realizando un estudio de investigación es &lt;em>¿qué tipo de estudio estadístico tengo que aplicar?&lt;/em>. Con esta guía pretendo ayudar a encontrar la respuesta a todos aquellos que se hagan esta pregunta.&lt;/p>
&lt;p>En esta guía no se abordan todos los tipos de estudios estadísticos que existen, pero si lo más habituales, dependiendo del objetivo perseguido, el número de variables que intervienen y el tipo de estas variables. Para facilitar la comprensión de cada tipo de estudio se muestra un ejemplo sencillo implementado con R.&lt;/p>
&lt;p>Espero que os sea útil.&lt;/p></description></item><item><title>Examen de Farmacia 2021-01-18</title><link>/docencia/calculo/examenes/farmacia/farmacia-2021-01-18/</link><pubDate>Mon, 18 Jan 2021 00:00:00 +0000</pubDate><guid>/docencia/calculo/examenes/farmacia/farmacia-2021-01-18/</guid><description>&lt;p>Grados: Farmacia y Biotecnología&lt;br>
Fecha: 18 de enero de 2021&lt;/p>
&lt;h2 id="ejercicio-1">Ejercicio 1&lt;/h2>
&lt;p>Un medicamento se administra por vía intravenosa a una velocidad de 15 mg/hora. Al mismo tiempo, el cuerpo metaboliza el medicamento a una velocidad del 80% de la cantidad presente en el cuerpo por hora.&lt;/p>
&lt;ol>
&lt;li>
&lt;p>Si el medicamento se administra de forma indefinida y suponiendo que al principio no había nada de medicamento en el cuerpo, ¿cuál será la máxima cantidad de medicamento que habrá en el
cuerpo?&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Si el medicamento deja de administrarse después de haber administrado 150 mg, ¿cuánto tiempo tiene que pasar desde ese momento hasta que la cantidad de medicamento en el cuerpo sea 10
mg?&lt;/p>
&lt;/li>
&lt;/ol>
&lt;div class="spoiler " >
&lt;p>
&lt;a class="btn btn-primary" data-toggle="collapse" href="#spoiler-0" role="button" aria-expanded="false" aria-controls="spoiler-0">
Solución
&lt;/a>
&lt;/p>
&lt;div class="collapse card " id="spoiler-0">
&lt;div class="card-body">
&lt;p>Sea $x(t)$ la cantidad de medicamento en el cuerpo en el instante $t$.&lt;/p>
&lt;ol>
&lt;li>
&lt;p>Ecuación diferencial: $x&amp;rsquo;=15-0.8x$. Condición inicial $x(0)=0$. Solución particular: $x(t)=18.75-18.75e^{-0.8t}$ y la cantidad máxima de medicamento en el cuerpo será 18.75 mg.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Ecuación diferencial: $x&amp;rsquo;=-0.8x$. Condición inicial $x(0)=18.74$. Solución particular: $x(t)=18.74e^{-0.8t}$ y el tiempo que tarda en haber una cantidad de 10 mg en el cuerpo es $0.7851$ horas.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="spoiler " >
&lt;p>
&lt;a class="btn btn-primary" data-toggle="collapse" href="#spoiler-1" role="button" aria-expanded="false" aria-controls="spoiler-1">
Resolución
&lt;/a>
&lt;/p>
&lt;div class="collapse card " id="spoiler-1">
&lt;div class="card-body">
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe src="https://www.youtube.com/embed/RlqKkf1Sxpk" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video">&lt;/iframe>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;h2 id="ejercicio-2">Ejercicio 2&lt;/h2>
&lt;p>La función $T(x,y)=\ln(3xy+2x^2-y)$ da la temperatura de la superficie de una montaña en la latitud $x$ y longitud $y$. Unos montañeros están perdidos en la posición $(1,2)$ y corren el riesgo de morir congelados.&lt;/p>
&lt;ol>
&lt;li>
&lt;p>¿En qué dirección deben moverse para evitar el riesgo de congelación lo más rápidamente posible?&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Si se mueven en una dirección equivocada de manera que la longitud decrece la mitad de lo que aumenta la latitud, ¿aumentará o disminuirá el riesgo de hipotermia?&lt;/p>
&lt;/li>
&lt;li>
&lt;p>¿En qué dirección deben moverse para que la temperatura permanezca constante?&lt;/p>
&lt;/li>
&lt;/ol>
&lt;div class="spoiler " >
&lt;p>
&lt;a class="btn btn-primary" data-toggle="collapse" href="#spoiler-2" role="button" aria-expanded="false" aria-controls="spoiler-2">
Solución
&lt;/a>
&lt;/p>
&lt;div class="collapse card " id="spoiler-2">
&lt;div class="card-body">
&lt;ol>
&lt;li>
&lt;p>$\nabla T(1,2)=\frac{1}{3}(5,1)$.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Sea $\mathbf{u}$ el vector $(1,-1/2)$, entonces $T&amp;rsquo;_{\mathbf{u}}(1,2) = \frac{3}{\sqrt{5}}$ ºC.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Siguiendo la dirección del vector $(1,-5)$.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="spoiler " >
&lt;p>
&lt;a class="btn btn-primary" data-toggle="collapse" href="#spoiler-3" role="button" aria-expanded="false" aria-controls="spoiler-3">
Resolución
&lt;/a>
&lt;/p>
&lt;div class="collapse card " id="spoiler-3">
&lt;div class="card-body">
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe src="https://www.youtube.com/embed/NQ5ra7-IiOY" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video">&lt;/iframe>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;h2 id="ejercicio-3">Ejercicio 3&lt;/h2>
&lt;p>Una pelota de playa tiene un volumen de 50 dm$^3$ en el momento que empieza a introducirse aire a razón de 2 dm$^3$/min.&lt;/p>
&lt;ol>
&lt;li>
&lt;p>¿A qué velocidad cambiará el radio?&lt;/p>
&lt;/li>
&lt;li>
&lt;p>¿Aproximadamente cuándo la superficie de la pelota se habrá duplicado?&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>Nota: El volumen de una esfera es $V(r)=\frac{4}{3}\pi r^3$ y la superficie $S(r)=4\pi r^2$.&lt;/p>
&lt;div class="spoiler " >
&lt;p>
&lt;a class="btn btn-primary" data-toggle="collapse" href="#spoiler-4" role="button" aria-expanded="false" aria-controls="spoiler-4">
Solución
&lt;/a>
&lt;/p>
&lt;div class="collapse card " id="spoiler-4">
&lt;div class="card-body">
&lt;ol>
&lt;li>
&lt;p>$\dfrac{dr}{dt}=0.0305$ dm/min.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Usando la aproximación lineal del diferencial $dt = S&amp;rsquo;/dS=37.5013$ minutos aproximadamente.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="spoiler " >
&lt;p>
&lt;a class="btn btn-primary" data-toggle="collapse" href="#spoiler-5" role="button" aria-expanded="false" aria-controls="spoiler-5">
Resolución
&lt;/a>
&lt;/p>
&lt;div class="collapse card " id="spoiler-5">
&lt;div class="card-body">
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe src="https://www.youtube.com/embed/JJK5kPhko0M" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video">&lt;/iframe>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div></description></item><item><title>Examen de Farmacia 2021-01-18</title><link>/docencia/estadistica/examenes/farmacia/farmacia-2021-01-18/</link><pubDate>Mon, 18 Jan 2021 00:00:00 +0000</pubDate><guid>/docencia/estadistica/examenes/farmacia/farmacia-2021-01-18/</guid><description>&lt;p>Grados: Farmacia y Biotecnología&lt;br>
Fecha: 18 de enero de 2021&lt;/p>
&lt;h2 id="ejercicio-1">Ejercicio 1&lt;/h2>
&lt;p>La siguiente tabla muestra las diferencias de notas entre las notas de bachillerato y las del examen de selectividad en los centros públicos ($X$) y privados ($Y$) de una región:&lt;/p>
&lt;p>$$
\begin{array}{lrrrrrrrrr}
\hline
\mbox{Centros públicos} &amp;amp; -1.2 &amp;amp; -0.7 &amp;amp; -0.4 &amp;amp; -0.9 &amp;amp; -1.6 &amp;amp; 0.5 &amp;amp; 0.2 &amp;amp; -1.8 &amp;amp; 0.8\newline&lt;br>
\mbox{Centros privados} &amp;amp; -2.1 &amp;amp; -0.5 &amp;amp; -0.7 &amp;amp; -1.9 &amp;amp; 0.2 &amp;amp; -2.8 &amp;amp; -1\newline&lt;br>
\hline
\end{array}
$$&lt;/p>
&lt;ol>
&lt;li>¿Cuál de los siguientes diagramas de cajas corresponde a cada variable? Comparar la dispersión central de las dos variables según los diagramas de caja. ¿En qué variable es menor la mediana de las diferencias de notas?&lt;/li>
&lt;/ol>
&lt;p>&lt;img src="../img/des-gen-16-boxplot-grades.svg" alt="image">&lt;/p>
&lt;ol start="2">
&lt;li>
&lt;p>¿En qué centros es más representativa la media de la diferencia de notas, en los públicos o en los privados?&lt;/p>
&lt;/li>
&lt;li>
&lt;p>¿En qué centros la distribución de la diferencia de notas es más simétrica?&lt;/p>
&lt;/li>
&lt;li>
&lt;p>¿En qué centros la distribución de la diferencia de notas es más apuntada?&lt;/p>
&lt;/li>
&lt;li>
&lt;p>¿Qué diferencia es relativamente menor, $-0.5$ puntos en un centro público o $-1$ en un centro privado?&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>Usar las siguientes sumas para los cálculos:&lt;br>
Public: $\sum x_i=-5.1$, $\sum x_i^2=9.63$, $\sum (x_i-\bar x)^3=0.95$ y $\sum (x_i-\bar x)^4=8.76$.
Private: $\sum y_i=-8.8$, $\sum y_i^2=17.64$, $\sum (y_i-\bar y)^3=-0.82$ y $\sum (y_i-\bar y)^4=11.28$.&lt;/p>
&lt;div class="spoiler " >
&lt;p>
&lt;a class="btn btn-primary" data-toggle="collapse" href="#spoiler-0" role="button" aria-expanded="false" aria-controls="spoiler-0">
Solución
&lt;/a>
&lt;/p>
&lt;div class="collapse card " id="spoiler-0">
&lt;div class="card-body">
&lt;ol>
&lt;li>
&lt;p>El diagrama de cajas 1 corresponde a los centros privados y el 2 a los centros públicos. La dispersión central (anchura de las cajas) es similar en ambas variables. La mediana es menor en los
centros privados.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Centros públicos: $\bar x=-0.5667$ , $s^2=0.7489$ , $s=0.8654$ y $cv=1.5271$.
Centros privados: $\bar y=-1.2571$ , $s^2=0.9396$ , $s=0.9693$ y $cv=0.7711$.
Por tanto, la media de las diferencias de notas es más representativa en los centros privados.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>$g_{1x}=0.1626$ y $g_{1y}=-0.1285$. Por tanto, la distribución de las diferencias de notas en los centros privados es más simétrica ya que su coeficiente de asimetría está más cerca de 0.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>$g_{2x}=-1.2651$ y $g_{2y}=-1.1748$. Así pues, la distribución de las diferencias de notas en los centros privados es más apuntada ya que su coeficiente de apuntamiento es mayor.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Centro público: $z(-0.5)=0.077$.
Centro privado: $z(-1)=0.2653$.
Por tanto, una diferencia de notas de -0.5 puntos en centros públicos es relativamente menor que una diferencia de -1 puntos en centros privados.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;h2 id="ejercicio-2">Ejercicio 2&lt;/h2>
&lt;p>Un auditor ha estudiado la relación entre el salario y el número de ausencias de los celadores de un hospital. La tabla siguiente muestra los salarios en miles de euros ($X$) y el número medio de ausencias anuales con esos salarios ($Y$).&lt;/p>
&lt;p>$$
\begin{array}{lrrrrrrrrr}
\hline
\mbox{Salario} &amp;amp; 20.0 &amp;amp; 22.5 &amp;amp; 25 &amp;amp; 27.5 &amp;amp; 30.0 &amp;amp; 32.5 &amp;amp; 35.0 &amp;amp; 37.5 &amp;amp; 40.0 \newline
\mbox{Ausencias} &amp;amp; 2.3 &amp;amp; 2.0 &amp;amp; 2 &amp;amp; 1.8 &amp;amp; 2.2 &amp;amp; 1.5 &amp;amp; 1.2 &amp;amp; 1.3 &amp;amp; 0.6 \newline
\hline
\end{array}
$$&lt;/p>
&lt;ol>
&lt;li>
&lt;p>Calcular la recta de regresión que explique las ausencias en función del salario.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>¿Cuál es el número de ausencias esperado de un celador con un salario de 29000€? ¿Es esta predicción fiable?&lt;/p>
&lt;/li>
&lt;li>
&lt;p>¿Cuánto aumentará o disminuirá el número de ausencias por cada incremento de 1000€ en el salario?&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>Usar las siguientes sumas para los cálculos:&lt;br>
$\sum x_i=270$ $10^3$€, $\sum y_i=14.9$ ausencias,&lt;br>
$\sum x_i^2=8475$ ($10^3$€)$^2$, $\sum y_i^2=27.11$ ausencias$^2$,&lt;br>
$\sum x_iy_j=420$ $10^3$€ ausencias.&lt;/p>
&lt;div class="spoiler " >
&lt;p>
&lt;a class="btn btn-primary" data-toggle="collapse" href="#spoiler-1" role="button" aria-expanded="false" aria-controls="spoiler-1">
Solución
&lt;/a>
&lt;/p>
&lt;div class="collapse card " id="spoiler-1">
&lt;div class="card-body">
&lt;ol>
&lt;li>
&lt;p>$\bar x=30$ $10^3$€, $s_x^2=41.6667$ ($10^3$€)$^2$,&lt;br>
$\bar y=1.6556$ ausencias, $s_y^2=0.2714$ ausencias$^2$,&lt;br>
$s_{xy}=-3$ $10^3$€ ausencias&lt;br>
Recta de regresión de las ausencias sobre el salario: $y=3.8156-0.072x$.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>$y(29) = 1.7276$ ausencias&lt;br>
$r^2 = 0.796$, de modo que el modelo lineal se ajusta bien ya que el coeficiente de determinación no está lejos de 1, pero el tamaño muestral es demasiado pequeño para que las predicciones sean fiables.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>El número de ausencias disminuirá 0.072 por cada incremento de 1000€ en el salario.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;h2 id="ejercicio-3">Ejercicio 3&lt;/h2>
&lt;p>En un estudio de regresión se sabe que la recta de regresión de $Y$ sobre $X$ es $y+2x-10=0$ y la recta de regresión de $X$ sobre $Y$ es $y+3x-14=0$.&lt;/p>
&lt;ol>
&lt;li>
&lt;p>Calcular las medias de $X$ e $Y$.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Calcular el coeficiente de correlación lineal e interpretarlo.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;div class="spoiler " >
&lt;p>
&lt;a class="btn btn-primary" data-toggle="collapse" href="#spoiler-2" role="button" aria-expanded="false" aria-controls="spoiler-2">
Solución
&lt;/a>
&lt;/p>
&lt;div class="collapse card " id="spoiler-2">
&lt;div class="card-body">
&lt;ol>
&lt;li>
&lt;p>$\bar x=4$ y $\bar y=2$.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>$r=-0.8165$. El coeficiente de correlación lineal está cerca de -1 lo que significa que existe una relación lineal fuerte e inversa entre $X$ e $Y$.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;h2 id="ejercicio-4">Ejercicio 4&lt;/h2>
&lt;p>Un test para diagnosticar el cáncer de próstata produce un 1% de falsos positivos y un 0.2% de falsos negativos. Se sabe también que una población 1 cada 400 hombres sufre este tipo de cáncer.&lt;/p>
&lt;ol>
&lt;li>
&lt;p>Calcular la sensibilidad y la especificidad del test.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Si un hombre tiene un resultado positivo en el test, ¿cuál es la probabilidad de que tenga cáncer de próstata?&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Calcular e interpretar el valor negativo predictivo del test.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>¿Es este teste mejor para detectar o para descartar el cáncer de próstata?&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Para ver si existe asociación entre el cáncer de próstata y la práctica del deporte, se tomó una muestra de 1000 hombres, de los cuales 700 practicaban deporte, y se observó que había 2 hombres con cáncer de próstata en el grupo de los que practicaban deporte y 3 hombres con cáncer de próstata en el
grupo de los que no practicaban deporte. Calcular el riesgo relativo y el odds ratio de sufrir cáncer de próstata cuando se practica deporte.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;div class="spoiler " >
&lt;p>
&lt;a class="btn btn-primary" data-toggle="collapse" href="#spoiler-3" role="button" aria-expanded="false" aria-controls="spoiler-3">
Solución
&lt;/a>
&lt;/p>
&lt;div class="collapse card " id="spoiler-3">
&lt;div class="card-body">
&lt;p>Sea $C$ el suceso correspondiente a sufrir cáncer de próstata y $+$ y $-$ los sucesos consistentes en tener un resultado positivo y negativo en el test respectivamente.&lt;/p>
&lt;ol>
&lt;li>
&lt;p>La sensibilidad es $P(+|D) = 0.2$ y la especificidad $P(-|\overline D) = 0.99$.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>El valor predictivo positivo es $P(D|+) = 0.0476$.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>El valor predictivo negativo es $P(\overline D|-) = 0.998$.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Como el valor predictivo negativo es mayor que el valor predictivo positivo, el test es mejor para descartar la enfermedad que para confirmarla. De hecho el test no permite detectar la enfermedad ya que el valor predictivo positivo es menor que 0.5.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>$RR(D)=0.2857$ y $OR(D)=0.2837$. Por tanto, existe una asociación entre la práctica del deporte y el cáncer de próstata, de manera que la probabilidad de sufrir cáncer de próstata cuando un hombre practica deporte es casi un cuarto de la probabilidad de sufrirlo cuando no se practica deporte, y con el odds ocurre algo similar.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="spoiler " >
&lt;p>
&lt;a class="btn btn-primary" data-toggle="collapse" href="#spoiler-4" role="button" aria-expanded="false" aria-controls="spoiler-4">
Resolución
&lt;/a>
&lt;/p>
&lt;div class="collapse card " id="spoiler-4">
&lt;div class="card-body">
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe src="https://www.youtube.com/embed/pWbsQeCsKY4" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video">&lt;/iframe>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;h2 id="ejercicio-5">Ejercicio 5&lt;/h2>
&lt;p>La probabilidad de que un hijo de una madre con el gen del daltonismo y un padre sin el gen del daltonismo sea un varón daltónico es $0.25$.&lt;/p>
&lt;ol>
&lt;li>
&lt;p>Si esta pareja tiene 5 hijos, ¿cuál es la probabilidad de que a lo sumo 2 sean varones daltónicos?&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Si esta pareja tiene 5 hijos, y el sexo de los hijos es equiprobable, ¿cuál es la probabilidad de que 3 o más sean mujeres?&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Si se toma una muestra aleatoria de 10000 hombres de una población en la que hay un varón daltónico por cada 5000 hombres, ¿cuál es la probabilidad de que haya más de 3 varones daltónicos?&lt;/p>
&lt;/li>
&lt;/ol>
&lt;div class="spoiler " >
&lt;p>
&lt;a class="btn btn-primary" data-toggle="collapse" href="#spoiler-5" role="button" aria-expanded="false" aria-controls="spoiler-5">
Solución
&lt;/a>
&lt;/p>
&lt;div class="collapse card " id="spoiler-5">
&lt;div class="card-body">
&lt;ol>
&lt;li>
&lt;p>Sea $X$ el número de hijos varones daltónicos en una muestra de 5 hijos de la pareja. Entonces $X\sim B(5, 0.25)$ y $P(X\leq 2)=0.8965$.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Sea $Y$ el número de mujeres en una muestra de 5 hijos de la pareja. Entonces $Y\sim B(5, 0.5)$ y $P(Y\geq 3)=0.5$.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Sea $Z$ el número de varones daltónicos en una muestra de 1000 hombres de la población. Entonces
$Z\sim B(10000, 2e-04)\approx P(2)$ y $P(Z&amp;gt;3)=0.1429$.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="spoiler " >
&lt;p>
&lt;a class="btn btn-primary" data-toggle="collapse" href="#spoiler-6" role="button" aria-expanded="false" aria-controls="spoiler-6">
Resolución
&lt;/a>
&lt;/p>
&lt;div class="collapse card " id="spoiler-6">
&lt;div class="card-body">
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe src="https://www.youtube.com/embed/4Si6aj1fM0k" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video">&lt;/iframe>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;h2 id="ejercicio-6">Ejercicio 6&lt;/h2>
&lt;p>La capacidad craneal de los primates sigue una distribución normal de media 1200 cm$^3$ y desviación típica 140 cm$^3$.&lt;/p>
&lt;ol>
&lt;li>
&lt;p>Calcular la probabilidad de que la capacidad craneal de un primate sea mayor de 1400 cm$^3$.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Calcular la probabilidad de que la capacidad craneal de un primate sea exáctamente 1400 cm$^3$.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Calcular la capacidad craneal por encima de la cual estarán el 20% of primates.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Calcular el rango intercuartílico de la capacidad craneal de los primates e interpretarlo.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;div class="spoiler " >
&lt;p>
&lt;a class="btn btn-primary" data-toggle="collapse" href="#spoiler-7" role="button" aria-expanded="false" aria-controls="spoiler-7">
Solución
&lt;/a>
&lt;/p>
&lt;div class="collapse card " id="spoiler-7">
&lt;div class="card-body">
&lt;p>Sea $X$ la capacidad craneal de los primates. Entonces $X\sim N(1200,140)$.&lt;/p>
&lt;ol>
&lt;li>
&lt;p>$P(X&amp;gt;1400) = 0.0766$.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>$P(X=1400) = 0$.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>$P_{80} = 1317.827$ cm$^3$.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>$Q_1 = 1105.5714$ cm$^3$, $Q_3 = 1294.4286$ cm$^3$ y $IQR = 188.8571$ cm$^3$. Por tanto, el 50% central de los datos está concentrado en un intervalo de amplitud $188.8571$ cm$^3$, que es poca dispersión.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="spoiler " >
&lt;p>
&lt;a class="btn btn-primary" data-toggle="collapse" href="#spoiler-8" role="button" aria-expanded="false" aria-controls="spoiler-8">
Resolución
&lt;/a>
&lt;/p>
&lt;div class="collapse card " id="spoiler-8">
&lt;div class="card-body">
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe src="https://www.youtube.com/embed/hwJ9ZQ_JDBs" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video">&lt;/iframe>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div></description></item><item><title>Examen de Óptica 2020-11-13</title><link>/docencia/estadistica/examenes/optica/optica-2020-11-13/</link><pubDate>Fri, 13 Nov 2020 00:00:00 +0000</pubDate><guid>/docencia/estadistica/examenes/optica/optica-2020-11-13/</guid><description>&lt;p>Titulación: Grado en Óptica&lt;br>
Fecha: 13 de Noviembre de 2020&lt;/p>
&lt;h2 id="ejercicio-1">Ejercicio 1&lt;/h2>
&lt;p>En una muestra de familias se ha medido la estatura del padre ($X$),
de la madre ($Y$) y de un hijo ($Z$) en centímetros, obteniendo los
siguientes resultados:&lt;/p>
&lt;p>$$
\begin{array}{ccc}
\mbox{Estatura padre} &amp;amp; \mbox{Estatura madre} &amp;amp; \mbox{Estatura hijo} \newline
\hline
175 &amp;amp; 164 &amp;amp; 177 \newline
182 &amp;amp; 175 &amp;amp; 180 \newline
190 &amp;amp; 165 &amp;amp; 193 \newline
165 &amp;amp; 160 &amp;amp; 172 \newline
172 &amp;amp; 155 &amp;amp; 173 \newline
183 &amp;amp; 172 &amp;amp; 188 \newline
187 &amp;amp; 160 &amp;amp; 185 \newline
174 &amp;amp; 151 &amp;amp; 177 \newline
168 &amp;amp; 165 &amp;amp; 168 \newline
178 &amp;amp; 163 &amp;amp; 182 \newline
\hline
\end{array}
$$&lt;/p>
&lt;p>Se pide:&lt;/p>
&lt;ol>
&lt;li>
&lt;p>¿En qué grupo es más representativa la media, en el de padres o en el de madres?&lt;/p>
&lt;/li>
&lt;li>
&lt;p>¿Hay alguna estatura atípica entre los hijos?&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Según su forma, ¿puede provenir la muestra de madres de una distribución normal?&lt;/p>
&lt;/li>
&lt;li>
&lt;p>¿Quién es más alto dentro de su grupo, una madre con una altura de 165 cm o un hijo con una altura de 178 cm?&lt;/p>
&lt;/li>
&lt;li>
&lt;p>¿Cómo afectaría a la representatividad de las medias que las alturas se midiesen en metros en vez de en centímetros?&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>Usar las siguientes sumas para los cálculos:&lt;br>
Estatura padre: $\sum x_i=1774$ cm, $\sum x_i^2=315300$ cm$^2$, $\sum (x_i-\bar x)^3=210.48$ cm$^3$ y $\sum (x_i-\bar x)^4=67596.27$ cm$^4$.&lt;br>
Estatura madre: $\sum y_i=1630$ cm, $\sum y_i^2=266150$ cm$^2$, $\sum (y_i-\bar y)^3=180$ cm$^3$ y $\sum (y_i-\bar y)^4=52324$ cm$^4$.&lt;br>
Estatura hijo : $\sum z_i=1795$ cm, $\sum z_i^2=322737$ cm$^2$, $\sum (z_i-\bar z)^3=1008$ cm$^3$ y $\sum (z_i-\bar z)^4=61906.62$ cm$^4$.&lt;/p>
&lt;div class="spoiler " >
&lt;p>
&lt;a class="btn btn-primary" data-toggle="collapse" href="#spoiler-0" role="button" aria-expanded="false" aria-controls="spoiler-0">
Solución
&lt;/a>
&lt;/p>
&lt;div class="collapse card " id="spoiler-0">
&lt;div class="card-body">
&lt;ol>
&lt;li>
&lt;p>Padres: $\bar x=177.4$ cm, $s^2=59.24$ cm$^2$, $s=7.6968$ cm y $cv=0.0434$.&lt;br>
Madres: $\bar y=163$ cm, $s^2=46$ cm$^2$, $s=6.7823$ cm y $cv=0.0416$.&lt;br>
La estatura media es un poco más representativa en el grupo de las madres.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Las vallas en la muestra de hijos son $f_1=155$ cm y $f_2=203$ cm por lo que no hay estaturas atípicas entre los hijos.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>$g_{1y}=0.0577$ y $g_{2y}=-0.5272$. Como el coeficiente de asimetría y el de apuntamiento están dentro del intervalo de -2 a 2, podemos asumir que la muestra de estaturas de madres proviene de una población normal.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Puntuación típica madres: $z(165)=0.2949$.&lt;br>
Puntuación típica hijos: $z(178)=-0.2052$.&lt;br>
Así pues, una madre de 165 cm es relativamente más alta que un hijo de 178 cm.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>La representatividad de las medias no cambiaría ya que tanto las medias como las desviaciones típicas estarían divididas por 100.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;h2 id="ejercicio-2">Ejercicio 2&lt;/h2>
&lt;p>Uno de los parámetros que se suele utilizar para diagnosticar el glaucoma de ángulo abierto es la distancia mínima al borde de la abertura de la membrana de Bruch ($X$) de la retina, pero se sabe
que esta medida depende de la edad del paciente ($Y$) en años y del área de la abertura de esta membrana por la que pasa el nervio óptico ($Z$). En un estudio se ha medido en 1000 pacientes estas
variables obteniendo los siguientes resultados:&lt;/p>
&lt;p>$\sum x_i=346337.03$ $\mu$m, $\sum y_i=47212.1$ años, $\sum z_i=2002.384$ mm$^2$,&lt;br>
$\sum x_i^2=123828243.48$ $\mu$m$^2$, $\sum y_i^2=2601264.99$ años$^2$, $\sum z_i^2=4175.89$ mm$^4$,&lt;br>
$\sum x_iy_j=15855138.59$ $\mu$m$\cdot$años, $\sum x_iz_j=686623.65$ $\mu$m$\cdot$mm$^2$, $\sum y_iz_j=94144.37$ años$\cdot$mm$^2$.&lt;/p>
&lt;p>Se pide:&lt;/p>
&lt;ol>
&lt;li>
&lt;p>Calcular las rectas de regresión de la distancia mínima al borde de la abertura de la membrana de Bruch sobre la edad, y de la distancia mínima al borde de la abertura de la membrana de Bruch
sobre el área de la abertura de la membrana.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>¿Cuánto aumenta o disminuye la distancia mínima al borde de la abertura de la membrana de Bruch por cada año más del paciente?&lt;/p>
&lt;/li>
&lt;li>
&lt;p>¿Qué porcentaje de la variabilidad de la distancia mínima al borde de la abertura de la membrana de Bruch explica cada uno de los modelos lineales anteriores?&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Utilizando el mejor de los modelos lineales anteriores predecir la distancia mínima al borde de la abertura de la membrana de Bruch de un paciente de 60 años con un área de la abertura de la
membrana de 2 mm$^2$.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;div class="spoiler " >
&lt;p>
&lt;a class="btn btn-primary" data-toggle="collapse" href="#spoiler-1" role="button" aria-expanded="false" aria-controls="spoiler-1">
Solución
&lt;/a>
&lt;/p>
&lt;div class="collapse card " id="spoiler-1">
&lt;div class="card-body">
&lt;ol>
&lt;li>
&lt;p>$\bar x=346.337$ $\mu$m, $s_x^2=3878.9051$ $\mu$m$^2$,&lt;br>
$\bar y=47.2121$ años, $s_y^2=372.2826$ años$^2$,&lt;br>
$\bar z=2.0024$ mm$^2$, $s_z^2=0.1664$ mm$^4$,&lt;br>
$s_{xy}=-496.1599$ $\mu$m$\cdot$años y $s_{xz}=-6.8761$ $\mu$m$\cdot$mm$^2$.&lt;br>
Recta de regresión de $X$ sobre $Y$: $x=409.259 + -1.3328y$.&lt;br>
Recta de regresión de $X$ sobre $Z$: $x=429.1056 + -41.335z$.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>La distancia mínima al borde de la abertura de la membrana de Bruch disminuye $1.3328$ $\mu$m por cada año más del paciente.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>$r^2_{xy}=0.1705$, de manera que la recta de regresión de $X$ sobre $Y$ explica el $17.05$% de la variabilidad de la distancia mínima al borde de la abertura de la membrana de Bruch, y $r^2_{xz}=0.0733$, de manera que la recta de regresión de $X$ sobre $Z$ explica el $7.33$% de la variabilidad de la distancia mínima al borde de la abertura de la membrana de Bruch.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>$x(60)=329.2939$ $\mu$m.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;/div>
&lt;/div></description></item><item><title>Examen de Farmacia 2020-10-26</title><link>/docencia/estadistica/examenes/farmacia/farmacia-2020-10-26/</link><pubDate>Mon, 26 Oct 2020 00:00:00 +0000</pubDate><guid>/docencia/estadistica/examenes/farmacia/farmacia-2020-10-26/</guid><description>&lt;p>Grados: Farmacia y Biotecnología&lt;br>
Fecha: 26 de octubre de 2020&lt;/p>
&lt;h2 id="ejercicio-1">Ejercicio 1&lt;/h2>
&lt;p>La siguiente tabla recoge el número de pacientes diarios que ingresaron en un hospital durante el mes de septiembre.&lt;/p>
&lt;p>$$
\begin{array}{cr}
\mbox{Pacientes} &amp;amp; \mbox{Frecuencia} \newline
\hline
(10,14] &amp;amp; 6 \newline
(14,18] &amp;amp; 10 \newline
(18,22] &amp;amp; 7 \newline
(22,26] &amp;amp; 6 \newline
(26,30] &amp;amp; 1 \newline
\hline
\end{array}$$&lt;/p>
&lt;p>Se pide:&lt;/p>
&lt;ol>
&lt;li>
&lt;p>Estudiar la dispersión del 50% de los datos centrales.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Calcular la media y estudiar la dispersión con respecto a ella.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Estudiar la normalidad de los datos.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Se sabe que en mismo hospital durante el mes de abril la media fue 35 pacientes y la varianza 40 pacientes$^2$. ¿En qué mes hubo más variabilidad relativa?&lt;/p>
&lt;/li>
&lt;li>
&lt;p>¿Qué número de ingresos es relativamente mayor, 20 ingresos en septiembre o 40 en abril?&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>Usar las siguientes sumas para los cálculos:&lt;br>
$\sum x_in_i=544$ pacientes, $\sum x_i^2n_i=10464$ pacientes$^2$, $\sum (x_i-\bar x)^3n_i=736.14$ pacientes$^3$ y $\sum (x_i-\bar x)^4n_i = 25367.44$ pacientes$^4$.&lt;br>
&lt;div class="spoiler " >
&lt;p>
&lt;a class="btn btn-primary" data-toggle="collapse" href="#spoiler-0" role="button" aria-expanded="false" aria-controls="spoiler-0">
Solución
&lt;/a>
&lt;/p>
&lt;div class="collapse card " id="spoiler-0">
&lt;div class="card-body">
&lt;ol>
&lt;li>
&lt;p>$Q_1=16$ pacientes, $Q_3=20$ pacientes y $RI=4$ pacientes. Por tanto, la dispersión central es pequeña.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>$\bar x=18.1333$ pacientes, $s^2=19.9822$ pacientes$^2$, $s=4.4701$ pacientes y $cv=0.2465$. Por tanto, la dispersión con respecto a la media es pequeña y la media representa bien.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>$g_1=0.2747$ y $g_2=-0.2346$. Como los coeficientes de asimetría y apuntamiento están entre -2 y 2, podemos asumir que la muestra proviene de una población normal.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Sea $Y$ el número de pacientes diarios hospitalizados durante el mes de abril. Entonces, $cv_y=0.8779$. Como el coeficiente de variación del mes de abril es mayor que el de septiembre, la dispersión relativa es mayor en abril.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Septiembre: $z(20)=-2.7143$.&lt;br>
Abril: $z(40)=-83.9682$.&lt;br>
Así pues, 40 pacientes hospitalizados en abril es relativamente mayor que 20 pacientes hospitalizados en septiembre ya que su puntuación típica es mayor.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;/div>
&lt;/div>&lt;/p>
&lt;h2 id="ejercicio-2">Ejercicio 2&lt;/h2>
&lt;p>El siguiente diagrama muestra la distribución de notas en tres asignaturas distintas.&lt;/p>
&lt;p>&lt;img src="../img/des-gen-14-diagrama-notas.svg" alt="Diagrama de caja de notas">&lt;/p>
&lt;ol>
&lt;li>
&lt;p>¿Qué asignatura es más difícil?&lt;/p>
&lt;/li>
&lt;li>
&lt;p>¿En qué asignatura hay más variabilidad central de los datos?&lt;/p>
&lt;/li>
&lt;li>
&lt;p>¿En qué asignaturas hay datos atípicos?&lt;/p>
&lt;/li>
&lt;li>
&lt;p>¿Qué asignatura tiene una distribución más asimétrica?&lt;/p>
&lt;/li>
&lt;/ol>
&lt;div class="spoiler " >
&lt;p>
&lt;a class="btn btn-primary" data-toggle="collapse" href="#spoiler-1" role="button" aria-expanded="false" aria-controls="spoiler-1">
Solución
&lt;/a>
&lt;/p>
&lt;div class="collapse card " id="spoiler-1">
&lt;div class="card-body">
&lt;ol>
&lt;li>
&lt;p>La asignatura $Y$ ya que sus puntuaciones son menores (la caja y los bigotes están más desplazados hacia la izquierda).&lt;/p>
&lt;/li>
&lt;li>
&lt;p>La asignatura $X$ porque la anchura de la caja es mayor.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>La asignatura $Z$ porque hay una nota que está fuera de los
bigotes.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>La asignatura $Z$ porque la distancia desde el primer cuartil hasta la mediana (lado izquierdo de la caja) es mayor que la distancia desde la mediana al tercer cuartil (lado derecho de la
caja).&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;h2 id="ejercicio-3">Ejercicio 3&lt;/h2>
&lt;p>Se quiere estudiar si la estatura de los hijos depende de la estatura de los padres y para ello se ha tomado una muestra de 10 familias con un hijo mayor de 20 años y se ha medido la estatura del padre ($X$), de la madre ($Y$) y del hijo ($Z$) en centímetros, obteniendo los siguientes resultados:&lt;/p>
&lt;p>$\sum x_i=1774$ cm, $\sum y_i=1630$ cm, $\sum z_i=1795$ cm,&lt;br>
$\sum x_i^2=315300$ cm$^2$, $\sum y_i^2=266150$ cm$^2$, $\sum z_i^2=322737$ cm$^2$,&lt;br>
$\sum x_iy_j=289364$ cm$^2$, $\sum x_iz_j=318958$ cm$^2$, $\sum y_iz_j=292757$ cm$^2$.&lt;/p>
&lt;p>Se pide:&lt;/p>
&lt;ol>
&lt;li>
&lt;p>¿De qué estatura depende más linealmente la estatura del hijo, de la estatura del padre o de la madre?&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Utilizando el mejor modelo lineal, predecir la estatura de un hijo cuyo padre mide 181 cm y cuya madre mide 163 cm.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>¿Cuánto aumentará la estatura del hijo por cada centímetro que aumente la estatura del padre? ¿Y de la madre?&lt;/p>
&lt;/li>
&lt;li>
&lt;p>¿Cómo afectaría a la fiabilidad de los modelos que las estaturas se hubiesen medido en pulgadas? (Una pulgada son 2.54 cm).&lt;/p>
&lt;/li>
&lt;/ol>
&lt;div class="spoiler " >
&lt;p>
&lt;a class="btn btn-primary" data-toggle="collapse" href="#spoiler-2" role="button" aria-expanded="false" aria-controls="spoiler-2">
Solución
&lt;/a>
&lt;/p>
&lt;div class="collapse card " id="spoiler-2">
&lt;div class="card-body">
&lt;ol>
&lt;li>
&lt;p>$\bar x=177.4$ cm, $s_x^2=59.24$ cm$^2$,&lt;br>
$\bar y=163$ cm, $s_y^2=46$ cm$^2$,&lt;br>
$\bar z=179.5$ cm, $s_z^2=53.45$ cm$^2$,&lt;br>
$s_{xz}=69.8861$ cm$^2$ y $s_{yz}=17.2$ cm$^2$.&lt;br>
$r^2_{xz}=0.9273$ y $r^2_{yz}=0.1203$, de manera que la estatura de los hijos depende linealmente más de la estatura del padre ya que su coeficiente de determinación es mayor.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Recta de regresión de $Z$ sobre $X$: $z=-29.7808 + 1.1797x$ y $z(181)=183.747$ cm.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>La estatura del hijo aumentará $1.1797$ cm por cada cm que aumente la estatura del padre y $0.3739$ cm por cada cm que aumente la estatura de la madre.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>La fiabilidad sería la misma, ya que al aplicar la misma transformación lineal a $X$ y $Z$, las varianzas quedan multiplicadas por el cuadrado de la pendiente y la covarianza también queda multiplicada por el cuadrado de la pendiente.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;/div>
&lt;/div></description></item><item><title>Examen de Farmacia 2019-12-16</title><link>/docencia/estadistica/examenes/farmacia/farmacia-2019-12-16/</link><pubDate>Mon, 16 Dec 2019 00:00:00 +0000</pubDate><guid>/docencia/estadistica/examenes/farmacia/farmacia-2019-12-16/</guid><description>&lt;p>Grados: Farmacia y Biotecnología&lt;br>
Fecha: 16 de Diciembre de 2019&lt;/p>
&lt;h2 id="ejercicio-1">Ejercicio 1&lt;/h2>
&lt;p>Se ha analizado en 50 casos el tiempo en minutos que, después de una operación, un paciente ha tardado en eliminar la anestesia, obteniéndose el siguiente resultado:&lt;/p>
&lt;p>$$
\begin{array}{cr}
\mbox{Tiempo} &amp;amp; \mbox{Pacientes} \newline
\hline
10-30 &amp;amp; 2 \newline
30-45 &amp;amp; 11 \newline
45-60 &amp;amp; 18 \newline
60-90 &amp;amp; 9 \newline
90-120 &amp;amp; 8 \newline
120-180 &amp;amp; 2 \newline
\hline
\end{array}
$$&lt;/p>
&lt;p>Se pide:&lt;/p>
&lt;ol>
&lt;li>¿Presenta la muestra algún dato atípico?&lt;/li>
&lt;li>¿Es la media un valor representativo de la muestra? ¿Cuánto vale?&lt;/li>
&lt;li>Si un protocolo de postoperatorio contempla monitorizar al 15% de los pacientes que más tardan en eliminar la anestesia. ¿A partir de que tiempo se debe monitorizar a un paciente según la muestra?&lt;/li>
&lt;li>Si se suministra un fármaco antagonista del anestésico, se sabe que el tiempo de eliminación de la anestesia disminuye en un 25%. ¿Cómo afectará esta disminución a la representatividad de la nueva media?&lt;/li>
&lt;li>Si se sabe que el tiempo de eliminación de otro tipo de anestesia $B$ tiene media 50 minutos y desviación típica 15 minutos, ¿qué tiempo de eliminación es relativamente mayor, 70 minutos con este tipo de anestesia o 60 minutos con el tipo de anestesia $B$?&lt;/li>
&lt;/ol>
&lt;p>Usar las siguientes sumas para los cálculos:&lt;br>
$\sum x_in_i=3212.5$ min, $\sum x_i^2n_i=249706.25$ min$^2$,&lt;br>
$\sum (x_i-\bar x)^3n_i=1400531.25$ min$^3$ y&lt;br>
$\sum (x_i-\bar x)^4n_i=143958437.7$ min$^4$.&lt;/p>
&lt;div class="spoiler " >
&lt;p>
&lt;a class="btn btn-primary" data-toggle="collapse" href="#spoiler-0" role="button" aria-expanded="false" aria-controls="spoiler-0">
Solución
&lt;/a>
&lt;/p>
&lt;div class="collapse card " id="spoiler-0">
&lt;div class="card-body">
&lt;ol>
&lt;li>$C_1=44.3182$, $C_3=81.6667$, $RI=37.3485$, $v_1=-11.7045$ y $v_2=137.6894$. Puesto que la última clase contiene valores por encima de la valla superior, podría haber datos atípicos.&lt;/li>
&lt;li>$\bar x=64.25$ min, $s^2=866.0625$ min$^2$, $s=29.4289$ min y $cv=0.458$. Por tanto, la representatividad de la media es moderada.&lt;/li>
&lt;li>$P_{85}=99.375$ min.&lt;/li>
&lt;li>Aplicando la transformación lineal $y=0.75x$, $\bar y=48.1875$ min, $s_y=22.0717$ min y $cv=0.458$. Por tanto, la representatividad de la media es la misma.&lt;/li>
&lt;li>Puntuación típica para la primera anestesia: $z(70)=0.1954$.&lt;br>
Puntuación típica para la anestesia $B$: $z(60)=0.6667$.&lt;br>
Por tanto, 60 min es relativamente mayor con la anestesia $B$.&lt;/li>
&lt;/ol>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;h2 id="ejercicio-2">Ejercicio 2&lt;/h2>
&lt;p>La siguiente tabla contiene las notas de un grupo de 10 alumnos de matemáticas de farmacia en tres exámenes parciales.&lt;/p>
&lt;p>$$
\begin{array}{rrr}
\mbox{Parcial 1} (X) &amp;amp; \mbox{Parcial 2} (Y) &amp;amp; \mbox{Parcial 3} (Z) \newline
\hline
5.5 &amp;amp; 3.2 &amp;amp; 5.0 \newline
7.5 &amp;amp; 6.5 &amp;amp; 2.0 \newline
2.5 &amp;amp; 4.0 &amp;amp; 1.0 \newline
6.0 &amp;amp; 4.0 &amp;amp; 6.0 \newline
8.0 &amp;amp; 7.5 &amp;amp; 6.0 \newline
4.0 &amp;amp; 3.5 &amp;amp; 1.0 \newline
7.0 &amp;amp; 5.5 &amp;amp; 4.0 \newline
9.5 &amp;amp; 10.0 &amp;amp; 9.0 \newline
10.0 &amp;amp; 9.5 &amp;amp; 8.0 \newline
1.0 &amp;amp; 3.0 &amp;amp; 0.5 \newline
\hline
\end{array}
$$&lt;/p>
&lt;p>Se pide:&lt;/p>
&lt;ol>
&lt;li>¿Cuáles son las dos notas que mejor se correlacionan linealmente?&lt;/li>
&lt;li>Utilizando modelos lineales, ¿cuáles serían las notas estimadas en los parciales 2 y 3 de un alumno que obtuvo un $6.5$ en el parcial 1?&lt;/li>
&lt;/ol>
&lt;p>Usar las siguientes sumas para los cálculos:&lt;br>
$\sum x_i=61$, $\sum y_i=56.7$, $\sum z_i=42.5$,&lt;br>
$\sum x_i^2=449$, $\sum y_i^2=382.49$, $\sum z_i^2=264.25$,&lt;br>
$\sum x_iy_j=405.85$, $\sum x_iz_j=327$, $\sum y_jz_j=295$.&lt;/p>
&lt;div class="spoiler " >
&lt;p>
&lt;a class="btn btn-primary" data-toggle="collapse" href="#spoiler-1" role="button" aria-expanded="false" aria-controls="spoiler-1">
Solución
&lt;/a>
&lt;/p>
&lt;div class="collapse card " id="spoiler-1">
&lt;div class="card-body">
&lt;ol>
&lt;li>$\bar x=6.1$, $s_x^2=7.69$, $\bar y=5.67$, $s_y^2=6.1001$, $\bar z=4.25$, $s_z^2=8.3625$, $s_{xy}=5.998$, $s_{xz}=6.775$, $s_{yz}=5.4025$, $r^2_{xy}=0.7669$, $r^2_{xz}=0.7138$ y $r^2_{yz}=0.5722$. Por tanto, las dos variables más correlacionadas linealmente son $X$ e $Y$, ya que su coeficiente de determinación es mayor.&lt;/li>
&lt;li>Recta de regresión de $Y$ sobre $X$: $y=0.9122 + 0.78x$ y $y(6.5)=5.982$.&lt;br>
Recta de regresión de $Z$ sobre $X$: $z=-1.1242 + 0.881x$ y $z(6.5)=4.6024$.&lt;/li>
&lt;/ol>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;h2 id="ejercicio-3">Ejercicio 3&lt;/h2>
&lt;p>Para ver si existe algún tipo de asociación entre la osteoporosis y el sexo se ha tomado una muestra aleatoria de personas entre 65 y 70 años y se ha observado el sexo y cuántos presentaban osteoporosis.
Los resultados se reflejan en la siguiente tabla.&lt;/p>
&lt;p>$$
\begin{array}{lcc}
\hline
&amp;amp; \mbox{Osteoporosis} &amp;amp; \mbox{No osteoporosis} \newline
\mbox{Mujeres} &amp;amp; 480 &amp;amp; 2320 \newline
\mbox{Hombres} &amp;amp; 255 &amp;amp; 1505 \newline
\hline
\end{array}
$$&lt;/p>
&lt;p>Se pide:&lt;/p>
&lt;ol>
&lt;li>Calcular la prevalencia de la osteoporosis en la población.&lt;/li>
&lt;li>Calcular el riesgo relativo de presentar osteoporosis de las mujeres con respecto a los hombres e interpretarlo.&lt;/li>
&lt;li>Calcular el odds ratio de presentar osteoporosis de las mujeres con respecto a los hombres e interpretarlo.&lt;/li>
&lt;li>¿Cuál de las dos medidas de asociación es más apropiada para estudiar la asociación entre la osteoporosis y el sexo? Justificar la respuesta.&lt;/li>
&lt;/ol>
&lt;div class="spoiler " >
&lt;p>
&lt;a class="btn btn-primary" data-toggle="collapse" href="#spoiler-2" role="button" aria-expanded="false" aria-controls="spoiler-2">
Solución
&lt;/a>
&lt;/p>
&lt;div class="collapse card " id="spoiler-2">
&lt;div class="card-body">
&lt;p>Sea $E$ el evento consistente en tener osteoporosis.&lt;/p>
&lt;ol>
&lt;li>Prevalencia: $P(E)=0.1612$.&lt;/li>
&lt;li>$RR(E)=1.1832$. Por tanto, el riesgo de sufrir osteoporosis en mujeres es mayor que en hombres, pero no mucho. No existe una asociación fuerte entre la osteoporosis y el sexo.&lt;/li>
&lt;li>$OR(E)=1.2211$. Por tanto, el odds de sufrir en mujeres es mayor que en hombres, pero no mucho.&lt;/li>
&lt;li>Puesto que es posible calcular la prevalencia de la osteoporosis, ambas medidas pueden calcularse, pero el riesgo relativo es más fácil de interpretar.&lt;/li>
&lt;/ol>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;h2 id="ejercicio-4">Ejercicio 4&lt;/h2>
&lt;p>La probabilidad de contraer la gripe en dos ciudades $A$ y $B$ del mismo tamaño es del 14% y del 8% respectivamente.
Se pide:&lt;/p>
&lt;ol>
&lt;li>Calcular la probabilidad de que en una muestra aleatoria de 10 individuos de la ciudad $A$ haya más de 2 que contraigan la gripe.&lt;/li>
&lt;li>Calcular la probabilidad de que en una muestra aleatoria de 50 individuos de la ciudad $B$ haya más de 2 y menos de 5 que contraigan la gripe.&lt;/li>
&lt;li>Calcular la probabilidad de que en una muestra aleatoria de 8 individuos tomados de ambas ciudades haya 2 que contraigan la gripe.&lt;/li>
&lt;li>Suponiendo que contraer la gripe en ambas ciudades son sucesos independientes, calcular la probabilidad de que en una muestra de 5 personas que han estado en las dos ciudades haya alguna que contraiga la gripe.&lt;/li>
&lt;/ol>
&lt;div class="spoiler " >
&lt;p>
&lt;a class="btn btn-primary" data-toggle="collapse" href="#spoiler-3" role="button" aria-expanded="false" aria-controls="spoiler-3">
Solución
&lt;/a>
&lt;/p>
&lt;div class="collapse card " id="spoiler-3">
&lt;div class="card-body">
&lt;ol>
&lt;li>Sea $X$ el número de personas que contraen la gripe en una muestra de 10 personas de la población $A$, entonces $X\sim B(10, 0.14)$ y $P(X&amp;gt;2)=0.1545$.&lt;/li>
&lt;li>Sea $Y$ el número de personas que contraen la gripe en una muestra de 50 personas de la población $B$, entonces $Y\sim B(50, 0.08)\approx P(4)$ y $P(2 &amp;lt; Y &amp;lt; 5) = 0.3907$.&lt;/li>
&lt;li>Sea $Z$ el número de personas que contraen la gripe en una muestra de 8 personas de las poblaciones $A$ y $B$, entonces $Z\sim B(8, 0.11)$ y $P(Z = 2) = 0.1684$.&lt;/li>
&lt;li>Sea $U$ el número de personas que contraen la gripe en una muestra de 5 personas que han vivido en ambas ciudades, entonces $U\sim B(5, 0.2088)$ y $P(U&amp;gt;0)=0.69$.&lt;/li>
&lt;/ol>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;h2 id="ejercicio-5">Ejercicio 5&lt;/h2>
&lt;p>En un estudio sobre el nivel de colesterol de los habitantes de una población se midió el nivel de colesterol de 10000 hombres y 10000 mujeres, obteniéndose que 3420 hombres y 1234 mujeres tenían un nivel de colesterol superior a 230 mg/dl, y que 4936 hombres tenían entre 210 y 230 mg/dl.
Suponiendo que los niveles de colesterol en los hombres y en las mujeres siguen distribuciones normales con la misma desviación típica, calcular:&lt;/p>
&lt;ol>
&lt;li>Las medias y la desviación típica de las distribuciones del nivel de colesterol en hombres y mujeres.&lt;br>
Nota: Si no se saben calcular las medias y desviación típica, tomar 215 mg/dl y 220 mg/dl como las medias de mujeres y hombres respectivamente, y 10 mg/dl como la desviación típica, para los próximos apartados.&lt;/li>
&lt;li>El porcentaje de hombres cuyo nivel de colesterol estará entre 200 y 240 mg/dl.&lt;/li>
&lt;li>El rango intercuartílico del nivel de colesterol en las mujeres.&lt;/li>
&lt;/ol>
&lt;div class="spoiler " >
&lt;p>
&lt;a class="btn btn-primary" data-toggle="collapse" href="#spoiler-4" role="button" aria-expanded="false" aria-controls="spoiler-4">
Solución
&lt;/a>
&lt;/p>
&lt;div class="collapse card " id="spoiler-4">
&lt;div class="card-body">
&lt;ol>
&lt;li>Sean $X$ e $Y$ los niveles de colesterol en hombres y mujeres respectivamente, entonces $X\sim N(224.1164, 14.4556)$ e $Y\sim N(213.2581, 14.4556)$.&lt;/li>
&lt;li>$P(200\leq X \leq 240) = 0.8164$. 3. $RI = 19.5003$ mg/dl.&lt;/li>
&lt;/ol>
&lt;/div>
&lt;/div>
&lt;/div></description></item><item><title>Examen de Farmacia 2018-12-17</title><link>/docencia/estadistica/examenes/farmacia/farmacia-2018-12-17/</link><pubDate>Mon, 17 Dec 2018 00:00:00 +0000</pubDate><guid>/docencia/estadistica/examenes/farmacia/farmacia-2018-12-17/</guid><description>&lt;p>Grados: Farmacia y Biotecnología&lt;br>
Fecha: 17 de Diciembre de 2018&lt;/p>
&lt;h2 id="ejercicio-1">Ejercicio 1&lt;/h2>
&lt;p>El siguiente gráfico representa la distribución acumulada del número de fármacos defectuosos diarios producidos por una máquina en una muestra de 40 fármacos.&lt;/p>
&lt;img src="../img/question1-1.svg" title="plot of chunk question1" alt="plot of chunk question1" />
&lt;ol>
&lt;li>Construir la tabla de frecuencias del número de fármacos defectuosos.&lt;/li>
&lt;li>Dibujar el diagrama de caja y bigotes del número de fármacos defectuosos.&lt;/li>
&lt;li>Estudiar la asimetría de la distribución del número de fármacos defectuosos.&lt;/li>
&lt;li>Si el número de fármacos defectuosos producidos por una segunda máquina sigue la ecuación $y=3x+2$, donde $x$ e $y$ son el número de fármacos defectuosos producidos con la primera y la segunda máquina respectivamente, ¿en qué máquina es más representativa la media del número de fármacos defectuosos?&lt;/li>
&lt;li>¿Qué número de fármacos defectuosos es relativamente menor, 3 fármacos en la primera máquina o 9 fármacos en la segunda?&lt;/li>
&lt;/ol>
&lt;div class="spoiler " >
&lt;p>
&lt;a class="btn btn-primary" data-toggle="collapse" href="#spoiler-0" role="button" aria-expanded="false" aria-controls="spoiler-0">
Solución
&lt;/a>
&lt;/p>
&lt;div class="collapse card " id="spoiler-0">
&lt;div class="card-body">
&lt;ol>
&lt;li>$$\begin{array}{|c|r|r|r|r|}
\hline
\mbox{Fármacos defectuosos} &amp;amp; n_i &amp;amp; f_i &amp;amp; N_i &amp;amp; F_i \newline
\hline
0 &amp;amp; 1 &amp;amp; 0.025 &amp;amp; 1 &amp;amp; 0.025 \newline
1 &amp;amp; 3 &amp;amp; 0.075 &amp;amp; 4 &amp;amp; 0.100 \newline
2 &amp;amp; 6 &amp;amp; 0.150 &amp;amp; 10 &amp;amp; 0.250 \newline
3 &amp;amp; 7 &amp;amp; 0.175 &amp;amp; 17 &amp;amp; 0.425 \newline
4 &amp;amp; 8 &amp;amp; 0.200 &amp;amp; 25 &amp;amp; 0.625 \newline
5 &amp;amp; 6 &amp;amp; 0.150 &amp;amp; 31 &amp;amp; 0.775 \newline
6 &amp;amp; 5 &amp;amp; 0.125 &amp;amp; 36 &amp;amp; 0.900 \newline
7 &amp;amp; 2 &amp;amp; 0.050 &amp;amp; 38 &amp;amp; 0.950 \newline
8 &amp;amp; 1 &amp;amp; 0.025 &amp;amp; 39 &amp;amp; 0.975 \newline
9 &amp;amp; 1 &amp;amp; 0.025 &amp;amp; 40 &amp;amp; 1.000 \newline
\hline
\end{array}
$$&lt;/li>
&lt;li>&lt;/li>
&lt;/ol>
&lt;img src="../img/boxplot-1.svg" title="plot of chunk boxplot" alt="plot of chunk boxplot" />
&lt;ol start="3">
&lt;li>$\bar x=3.975$ fármacos, $s_x=1.9936$ fármacos y $g_1=0.3184$. Por tanto, la distribución es un poco asimétrica hacia la derecha.&lt;/li>
&lt;li>$cv_x=0.5015$, $\bar y=13.925$ fármacos, $s_y=5.9808$ fármacos y $cv_y=0.4295$.&lt;br>
Así pues, la media de $y$ es más representativa que la media de $x$ ya que su coeficiente de variación es menor.&lt;/li>
&lt;li>$z_x=-0.4891$ y $z_y=-0.8235$, por tanto, 9 fármacos defectuosos en la máquina $y$ es relativamente menor.&lt;/li>
&lt;/ol>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;h2 id="ejercicio-2">Ejercicio 2&lt;/h2>
&lt;p>Un laboratorio farmacéutico fabrica dos modelos de tensiómetro, uno de brazo y otro de muñeca.
Para comprobar la precisión de los mismos se ha realizado un control de calidad tomando la tensión a 20 pacientes y se han obtenido obtenido los siguientes resultados:&lt;/p>
&lt;p>$\sum x_i=265.4$ mmHg, $\sum y_i=262.5$ mmHg , $\sum z_i=262.4$ mmHg,&lt;br>
$\sum x_i^2=3701.14$ mmHg$^2$, $\sum y_i^2=3629.41$ mmHg$^2$, $\sum z_i^2=3615.38$ mmHg$^2$,&lt;br>
$\sum x_iy_j=3658.28$ mmHg$^2$, $\sum x_iz_j=3655.95$ mmHg$^2$, $\sum y_jz_j=3613.97$ mmHg$^2$.&lt;/p>
&lt;p>Donde $X$ es la tensión con el tensiómetro de brazo, $Y$ con el tensiómetro de muñeca y $Z$ la tensión real.
Se pide:&lt;/p>
&lt;ol>
&lt;li>¿Qué tensiómetro predice mejor la tensión real?&lt;/li>
&lt;li>Si un paciente tiene una tensión real de $13.5$ mmHg, ¿qué se espera que marque el tensiómetro de brazo?&lt;/li>
&lt;/ol>
&lt;div class="spoiler " >
&lt;p>
&lt;a class="btn btn-primary" data-toggle="collapse" href="#spoiler-1" role="button" aria-expanded="false" aria-controls="spoiler-1">
Solución
&lt;/a>
&lt;/p>
&lt;div class="collapse card " id="spoiler-1">
&lt;div class="card-body">
&lt;ol>
&lt;li>Presión arterial con el tensiómetro de brazo: $\bar x=13.27$ mmHg, $s^2_x=8.9641$ mmHg².&lt;br>
Presión arterial con el tensiómetro de muñeca: $\bar y=13.125$ mmHg, $s^2_y=9.2049$ mmHg².&lt;br>
Presión arterial real: $\bar z=13.12$ mmHg, $s^2_z=8.6346$ mmHg².&lt;br>
$s_{xz}=8.6951$ mmHg², $s_{yz}=8.4985$ mmHg², $r^2_{xz}=0.9768$ y $r^2_{yz}=0.9087$.&lt;br>
Así pues, el tensiómetro de brazo predice mejor la presión arterial real con un modelo de regresión lineal ya que el coeficiente de determinación lineal es mayor.&lt;/li>
&lt;li>Recta de regresión de $X$ sobre $Z$: $x=0.0581+1.007z$.&lt;br>
Predicción: $x(13.5)=13.6527$ mmHg.&lt;/li>
&lt;/ol>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;h2 id="ejercicio-3">Ejercicio 3&lt;/h2>
&lt;p>La recta de regresión de $Y$ sobre $X$ es $y=1.2x-0.6$.
Se pide:&lt;/p>
&lt;style type="text/css">
ol ol { list-style-type: lower-alpha; }
&lt;/style>
&lt;ol>
&lt;li>Indicar razonadamente cuáles de las siguientes rectas no pueden ser las recta de regresión de $X$ sobre $Y$.
&lt;ol>
&lt;li>$x=0.9y-0.6$&lt;/li>
&lt;li>$x=-0.7y+0.4$&lt;/li>
&lt;li>$x=0.8y-0.7$&lt;/li>
&lt;li>$x=-0.6y-0.5$&lt;/li>
&lt;li>$x=0.4y-0.6$&lt;/li>
&lt;li>$x=-0.5y+0.9$&lt;/li>
&lt;/ol>
&lt;/li>
&lt;li>Entre las que puedan ser indicar razonadamente con cuál de ellas serían más fiables las predicciones.&lt;/li>
&lt;/ol>
&lt;div class="spoiler " >
&lt;p>
&lt;a class="btn btn-primary" data-toggle="collapse" href="#spoiler-2" role="button" aria-expanded="false" aria-controls="spoiler-2">
Solución
&lt;/a>
&lt;/p>
&lt;div class="collapse card " id="spoiler-2">
&lt;div class="card-body">
&lt;ol>
&lt;li>(b), (d) y (f) no son posibles porque tienen pendiente negativa, y (a) no es posible porque el coeficiente de determinación lineal es mayor que 1.&lt;/li>
&lt;li>(c) da las mejores predicciones porque su coeficiente de determinación es mayor.&lt;/li>
&lt;/ol>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;h2 id="ejercicio-4">Ejercicio 4&lt;/h2>
&lt;p>En un estudio epidemiológico se tomó una muestra de 400 personas con cáncer de pulmón y otra de 1200 sin cáncer de pulmón.
Entre las personas con cáncer de pulmón se observó que había 180 fumadoras, mientras que entre las personas sin cáncer de pulmón había 1140 no fumadoras.
Se pide:&lt;/p>
&lt;ol>
&lt;li>Calcular el riesgo relativo de desarrollar cáncer al fumar e interpretarlo.&lt;/li>
&lt;li>Calcular el odds ratio de desarrollar cáncer al fumar e interpretarlo.&lt;/li>
&lt;/ol>
&lt;div class="spoiler " >
&lt;p>
&lt;a class="btn btn-primary" data-toggle="collapse" href="#spoiler-3" role="button" aria-expanded="false" aria-controls="spoiler-3">
Solución
&lt;/a>
&lt;/p>
&lt;div class="collapse card " id="spoiler-3">
&lt;div class="card-body">
&lt;p>Sea $C$ el evento correspondiente a tener cáncer de pulmón.&lt;/p>
&lt;ol>
&lt;li>$RR(C)=9$. Esto quiere decir que la probabilidad de tener cancer de pulmón al fumar es 9 veces mayor que sin fumar.&lt;/li>
&lt;li>$OR(C)=15.5455$. Como es positivo existe una asociación directa entre fumar y tener cáncer de pulmón. El odds de tener cáncer de pulmón si se fuma es más the 15 veces mayor que si no se fuma.&lt;/li>
&lt;/ol>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;h2 id="ejercicio-5">Ejercicio 5&lt;/h2>
&lt;p>Se quiere desarrollar un test diagnóstico que sirva para descartar una enfermedad cuando el test es negativo (valor predictivo negativo) con al menos una probabilidad del 90% para aplicarlo en una población en la que se sabe que hay un 15% de individuos que presentan la enfermedad.
Si la sensibilidad del test se ha establecido en un 80%,&lt;/p>
&lt;ol>
&lt;li>¿Qué especificidad mínima tendría que tener el test?&lt;/li>
&lt;li>¿Cuál sería en ese caso su probabilidad de diagnóstico correcto?&lt;/li>
&lt;li>¿Cuál sería la probabilidad de descartar la enfermedad en un paciente que se le ha aplicado dos veces el test y ha dado negativo en ambos casos?&lt;/li>
&lt;/ol>
&lt;div class="spoiler " >
&lt;p>
&lt;a class="btn btn-primary" data-toggle="collapse" href="#spoiler-4" role="button" aria-expanded="false" aria-controls="spoiler-4">
Solución
&lt;/a>
&lt;/p>
&lt;div class="collapse card " id="spoiler-4">
&lt;div class="card-body">
&lt;p>Sea $E$ el evento correspondiente a tener la enfermedad y $+$ y $-$ los eventos correspondientes a tener un resultado positivo o negativo en el test diagnóstico respectivamente.&lt;/p>
&lt;ol>
&lt;li>Especificidad mínima $P(-|\overline{E})=0.3176$.&lt;/li>
&lt;li>$P(VP) + P(VN) = P(E\cap +) + P(\overline{E}\cap -) = 0.12+0.27 = 0.39$.&lt;/li>
&lt;li>$P(\overline{E}| -_1\cap -_2)=0.9346$.&lt;/li>
&lt;/ol>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;h2 id="ejercicio-6">Ejercicio 6&lt;/h2>
&lt;p>Se sabe que en una ciudad una de cada 20 personas, por término medio, tiene sangre del tipo $AB$.&lt;/p>
&lt;ol>
&lt;li>Si se eligen al azar doscientos donantes de sangre, ¿cuál es la probabilidad de que al menos 5 tengan sangre de tipo $AB$?&lt;/li>
&lt;li>Si se eligen al azar 10 personas, ¿cuál es la probabilidad de que haya más de 8 con grupo sanguíneo distinto de $AB$?&lt;/li>
&lt;/ol>
&lt;div class="spoiler " >
&lt;p>
&lt;a class="btn btn-primary" data-toggle="collapse" href="#spoiler-5" role="button" aria-expanded="false" aria-controls="spoiler-5">
Solución
&lt;/a>
&lt;/p>
&lt;div class="collapse card " id="spoiler-5">
&lt;div class="card-body">
&lt;ol>
&lt;li>Sea $X$ el número de donantes con grupo sanguíneo $AB$ en una muestra de 200 donantes de sangre. Entonces, $X\sim B(200,1/20)\approx P(10)$, y $P(X\geq 5)=0.9707$.&lt;/li>
&lt;li>Sea $Y$ el número de donantes con grupo sanguíneo distinto de $AB$ en una muestra de 10 donantes. Entonces, $Y\sim B(10,19/20)$, y $P(Y&amp;gt;8)=0.9139$.&lt;/li>
&lt;/ol>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;h2 id="ejercicio-7">Ejercicio 7&lt;/h2>
&lt;p>En una asignatura hay 230 alumnos, de los cuales 150 son chicas y 80 chicos.
Se sabe que las notas siguen distribuciones normales con la misma desviación típica en las chicas y en los chicos.
Si hay 120 chicas y 56 chicos que tienen una nota superior a 5 y 36 chicos tienen una nota entre 5 y 7.
Se pide:&lt;/p>
&lt;ol>
&lt;li>Las medias y las desviaciones típicas de las notas de chicas y chicos.&lt;/li>
&lt;li>¿Cuántas chicas tendrán una nota entre 4.5 y 8?&lt;/li>
&lt;li>¿Por encima de qué nota estarán el 10% de las chicas?&lt;/li>
&lt;/ol>
&lt;div class="spoiler " >
&lt;p>
&lt;a class="btn btn-primary" data-toggle="collapse" href="#spoiler-6" role="button" aria-expanded="false" aria-controls="spoiler-6">
Solución
&lt;/a>
&lt;/p>
&lt;div class="collapse card " id="spoiler-6">
&lt;div class="card-body">
&lt;p>Sea $X$ la nota de un chico aleatorio del curso e $Y$ la nota de una chica aleatoria del curso. Entonces, $X\sim N(\mu_x,\sigma)$ y $Y\sim N(\mu_y,\sigma)$.&lt;/p>
&lt;ol>
&lt;li>$\mu_x=5.87$, $\mu_y=6.41$ y $\sigma=1.68$.&lt;/li>
&lt;li>$P(4.5\leq Y\leq 8) = 0.7018$, es decir, $105.27$ chicas.&lt;/li>
&lt;li>$P_{90}=8.8$.&lt;/li>
&lt;/ol>
&lt;/div>
&lt;/div>
&lt;/div></description></item><item><title>Examen de Óptica 2018-10-24</title><link>/docencia/estadistica/examenes/optica/optica-2018-10-24/</link><pubDate>Wed, 24 Oct 2018 00:00:00 +0000</pubDate><guid>/docencia/estadistica/examenes/optica/optica-2018-10-24/</guid><description>&lt;p>Titulación: Grado en Óptica&lt;br>
Fecha: 24 de Octubre de 2018&lt;/p>
&lt;h2 id="ejercicio-1">Ejercicio 1&lt;/h2>
&lt;p>En un estudio sobre la presbicia se tomó una muestra de pacientes y se midió la edad y la distancia mínima a la que eran capaces de leer una frase en cm.
Los datos se muestran en la siguiente tabla.&lt;/p>
&lt;p>$$
\begin{array}{lrrrrrrrrrrrrrrrrrrrr}
\hline
\mbox{Edad} &amp;amp; 7 &amp;amp; 12 &amp;amp; 15 &amp;amp; 15 &amp;amp; 18 &amp;amp; 21 &amp;amp; 25 &amp;amp; 28 &amp;amp; 32 &amp;amp; 35 &amp;amp; 43 &amp;amp; 46 &amp;amp; 48 &amp;amp; 51 &amp;amp; 54 &amp;amp; 57 &amp;amp; 60 &amp;amp; 66 &amp;amp; 72 &amp;amp; 92 \newline
\mbox{Distancia} &amp;amp; 13 &amp;amp; 14 &amp;amp; 12 &amp;amp; 14 &amp;amp; 13 &amp;amp; 14 &amp;amp; 13 &amp;amp; 14 &amp;amp; 16 &amp;amp; 13 &amp;amp; 18 &amp;amp; 19 &amp;amp; 22 &amp;amp; 22 &amp;amp; 26 &amp;amp; 25 &amp;amp; 27 &amp;amp; 28 &amp;amp; 29 &amp;amp; 36 \newline
\hline
\end{array}
$$&lt;/p>
&lt;p>Utilizar las siguientes sumas para los cálculos ($X$= Edad e $Y$= Distancia mínima de enfoque):&lt;/p>
&lt;p>&lt;strong>Menores de 40&lt;/strong>&lt;br>
$\sum x_i=208$ años, $\sum x_i^2=5066$ años², $\sum(x_i-\bar x)^3=993.84$ años³, $\sum(x_i-\bar x)^4=103981.55$ años⁴,&lt;br>
$\sum y_j=136$ cm, $\sum y_j^2=1860$ cm², $\sum(y_j-\bar y)^3=9.12$ cm³, $\sum(y_j-\bar y)^4=40.35$ cm⁴,&lt;br>
$\sum x_iy_j=2861$ años$\cdot$cm.&lt;br>
&lt;strong>Mayores de 40&lt;/strong>&lt;br>
$\sum x_i=589$ años, $\sum x_i^2=36639$ años², $\sum(x_i-\bar x)^3=30793.08$ años³, $\sum(x_i-\bar x)^4=1342559.42$ años⁴,&lt;br>
$\sum y_j=252$ cm, $\sum y_j^2=6604$ cm², $\sum(y_j-\bar y)^3=665.76$ cm³, $\sum(y_j-\bar y)^4=18260.51$ cm⁴,&lt;br>
$\sum x_iy_j=15523$ años$\cdot$cm.&lt;/p>
&lt;p>Se pide:&lt;/p>
&lt;ol>
&lt;li>Dibujar el diagrama de caja y bigotes de la distancia mínima de enfoque. ¿Existen datos atípicos?&lt;/li>
&lt;li>¿En qué distribución de la distancia mínima de enfoque es más representativa la media, en la de menores o en la de mayores de 40 años?&lt;/li>
&lt;li>¿Qué distribución de la distancia mínima de enfoque es más asimétrica, la de los menores o la de los mayores de 40 años?&lt;/li>
&lt;li>¿Qué distancia mínima de enfoque es relativamente menor, una distancia de 12 cm en los menores de 40 años, o una distancia de 30 cm en los mayores de 40 años?&lt;/li>
&lt;li>Dibujar el diagrama de dispersión de la edad y la distancia mínima de enfoque. Según del diagrama, ¿existe relación lineal entre la distancia mínima de enfoque y la edad?&lt;/li>
&lt;li>¿En qué grupo existe una relación lineal más fuerte entre la distancia mínima de enfoque y la edad, en los menores o en los mayores de 40 años?&lt;/li>
&lt;li>Según la recta de regresión, ¿cuánto aumenta la distancia mínima de enfoque por cada año que pasa en el grupo de los mayores de 40 años?&lt;/li>
&lt;li>A qué edad se espera tener una distancia mínima de enfoque de 32 cm en el grupo de los mayores de 40 años? ¿Es fiable esta predicción?&lt;/li>
&lt;/ol>
&lt;div class="spoiler " >
&lt;p>
&lt;a class="btn btn-primary" data-toggle="collapse" href="#spoiler-0" role="button" aria-expanded="false" aria-controls="spoiler-0">
Solución
&lt;/a>
&lt;/p>
&lt;div class="collapse card " id="spoiler-0">
&lt;div class="card-body">
&lt;ol>
&lt;li>&lt;/li>
&lt;/ol>
&lt;img src="../img/diagrama-caja-distancia-minima-enfoque-1.svg" title="Diagrama de caja de la distancia mínima de enfoque" alt="Diagrama de caja de la distancia mínima de enfoque" />
No hay datos atípicos.
&lt;ol start="2">
&lt;li>Menores de 40: $\bar y=13.6$ cm, $s^2_y=1.04$ cm², $s_y=1.0198$ cm y $cv_y=0.075$.&lt;br>
Mayores de 40: $\bar y=25.2$ cm, $s^2_y=25.36$ cm², $s_y=5.0359$ cm y $cv_y=0.1998$.&lt;br>
Así pues, la media es más representativa en los menores de 40 años ya que su coeficiente de variación es menor.&lt;/li>
&lt;li>Menores de 40: $g_1=0.86$&lt;br>
Mayores de 40: $g_1=0.52$&lt;br>
Por tanto, la distribución de los menores de 40 es más asimétrica ya que el coeficiente de asimetría está más lejos de 0.&lt;/li>
&lt;li>Menores de 40: $z(12)=-1.57$.&lt;br>
Mayores de 40: $z(30)=0.95$.&lt;br>
Así pues, una distancia de 12 cm en menores de 40 es relativamente menor.&lt;/li>
&lt;li>&lt;/li>
&lt;/ol>
&lt;p>Se observan claramente dos tendencias, una para los menores de 40 y la otra para los mayores.
En el caso de los menores no parece haber una relación fuerte entre la distancia mínima de enfoque y la edad, mientras que en el caso de los mayores si parece que la hay y además es lineal.&lt;/p>
&lt;ol start="6">
&lt;li>Menores de 40: $\bar x=20.8$ años, $s^2=73.96$, $s_{xy}=3.22$ y $r^2=0.13$.&lt;br>
Mayores de 40: $\bar x=58.9$ años, $s^2=194.69$, $s_{xy}=68.02$ y $r^2=0.94$.&lt;br>
Por tanto, la relación lineal es más fuerte en los mayores de 40 ya que el coeficiente de determinación es mayor.&lt;/li>
&lt;li>Recta de regresión de $Y$ sobre $X$ en los mayores de 40: $y=4.6218+0.3494x$.&lt;br>
Así pues, por cada año que pasa la distancia mínima de enfoque aumenta $0.3494$ cm.&lt;/li>
&lt;li>Recta de regresión de $X$ sobre $Y$ en los mayores de 40: $x=-8.6909+2.6822y$.&lt;br>
$X(32)=77.14$ años. Según el coeficiente de determinación la predicción es muy fiable, aunque el tamaño muestral no es muy grande y eso resta un poco de fiabilidad.&lt;/li>
&lt;/ol>
&lt;/div>
&lt;/div>
&lt;/div></description></item><item><title>Examen de Fisioterapia 2018-06-18</title><link>/docencia/estadistica/examenes/fisioterapia/fisioterapia-2018-06-18/</link><pubDate>Mon, 18 Jun 2018 00:00:00 +0000</pubDate><guid>/docencia/estadistica/examenes/fisioterapia/fisioterapia-2018-06-18/</guid><description>&lt;p>Grados: Fisioterapia&lt;br>
Fecha: 18 de junio de 2019&lt;/p>
&lt;h2 id="ejercicio-1">Ejercicio 1&lt;/h2>
&lt;p>En un estudio sobre la efectividad de un programa de prevención de riesgos laborales en oficios que requieren estar sentados muchas horas, se tomó una muestra aleatoria de individuos entre 40 y 50 años que pasaban más de 5 horas sentados y se observó si habían seguido las recomendaciones del programa de prevención o no y el número de lesiones vertebrales transcurridos 10 años.
Los resultados obtenidos aparecen en la siguiente tabla.&lt;/p>
&lt;p>$$
\begin{array}{lrrrrrrrrrrrrrrr}
\hline
\mbox{Con programa de prevención} &amp;amp; 1 &amp;amp; 3 &amp;amp; 2 &amp;amp; 4 &amp;amp; 4 &amp;amp; 0 &amp;amp; 2 &amp;amp; 4 &amp;amp; 2 &amp;amp; 2 &amp;amp; 5 &amp;amp; 2 &amp;amp; 3 &amp;amp; 2 &amp;amp; 0 \newline
\mbox{Sin programa de prevención} &amp;amp; 6 &amp;amp; 3 &amp;amp; 1 &amp;amp; 3 &amp;amp; 7 &amp;amp; 6 &amp;amp; 5 &amp;amp; 5 &amp;amp; 9 &amp;amp; 5 &amp;amp; 5 &amp;amp; 4 &amp;amp; 4 &amp;amp; 3 &amp;amp; \newline
\hline
\end{array}$$&lt;/p>
&lt;p>Se pide:&lt;/p>
&lt;ol>
&lt;li>Dibujar el polígono de frecuencias relativas acumuladas de la muestra global.&lt;/li>
&lt;li>Según el rango intercuartílico, ¿en qué muestra hay una mayor dispersión central del número de lesiones vertebrales, en la de los que siguieron el programa de prevención o en la de los que no?&lt;/li>
&lt;li>¿En qué muestra hay una mayor dispersión relativa del número de lesiones vertebrales, en la de los que siguieron el programa de prevención o en la de los que no?&lt;/li>
&lt;li>¿Qué muestra tienen un apuntamiento más normal del número de lesiones vertebrales, la de los que siguieron el programa de prevención o en la de los que no?&lt;/li>
&lt;li>¿Qué número de lesiones vertebrales es relativamente mayor, 2 lesiones siguiendo el programa de prevención o 4 sin seguirlo?&lt;/li>
&lt;/ol>
&lt;p>Usar las siguientes sumas para los cálculos:&lt;br>
Siguiendo el programa de prevención: $\sum x_i=36$ lesiones, $\sum x_i^2=116$ lesiones$^2$, $\sum (x_i-\bar x)^3=-0.48$ lesiones$^3$ y $\sum (x_i-\bar x)^4=135.97$ lesiones$^4$.&lt;br>
No siguiendo el programa de prevención: $\sum y_i=66$ lesiones, $\sum y_i^2=362$ lesiones$^2$, $\sum (y_i-\bar y)^3=27.92$ lesiones$^3$ y $\sum (y_i-\bar y)^4=586.9$ lesiones$^4$.&lt;/p>
&lt;div class="spoiler " >
&lt;p>
&lt;a class="btn btn-primary" data-toggle="collapse" href="#spoiler-0" role="button" aria-expanded="false" aria-controls="spoiler-0">
Solución
&lt;/a>
&lt;/p>
&lt;div class="collapse card " id="spoiler-0">
&lt;div class="card-body">
&lt;ol>
&lt;li>
&lt;img src="../img/des-fis-5-poligono-frecuencias-relativas-acumuladas-lesiones-vertebrales.svg" title="Cumulative relative frequency polygon of spinal injuries" alt="Cumulative relative frequency polygon of spinal injuries" style="display: block; margin: auto;" width="600" />
&lt;/li>
&lt;li>
&lt;p>Con programa de prevención: $C_1=2$ lesiones, $C_3=4$ lesiones, $RI=2$ lesiones.&lt;br>
Sin programa de prevención: $C_1=3$ lesiones, $C_3=6$ lesiones, $RI=3$ lesiones.&lt;br>
La muestra que no siguió el programa de prevención tiene una dispersión central mayor ya que su rango intercuartílico es mayor.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Con programa de prevención: $\bar x=2.4$ lesiones, $s^2=1.9733$ lesiones$^2$, $s=1.4048$ lesiones and $cv=0.5853$.&lt;br>
Sin programa de prevención: $\bar y=4.7143$ lesiones, $s^2=3.6327$ lesiones$^2$, $s=1.906$ lesiones and $cv=0.4043$.&lt;br>
La muestra que siguió el programa de prevención tiene una dispersión relativa con respecto a la media mayor ya que su coeficiente de variación es mayor.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Con programa de prevención: $g_2=-0.6722$.&lt;br>
Sin programa de prevención: $g_2=0.1768$.&lt;br>
Así pues, la muestra que no siguió el programa de prevención tiene un apuntamiento más normal ya que el coeficiente de apuntamiento está más próximo a 0.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Con programa de prevención: $z(2)=-0.2847$.&lt;br>
Sin programa de prevención: $z(4)=-0.3748$.&lt;br>
Así pues, 4 lesiones sin seguir el programa de prevención es relativamente menor que 2 lesiones siguiendo el programa ya que su puntuación típica es menor.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;h2 id="ejercicio-2">Ejercicio 2&lt;/h2>
&lt;p>El precio de cierto relajante muscular evolucionó entre 2015 y 2019
como indica la siguiente tabla:&lt;/p>
&lt;p>$$
\begin{array}{lrrrrr}
\hline
\mbox{Año} &amp;amp; 2015 &amp;amp; 2016 &amp;amp; 2017 &amp;amp; 2018 &amp;amp; 2019 \newline
\mbox{Precio (€)} &amp;amp; 1.40 &amp;amp; 1.60 &amp;amp; 1.92 &amp;amp; 2.30 &amp;amp; 2.91 \newline
\hline
\end{array}
$$&lt;/p>
&lt;ol>
&lt;li>¿Qué modelo de regresión es mejor para predecir el precio del función del año, el lineal o el exponencial?&lt;/li>
&lt;li>Utilizar el mejor de los dos modelos anteriores para predecir el precio del medicamento en 2020.&lt;/li>
&lt;/ol>
&lt;div class="spoiler " >
&lt;p>
&lt;a class="btn btn-primary" data-toggle="collapse" href="#spoiler-1" role="button" aria-expanded="false" aria-controls="spoiler-1">
Solución
&lt;/a>
&lt;/p>
&lt;div class="collapse card " id="spoiler-1">
&lt;div class="card-body">
&lt;ol>
&lt;li>
&lt;p>$\bar x=2017$ años, $s_x^2=2$ años$^2$.&lt;br>
$\bar y=2.026$ €, $s_y^2=0.2882$ €$^2$.&lt;br>
$\overline{\log(y)}=0.672$ log(€), $s_{\log(y)}^2=0.0673$ log(€)$^2$.&lt;br>
$s_{xy}=0.744$ años$\cdot$€, $s_{x\log(y)}=0.3653$ años$\cdot\log(€)$.&lt;br>
Coeficiente de determinación lineal: $r^2=0.9603$.&lt;br>
Coeficiente de determinación exponencial: $r^2=0.9909$.&lt;br>
Así pues, el modelo de regresión exponencial es mejor para predecir el precio ya que su coeficiente de determinación es mayor.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Modelo de regresión exponencial: $y=e^{-367.6861+0.1826x}$.&lt;br>
Predicción: $y(2020)=3.3867$ €.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;h2 id="ejercicio-3">Ejercicio 3&lt;/h2>
&lt;p>En un problema de regresión lineal entre dos variables $X$ e $Y$ se conoce $\bar x = 3$, $s_x^2=2$, $s_y^2=10.8$ y la ecuación de la recta de regresión de $Y$ sobre $X$ es $y=90.9-2.3x$.&lt;/p>
&lt;ol>
&lt;li>Calcular la media de $Y$.&lt;/li>
&lt;li>Calcular e interpretar el coeficiente de correlación lineal.&lt;/li>
&lt;/ol>
&lt;div class="spoiler " >
&lt;p>
&lt;a class="btn btn-primary" data-toggle="collapse" href="#spoiler-2" role="button" aria-expanded="false" aria-controls="spoiler-2">
Solución
&lt;/a>
&lt;/p>
&lt;div class="collapse card " id="spoiler-2">
&lt;div class="card-body">
&lt;ol>
&lt;li>$\bar y = 84$.&lt;/li>
&lt;li>$r=-0.9898$.&lt;/li>
&lt;/ol>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;h2 id="ejercicio-4">Ejercicio 4&lt;/h2>
&lt;p>En un estudio sobre la efectividad de un programa de prevención de riesgos laborales en oficios que requieren estar sentados muchas horas, se tomó una muestra aleatoria 500 de individuos entre 40 y 50 años sin lesiones vertebrales que pasaban más de 5 horas sentados.
La mitad de los individuos siguieron un programa de prevención de riesgos laborales mientras que los demás no.
Transcurridos 5 años el número de personas que desarrollaron alguna lesión vertebral en el grupo de los que siguieron el programa de prevención fue de 12, mientras que en el otro grupo fue de 32.
En los siguientes 5 años hubo otras 21 personas que desarrollaron alguna lesión vertebral en el grupo de los que siguieron el programa de prevención, mientras que en el otro grupo fue de 48.&lt;/p>
&lt;ol>
&lt;li>Calcular la incidencia acumulada de lesiones vertebrales en la muestra total a los 5 y a los 10 años.&lt;/li>
&lt;li>Calcular el riesgo absoluto de desarrollar alguna lesión vertebral a los 10 años en el grupo de los que siguieron el programa de prevención y en el de los que no.&lt;/li>
&lt;li>Calcular el riesgo relativo de desarrollar alguna lesión vertebral a los 10 años de los que siguieron el programa de prevención de riesgos con respecto a los que no e interpretarlo.&lt;/li>
&lt;li>Calcular el odds ratio de desarrollar alguna lesión vertebral a los 10 años de los que siguieron el programa de prevención de riesgos con respecto a los que no e interpretarlo.&lt;/li>
&lt;li>¿Cuál de las dos medidas anteriores, riesgo relativo u odds ratio, tiene más sentido en este estudio?
Justificar la respuesta.&lt;/li>
&lt;/ol>
&lt;div class="spoiler " >
&lt;p>
&lt;a class="btn btn-primary" data-toggle="collapse" href="#spoiler-3" role="button" aria-expanded="false" aria-controls="spoiler-3">
Solución
&lt;/a>
&lt;/p>
&lt;div class="collapse card " id="spoiler-3">
&lt;div class="card-body">
&lt;p>Sea $E$ el evento consistente en sufrir una lesión vertebral.&lt;/p>
&lt;ol>
&lt;li>
&lt;p>Incidencia acumulada después de 5 años: $R(E)=0.088$.&lt;br>
Incidencia acumulada después de 10 años: $R(E)=0.226$.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Riesgo en el grupo tratamiento: $R_T(E)=0.132$.&lt;br>
Riesgo en el grupo control: $R_C(E)=0.32$.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>$RR(D)=0.4125$. Por tanto, el riesgo de sufrir una lesión vertebral es menos de la mitad si se sigue el programa de prevención.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>$OR(D)=0.3232$. Por tanto, el odd de sufrir una lesión vertebral es menos de un tercio si se sigue el programa de prevención.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Puesto que se trata de un estudio prospectivo se puede estimar la prevalencia de $D$ y ambos estadísticos son válidos, pero el riesgo relativo es más fácil de interpretar.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;h2 id="ejercicio-5">Ejercicio 5&lt;/h2>
&lt;p>En la siguiente tabla se muestran los resultados de un estudio para evaluar la utilidad de una tira reactiva para el diagnóstico de infección urinaria:&lt;/p>
&lt;p>$$\begin{array}{ccc}
\hline
\mbox{Resultado} &amp;amp; \mbox{Con infección} &amp;amp; \mbox{Sin infección}\newline
\mbox{Positivo} &amp;amp; 60 &amp;amp; 80\newline
\mbox{Negativo} &amp;amp; 10 &amp;amp; 200\newline
\hline
\end{array}
$$&lt;/p>
&lt;ol>
&lt;li>Calcular la sensibilidad y la especificidad del test.&lt;/li>
&lt;li>Calcular los valores predictivos positivo y negativo del test.
¿El test es mejor para confirmar la enfermedad o para descartarla?&lt;/li>
&lt;li>Si a partir de un estudio de prevalencia efectuado previamente conociéramos que la verdadera prevalencia de la infección urinaria en la población es del 2%, ¿cómo se verían afectados los valores predictivos?&lt;/li>
&lt;/ol>
&lt;div class="spoiler " >
&lt;p>
&lt;a class="btn btn-primary" data-toggle="collapse" href="#spoiler-4" role="button" aria-expanded="false" aria-controls="spoiler-4">
Solución
&lt;/a>
&lt;/p>
&lt;div class="collapse card " id="spoiler-4">
&lt;div class="card-body">
&lt;p>Sea $E$ el suceso consistente en tener la infección urinaria y $+$ y $-$ los sucesos correspondientes a obtener un resultado positivo y negativo respectivamente en el test.&lt;/p>
&lt;ol>
&lt;li>Sensibilidad = $0.8571$ y Especificidad = $0.7143$.&lt;/li>
&lt;li>$VPP=0.4286$ y $VPN=0.9524$. Puesto que $VPP&amp;lt;VPN$ el test es mejor para descartar la enfermedad.&lt;/li>
&lt;li>$VPP=0.0577$ y $VPN=0.9959$. El valor predictivo positivo decrece mucho mientras el valor predictivo negativo aumenta un poco.&lt;/li>
&lt;/ol>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;h2 id="ejercicio-6">Ejercicio 6&lt;/h2>
&lt;p>El tiempo de recuperación tras un tipo de lesión sigue una distribución normal con varianza 64 días. Se sabe además que el 10% de las personas con esta lesión tardan en curarse más de 80 días.&lt;/p>
&lt;ol>
&lt;li>¿Cuál es el tiempo esperado de curación para esta lesión?&lt;/li>
&lt;li>¿Qué porcentaje de individuos tardará en curarse entre 60 y 75 días?&lt;/li>
&lt;li>Si se toma una muestra aleatoria de 12 individuos con esta lesión, ¿cuál es la probabilidad de que haya entre 9 y 11 individuos, ambos incluidos, que tarden menos de 80 días en curarse?&lt;/li>
&lt;li>Si se toma una muestra aleatoria de 500 individuos con esta lesión, ¿cuál es la probabilidad de haya menos de 4 por encima del percentil 99 del tiempo de curación?&lt;/li>
&lt;/ol>
&lt;div class="spoiler " >
&lt;p>
&lt;a class="btn btn-primary" data-toggle="collapse" href="#spoiler-5" role="button" aria-expanded="false" aria-controls="spoiler-5">
Solución
&lt;/a>
&lt;/p>
&lt;div class="collapse card " id="spoiler-5">
&lt;div class="card-body">
&lt;p>Sea $X$ el tiempo requerido para recuperarse de la lesión.
Entonces $X\sim N(\mu, 8)$.&lt;/p>
&lt;ol>
&lt;li>$\mu=69.7476$ días.&lt;/li>
&lt;li>$P(60&amp;lt;X&amp;lt;75) = 0.6327$.&lt;/li>
&lt;li>Sea $Y$ el número de individuos con la lesión que requieren más de 80 días para recuperarse en una muestra aleatoria de 12 individuos. Entonces $Y\sim B(12, 0.9)$ y $P(9\leq Y\leq 11)=0.6919$.&lt;/li>
&lt;li>Sea $Z$ be el número de individuos con la lesión que requieren un tiempo de recuperación por encima del percentil 99 en una muestra aleatoria de 500 individuos. Entonces $Z\sim B(500, 0.01)\approx P(5)$ y $P(Z\leq 4)=0.265$.&lt;/li>
&lt;/ol>
&lt;/div>
&lt;/div>
&lt;/div></description></item><item><title>Examen de Fisioterapia 2018-05-31</title><link>/docencia/estadistica/examenes/fisioterapia/fisioterapia-2018-05-31/</link><pubDate>Thu, 31 May 2018 00:00:00 +0000</pubDate><guid>/docencia/estadistica/examenes/fisioterapia/fisioterapia-2018-05-31/</guid><description>&lt;p>Grados: Fisioterapia&lt;br>
Fecha: 31 de mayo de 2018&lt;/p>
&lt;h2 id="ejercicio-1">Ejercicio 1&lt;/h2>
&lt;p>Las edades de una muestra de pacientes que acuden a una clínica de fisioterapia son las siguientes:&lt;/p>
&lt;p>25, 30, 44, 44, 51, 51, 53, 56, 57, 58, 58, 58, 59, 59, 61, 63, 63, 63, 66, 68, 70, 71, 72, 74, 82, 85&lt;/p>
&lt;p>Se pide:&lt;/p>
&lt;ol>
&lt;li>Calcular los cuartiles.&lt;/li>
&lt;li>Dibujar el diagrama de cajas e identificar los datos atípicos (no agrupar los datos en intervalos).&lt;/li>
&lt;li>Considerando los grupos de los menores y mayores de 65 años, ¿en cuál de ellos es más representativa la media?&lt;/li>
&lt;li>¿Qué distribución es menos simétrica, la de los menores o la de los mayores de 65 años?&lt;/li>
&lt;li>¿Qué edad es relativamente mayor con respecto a su grupo, 50 años en el grupo de los menores o 75 en el de los mayores?&lt;/li>
&lt;/ol>
&lt;p>Usar las siguientes sumas para los cálculos.&lt;br>
Menores de 65: $\sum x_i=953$ años, $\sum x_i^2=52475$ años$^2$, $\sum (x_i-\bar x)^3=-30846.51$ años$^3$ y $\sum (x_i-\bar x)^4=939658.83$ años$^4$.&lt;br>
Mayores de 65: $\sum x_i=588$ años, $\sum x_i^2=43530$ años$^2$, $\sum (x_i-\bar x)^3=1485$ años$^3$ y $\sum (x_i-\bar x)^4=26983.5$ años$^4$.&lt;/p>
&lt;div class="spoiler " >
&lt;p>
&lt;a class="btn btn-primary" data-toggle="collapse" href="#spoiler-0" role="button" aria-expanded="false" aria-controls="spoiler-0">
Solución
&lt;/a>
&lt;/p>
&lt;div class="collapse card " id="spoiler-0">
&lt;div class="card-body">
&lt;ol>
&lt;li>$C_1=53$ años, $C_2=59$ años and $C_3=68$ años.&lt;/li>
&lt;li>Existen dos datos atípicos: 25 y 30.&lt;br>
&lt;img src="../img/des-fis-1-diagrama-caja-edades.svg" title="Diagrama de caja de edades" alt="Diagrama de caja de edades de pacientes" width="600" />&lt;/li>
&lt;li>Sea $X$ la edad de los pacientes menores de 65 años e $Y$ la de los mayores.&lt;br>
$\bar x=52.9444$ años, $s_x^2=112.1636$ años$^2$, $s_x=10.5907$ años y $cv_x=0.2$.&lt;br>
$\bar y=73.5$ años, $s_y^2=39$ años$^2$, $s_y=6.245$ años y $cv_y=0.085$.&lt;br>
La media es más representativa en los pacientes mayores de 65 ya que el coeficiente de variación es menor.&lt;/li>
&lt;li>$g_{1x}=-1.4426$ y $g_{1y}=0.7621$, de manera que la distribución menos simétrica es la de los menores de 65 años.&lt;/li>
&lt;li>Las puntuaciones típicas son $z_x(50)=-0.278$ y $z_y(72)=-0.2402$, de manera que una edad de 50 años es relativamente menor en el grupo de los menores de 65 años.&lt;/li>
&lt;/ol>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;h2 id="ejercicio-2">Ejercicio 2&lt;/h2>
&lt;p>La siguiente tabla recoge el número de lesiones en un equipo durante una temporada y el número medio de minutos diarios de calentamiento que hacen sus jugadores.&lt;/p>
&lt;p>$$
\begin{array}{lrrrrrrrrrr}
\hline
\mbox{Tiempo calentamiento} &amp;amp; 15 &amp;amp; 35 &amp;amp; 22 &amp;amp; 28 &amp;amp; 21 &amp;amp; 18 &amp;amp; 25 &amp;amp; 30 &amp;amp; 23 &amp;amp; 20 \newline
\mbox{Lesiones} &amp;amp; 42 &amp;amp; 2 &amp;amp; 16 &amp;amp; 6 &amp;amp; 17 &amp;amp; 29 &amp;amp; 10 &amp;amp; 3 &amp;amp; 12 &amp;amp; 20 \newline
\hline
\end{array}
$$&lt;/p>
&lt;p>Se pide:&lt;/p>
&lt;ol>
&lt;li>Dibujar el diagrama de dispersión.&lt;/li>
&lt;li>¿Qué modelo de regresión es más apropiado para predecir el número de lesiones en función del tiempo de calentamiento, el logarítmico o el exponencial? Utilizar dicho modelo para predecir el número de lesiones esperado para 20 minutos de calentamiento diarios.&lt;/li>
&lt;li>¿Qué modelo de regresión es más apropiado para predecir el tiempo de calentamiento en función del número de lesiones, el logarítmico o el exponencial? Utilizar dicho modelo para predecir el mínimo tiempo de calentamiento diario necesario para no tener más de 10 lesiones en la temporada.&lt;/li>
&lt;li>¿Son fiables estas predicciones? ¿Cuál de ellas es más fiable?&lt;/li>
&lt;/ol>
&lt;p>Usar las siguientes sumas para los cálculos (X=tiempo de calentamiento e Y=número de lesiones):
$\sum x_i=237$, $\sum \log(x_i)=31.3728$, $\sum y_j=157$, $\sum \log(y_j)=24.0775$,&lt;br>
$\sum x_i^2=5937$, $\sum \log(x_i)^2=98.9906$, $\sum y_j^2=3843$, $\sum \log(y_j)^2=66.3721$,&lt;br>
$\sum x_iy_j=3115$, $\sum x_i\log(y_j)=519.1907$, $\sum \log(x_i)y_j=465.8093$, $\sum \log(x_i)\log(y_j)=73.3995$.&lt;/p>
&lt;div class="spoiler " >
&lt;p>
&lt;a class="btn btn-primary" data-toggle="collapse" href="#spoiler-1" role="button" aria-expanded="false" aria-controls="spoiler-1">
Solución
&lt;/a>
&lt;/p>
&lt;div class="collapse card " id="spoiler-1">
&lt;div class="card-body">
&lt;ol>
&lt;li>
&lt;img src="../img/des-fis-5-poligono-frecuencias-relativas-acumuladas-lesiones-vertebrales.svg" title="Diagrama de dispersión de lesiones vs tiempo de calentamiento" alt="Diagrama de dispersión de lesiones vs tiempo de calentamiento" width="600" />
&lt;/li>
&lt;li>$\bar x=23.7$ min, $s_x^2=32.01$ min$^2$.&lt;br>
$\overline{\log(x)}=3.1373$ log(min), $s_{\log(x)}^2=0.0565$ log(min)$^2$.&lt;br>
$\bar y=15.7$ lesiones, $s_y^2=137.81$ lesiones$^2$.&lt;br>
$\overline{\log(y)}=2.4078$ log(lesiones), $s_{\log(y)}^2=0.8399$ log(lesiones)$^2$.&lt;br>
$s_{x\log(y)}=-5.1446$, $s_{\log(x)y}=-2.6744$&lt;br>
Coeficiente de determinanción exponencial: $r^2=0.9844$&lt;br>
Coeficiente de determinación logarítmico: $r^2=0.9185$&lt;br>
Por tanto, el modelo de regresión exponencial es mejor para predecir el número de lesiones en función del tiempo de
calentamiento.&lt;br>
Modelo de regresión exponencial: $y=e^{6.2168+-0.1607x}$.&lt;br>
Predicción: $y(20)=20.1341$ lesiones.&lt;/li>
&lt;li>El modelo logarítmico es mejor para predecir el tiempo de calentamiento en función del número de lesiones.&lt;br>
Modelo de regresión logarítmico: $x=164.1851+-47.3292\log(y)$.&lt;br>
Predicción: $x(10)=55.2056$ min.&lt;/li>
&lt;li>De acuerdo al coeficiente de determinación ambas predicciones son muy fiables pero la última lo es menos ya que es para un valor que no está incluido en el rango de valores de la muestra.&lt;/li>
&lt;/ol>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;h2 id="ejercicio-3">Ejercicio 3&lt;/h2>
&lt;p>Se recurre a cierta técnica con ultrasonidos en el proceso de diagnosis de una enfermedad.
Su sensibilidad es del 91% y su especificidad del 98%.
Sabiendo que la prevalencia de dicha enfermedad es del 20%, se pide:&lt;/p>
&lt;ol>
&lt;li>Si a un individuo se le aplica la técnica y el resultado es positivo, ¿cuál es la probabilidad de que sufra esta enfermedad?&lt;/li>
&lt;li>Si el resultado fuese negativo, ¿cuál sería la probabilidad de que no tuviera la enfermedad?&lt;/li>
&lt;li>¿La técnica es más fiable para confirmar la enfermedad o para descartarla? Justificar la respuesta.&lt;/li>
&lt;li>Calcular la probabilidad de obtener un diagnóstico acertado con esta técnica.&lt;/li>
&lt;/ol>
&lt;div class="spoiler " >
&lt;p>
&lt;a class="btn btn-primary" data-toggle="collapse" href="#spoiler-2" role="button" aria-expanded="false" aria-controls="spoiler-2">
Solución
&lt;/a>
&lt;/p>
&lt;div class="collapse card " id="spoiler-2">
&lt;div class="card-body">
&lt;p>Sea $E​$ el suceso consistente en tener la enfermedad y $+​$ y $-​$ los sucesos correspondientes a obtener un resultado positivo y negativo respectivamente en el test.&lt;/p>
&lt;ol>
&lt;li>$VPP=0.9192$.&lt;/li>
&lt;li>$VPN=0.9776$.&lt;/li>
&lt;li>Es más fiable para descartar la enfermedad ya que el valor predictivo negativo es mayor que el valor predictivo positivo.&lt;/li>
&lt;li>$P(E\cap +)+P(\overline E\cap -) = 0.966$.&lt;/li>
&lt;/ol>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;h2 id="ejercicio-4">Ejercicio 4&lt;/h2>
&lt;p>Se sabe que la longitud del fémur de un feto a las 25 semanas de embarazo sigue una distribución normal de media 44 mm y desviación típica 2 mm.
Se pide:&lt;/p>
&lt;ol>
&lt;li>Calcular la probabilidad de que, tomando un feto de 25 semanas al azar, el fémur mida más de 46 mm.&lt;/li>
&lt;li>Calcular la probabilidad de que, tomando un feto de 25 semanas al azar, el fémur mida entre 46 y 49 mm.&lt;/li>
&lt;li>Determina un intervalo $(a,b)$ centrado en la media, que contenga el 80% de los valores de la longitud del fémur de fetos de 25 semanas.&lt;/li>
&lt;/ol>
&lt;div class="spoiler " >
&lt;p>
&lt;a class="btn btn-primary" data-toggle="collapse" href="#spoiler-3" role="button" aria-expanded="false" aria-controls="spoiler-3">
Solución
&lt;/a>
&lt;/p>
&lt;div class="collapse card " id="spoiler-3">
&lt;div class="card-body">
&lt;p>Sea $X\sim N(44,2)$ la longitud del fémur de un feto a las 25 semanas de embarazo.&lt;/p>
&lt;ol>
&lt;li>$P(X&amp;gt;46)=0.1587$.&lt;/li>
&lt;li>$P(46&amp;lt;X&amp;lt;49)=0.1524$.&lt;/li>
&lt;li>El intervalo centrado en $44$ que contiene 80% de las longitudes del fémur de fetos de 25 semanas es $(41.4369,46.5631)$.&lt;/li>
&lt;/ol>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;h2 id="ejercicio-5">Ejercicio 5&lt;/h2>
&lt;p>La probabilidad de que una lesión $A$ se reproduzca es $4/5$, la de que se reproduzca otra lesión $B$ es $1/2$, y la de que ninguna se reproduzca $1/20$.
Hallar la probabilidad de que:&lt;/p>
&lt;ol>
&lt;li>Al menos una se reproduzca.&lt;/li>
&lt;li>Sólo se reproduzca la lesión $B$.&lt;/li>
&lt;li>Se reproduzca la lesión $B$ si se ha reproducido la $A$.&lt;/li>
&lt;li>Se reproduzca la lesión $B$ si no se reproduce la lesión $A$.&lt;/li>
&lt;/ol>
&lt;div class="spoiler " >
&lt;p>
&lt;a class="btn btn-primary" data-toggle="collapse" href="#spoiler-4" role="button" aria-expanded="false" aria-controls="spoiler-4">
Solución
&lt;/a>
&lt;/p>
&lt;div class="collapse card " id="spoiler-4">
&lt;div class="card-body">
&lt;ol>
&lt;li>$P(A\cup B)=19/20$.&lt;/li>
&lt;li>$P(B\cap\overline{A})=3/20$.&lt;/li>
&lt;li>$P(B/A)=7/16$.&lt;/li>
&lt;li>$P(B/\overline{A})=3/4$.&lt;/li>
&lt;/ol>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;h2 id="ejercicio-6">Ejercicio 6&lt;/h2>
&lt;p>Una clínica de fisioterapia abre 6 horas al día y se sabe que el número medio de pacientes por día que llegan a la clínica es 12.
Se pide:&lt;/p>
&lt;ol>
&lt;li>Calcular la probabilidad de que lleguen más de 4 pacientes en 1 horas.&lt;/li>
&lt;li>Si la clínica tiene 4 fisioterapeutas y cada uno puede atender a un paciente por hora, ¿cuál es la probabilidad de que un día cualquiera haya alguna hora en la que algún paciente no pueda ser atendido? ¿Cuántos empleados debería haber para asegurarse de que esta probabilidad es menor del 10%?&lt;/li>
&lt;/ol>
&lt;div class="spoiler " >
&lt;p>
&lt;a class="btn btn-primary" data-toggle="collapse" href="#spoiler-5" role="button" aria-expanded="false" aria-controls="spoiler-5">
Solución
&lt;/a>
&lt;/p>
&lt;div class="collapse card " id="spoiler-5">
&lt;div class="card-body">
&lt;ol>
&lt;li>Sea $X$ el número de pacientes que llegan en 1 horas. $X\sim P(2)$ y $P(X&amp;gt;4)=0.0527$.&lt;/li>
&lt;li>Sea $Y$ el número de horas en un día en las que algún paciente no puede ser atendido. $Y\sim B(6, 0.0527)$ y $P(Y&amp;gt;0)=0.2771$.&lt;br>
Se necesitan 5 empleados para que esta probabilidad sea menor del 10%, ya que $P(X&amp;gt;5)=0.0527$ y $P(Y&amp;gt;0)=0.0954$, siendo ahora $Y\sim B(6, 0.0166)$.&lt;/li>
&lt;/ol>
&lt;/div>
&lt;/div>
&lt;/div></description></item><item><title>Examen de Fisioterapia 2018-04-09</title><link>/docencia/estadistica/examenes/fisioterapia/fisioterapia-2018-04-09/</link><pubDate>Mon, 09 Apr 2018 00:00:00 +0000</pubDate><guid>/docencia/estadistica/examenes/fisioterapia/fisioterapia-2018-04-09/</guid><description>&lt;p>Grados: Fisioterapia&lt;br>
Fecha: 9 de abril de 2018&lt;/p>
&lt;h2 id="ejercicio-1">Ejercicio 1&lt;/h2>
&lt;p>En un estudio se ha medido el arco de rotación de la cabeza en personas que trabajan habitualmente con ordenador y en personas que no.
Los resultados aparecen en el siguiente histograma.&lt;/p>
&lt;img src="../img/histograma_arco_rotacion-1.svg" title="plot of chunk histograma_arco_rotacion" alt="plot of chunk histograma_arco_rotacion" />
&lt;p>Se pide:&lt;/p>
&lt;ol>
&lt;li>Dibujar el polígono de frecuencias relativas acumuladas del arco de rotación de la cabeza en personas que trabajan con ordenador.&lt;/li>
&lt;li>Si se considera que una persona con un arco de rotación menor o igual de 115 grados tiene movilidad reducida, ¿qué porcentaje personas que trabajan con ordenador tienen movilidad reducida?&lt;/li>
&lt;li>¿En qué distribución es más representativa la media del arco de rotación de la cabeza, en la de las personas que trabajan con ordenador o en las que no?&lt;/li>
&lt;li>Calcular la media global del arco de rotación de la cabeza.&lt;/li>
&lt;li>¿Qué distribución es más asimétrica, la de las personas que trabajan con ordenador o la de las que no?&lt;/li>
&lt;li>¿Qué valor del arco de rotación de la cabeza es relativamente mayor, 150 grados en las personas que trabajan con ordenador o 170 grados en las que no?&lt;/li>
&lt;/ol>
&lt;p>Usar las siguientes sumas para los cálculos.
Con ordenador: $\sum x_i=3970$ grados, $\sum x_i^2=534750$ grados², $\sum (x_i-\bar x)^3=103662.2222$ grados³ y $\sum (x_i-\bar x)^4=7903715.5556$ grados⁴.&lt;br>
Sin ordenador: $\sum x_i=4230$ grados, $\sum x_i^2=645900$ grados², $\sum (x_i-\bar x)^3=-42359.6939$ grados³ y $\sum (x_i-\bar x)^4=4101700.5284$ grados⁴.&lt;/p>
&lt;div class="spoiler " >
&lt;p>
&lt;a class="btn btn-primary" data-toggle="collapse" href="#spoiler-0" role="button" aria-expanded="false" aria-controls="spoiler-0">
Solución
&lt;/a>
&lt;/p>
&lt;div class="collapse card " id="spoiler-0">
&lt;div class="card-body">
&lt;ol>
&lt;li>&lt;/li>
&lt;li>
&lt;p>$F(115)=0.1667 \rightarrow 16.67$% de los que trabajan con ordenador tienen movilidad reducida.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Con ordenador: $\bar x=132.3333$ grados, $s_x^2=312.8889$ grados², $s_x=17.6887$ grados y $cv_x=0.1337$&lt;br>
Sin ordenador: $\bar x=151.0714$ grados, $s_x^2=245.2806$ grados², $s_x=15.6614$ grados y $cv_x=0.1037$&lt;br>
La media de los que trabajan sin ordenador es más representativa que la de los que trabajan con ordenador ya que su coeficiente de variación es menor.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>$\bar x=141.3793$.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Con ordenador $g_1=0.6243$ y sin ordenador $g_1=-0.3938$. Por tanto, la distribución de los que trabajan con ordenador es más asimétrica.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Puntuaciones típicas: $z(150)=0.9988$ y $z(170)=1.2086$. Por tanto, un arco de rotación de 150 grados en los que trabajan con ordenador es relativamente menor que un arco de rotación de 170 en los que trabajan sin ordenador.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;h2 id="ejercicio-2">Ejercicio 2&lt;/h2>
&lt;p>La concentración de un fármaco en sangre $C$, medida en mg/dl, viene dada en función del tiempo $t$, en horas, según se recoge en la siguiente tabla:&lt;/p>
&lt;p>$$
\begin{array}{lrrrrrrr}
\hline
\mbox{Tiempo} &amp;amp; 2 &amp;amp; 3 &amp;amp; 4 &amp;amp; 5 &amp;amp; 6 &amp;amp; 7 &amp;amp; 8\newline
\mbox{Concentración} &amp;amp; 25 &amp;amp; 36 &amp;amp; 48 &amp;amp; 64 &amp;amp; 86 &amp;amp; 114 &amp;amp; 168\newline
\hline
\end{array}
$$&lt;/p>
&lt;p>Se pide:&lt;/p>
&lt;ol>
&lt;li>¿Qué modelo de regresión te parece más fiable para predecir la concentración que habría a las $4.8$ horas, el lineal o el exponencial?&lt;/li>
&lt;li>Realiza dicha predicción con el mejor modelo de los dos anteriores.&lt;/li>
&lt;/ol>
&lt;!-- 3. Según el modelo logarítmico, ¿cuántas horas deben transcurrir para que la concentración sea de 100 mg/dl? -->
&lt;p>Usar las siguientes sumas para los cálculos:&lt;br>
$\sum x_i=35$, $\sum \log(x_i)=10.6046$, $\sum y_j=541$, $\sum \log(y_j)=29.147$,&lt;br>
$\sum x_i^2=203$, $\sum \log(x_i)^2=17.5205$, $\sum y_j^2=56937$, $\sum \log(y_j)^2=124.0131$,&lt;br>
$\sum x_iy_j=3328$, $\sum x_i\log(y_j)=154.3387$, $\sum \log(x_i)y_j=951.6961$, $\sum \log(x_i)\log(y_j)=46.0805$.&lt;/p>
&lt;div class="spoiler " >
&lt;p>
&lt;a class="btn btn-primary" data-toggle="collapse" href="#spoiler-1" role="button" aria-expanded="false" aria-controls="spoiler-1">
Solución
&lt;/a>
&lt;/p>
&lt;div class="collapse card " id="spoiler-1">
&lt;div class="card-body">
&lt;ol>
&lt;li>Modelo lineal de Concentración sobre Tiempo:&lt;br>
$\bar x=5$ horas, $s_x^2=4$ horas² .&lt;br>
$\bar y=77.2857$ mg/dl, $s_y^2=2160.7755$ (mg/dl)².&lt;br>
$s_{xy}=89$ horas⋅mg/dl.&lt;br>
Coeficiente de determinación lineal de Concentración sobre Tiempo $r^2=0.9165$.&lt;br>
Modelo exponencial de Concentración sobre tiempo:&lt;br>
$\overline{\log(y)}=4.1639$ log(mg/dl), $s_{\log(y)}^2=0.3785$ log(mg/dl)².&lt;br>
$s_{x\log(y)}=1.2291$ horas⋅log(mg/dl).&lt;br>
Coeficiente de determinación exponencial de Concentración sobre Tiempo $r^2=0.9979$.&lt;br>
Por tanto, el modelo exponencial explica mejor la relación entre la concentración y el tiempo ya que su coeficiente de determinación es mayor.&lt;/li>
&lt;li>Modelo exponencial de Concentración sobre Tiempo: $y=e^{2.6275 + 0.3073x}$.&lt;br>
$y(4.8)=60.4853$ mg/dl.&lt;/li>
&lt;/ol>
&lt;/div>
&lt;/div>
&lt;/div></description></item><item><title>Examen de Farmacia 2018-01-19</title><link>/docencia/estadistica/examenes/farmacia/farmacia-2018-01-19/</link><pubDate>Fri, 19 Jan 2018 00:00:00 +0000</pubDate><guid>/docencia/estadistica/examenes/farmacia/farmacia-2018-01-19/</guid><description>&lt;p>Grados: Farmacia y Biotecnología&lt;br>
Fecha: 19 de Enero de 2018&lt;/p>
&lt;h2 id="ejercicio-1">Ejercicio 1&lt;/h2>
&lt;p>Se realizó un estudio en pacientes mayores de 60 años de la relación entre la edad de los pacientes $X$ y el número de veces que han acudido a consulta médica en el último año $Y$, obteniéndose los siguientes resultados:&lt;/p>
&lt;p>$$
\begin{array}{lrrrrrrrr}
\hline
\mbox{Edad} &amp;amp; 62 &amp;amp; 65 &amp;amp; 71 &amp;amp; 79 &amp;amp; 83 &amp;amp; 88 &amp;amp; 90 &amp;amp; 95 \newline
\mbox{Consultas} &amp;amp; 2 &amp;amp; 3 &amp;amp; 4 &amp;amp; 6 &amp;amp; 6 &amp;amp; 8 &amp;amp; 10 &amp;amp; 14 \newline
\hline
\end{array}
$$&lt;/p>
&lt;p>Se pide:&lt;/p>
&lt;ol>
&lt;li>Calcular el número de veces que acudirá a consulta médica un paciente de 70 años según el modelo de regresión lineal.&lt;/li>
&lt;li>Lo mismo pero empleando el modelo de regresión exponencial.&lt;/li>
&lt;li>Razonar cuál de las dos predicciones es más fiable.&lt;/li>
&lt;li>Teniendo en cuenta que la ecuación del modelo potencial es $Y=aX^b$, explicar qué transformaciones hay que aplicar a las variables $X$ e $Y$ para convertirlo en un modelo lineal.&lt;/li>
&lt;/ol>
&lt;p>Usar las siguientes sumas para los cálculos:
$\sum x_i=633$, $\sum \log(x_i)=34.8835$, $\sum y_j=53$, $\sum \log(y_j)=13.7827$,
$\sum x_i^2=51109$, $\sum \log(x_i)^2=152.28$, $\sum y_j^2=461$, $\sum \log(y_j)^2=26.6206$,
$\sum x_iy_j=4509$, $\sum x_i\log(y_j)=1144.0108$, $\sum \log(x_i)y_j=235.1289$, $\sum \log(x_i)\log(y_j)=60.7921$.&lt;/p>
&lt;div class="spoiler " >
&lt;p>
&lt;a class="btn btn-primary" data-toggle="collapse" href="#spoiler-0" role="button" aria-expanded="false" aria-controls="spoiler-0">
Solución
&lt;/a>
&lt;/p>
&lt;div class="collapse card " id="spoiler-0">
&lt;div class="card-body">
&lt;ol>
&lt;li>Modelo lineal de Consultas sobre Edad:&lt;br>
$\bar x=79.125$ años, $s_x^2=127.8594$ años² .&lt;br>
$\bar y=6.625$ consultas, $s_y^2=13.7344$ consultas².&lt;br>
$s_{xy}=39.4219$ años⋅consultas.&lt;br>
Recta de regresión de Consultas sobre Edad: $y=-17.771 + 0.3083x$.&lt;br>
$y(70) =3.8116$ consultas.&lt;/li>
&lt;li>$\overline{\log(y)}=1.7228$ log(consultas), $s_{\log(y)}^2=0.3594$ log(consultas)².&lt;br>
$s_{x\log(y)}=6.6823$ años⋅log(consultas).&lt;br>
Modelo exponencial de consultas sobre Edad: $y=e^{-2.4124 + 0.0523x}$.&lt;br>
$y(70)=3.4762$ consultas.&lt;/li>
&lt;li>Coeficiente de determinación lineal de Consultas sobre Edad $r^2=0.885$.&lt;br>
Coeficiente de determinación exponencial de Consultas sobre Edad $r^2=0.9716$.&lt;br>
Por tanto, el modelo exponencial explica un poco mejor el número de consultas médicas con respecto a la edad.&lt;/li>
&lt;li>Hay que aplicar la transformación logarítmica tanto a las Consultas como a la Edad: $\log(Y)=\log(aX^b)\Rightarrow \log(Y)=\log(a)+\log(X^b)=\log(a)+b\log(X)=a&amp;rsquo;+b\log(X)$.&lt;/li>
&lt;/ol>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;h2 id="ejercicio-2">Ejercicio 2&lt;/h2>
&lt;p>Se ha medido la concentración de polen en granos/m$^3$ de una determinada planta en el centro de una ciudad a lo largo de un año y se han obtenido los siguientes resultados:&lt;/p>
&lt;p>$$
\begin{array}{cr}
\hline
\mbox{Nivel de polen} &amp;amp; \mbox{Nº de días} \newline
0-300 &amp;amp; 51 \newline
300-500 &amp;amp; 60 \newline
500-600 &amp;amp; 79 \newline
600-800 &amp;amp; 91 \newline
800-1000 &amp;amp; 60 \newline
1000-1300 &amp;amp; 24 \newline
\hline
\end{array}
$$&lt;/p>
&lt;ol>
&lt;li>Si el 75% de los días se considera que los niveles de polen no han sido excesivos.
¿A partir de que nivel de polen se ha considerado un nivel excesivo?&lt;/li>
&lt;li>Se ha establecido una alerta naranja cuando el nivel de polen se sitúa entre 575 y 850.
¿En cuántos días del año se produjo dicha alerta naranja?&lt;/li>
&lt;li>¿Hay datos atípicos en la muestra?&lt;/li>
&lt;li>Sabemos que hay otra planta que tiene un ciclo de polinización muy parecido al de la muestra, con unos niveles de polen que se pueden calcular de la forma $Y=0.5X-100$. ($Y$= niveles de la otra planta y $X$=niveles de la planta de la muestra)
¿Cuál sería la media de nivel de polen para esta otra planta?
¿Es un valor más o menos representativo que la de los niveles de la planta de la muestra recogida?&lt;/li>
&lt;li>¿Se podría considerar que el nivel de polen en general sigue una distribución normal?&lt;/li>
&lt;/ol>
&lt;p>Usar las siguientes sumas para los cálculos: $\sum x_i=220400$ granos/m$^3$, $\sum x_i^2=159575000$ (granos/m$^3$)$^2$, $\sum (x_i-\bar x)^3=261917220.867$ (granos/m$^3$)$^3$ y $\sum (x_i-\bar x)^4=4872705679772.61$ (granos/m$^3$)$^4$.&lt;/p>
&lt;div class="spoiler " >
&lt;p>
&lt;a class="btn btn-primary" data-toggle="collapse" href="#spoiler-1" role="button" aria-expanded="false" aria-controls="spoiler-1">
Solución
&lt;/a>
&lt;/p>
&lt;div class="collapse card " id="spoiler-1">
&lt;div class="card-body">
&lt;ol>
&lt;li>$P_{75}=784.0417$ granos/m³.&lt;/li>
&lt;li>$F(575)=0.4664$ y $F(860)=0.8192$, por lo que la frecuencia del número de días con alerta es $0.3528$ que corresponde a $128.77$ días.&lt;/li>
&lt;li>$Q_1=434.1849$ granos/m³, $Q_3=784.0417$ granos/m³ y $RI=349.8568$ granos/m³. Vallas: $v_1=-90.6001$ granos/m³ y $v_2=1308.8269$ granos/m³.&lt;br>
Como todos los valores caen dentro de las vallas no hay datos atípicos.&lt;/li>
&lt;li>$\bar x=603.8356$ granos/m³, $s_x^2=72574.3291$ (granos/m³)², $s_x=269.3962$ granos/m³ y $cv_x=0.4461$&lt;br>
$\bar y=201.9178$ granos/m³, $s_y=134.6981$ granos/m³ y $cv_y=0.6671$.&lt;br>
La media de $X$ es más representativa que la media de $Y$ ya que $cv_x&amp;lt;cv_y$.&lt;/li>
&lt;li>$g_1=0.0367$ y $g_2=-0.4654$. Como ambos están entre -2 y 2, se puede asumir que el nivel de polen se distribuye normalmente.&lt;/li>
&lt;/ol>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;h2 id="ejercicio-3">Ejercicio 3&lt;/h2>
&lt;p>Los niveles de polen de gramíneas registrados en Madrid durante el año 2017 se distribuyeron de forma normal y tuvieron una media de 90.
Si en 42 días del año 2017 se superó los 120 granos de polen/m$^3$ de aire, se pide:&lt;/p>
&lt;ol>
&lt;li>Calcular la desviación típica del nivel de polen de gramíneas en 2017.&lt;br>
Nota: Si no se sabe calcular tomar una desviación típica de 20 granos/m$^3$ para los demás apartados.&lt;/li>
&lt;li>¿Durante cuantos días no se llegaron a 50 granos de polen/m$^3$ de aire?&lt;/li>
&lt;li>Si el 20% de los días hubo un nivel excesivamente alto de polen y hubo que avisar a la población, ¿a partir de qué nivel de polen se produjeron estos avisos?&lt;/li>
&lt;/ol>
&lt;div class="spoiler " >
&lt;p>
&lt;a class="btn btn-primary" data-toggle="collapse" href="#spoiler-2" role="button" aria-expanded="false" aria-controls="spoiler-2">
Solución
&lt;/a>
&lt;/p>
&lt;div class="collapse card " id="spoiler-2">
&lt;div class="card-body">
&lt;p>Sea $X$ el nivel de polen en Madrid en 2017. $X\sim N(90,\sigma)$.&lt;/p>
&lt;ol>
&lt;li>$\sigma=25$ granos/m³.&lt;/li>
&lt;li>$P(X\leq 50)=0.0548$ que corresponde a $20.0017$ días.&lt;/li>
&lt;li>$P_{80}=111.0405$ granos/m³.&lt;/li>
&lt;/ol>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;h2 id="ejercicio-4">Ejercicio 4&lt;/h2>
&lt;p>Se han ensayado dos tipos de medicamentos para reducir los niveles de colesterol y se ha observado que el medicamento $A$ es efectivo en el 75% de los casos y el medicamento B es efectivo en el $85%$ de los casos.
Sin embargo, hay un 5% de casos en los que ninguno de los medicamentos es efectivo.&lt;/p>
&lt;ol>
&lt;li>¿En qué porcentaje de casos sería efectivo exclusivamente el medicamento $A$?&lt;/li>
&lt;li>Si en un paciente se ha comprobado que el medicamento $A$ es efectivo, ¿qué probabilidad hay de que también lo sea el medicamento $B$?&lt;/li>
&lt;li>Si en un paciente se ha comprobado que el medicamento $B$ no es efectivo, ¿qué probabilidad hay de que el medicamento $A$ si lo sea?&lt;/li>
&lt;li>¿Es independiente la efectividad de estos medicamentos?&lt;/li>
&lt;/ol>
&lt;div class="spoiler " >
&lt;p>
&lt;a class="btn btn-primary" data-toggle="collapse" href="#spoiler-3" role="button" aria-expanded="false" aria-controls="spoiler-3">
Solución
&lt;/a>
&lt;/p>
&lt;div class="collapse card " id="spoiler-3">
&lt;div class="card-body">
&lt;ol>
&lt;li>$P(A\cap \overline B)=0.1$, es decir, un $10%$.&lt;/li>
&lt;li>$P(B|A)=0.8667$.&lt;/li>
&lt;li>$P(A|\overline B)=0.6667$.&lt;/li>
&lt;li>$P(B|A)\neq P(B)$, de manera que los sucesos son dependientes.&lt;/li>
&lt;/ol>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;h2 id="ejercicio-5">Ejercicio 5&lt;/h2>
&lt;p>El número medio de nacimientos que se producen en una semana en un hospital es 14.
Se pide:&lt;/p>
&lt;ol>
&lt;li>Calcular la probabilidad de que un día se produzcan más de 2 nacimientos.&lt;/li>
&lt;li>Calcular la probabilidad de que una semana haya más de un día en que no se produzcan nacimientos.&lt;/li>
&lt;/ol>
&lt;div class="spoiler " >
&lt;p>
&lt;a class="btn btn-primary" data-toggle="collapse" href="#spoiler-4" role="button" aria-expanded="false" aria-controls="spoiler-4">
Solución
&lt;/a>
&lt;/p>
&lt;div class="collapse card " id="spoiler-4">
&lt;div class="card-body">
&lt;ol>
&lt;li>Sea $X$ el número de nacimientos en un día. $X\sim P(2)$ y $P(X&amp;gt;2)=0.3233.$&lt;/li>
&lt;li>Sea $Y$ el número de días sin nacimientos en una semana. $Y\sim B(7,0.1353)$ y $P(Y&amp;gt;1)=0.2427$.&lt;/li>
&lt;/ol>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;h2 id="ejercicio-6">Ejercicio 6&lt;/h2>
&lt;p>Se está trabajando en el diseño de un test para detectar una enfermedad y para ensayarlo se dispone de una muestra de 250 individuos de los cuales 50 presentan la enfermedad y 200 son individuos sanos.
Si se pretende que el test tenga un valor predictivo positivo de $0.7$ y un valor predictivo negativo de $0.9$, al realizar los ensayos sobre la muestra:&lt;/p>
&lt;ol>
&lt;li>¿Cuántos de los individuos sanos deberían dar positivo en el test?&lt;/li>
&lt;li>¿Cuántos de los individuos enfermos deberían dar negativo en el test?&lt;/li>
&lt;li>¿Qué probabilidad hay de que un individuo que ha dado dos veces positivo en el test sufra la enfermedad?&lt;/li>
&lt;/ol>
&lt;div class="spoiler " >
&lt;p>
&lt;a class="btn btn-primary" data-toggle="collapse" href="#spoiler-5" role="button" aria-expanded="false" aria-controls="spoiler-5">
Solución
&lt;/a>
&lt;/p>
&lt;div class="collapse card " id="spoiler-5">
&lt;div class="card-body">
&lt;p>Sea $E$ el suceso correspondiente a tener la enfermedad.&lt;/p>
&lt;ol>
&lt;li>$P(+|\overline{E})=0.0625\Rightarrow 12.5$ personas.&lt;/li>
&lt;li>$P(-|E)=0.4165\Rightarrow 20.825$ personas.&lt;/li>
&lt;li>$P(E|+\cap +)=0.9561$.&lt;/li>
&lt;/ol>
&lt;/div>
&lt;/div>
&lt;/div></description></item><item><title>Examen de Óptica 2017-12-18</title><link>/docencia/estadistica/examenes/optica/optica-2017-12-18/</link><pubDate>Mon, 18 Dec 2017 00:00:00 +0000</pubDate><guid>/docencia/estadistica/examenes/optica/optica-2017-12-18/</guid><description>&lt;p>Titulación: Grado en Óptica&lt;br>
Fecha: 18 de Diciembre de 2017&lt;/p>
&lt;h2 id="ejercicio-1">Ejercicio 1&lt;/h2>
&lt;p>En un examen de estadística al que se han presentado 66 alumnos se ha contado el número de exámenes finalizados cada media hora, obteniendo el siguiente polígono:&lt;/p>
&lt;img src="../img/poligono_acumulado_tiempo_examen.svg" alt="polígono de frecuencias acumuladas del tiempo de finalización de un examen" style="display: block; margin: auto;" />
&lt;p>Se pide:&lt;/p>
&lt;ol>
&lt;li>Construir la tabla de frecuencias del tiempo de finalización del examen.&lt;/li>
&lt;li>¿Cuánto tiempo tiene que pasar para que hayan finalizado el examen la mitad de los alumnos?&lt;/li>
&lt;li>¿Qué porcentaje de alumnos habrá terminado a los 100 minutos de examen?&lt;/li>
&lt;li>¿Cuál es el tiempo de duración del examen que mejor representa a los estudiantes de la muestra?
¿Es un valor representativo?&lt;/li>
&lt;li>Según su simetría y apuntamiento, ¿se puede afirmar que la distribución del tiempo de duración del examen es normal?&lt;/li>
&lt;li>Se sabe que en otro examen diferente el tiempo medio de finalización es de 100 minutos y la desviación típica es 20 minutos.
Un alumno tardó 110 minutos en el examen de Estadística y 122 minutos en este otro examen.
¿Qué examen finalizó antes en términos relativos?&lt;/li>
&lt;/ol>
&lt;p>Utilizar las siguientes sumas para los cálculos: $\sum x_i=5670$ min, $\sum x_i^2=580050$ min², $\sum (x_i-\bar x)^3=-2155537.1901$ min³ y $\sum (x_i-\bar x)^4=311877385.4245$ min⁴.&lt;/p>
&lt;div class="spoiler " >
&lt;p>
&lt;a class="btn btn-primary" data-toggle="collapse" href="#spoiler-0" role="button" aria-expanded="false" aria-controls="spoiler-0">
Solución
&lt;/a>
&lt;/p>
&lt;div class="collapse card " id="spoiler-0">
&lt;div class="card-body">
&lt;ol>
&lt;li>$$
\begin{array}{crrrrr}
\hline
X &amp;amp; x_i &amp;amp; n_i &amp;amp; f_i &amp;amp; N_i &amp;amp; Fi \newline
0-30 &amp;amp; 15 &amp;amp; 9 &amp;amp; 0.1364 &amp;amp; 9 &amp;amp; 0.1364 \newline
30-60 &amp;amp; 45 &amp;amp; 6 &amp;amp; 0.0909 &amp;amp; 15 &amp;amp; 0.2273 \newline
60-90 &amp;amp; 75 &amp;amp; 14 &amp;amp; 0.2121 &amp;amp; 29 &amp;amp; 0.4394 \newline
90-120 &amp;amp; 105 &amp;amp; 26 &amp;amp; 0.3939 &amp;amp; 55 &amp;amp; 0.8333 \newline
120-150 &amp;amp; 135 &amp;amp; 11 &amp;amp; 0.1667 &amp;amp; 66 &amp;amp; 1 \newline
\hline
\end{array}
$$&lt;/li>
&lt;li>$Me=94.6154$ min.&lt;/li>
&lt;li>$F(100)=0.5708\Rightarrow 57.08%$ de los estudiantes.&lt;/li>
&lt;li>$\bar x=85.9091$ min, $s^2=1408.2645$ min², $s=37.5268$ min y $cv=0.4368$, luego la dispersión relativa con respecto a la media es moderada y la representatividad de la media también.&lt;/li>
&lt;li>$g_1=-0.618$, de manera que la distribución es asimétrica hacia la izquierda. $g_2=-0.6173$, de manera que la distribución es menos apuntada de lo normal (leptocúrtica). Como tanto $g_1$ como $g_2$ están entre -2 y 2 podemos asumir que la muestra proviene de una población normal.&lt;/li>
&lt;li>Examen de Estadística: $z(110)=0.642$.&lt;br>
Otro examen: $z(122)=1.1$.&lt;br>
Así pues, terminó antes el examen de Estadística.&lt;/li>
&lt;/ol>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;h2 id="ejercicio-2">Ejercicio 2&lt;/h2>
&lt;p>En un estudio sobre la presbicia se tomó una muestra de pacientes y se midió la edad y la distancia mínima a la que eran capaces de leer una frase en cm.
Los resultados se muestran en la siguiente tabla:&lt;/p>
&lt;p>$$
\begin{array}{lrrrrrrrrrrrr}
\hline
\mbox{Edad} &amp;amp; 25 &amp;amp; 46 &amp;amp; 76 &amp;amp; 32 &amp;amp; 18 &amp;amp; 43 &amp;amp; 40 &amp;amp; 51 &amp;amp; 68 &amp;amp; 54 &amp;amp; 47 &amp;amp; 37\newline
\mbox{Distancia mínima de enfoque} &amp;amp; 15 &amp;amp; 28 &amp;amp; 51 &amp;amp; 23 &amp;amp; 14 &amp;amp; 28 &amp;amp; 25 &amp;amp; 36 &amp;amp; 47 &amp;amp; 42 &amp;amp; 31 &amp;amp; 29\newline
\hline
\end{array}
$$&lt;/p>
&lt;p>Se pide:&lt;/p>
&lt;ol>
&lt;li>Calcular la recta de regresión de la distancia mínima de enfoque con respecto a la edad.
¿Cuánto aumenta la distancia mínima de enfoque por cada año que pasa?&lt;/li>
&lt;li>Calcular el modelo de regresión logarítmico de la distancia mínima de enfoque con respecto a la edad.&lt;/li>
&lt;li>Utilizar el mejor modelo de regresión de los dos anteriores para predecir la distancia mínima de enfoque a los 65 años. ¿Es fiable esta predicción?&lt;/li>
&lt;li>Si la presbicia se diagnostica cuando la distancia mínima de enfoque es de 35 cm, ¿a qué edad aparecerá la presbicia?&lt;/li>
&lt;/ol>
&lt;p>Utilizar las siguientes sumas para los cálculos ($X=$Edad e $Y=$Distancia):&lt;br>
$\sum x_i=537$, $\sum \log(x_i)=44.7858$, $\sum y_j=369$, $\sum \log(y_j)=40.2703$,
$\sum x_i^2=27033$, $\sum \log(x_i)^2=168.9328$, $\sum y_j^2=12815$, $\sum \log(y_j)^2=136.9234$,
$\sum x_iy_j=18561$, $\sum x_i\log(y_j)=1872.0711$, $\sum \log(x_i)y_j=1425.5363$, $\sum \log(x_i)\log(y_j)=152.0296$.&lt;/p>
&lt;div class="spoiler " >
&lt;p>
&lt;a class="btn btn-primary" data-toggle="collapse" href="#spoiler-1" role="button" aria-expanded="false" aria-controls="spoiler-1">
Solución
&lt;/a>
&lt;/p>
&lt;div class="collapse card " id="spoiler-1">
&lt;div class="card-body">
&lt;ol>
&lt;li>
&lt;p>Modelo de regresión de la distancia mínima de enfoque sobre la edad:&lt;br>
$\bar x=44.75$ años, $s_x^2=250.1875$ años².&lt;br>
$\bar y=30.75$ cm, $s_y^2=122.3542$ cm².&lt;br>
$s_{xy}=170.6875$ años⋅cm.&lt;br>
Recta de regresión de la distancia mínima de enfoque sobre la edad: $y=0.2198 + 0.6822x$.&lt;br>
Por cada año que pasa la distancia mínima de enfoque aumenta 0.6822 cm.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>$\overline{\log(x)}=3.7322$ log(años), $s_{\log(x)}^2=0.1488$ log(años)².&lt;br>
$s_{\log(x)y}=4.031$ log(años)⋅cm.&lt;br>
Modelo de regresión logarítmico de la distancia mínima de enfoque sobre la edad: $y=-70.3708 + 27.0945\log(x)$.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Coeficiente de determinación lineal: $r^2=0.9517$.&lt;br>
Coeficiente de determinación logarítmico: $r^2=0.8926$.&lt;br>
Por tanto, el modelo lineal explica mejor la relación entre la distancia mínima de enfoque y la edad, ya que su coeficiente de determinación es mayor.&lt;br>
$y(65)=44.5653$ cm.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Recta de regresión de la edad sobre la distancia mínima de enfoque: $x=1.8529 + 1.395y$.&lt;br>
$x(35)=50.6789$ años.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;/div>
&lt;/div></description></item><item><title>Examen de Farmacia 2017-11-27</title><link>/docencia/estadistica/examenes/farmacia/farmacia-2017-11-27/</link><pubDate>Mon, 27 Nov 2017 00:00:00 +0000</pubDate><guid>/docencia/estadistica/examenes/farmacia/farmacia-2017-11-27/</guid><description>&lt;p>Titulación: Grado en Farmacia y Biotecnología&lt;br>
Fecha: 27 de Noviembre de 2017&lt;/p>
&lt;h2 id="ejercicio-1">Ejercicio 1&lt;/h2>
&lt;p>El siguiente diagrama muestra la distribución de emisiones de NO₂ (𝜇g/m³) en Madrid en los días de octubre de 2017.&lt;/p>
&lt;img src="../img/histograma-emisiones-no2-1.svg" title="plot of chunk histograma-emisiones-no2" alt="plot of chunk histograma-emisiones-no2" />
&lt;ol>
&lt;li>La normativa europea sobre calidad del aire establece que el valor medio mensual no debe exceder de 40 𝜇g/m³. ¿Se ha cumplido la norma en el mes de Octubre?
¿Es este un valor representativo de las mediciones tomadas en octubre?&lt;/li>
&lt;li>El Ayuntamiento de Madrid ha decidido que se establecerán restricciones de velocidad en los accesos los días en los que se superen los 72 𝜇g/m³ y que además de estas restricciones se establecerán también restricciones al aparcamiento los días que se superen los 92 𝜇g/m³.
¿Qué porcentaje de días de octubre se establecieron solo restricciones de velocidad en los accesos?&lt;/li>
&lt;li>De acuerdo con esta muestra de datos tomada durante el mes de octubre, ¿puede establecerse por la forma de la distribución de la muestra que la distribución de las emisiones en toda la ciudad sigue una distribución normal?&lt;/li>
&lt;li>Además del nivel de NO₂, el Ayuntamiento también controla los niveles de SO₂, y se sabe que el nivel medio de esta sustancia durante el mes de octubre fue de 2.85 𝜇g/m³ con una desviación típica de 0.42 𝜇g/m³.
Si un día hubo un nivel de NO₂ de 46 y un nivel de SO₂ de 2.24, ¿cuál de las dos sustancias tenía niveles más altos en referencia a sus mediciones?&lt;/li>
&lt;li>Si el índice de calidad del aire (ICA) puede estimarse multiplicando el nivel de NO₂ por 0.95 y sumándole una cantidad fija de 30.
¿Cuál fue el índice medio de la calidad del aire en Madrid el mes de octubre?
¿Es un valor más o menos representativo que el nivel de emisiones medio de NO₂?&lt;/li>
&lt;li>¿Existen días atípicos en las emisiones de NO₂ del mes de octubre? Justificar la respuesta.&lt;/li>
&lt;/ol>
&lt;p>Utilizar las siguientes sumas para los cálculos: $\sum x_i=1945$ 𝜇g/m³, $\sum x_i^2=131575$ (𝜇g/m³)², $\sum (x_i-\bar x)^3=93995.838$ (𝜇g/m³)³ y $\sum (x_i-\bar x)^4=7766271.021$ (𝜇g/m³)⁴.&lt;/p>
&lt;div class="spoiler " >
&lt;p>
&lt;a class="btn btn-primary" data-toggle="collapse" href="#spoiler-0" role="button" aria-expanded="false" aria-controls="spoiler-0">
Solución
&lt;/a>
&lt;/p>
&lt;div class="collapse card " id="spoiler-0">
&lt;div class="card-body">
&lt;ol>
&lt;li>$\bar x=62.7419$ 𝜇g/m³, de manera que no se cumple el requisito.&lt;br>
$s^2=307.8044$ (𝜇g/m³)², $s=17.5444$ 𝜇g/m³, $cv=0.2796$.&lt;br>
Como el coeficiente de variación es menor que 0.3 hay poca variabilidad en los datos y la media es bastante representativa.&lt;/li>
&lt;li>$F(72)=0.7097$ y $F(92)=0.9161$, de manera que el porcentaje de días únicamente con restricciones de velocidad es $20.64%$.&lt;/li>
&lt;li>$g_1=0.5615$ y $g_2=-0.3558$. Como ambos están entre -2 y 2, se puede asumir que la distribución de emisiones es normal.&lt;/li>
&lt;li>NO₂: $z(46)=-0.9543$.&lt;br>
SO₂: $z(2.24)=-1.4524$.&lt;br>
Así pues, las emisiones de NO₂ son relativamente mayores.&lt;/li>
&lt;li>Sea $y=0.95x+30$ el ICA.&lt;br>
$\bar y=89.6048$, $s_y=16.6671$, $cv=0.186$. Como el coeficiente de variación es menor, la media del ICA es más representativa.&lt;/li>
&lt;li>$Q_1=49.5816$ 𝜇g/m³, $Q_3=74.0093$ 𝜇g/m³ y $IQR=24.4277$ 𝜇g/m³. Vallas: $v_1=12.94$ 𝜇g/m³ y $v_2=110.65$ 𝜇g/m³. Por tanto, no hay datos atípicos.&lt;/li>
&lt;/ol>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;h2 id="ejercicio-2">Ejercicio 2&lt;/h2>
&lt;p>La siguiente tabla muestra las tasas de incidencia de gripe por cada 100.000 habitantes registradas al cabo de un número de días desde el comienzo de el estudio.&lt;/p>
&lt;p>$$
\begin{array}{lrrrrrrrr}
\hline
\mbox{Días} &amp;amp; 1 &amp;amp; 5 &amp;amp; 8 &amp;amp; 12 &amp;amp; 20 &amp;amp; 26 &amp;amp; 38 &amp;amp; 44 \newline
\mbox{Tasa de gripe} &amp;amp; 60 &amp;amp; 66 &amp;amp; 71 &amp;amp; 80 &amp;amp; 106 &amp;amp; 132 &amp;amp; 194 &amp;amp; 235 \newline
\hline
\end{array}
$$&lt;/p>
&lt;p>Se pide:&lt;/p>
&lt;ol>
&lt;li>Calcular la tasa de incidencia de gripe a los 50 días desde el comienzo del estudio mediante un modelo de regresión lineal.&lt;/li>
&lt;li>¿Cuánto varía la tasa de incidencia de gripe cada día según el modelo lineal?&lt;/li>
&lt;li>Calcular la tasa de incidencia de gripe a los 50 días desde el comienzo del estudio mediante un modelo de regresión exponencial.&lt;/li>
&lt;li>¿Cuál de las predicciones anteriores es más fiable?
Razonar la respuesta.&lt;/li>
&lt;/ol>
&lt;p>Utilizar las siguientes sumas para los cálculos ($X=$Días e $Y=$Tasa de gripe): $\sum x_i=154$, $\sum \log(x_i)=19.8494$, $\sum y_j=944$, $\sum \log(y_j)=37.2024$, $\sum x_i^2=4690$, $\sum \log(x_i)^2=60.2309$, $\sum y_j^2=140918$, $\sum \log(y_j)^2=174.8363$, $\sum x_iy_j=25182$, $\sum \log(x_i)y_j=2795.2484$, $\sum x_i\log(y_j)=772.3504$, $\sum \log(x_i)\log(y_j)=96.1974$.&lt;/p>
&lt;div class="spoiler " >
&lt;p>
&lt;a class="btn btn-primary" data-toggle="collapse" href="#spoiler-1" role="button" aria-expanded="false" aria-controls="spoiler-1">
Solución
&lt;/a>
&lt;/p>
&lt;div class="collapse card " id="spoiler-1">
&lt;div class="card-body">
&lt;ol>
&lt;li>Modelo lineal de la tasa de gripe sobre los días:&lt;br>
$\bar x=19.25$ días, $s_x^2=215.6875$ días².&lt;br>
$\bar y=118$ personas, $s_y^2=3690.75$ personas².&lt;br>
$s_{xy}=876.25$ días⋅personas.&lt;br>
Recta de regresión de la tasa de gripe sobre los días: $y=39.7951 + 4.0626x$.&lt;br>
$y(50) =242.9247$.&lt;/li>
&lt;li>$4.0626$ personas por día.&lt;/li>
&lt;li>$\overline{\log(y)}=4.6503$ log(personas), $s_{\log(y)}^2=0.2293$ log(personas)².&lt;br>
$s_{x\log(y)}=7.0255$ días⋅log(personas).&lt;br>
Modelo exponencial de la tasa de gripe sobre los días: $y=e^{4.0233 + 0.0326x}$.&lt;br>
$y(50)=284.8357$.&lt;/li>
&lt;li>Coeficiente de determinación lineal de la tasa de gripe sobre los días $r^2=0.9645$. Coeficiente de determinación exponencial de la tasa de gripe sobre los días $r^2=0.9982$.&lt;br>
Así pues, el modelo exponencial explica un poco mejor la evolución de la tasa de gripe con respecto a los días.&lt;/li>
&lt;/ol>
&lt;/div>
&lt;/div>
&lt;/div></description></item><item><title>Hojas de fórmulas de Estadística y Cálculo</title><link>/post/chuletas/</link><pubDate>Thu, 02 Nov 2017 10:21:50 +0000</pubDate><guid>/post/chuletas/</guid><description>&lt;p>A partir de ahora están disponibles varias hojas de fórmulas de cálculo y Estadística.&lt;/p>
&lt;p>Estas hojas contienen un resumen con las principales fórmulas utilizadas en Cálculo y Estadística.&lt;/p>
&lt;p>Las hojas de cálculo pueden descargarse desde los siguientes enlaces:&lt;/p>
&lt;ul>
&lt;li>
&lt;a href="https://aprendeconalf.es/docencia/calculo/formulas/" target="_blank" rel="noopener">Hoja de fórmulas de Cálculo&lt;/a>&lt;/li>
&lt;li>
&lt;a href="https://aprendeconalf.es/docencia/estadistica/formulas/" target="_blank" rel="noopener">Hoja de fórmulas de Estadística&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>Estaría muy agradecido si me informáis de cualquier error que detectéis en estas hojas.&lt;/p></description></item><item><title>Examen de Farmacia 2017-01-10</title><link>/docencia/estadistica/examenes/farmacia/farmacia-2017-01-10/</link><pubDate>Tue, 10 Jan 2017 00:00:00 +0000</pubDate><guid>/docencia/estadistica/examenes/farmacia/farmacia-2017-01-10/</guid><description>&lt;p>Grados: Farmacia, Biotecnología
Fecha: 10 de enero de 2017&lt;/p>
&lt;h2 id="ejercicio-1">Ejercicio 1&lt;/h2>
&lt;p>La siguiente tabla recoge la distribución de frecuencias del tiempo de espera en un servicio de urgencias de una muestra de pacientes.&lt;/p>
&lt;p>$$
\begin{array}{cr}
\hline
\mbox{Tiempo} &amp;amp; \mbox{Pacientes} \newline
(0,10] &amp;amp; 22 \newline
(10,20] &amp;amp; 43 \newline
(20,30] &amp;amp; 33 \newline
(30,40] &amp;amp; 12 \newline
(40,50] &amp;amp; 6 \newline
(50,60] &amp;amp; 4 \newline
\hline
\end{array}
$$&lt;/p>
&lt;p>Se pide:&lt;/p>
&lt;ol>
&lt;li>Dibujar el polígono de frecuencias relativas acumuladas del tiempo de espera.&lt;/li>
&lt;li>Calcular la mediana el tiempo de espera e interpretarla.&lt;/li>
&lt;li>¿Qué porcentaje de pacientes han tenido que esperar más de 38 minutos?&lt;/li>
&lt;/ol>
&lt;div class="spoiler " >
&lt;p>
&lt;a class="btn btn-primary" data-toggle="collapse" href="#spoiler-0" role="button" aria-expanded="false" aria-controls="spoiler-0">
Solución
&lt;/a>
&lt;/p>
&lt;div class="collapse card " id="spoiler-0">
&lt;div class="card-body">
&lt;ol>
&lt;li>&lt;/li>
&lt;li>
&lt;p>$Me=18.89$ min.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>El 10% de los pacientes han tenido que esperar más de 18 minutos.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;p>En dos poblaciones de mujeres A y B se ha tomado una muestra y se ha medido el número de embarazos de cada mujer durante su vida fértil obteniéndo los siguientes resultados:&lt;/p>
&lt;p>$$
\begin{array}{ccccccccccccccccc}
\hline
A &amp;amp; 2 &amp;amp; 3 &amp;amp; 4 &amp;amp; 4 &amp;amp; 3 &amp;amp; 2 &amp;amp; 6 &amp;amp; 1 &amp;amp; 5 &amp;amp; 3 &amp;amp; 4 &amp;amp; 4 &amp;amp; 3 &amp;amp; 2 &amp;amp; 5 &amp;amp; 0 \newline
B &amp;amp; 1 &amp;amp; 0 &amp;amp; 2 &amp;amp; 1 &amp;amp; 0 &amp;amp; 2 &amp;amp; 0 &amp;amp; 3 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0 &amp;amp; 2 &amp;amp; 5 &amp;amp; 1 &amp;amp; 1 &amp;amp; 1 \newline
\hline
\end{array}
$$&lt;/p>
&lt;p>Se pide:&lt;/p>
&lt;ol>
&lt;li>Construir los diagramas de caja de ambas muestras y compararlos.&lt;/li>
&lt;li>¿En qué muestra es más representativa la media? Justificar la respuesta.&lt;/li>
&lt;li>Calcular el coeficiente de asimetría de ambas distribuciones. ¿Qué distribución es más asimétrica?&lt;/li>
&lt;li>¿Qué número de embarazos es relativamente mayor, 5 embarazos en la población A o 3 en la B?&lt;/li>
&lt;/ol>
&lt;p>Utilizar las siguientes sumas para los cálculos:&lt;br>
$\sum a_i=51$, $\sum a_i^2=199$, $\sum (a_i-\bar a)^3=-11.6016$, $\sum (a_i-\bar a)^4=217.9954$,&lt;br>
$\sum b_i=20$, $\sum b_i^2=52$, $\sum (b_i-\bar b)^3=49.5$, $\sum (b_i-\bar b)^4=220.3125$.&lt;/p>
&lt;div class="spoiler " >
&lt;p>
&lt;a class="btn btn-primary" data-toggle="collapse" href="#spoiler-1" role="button" aria-expanded="false" aria-controls="spoiler-1">
Solución
&lt;/a>
&lt;/p>
&lt;div class="collapse card " id="spoiler-1">
&lt;div class="card-body">
&lt;ol>
&lt;li>&lt;/li>
&lt;li>
&lt;p>$\bar a=3.1875$ embarazos, $s_a^2=2.2773$ embarazos², $s_a=1.5091$ embarazos, $cv_a=0.4734$.&lt;br>
$\bar b=1.25$ embarazos, $s_b^2=1.6875$ embarazos², $s_b=1.299$ embarazos, $cv_b=1.0392$.&lt;br>
Como el coeficiente de variación de $A$ es menor que el coeficiente de variación de $B$, la media de la población $A$ es más representativa que la media de la población $B$.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>$g_{1,a}=-0.211$ y $g_{1,b}=1.4113$, de modo que la distribución de $B$ es más asimétrica que la distribución de $A$.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>$z_a(5)=1.2011$ y $z_b(3)=1.3472$, de modo que 3 embarazos en la población $B$ es relativamente mayor que 5 embarazos en la población $A$.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;h2 id="ejercicio-3">Ejercicio 3&lt;/h2>
&lt;p>En un estudio se ha medido la reducción en el nivel de colesterol de un grupo de personas hipertensas tras un programa de ejercicios. Los resultados aparecen en la siguiente tabla.&lt;/p>
&lt;ol>
&lt;li>¿Qué modelo de regresión explica mejor la reducción de colesterol en función de los minutos de ejercicio, el lineal o el exponencial? Justificar la respuesta.&lt;/li>
&lt;li>Según el modelo de regresión lineal, ¿cuánto disminuirá el colesterol por cada minuto más de ejercicio?&lt;/li>
&lt;li>Según el modelo logarítmico, ¿cuántos minutos de ejercicio se necesitan para reducir el colesterol 100 mg/dl? ¿Es fiable la predicción? Justificar la respuesta.&lt;/li>
&lt;/ol>
&lt;p>Utilizar las siguientes sumas para los cálculos ($X$=Minutos de ejercicio e $Y$=Reducción de colesterol):&lt;br>
$\sum x_i=2148$, $\sum \log(x_i)=53.0559$, $\sum y_j=199$, $\sum \log(y_j)=27.1766$,&lt;br>
$\sum x_i^2=507082$, $\sum \log(x_i)^2=282.9578$, $\sum y_j^2=5779$, $\sum \log(y_j)^2=80.035$,&lt;br>
$\sum x_iy_j=50750$, $\sum x_i\log(y_j)=6359.0468$, $\sum \log(x_i)y_j=1097.978$, $\sum \log(x_i)\log(y_j)=147.0682$.&lt;/p>
&lt;div class="spoiler " >
&lt;p>
&lt;a class="btn btn-primary" data-toggle="collapse" href="#spoiler-2" role="button" aria-expanded="false" aria-controls="spoiler-2">
Solución
&lt;/a>
&lt;/p>
&lt;div class="collapse card " id="spoiler-2">
&lt;div class="card-body">
&lt;ol>
&lt;li>Modelo de regresión lineal de la reducción del colesterol sobre el tiempo de ejercicio:&lt;br>
$\bar x=214.8$ min, $s_x^2=4569.16$ min².&lt;br>
$\bar y=19.9$ mg/dl, $s_y^2=181.89$ (mg/dl)².&lt;br>
$s_{xy}=800.48$ min⋅mg/dl.&lt;br>
$r^2 = 0.771$.&lt;br>
Modelo de regresión exponencial de la reducción de colesterol sobre el tiempo de ejercicio: $\overline{\log(y)}=2.7177$ log(mg/dl), $s_{\log(y)}^2=0.6178$ log(mg/dl)².&lt;br>
$s_{x\log(y)}=52.1504$ min⋅log(mg/dl).&lt;br>
$r^2 = 0.9635$.&lt;br>
Por tanto, el modelo de regresión exponencial es mejor ya que su coeficiente de determinación es mayor.&lt;/li>
&lt;li>Recta de regresión de la reducción del colesterol sobre el tiempo de ejercicio: $y=-17.7312 + 0.1752x$.&lt;br>
Por cada minuto más de ejercicio la reducción del colesterol aumenta 0.1752 mg/dl.&lt;/li>
&lt;li>Modelo de regresión logarítmico del tiempo de ejercicio sobre la reducción del colesterol: $x=-14.6075 + 84.4135\log(y)$.&lt;br>
$x(100)=374.131$.&lt;br>
A pesar de que el coeficiente de determinación está muy cerca de 1, la estimación no es muy fiable porque 100 mg/dl está bastante lejos del rango de valores de la muestra.&lt;/li>
&lt;/ol>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;h2 id="ejercicio-4">Ejercicio 4&lt;/h2>
&lt;p>En el servicio de emergencias de un municipio se sabe que por término medio se producen 6 avisos cada día.
Sabiendo que el servicio está organizado en 3 turnos diários de 8 horas, se pide:&lt;/p>
&lt;ol>
&lt;li>Calcular la probabilidad de que en un turno se produzcan más de 3 avisos.&lt;/li>
&lt;li>Calcular la probabilidad de que en alguno de los tres turnos de un día no se produzca ningún aviso.&lt;/li>
&lt;/ol>
&lt;div class="spoiler " >
&lt;p>
&lt;a class="btn btn-primary" data-toggle="collapse" href="#spoiler-3" role="button" aria-expanded="false" aria-controls="spoiler-3">
Solución
&lt;/a>
&lt;/p>
&lt;div class="collapse card " id="spoiler-3">
&lt;div class="card-body">
&lt;ol>
&lt;li>Llamando $X$ al número de avisos en un turno de 8 horas, $X\sim P(2)$ y $P(X&amp;gt;3)=0.1429$.&lt;/li>
&lt;li>Llamando $Y$ al número de turnos sin avisos, $Y\sim B(3,0.1353)$ y $P(Y&amp;gt;0)=0.3535$.&lt;/li>
&lt;/ol>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;h2 id="ejercicio-5">Ejercicio 5&lt;/h2>
&lt;p>Para detectar una enfermedad con una prevalencia del 10% se dispone de un test diagnóstico con una sensibilidad del 95% y una especificidad del 85%.
Se pide:&lt;/p>
&lt;ol>
&lt;li>Calcular los valores predictivos positivo y negativo del test e interpretarlos.
¿Se trata de un test más útil para detectar la enfermedad o para descartarla?&lt;/li>
&lt;li>¿Cuál debería la especificidad del test para que el valor predictivo positivo fuera del 80%?&lt;/li>
&lt;/ol>
&lt;div class="spoiler " >
&lt;p>
&lt;a class="btn btn-primary" data-toggle="collapse" href="#spoiler-4" role="button" aria-expanded="false" aria-controls="spoiler-4">
Solución
&lt;/a>
&lt;/p>
&lt;div class="collapse card " id="spoiler-4">
&lt;div class="card-body">
&lt;ol>
&lt;li>$VPP=P(D|+)=0.413$ y $VPN=P(\overline D|-)=0.9935$.&lt;/li>
&lt;li>La especificidad debería ser $97.37%$.&lt;/li>
&lt;/ol>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;h2 id="ejercicio-6">Ejercicio 6&lt;/h2>
&lt;p>Se ha medido la presión arterial sistólica a 8000 individuos de una población se ha observado que 2254 tiene más de 130 mmHg y 3126 tienen entre 110 y 130 mmHg.
Suponiendo que la presión arterial sistólica sigue una distribución de probabilidad normal, se pide:&lt;/p>
&lt;ol>
&lt;li>Calcular la media y la desviación típica.&lt;/li>
&lt;li>Si se consideran hipertensas las personas con una presión arterial superior a 140 mmHg, ¿cuántas personas hipertensas hay en la población?&lt;/li>
&lt;li>Si una analítica sanguínea marca como anormales el 5% de los individuos con menor presión arterial y el 5% con mayor presión arterial, ¿entre qué presiones arteriales debe estar la presión de un individuo para que la analítica lo considere normal?&lt;/li>
&lt;/ol>
&lt;div class="spoiler " >
&lt;p>
&lt;a class="btn btn-primary" data-toggle="collapse" href="#spoiler-5" role="button" aria-expanded="false" aria-controls="spoiler-5">
Solución
&lt;/a>
&lt;/p>
&lt;div class="collapse card " id="spoiler-5">
&lt;div class="card-body">
&lt;ol>
&lt;li>Llamando $X$ a la presión arterial, $X\sim N(118.723, 19.5221)$.&lt;/li>
&lt;li>$P(X&amp;gt;140)=0.1379$ y por tanto existen $1103.0473$ personas con hipertensión.&lt;/li>
&lt;li>La presión es normal en el intervalo $(86.612, 150.8341)$.&lt;/li>
&lt;/ol>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;h2 id="ejercicio-7">Ejercicio 7&lt;/h2>
&lt;p>En una asignatura se hacen dos exámenes parciales a lo largo del curso.
El primer parcial lo aprobaron el 60% de los alumnos y el segundo parcial lo aprobaron el 68%.
Del grupo de alumnos que aprobaron el primer parcial, el 80% de ellos aprobaron el segundo.
Si se elige un alumno al azar, calcular:&lt;/p>
&lt;ol>
&lt;li>Probabilidad de que no haya aprobado ningún parcial.&lt;/li>
&lt;li>Probabilidad de que haya aprobado el primer parcial si no ha aprobado el segundo.&lt;/li>
&lt;/ol>
&lt;div class="spoiler " >
&lt;p>
&lt;a class="btn btn-primary" data-toggle="collapse" href="#spoiler-6" role="button" aria-expanded="false" aria-controls="spoiler-6">
Solución
&lt;/a>
&lt;/p>
&lt;div class="collapse card " id="spoiler-6">
&lt;div class="card-body">
&lt;p>Llamando $E_1$ al evento consistente en aprobar el primer examen y $E_2$ al evento consistente en aprobar el segundo examen:&lt;/p>
&lt;ol>
&lt;li>$P(\overline E_1\cap \overline E_2)=0.2$.&lt;/li>
&lt;li>$P(E_1|\overline E_2)=0.375$.&lt;/li>
&lt;/ol>
&lt;/div>
&lt;/div>
&lt;/div></description></item><item><title>Examen de Farmacia 2016-11-28</title><link>/docencia/estadistica/examenes/farmacia/farmacia-2016-11-28/</link><pubDate>Mon, 28 Nov 2016 00:00:00 +0000</pubDate><guid>/docencia/estadistica/examenes/farmacia/farmacia-2016-11-28/</guid><description>&lt;p>Grados: Farmacia y Biotecnología
Fecha: 28 de Noviembre de 2016&lt;/p>
&lt;h2 id="ejercicio-1">Ejercicio 1&lt;/h2>
&lt;p>La siguiente tabla contiene la distribución de las puntuaciones obtenidas por una muestra de alumnos de medicina que se presentaron al examen del MIR.&lt;/p>
&lt;p>$$
\begin{array}{|c|r|r|r|r|r|}
\hline
x &amp;amp; n_i &amp;amp; x_in_i &amp;amp; x_i^2n_i &amp;amp; (x_i-\bar x)^3n_i &amp;amp; (x_i-\bar x)^4n_i \newline
\hline
(0,40] &amp;amp; 84 &amp;amp; 1680 &amp;amp; 33600 &amp;amp; -12155062.50 &amp;amp; 638140781.25 \newline
(40,80] &amp;amp; 185 &amp;amp; 11100 &amp;amp; 666000 &amp;amp; -361328.13 &amp;amp; 4516601.56 \newline
(80,120] &amp;amp; 72 &amp;amp; 7200 &amp;amp; 720000 &amp;amp; 1497375.00 &amp;amp; 41177812.50 \newline
(120,160] &amp;amp; 40 &amp;amp; 5600 &amp;amp; 784000 &amp;amp; 12301875.00 &amp;amp; 830376562.50 \newline
(160,200] &amp;amp; 19 &amp;amp; 3420 &amp;amp; 615600 &amp;amp; 23603640.63 &amp;amp; 2537391367.19 \newline
\hline
\sum &amp;amp; 400 &amp;amp; 29000 &amp;amp; 2819200 &amp;amp; 24886500.00 &amp;amp; 4051603125.00 \newline
\hline
\end{array}
$$&lt;/p>
&lt;ol>
&lt;li>Calcular el rango intercuartílico de las puntuaciones e interpretarlo.
¿Hay datos atípicos en la muestra?&lt;/li>
&lt;li>Si la nota de corte para aprobar el examen es 150, ¿qué porcentaje de alumnos aprobó el examen?&lt;/li>
&lt;li>Estudiar la representatividad de la media.&lt;/li>
&lt;li>Según la asimetría y el apuntamiento de la muestra, ¿se puede suponer que proviene de una población normal? Justificarlo con el cálculo de estadísticos de forma.&lt;/li>
&lt;li>Calcular la puntuación típica que le correspondería a un alumno con una puntuación de 150 puntos.&lt;/li>
&lt;/ol>
&lt;div class="spoiler " >
&lt;p>
&lt;a class="btn btn-primary" data-toggle="collapse" href="#spoiler-0" role="button" aria-expanded="false" aria-controls="spoiler-0">
Solución
&lt;/a>
&lt;/p>
&lt;div class="collapse card " id="spoiler-0">
&lt;div class="card-body">
&lt;ol>
&lt;li>$C_1=43.48$ puntos, $C_3=97.78$ puntos y $RI=54.3$ puntos.&lt;br>
Vallas: $V_1=-37.97$ puntos y $V_2=179.23$ puntos. Por tanto, existen datos atípicos.&lt;/li>
&lt;li>$F_{150}=0.925$, de manera que el porcentaje de estudiantes que aprobaron el examen fue $7.5%$.&lt;/li>
&lt;li>$\bar x=72.5$ puntos, $s^2=1791.75$ puntos², $s=42.3291$ puntos, $cv=0.5838$. Como el coeficiente de variación es mayor que 0.5 pero no demasiado, existe una variabilidad moderada y la representatividad de la media es también moderada.&lt;/li>
&lt;li>$g_1=0.8203$, de manera que la distribución es asimétrica hacia la izquierda. $g_2=0.1551$, de manera que la distribución es un poco más apuntada de lo normal (leptocúrtica). Como tanto $g_1$ como $g_2$ están entre -2 y 2 podemos asumir que la muestra proviene de una población normal.&lt;/li>
&lt;li>$z(150)=1.83$.&lt;/li>
&lt;/ol>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;h2 id="ejercicio-2">Ejercicio 2&lt;/h2>
&lt;p>La siguiente tabla refleja la evolución del Producto Interior Bruto (PIB) per capita (en miles de euros) y la mortalidad infantil (niños por cada mil habitantes) de una serie de años.&lt;/p>
&lt;p>$$
\begin{array}{lrrrrrrrr}
\hline
\mbox{Año} &amp;amp; 1993 &amp;amp; 1994 &amp;amp; 1995 &amp;amp; 1996 &amp;amp; 1997 &amp;amp; 1998 &amp;amp; 1999 &amp;amp; 2000 \newline
\mbox{PIB} &amp;amp; 17 &amp;amp; 17 &amp;amp; 18 &amp;amp; 18 &amp;amp; 19 &amp;amp; 20 &amp;amp; 21 &amp;amp; 22 \newline
\mbox{Mortalidad} &amp;amp; 6 &amp;amp; 5.6 &amp;amp; 5.2 &amp;amp; 4.9 &amp;amp; 4.6 &amp;amp; 4.3 &amp;amp; 4.1 &amp;amp; 4 \newline
\hline
\end{array}
$$&lt;/p>
&lt;ol>
&lt;li>Estimar el PIB correspondiente a una mortalidad de $3.8$ según el modelo lineal. ¿Qué modelo de regresión expresa mejor la relación entre el PIB y la mortalidad, el lineal o el exponencial?&lt;/li>
&lt;li>Si el PIB del año 2001 fue de 23, ¿cuál es la mortalidad esperada ese año según el modelo de regresión exponencial?&lt;/li>
&lt;li>Considerando los modelos lineales del PIB sobre la mortalidad y de la mortalidad sobre el PIB, ¿cuál de los dos modelos es más fiable?&lt;/li>
&lt;/ol>
&lt;p>Utilizar las siguientes sumas ($X$=PIB y $Y$=Mortalidad) para los cálculos:
$\sum x_i=152$, $\sum \log(x_i)=23.5229$, $\sum y_j=38.7$, $\sum \log(y_j)=12.5344$,
$\sum x_i^2=2912$, $\sum \log(x_i)^2=69.2305$, $\sum y_j^2=190.87$, $\sum \log(y_j)^2=19.7912$,
$\sum x_iy_j=726.5$, $\sum x_i\log(y_j)=236.3256$, $\sum \log(x_i)y_j=113.3308$, $\sum \log(x_i)\log(y_j)=36.76$.&lt;/p>
&lt;div class="spoiler " >
&lt;p>
&lt;a class="btn btn-primary" data-toggle="collapse" href="#spoiler-1" role="button" aria-expanded="false" aria-controls="spoiler-1">
Solución
&lt;/a>
&lt;/p>
&lt;div class="collapse card " id="spoiler-1">
&lt;div class="card-body">
&lt;ol>
&lt;li>Modelo de regresión lineal del PIB sobre la mortalidad infantil:
$\bar x=19$ 10³€, $s_x^2=3$ 10⁶€.&lt;br>
$\bar y=4.8375$ niños por cada mil, $s_y^2=0.4573$ (niños por cada mil)².&lt;br>
$s_{xy}=-1.1$ 10³€⋅niños por cada mil.&lt;br>
Recta de regresión del PIB sobre la mortalidad infantil: $x=30.6351 + -2.4052y$.&lt;br>
$x(3.8) =21.4954$.&lt;/li>
&lt;li>$\overline{\log(x)}=2.9404$ log(10³€), $s_{\log(x)}^2=0.0081$ log(10³€)².&lt;br>
$s_{\log(x)y}=-0.0577$ log(10³€)•niños por cada mil.&lt;br>
Coeficiente de determinación lineal del PIB sobre la mortaliad infantil $r^2=0.8819$.&lt;br>
Coeficiente de determinación exponencial del PIB sobre la mortaliad infantil $r^2=0.9002$.&lt;br>
Por tanto, el modelo exponencial explica mejor la relación entre el PIB y la mortalidad infantil ya que su coeficiente de determinación es mayor.&lt;/li>
&lt;li>$\overline{\log(y)}=1.5668$ log(niños por cada mil), $s_{\log(y)}^2=0.019$ log(niños por cada mil)².&lt;br>
$s_{x\log(y)}=-0.2284$ 10³€⋅log(niños por cada mil).&lt;br>
Modelo de regresión exponencial de la mortalidad infantil sobre el PIB: $y=e^{3.0135 + -0.0761x}$.&lt;br>
y(23)=3.5332$. niños por cada mil.&lt;/li>
&lt;li>La fiabilidad de ambos modelos es la misma ya que tienen el mismo coeficiente de determinación.&lt;/li>
&lt;/ol>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;h2 id="ejercicio-3">Ejercicio 3&lt;/h2>
&lt;p>Sabiendo que las rectas de regresión correspondientes a dos variables $X$ e $Y$ se cortan en el punto $(2,3)$ y que la predicción que da la recta de regresión para $x=3$ es $y=1$, ¿cuánto cambiará $Y$ según el modelo lineal por cada unidad que aumente $X$ ?
Si el coeficiente de correlación lineal es $-0.8$, ¿cuánto cambiará $X$ según el modelo lineal por cada unidad que aumente $Y$?&lt;/p>
&lt;div class="spoiler " >
&lt;p>
&lt;a class="btn btn-primary" data-toggle="collapse" href="#spoiler-2" role="button" aria-expanded="false" aria-controls="spoiler-2">
Solución
&lt;/a>
&lt;/p>
&lt;div class="collapse card " id="spoiler-2">
&lt;div class="card-body">
$\bar x=2$ and $\bar y=3$.&lt;br>
$b_{yx}=-2$, de modo que $Y$ decrece 2 unidades cuando $X$ crece una unidad.&lt;br>
$b_{xy}=-0.32$, de modo que $X$ decrece 0.32 unidades cuando $Y$ crece una unidad.
&lt;/div>
&lt;/div>
&lt;/div></description></item><item><title>rkTeaching en BEIO</title><link>/post/articulo-rkteaching-beio/</link><pubDate>Sat, 01 Aug 2015 00:00:00 +0000</pubDate><guid>/post/articulo-rkteaching-beio/</guid><description>&lt;p>El último numero del
&lt;a href="http://www.seio.es/BEIO/" target="_blank" rel="noopener">Boletín de Estadística e Investigación Operativa (BEIO)&lt;/a> que publica la Sociedad de Estadística e Investigación Operativa contiene un artículo sobre RKTeaching y su uso en la docencia de Estadística.&lt;/p>
&lt;p>Recomiendo su lectura especialmente a aquellos docentes de Estadística que usen R o quieran pasar a utilizar R en sus clases sin que suponga un trauma para sus alumnos.&lt;/p>
&lt;p>
&lt;a href="/docs/articulo-rkteachig-beio.pdf">Descarga el artículo&lt;/a>&lt;/p></description></item><item><title>Examen de Farmacia 2015-01-13</title><link>/docencia/estadistica/examenes/farmacia/farmacia-2015-01-13/</link><pubDate>Tue, 13 Jan 2015 00:00:00 +0000</pubDate><guid>/docencia/estadistica/examenes/farmacia/farmacia-2015-01-13/</guid><description>&lt;p>Grados: Farmacia y Biotecnología&lt;br>
Fecha: 13 de Enero de 2015&lt;/p>
&lt;h2 id="ejercicio-1">Ejercicio 1&lt;/h2>
&lt;p>Un laboratorio farmacéutico está probando un nuevo medicamento y se están estudiando los efectos secundarios que provoca. Se sabe que la probabilidad de que el medicamento provoque mareos es de 0.20 y de que provoque náuseas es de 0.50. También se sabe que la probabilidad de que provoque solo mareos es 0.15.&lt;/p>
&lt;ol>
&lt;li>¿Que probabilidad hay de que el medicamento provoque algún efecto secundario?&lt;/li>
&lt;li>¿Que probabilidad hay de que el medicamento provoque los dos efectos secundarios?&lt;/li>
&lt;li>¿Que probabilidad hay de que el medicamento provoque solo náuseas?&lt;/li>
&lt;li>¿Que probabilidad hay de que el medicamento provoque náuseas si ha provocado mareos?&lt;/li>
&lt;li>¿Son independientes los efectos secundarios?&lt;/li>
&lt;/ol>
&lt;div class="spoiler " >
&lt;p>
&lt;a class="btn btn-primary" data-toggle="collapse" href="#spoiler-0" role="button" aria-expanded="false" aria-controls="spoiler-0">
Resolución
&lt;/a>
&lt;/p>
&lt;div class="collapse card " id="spoiler-0">
&lt;div class="card-body">
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe src="https://www.youtube.com/embed/5On725uKqBU" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video">&lt;/iframe>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;h2 id="ejercicio-2">Ejercicio 2&lt;/h2>
&lt;p>Se sabe que en personas con infección urinaria el número medio de bacterias por mm$^3$ de orina es 5, mientras que en personas sanas la media es de 2 bacterias por mm$^3$. Se pide:&lt;/p>
&lt;ol>
&lt;li>Calcular la probabilidad de que en una muestra de medio mm$^3$ de orina de un individuo con infección haya alguna bacteria.&lt;/li>
&lt;li>Calcular la probabilidad de que en una muestra de dos mm$^3$ de orina de un individuo sano haya menos de 3 bacterias.&lt;/li>
&lt;li>Si un test diagnóstico para detectar la infección urinaria da positivo cuando en un mm$^3$ de orina hay más de 6 bacterias, ¿cuál es la sensibilidad del test? ¿Y cuál es su especificidad?&lt;/li>
&lt;li>Si la prevalencia de la infección urinaria en la población es del 5%, ¿cuál es el valor predictivo positivo del test diagnóstico del apartado anterior? ¿Y su valor predictivo negativo?&lt;/li>
&lt;li>Si se toman 5 muestras de un mm$^3$ de una persona con infección de orina, ¿cuál es la probabilidad de que se produzca algún falso negativo?&lt;/li>
&lt;/ol>
&lt;p>Nota: La sensibilidad de un test el porcentaje de resultados positivos en personas enfermas, la especificidad es el porcentaje de
resultados negativos en personas sanas, la prevalencia es el porcentaje de personas enfermas en la población, el valor predictivo
positivo es el porcentaje de personas enfermas entre las que han dado positivo en el test, y el valor predictivo negativo es el
porcentaje de personas sanas entre las que han dado negativo en el test.&lt;/p>
&lt;div class="spoiler " >
&lt;p>
&lt;a class="btn btn-primary" data-toggle="collapse" href="#spoiler-1" role="button" aria-expanded="false" aria-controls="spoiler-1">
Resolución
&lt;/a>
&lt;/p>
&lt;div class="collapse card " id="spoiler-1">
&lt;div class="card-body">
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe src="https://www.youtube.com/embed/FmKjZjTREYU" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video">&lt;/iframe>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;h2 id="ejercicio-3">Ejercicio 3&lt;/h2>
&lt;p>En un estudio realizado a 720 niños de 8 años se observó que 324 tenían un peso superior a 27.2 kg y que 216 tenían un peso entre 24.6 y 27.2 kg. Suponiendo que el peso de los niños de 8 años sigue una distribución normal, se pide:&lt;/p>
&lt;ol>
&lt;li>Calcular la media y la desviación típica del peso de los niños de 8 años.&lt;/li>
&lt;li>¿Cuántos niños de 8 años tendrán un peso comprendido entre 24 y 28 kg?&lt;/li>
&lt;li>Si un niño de 8 años pesa 28.5 kg, ¿cuánto debe adelgazar para situarse por debajo del percentil 60 del peso?&lt;/li>
&lt;/ol>
&lt;div class="spoiler " >
&lt;p>
&lt;a class="btn btn-primary" data-toggle="collapse" href="#spoiler-2" role="button" aria-expanded="false" aria-controls="spoiler-2">
Resolución
&lt;/a>
&lt;/p>
&lt;div class="collapse card " id="spoiler-2">
&lt;div class="card-body">
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe src="https://www.youtube.com/embed/wgIbPz3wTbk" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video">&lt;/iframe>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div></description></item><item><title>3ª edición del Curso Práctico de Bioestadística con R</title><link>/post/curso-bioestadistica-miriadax-3ed/</link><pubDate>Thu, 08 Jan 2015 00:00:00 +0000</pubDate><guid>/post/curso-bioestadistica-miriadax-3ed/</guid><description>&lt;p>Ya está aquí la tercera edición del Curso Práctico de Bioestadística con R ofrecido por la plataforma MiriadaX, que se desarrollará del 8 de enero al 16 de febrero de 2015.&lt;/p>
&lt;p>Si te perdiste las dos primeras ediciones no dudes en apuntarte a esta tercera edición que, al igual que todos los cursos de MiriadaX, son es gratuíta.&lt;/p>
&lt;p>Sólo tienes que registrarte en la página web de MiriadaX y matricularte en el curso en la dirección:
&lt;a href="https://www.miriadax.net/web/curso-practico-bioestadistica-r-3edicion" target="_blank" rel="noopener">https://www.miriadax.net/web/curso-practico-bioestadistica-r-3edicion&lt;/a>&lt;/p>
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe src="https://www.youtube.com/embed/BTFOsbzInZo" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video">&lt;/iframe>
&lt;/div>
&lt;p>&lt;em>¡No lo dejes para más tarte! &amp;lsquo;Apúntate ya, y díselo a tus conocidos!&lt;/em>&lt;/p></description></item><item><title>Examen de Farmacia 2014-11-24</title><link>/docencia/estadistica/examenes/farmacia/farmacia-2014-11-24/</link><pubDate>Mon, 24 Nov 2014 00:00:00 +0000</pubDate><guid>/docencia/estadistica/examenes/farmacia/farmacia-2014-11-24/</guid><description>&lt;p>Grados: Farmacia y Biotecnología&lt;br>
Fecha: 24 de Noviembre de 2014&lt;/p>
&lt;h2 id="ejercicio-1">Ejercicio 1&lt;/h2>
&lt;p>El siguiente diagrama refleja la distribución acumulada del número de partes de asistencia médica que han dado durante un año una muestra de 100 asegurados.&lt;/p>
&lt;img src="../img/poligono.png" width="600" alt="Polígono de frecuencias relativas acumuladas"/>
&lt;p>Dibujar el diagrama de cajas y ver si existen datos atípicos en la muestra.&lt;/p>
&lt;div class="spoiler " >
&lt;p>
&lt;a class="btn btn-primary" data-toggle="collapse" href="#spoiler-0" role="button" aria-expanded="false" aria-controls="spoiler-0">
Resolución
&lt;/a>
&lt;/p>
&lt;div class="collapse card " id="spoiler-0">
&lt;div class="card-body">
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe src="https://www.youtube.com/embed/-de4qdVapDY" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video">&lt;/iframe>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;h2 id="ejercicio-2">Ejercicio 2&lt;/h2>
&lt;p>En un centro de salud, la ocupación del aparcamiento durante la última semana fue registrada mediante la siguiente tabla:&lt;/p>
&lt;p>$$
\begin{array}{|c|r|r|r|r|r|}
\hline
x &amp;amp; n_i &amp;amp; x_in_i &amp;amp; x_i^2n_i &amp;amp; (x_i-\bar x)^3n_i &amp;amp; (x_i-\bar x)^4n_i \newline
\hline
(0,40] &amp;amp; 84 &amp;amp; 1680 &amp;amp; 33600 &amp;amp; -12155062.50 &amp;amp; 638140781.25 \newline
(40,80] &amp;amp; 185 &amp;amp; 11100 &amp;amp; 666000 &amp;amp; -361328.13 &amp;amp; 4516601.56 \newline
(80,120] &amp;amp; 72 &amp;amp; 7200 &amp;amp; 720000 &amp;amp; 1497375.00 &amp;amp; 41177812.50 \newline
(120,160] &amp;amp; 40 &amp;amp; 5600 &amp;amp; 784000 &amp;amp; 12301875.00 &amp;amp; 830376562.50 \newline
(160,200] &amp;amp; 19 &amp;amp; 3420 &amp;amp; 615600 &amp;amp; 23603640.63 &amp;amp; 2537391367.19 \newline
\hline
\sum &amp;amp; 400 &amp;amp; 29000 &amp;amp; 2819200 &amp;amp; 24886500.00 &amp;amp; 4051603125.00 \newline
\hline
\end{array}
$$&lt;/p>
&lt;p>Se pide:&lt;/p>
&lt;ol>
&lt;li>Calcular el tiempo por encima del cual han estacionado el 60% de los vehículos. ¿Qué porcentaje de vehículos ha estacionado por encima de 100 minutos?&lt;/li>
&lt;li>Calcular la media del tiempo de estacionamiento. ¿Es representativa la media?&lt;/li>
&lt;li>Calcular el coeficiente de asimetría y de apuntamiento de la distribución del tiempo de estacionamiento e interpretarlos.&lt;/li>
&lt;li>Sabiendo que la empresa responsable del aparcamiento cobra 3 céntimos por minuto de aparcamiento más una cantidad fija de 20 céntimos, calcular el precio medio del aparcamiento y la desviación típica del mismo.&lt;/li>
&lt;/ol>
&lt;div class="spoiler " >
&lt;p>
&lt;a class="btn btn-primary" data-toggle="collapse" href="#spoiler-1" role="button" aria-expanded="false" aria-controls="spoiler-1">
Resolución
&lt;/a>
&lt;/p>
&lt;div class="collapse card " id="spoiler-1">
&lt;div class="card-body">
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe src="https://www.youtube.com/embed/8XcjtIqB83U" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video">&lt;/iframe>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;h2 id="ejercicio-3">Ejercicio 3&lt;/h2>
&lt;p>Una botánica comenzó a tratar una planta de soja con cierta sustancia estimulante del crecimiento. Para ver cómo evolucionaba el peso en función del tiempo, hizo 8 medidas del peso en distintos instantes, obteniendo los siguientes resultados&lt;/p>
&lt;p>$$
\begin{array}{lllllll}
\sum t = 250 &amp;amp; \quad &amp;amp; \sum p = 2369 &amp;amp; \quad &amp;amp; \sum \ln(t) = 25.94 &amp;amp; \quad &amp;amp; \sum \ln(p) = 27.17 \newline
\sum t^2= 10358 &amp;amp; &amp;amp; \sum p^2 = 2848799 &amp;amp; &amp;amp; \sum (\ln t)^2 = 87.70 &amp;amp; &amp;amp; \sum (\ln p)^2 = 139.52 \newline
\sum tp= 133399 &amp;amp; &amp;amp; \sum \ln(t) p = 9527.34 &amp;amp; &amp;amp; \sum t\ln(p) = 1193.26 &amp;amp; &amp;amp; \sum \ln(t)\ln(p) = 100.60
\end{array}
$$&lt;/p>
&lt;p>Se pide:&lt;/p>
&lt;ol>
&lt;li>Estudiar si el modelo logarítmico es más fiable que el lineal para predecir los días de tratamiento en función el peso de la planta. Utilizar el mejor modelo para estimar los días de tratamiento necesarios para que la planta pese 500 gr.&lt;/li>
&lt;li>Considerando el resultado del apartado anterior, ¿cuál sería el mejor modelo de regresión para estimar el peso de la planta a los 30 días de tratamiento? Hacer dicha estimación.&lt;/li>
&lt;/ol>
&lt;div class="spoiler " >
&lt;p>
&lt;a class="btn btn-primary" data-toggle="collapse" href="#spoiler-2" role="button" aria-expanded="false" aria-controls="spoiler-2">
Resolución
&lt;/a>
&lt;/p>
&lt;div class="collapse card " id="spoiler-2">
&lt;div class="card-body">
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe src="https://www.youtube.com/embed/T4hu8kOIF28" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video">&lt;/iframe>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;h2 id="ejercicio-4">Ejercicio 4&lt;/h2>
&lt;p>La recta de regresión de una variable $Y$ sobre otra $X$ tiene ecuación $y+\frac{1}{4}x-1=0$, mientras que la recta de regresión de $X$ sobre $Y$, tiene ecuación $y+\frac{3}{4}x-2=0$. Se pide:&lt;/p>
&lt;ol>
&lt;li>Calcular la media de $X$ y la de $Y$.&lt;/li>
&lt;li>Calcular el coeficiente de correlación lineal e interpretarlo.&lt;/li>
&lt;/ol>
&lt;div class="spoiler " >
&lt;p>
&lt;a class="btn btn-primary" data-toggle="collapse" href="#spoiler-3" role="button" aria-expanded="false" aria-controls="spoiler-3">
Resolución
&lt;/a>
&lt;/p>
&lt;div class="collapse card " id="spoiler-3">
&lt;div class="card-body">
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe src="https://www.youtube.com/embed/z-CxzqBf9t4" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video">&lt;/iframe>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div></description></item><item><title>Nuevo libro de Bioestadística Aplicada con SPSS</title><link>/post/libro-bioestadistica/</link><pubDate>Thu, 10 Jul 2014 00:00:00 +0000</pubDate><guid>/post/libro-bioestadistica/</guid><description>&lt;p>Acaba de publicase un nuevo libro práctico para el análisis de datos con SPSS aplicado principalmente a las ciencias de la Salud.&lt;/p>
&lt;p>El análisis de datos en cualquier Ciencia Experimental o de la Salud es imprescindible para la compresión de los fenómenos biológicos, físicos o químicos.
Las nuevas tecnologías han hecho posible el desarrollo de programas capaces de recopilar, organizar y analizar enormes cantidades de datos con poco esfuerzo.&lt;/p>
&lt;p>SPSS es uno de los programas de análisis estadísticos más utilizados, sobre todo en el ámbito de las ciencias biosanitarias.
Este libro presenta las principales técnicas Estadísticas, tanto de Estadística Descriptiva como de Inferencia Estadística, aplicadas con SPSS a multitud de ejemplos del ámbito de las Ciencias de la Salud, desarrollados paso a paso.&lt;/p>
&lt;p>
&lt;a href="/es/docencia/spss">Más información&lt;/a>.&lt;/p></description></item><item><title>2ª edición del Curso Práctico de Bioestadística con R</title><link>/post/curso-bioestadistica-miriadax/</link><pubDate>Mon, 12 May 2014 00:00:00 +0000</pubDate><guid>/post/curso-bioestadistica-miriadax/</guid><description>&lt;p>Tras el éxito de la primera edición del Curso Práctico de Bioestadística con R ofrecido por la plataforma MiriadaX, el próximo 19 de mayo comienza la segunda edición.&lt;/p>
&lt;p>Si te perdiste la primera edición no dudes en apuntarte a esta segunda edición que como la primera es gratuíta.&lt;/p>
&lt;p>Sólo tienes que registrarte en la página web de MiriadaX y matricularte en el curso en la dirección:
&lt;a href="https://www.miriadax.net/web/curso-practico-bioestadistica-r-2edicion" target="_blank" rel="noopener">https://www.miriadax.net/web/curso-practico-bioestadistica-r-2edicion&lt;/a>&lt;/p>
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe src="https://www.youtube.com/embed/BTFOsbzInZo" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video">&lt;/iframe>
&lt;/div>
&lt;p>&lt;em>¡Que corra la voz!&lt;/em>&lt;/p></description></item><item><title>Examen de Farmacia 2014-01-27</title><link>/docencia/estadistica/examenes/farmacia/farmacia-2014-01-27/</link><pubDate>Mon, 27 Jan 2014 00:00:00 +0000</pubDate><guid>/docencia/estadistica/examenes/farmacia/farmacia-2014-01-27/</guid><description>&lt;p>Grados: Farmacia y Biotecnología&lt;br>
Fecha: 27 de Enero de 2014&lt;/p>
&lt;h2 id="ejercicio-1">Ejercicio 1&lt;/h2>
&lt;p>Se realiza un estudio para determinar la efectividad de un medicamento para controlar la hipertensión a 180 pacientes hipertensos.
Para ello se les suministra una cantidad determinada del mismo obteniéndose los siguientes resultados&lt;/p>
&lt;p>$$
\begin{array}{|c|c|c|c|c|}
\hline
\textrm{Dosis (mg)} &amp;amp; n_i &amp;amp; f_i &amp;amp; N_i &amp;amp; F_i \newline
\hline\hline
(100,400] &amp;amp; 15 &amp;amp; &amp;amp; &amp;amp; \newline
\hline
(400,700] &amp;amp; &amp;amp; &amp;amp; &amp;amp; 0.2167 \newline
\hline
(700,800] &amp;amp; 36 &amp;amp; &amp;amp; &amp;amp; \newline
\hline
(800,900] &amp;amp; &amp;amp; 0.3333 &amp;amp; &amp;amp; \newline
\hline
(900,1000] &amp;amp; &amp;amp; &amp;amp; &amp;amp; \newline
\hline
\end{array}
$$&lt;/p>
&lt;p>Se pide:&lt;/p>
&lt;ol>
&lt;li>Completar la tabla.&lt;/li>
&lt;li>¿Cuál ha sido la dosis media de medicamento administrado? ¿Es representativa?&lt;/li>
&lt;li>Si se considera que a partir de una administración de 725mg hay que hacer un seguimiento para controlar posibles hipotensiones, ¿qué porcentaje de pacientes necesitan ese seguimiento?&lt;/li>
&lt;li>¿Cuál fue la cantidad mínima de medicamento suministrada al 60% de los pacientes más medicados?&lt;/li>
&lt;li>¿Cuál fue la cantidad más habitual de medicamento administrado?&lt;/li>
&lt;li>Si a un paciente se le suministró una cantidad de medicamento de 725 mg y a otro una cantidad tipificada de 0.95, ¿A cuál se le administró una cantidad mayor? Justificar la respuesta.&lt;/li>
&lt;li>Calcular el coeficiente de asimetría e interpretarlo.&lt;/li>
&lt;li>Dibujar el diagrama de cajas e interpretarlo.&lt;/li>
&lt;li>Si se cambia de medicamento por otro cuya cantidad a administrar viene dada en función del anterior medicamento mediante la relación $Y=100+0.7X$, siendo $X$ la cantidad de medicamento original e $Y$ la cantidad de medicamento nuevo, ¿cuál será la media de la cantidad administrada del nuevo medicamento? ¿Es más representativa que en el medicamento original? Justificar la respuesta.&lt;/li>
&lt;/ol>
&lt;p>Nota: Para facilitar los cálculos se dan las siguientes sumas:&lt;/p>
&lt;p>$$
\begin{array}{c}
\sum x_in_i=137700 \quad \sum x_i^2n_i=112410000 \newline
\sum (x_i-\bar x)^3n_i= -1965735000 \quad \sum (x_i-\bar x)^4n_i=1162291162500
\end{array}
$$&lt;/p>
&lt;h2 id="ejercicio-2">Ejercicio 2&lt;/h2>
&lt;p>En un estudio se ha medido el calor liberado en una reacción química en distintos instantes desde el comienzo de la reacción, obteniendo los siguientes datos:&lt;/p>
&lt;p>$$
\begin{array}{lrrrrr}
\hline
\textrm{Tiempo en minutos} &amp;amp; 2.5 &amp;amp; 3.7 &amp;amp; 4.1 &amp;amp; 5.3 &amp;amp; 6.2 \newline
\textrm{Calor en calorías} &amp;amp; 15.9 &amp;amp; 44.5 &amp;amp; 65.6 &amp;amp; 206.5 &amp;amp; 498.7 \newline
\hline
\end{array}
$$&lt;/p>
&lt;p>Se pide:&lt;/p>
&lt;ol>
&lt;li>Calcular el modelo de regresión lineal del calor sobre el tiempo. Según este modelo ¿Cuándo cambiarán las calorías por cada minuto que pase?&lt;/li>
&lt;li>Calcular el modelo de regresión exponencial del calor sobre el tiempo.&lt;/li>
&lt;li>Utilizando el mejor de los dos modelos anteriores, predecir el calor generado a los 5 minutos de la reacción. ¿Es fiable la predicción? Justificar la respuesta.&lt;/li>
&lt;/ol>
&lt;div class="spoiler " >
&lt;p>
&lt;a class="btn btn-primary" data-toggle="collapse" href="#spoiler-0" role="button" aria-expanded="false" aria-controls="spoiler-0">
Resolución
&lt;/a>
&lt;/p>
&lt;div class="collapse card " id="spoiler-0">
&lt;div class="card-body">
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe src="https://www.youtube.com/embed/IbyZwm1cv8Y" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video">&lt;/iframe>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div></description></item><item><title>Examen de Farmacia 2013-01-24</title><link>/docencia/estadistica/examenes/farmacia/farmacia-2013-01-24/</link><pubDate>Thu, 24 Jan 2013 00:00:00 +0000</pubDate><guid>/docencia/estadistica/examenes/farmacia/farmacia-2013-01-24/</guid><description>&lt;p>Grados: Farmacia y Biotecnología&lt;br>
Fecha: 24 de Enero de 2013&lt;/p>
&lt;h2 id="ejercicio-1">Ejercicio 1&lt;/h2>
&lt;p>En un grupo de personas sometidas a una anestesia general se ha medido la dosis de sustancia anestésica recibida $X$ en mg y el tiempo que estuvieron dormidas $Y$ en horas. Las frecuencias observadas aparecen en la siguiente tabla:&lt;/p>
&lt;p>$$
\begin{array}{|l|rrr|r|}
\hline
X\backslash Y &amp;amp; [1,2) &amp;amp; [2,3) &amp;amp; [3,4) &amp;amp; n_x \newline
\hline
(20,30] &amp;amp; 14 &amp;amp; 10 &amp;amp; 0 &amp;amp; 24 \newline
(30,40] &amp;amp; 12 &amp;amp; 26 &amp;amp; 7 &amp;amp; 45 \newline
(40,50] &amp;amp; 2 &amp;amp; 12 &amp;amp; 17 &amp;amp; 31 \newline
\hline
n_y &amp;amp; 28 &amp;amp; 48 &amp;amp; 24 &amp;amp; 100 \newline
\hline
\end{array}
$$&lt;/p>
&lt;p>Se pide:&lt;/p>
&lt;ol>
&lt;li>¿En qué variable es más representativa la media? Justificar la respuesta&lt;/li>
&lt;li>¿Por encima de cuánto tiempo estarán dormidas el 10% de las personas que reciben una dosis entre 30 y 40 mg?&lt;/li>
&lt;li>¿En qué variable hay más asimetría? Justificar la respuesta.&lt;/li>
&lt;li>Según el modelo de regresión lineal, ¿cuánta sustancia anestésica será necesaria para dormir a alguien durante al menos dos horas? ¿Es fiable la predicción? Justificar la respuesta.&lt;/li>
&lt;/ol>
&lt;div class="spoiler " >
&lt;p>
&lt;a class="btn btn-primary" data-toggle="collapse" href="#spoiler-0" role="button" aria-expanded="false" aria-controls="spoiler-0">
Resolución
&lt;/a>
&lt;/p>
&lt;div class="collapse card " id="spoiler-0">
&lt;div class="card-body">
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe src="https://www.youtube.com/embed/q5j2ryj0oCQ" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video">&lt;/iframe>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;h2 id="ejercicio-2">Ejercicio 2&lt;/h2>
&lt;p>Se sometió a una persona a unas sesiones de entrenamiento para el manejo de una máquina de análisis químicos y se valoró la destreza en el manejo en diversas ocasiones, valorandola en una escala de 0 a 100.
Los resultados obtenidos aparecen en la siguiente tabla&lt;/p>
&lt;p>$$
\begin{array}{lrrrrrr}
\hline
\textrm{Sesiones} &amp;amp; 2 &amp;amp; 5 &amp;amp; 7 &amp;amp; 10 &amp;amp; 12 &amp;amp; 16 \newline
\textrm{Destreza} &amp;amp; 15 &amp;amp; 40 &amp;amp; 62 &amp;amp; 86 &amp;amp; 92 &amp;amp; 95 \newline
\hline
\end{array}
$$&lt;/p>
&lt;p>Se pide:&lt;/p>
&lt;ol>
&lt;li>Calcular la destreza alcanzada al cabo de 8 sesiones empleando el modelo logarítmico.&lt;/li>
&lt;li>Calcular el número de sesiones necesarias para alcanzar una destreza de 80 empleando el modelo exponencial.&lt;/li>
&lt;li>Justificar razonadamente cuál de las predicciones anteriores es más fiable.&lt;/li>
&lt;/ol>
&lt;div class="spoiler " >
&lt;p>
&lt;a class="btn btn-primary" data-toggle="collapse" href="#spoiler-1" role="button" aria-expanded="false" aria-controls="spoiler-1">
Resolución
&lt;/a>
&lt;/p>
&lt;div class="collapse card " id="spoiler-1">
&lt;div class="card-body">
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe src="https://www.youtube.com/embed/Jx8R4fTFjoE" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video">&lt;/iframe>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;h2 id="ejercicio-3">Ejercicio 3&lt;/h2>
&lt;p>Al realizar un estudio de regresión lineal de dos variables $X$ e $Y$, se sabe que las rectas de regresión se cortan en el punto $(5,15)$, que el coeficiente de correlación lineal es $-0.85$ y que la pendiente de la recta de regresión de $X$ sobre $Y$ es el doble que la de la recta de $Y$ sobre $X$. Se pide:&lt;/p>
&lt;ol>
&lt;li>Calcular las ecuaciones de las rectas de regresión de $Y$ sobre $X$ y de $X$ sobre $Y$.&lt;/li>
&lt;li>¿Qué porcentaje de la variabilidad de $Y$ queda explicado por el modelo lineal?&lt;/li>
&lt;/ol>
&lt;div class="spoiler " >
&lt;p>
&lt;a class="btn btn-primary" data-toggle="collapse" href="#spoiler-2" role="button" aria-expanded="false" aria-controls="spoiler-2">
Resolución
&lt;/a>
&lt;/p>
&lt;div class="collapse card " id="spoiler-2">
&lt;div class="card-body">
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe src="https://www.youtube.com/embed/XKrRifxAfDg" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video">&lt;/iframe>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div></description></item><item><title>Hoja de Fórmulas de Estadística</title><link>/docencia/estadistica/formulas/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/docencia/estadistica/formulas/</guid><description>&lt;h2 id="fórmulas-de-estadística">Fórmulas de Estadística&lt;/h2>
&lt;ul>
&lt;li>
&lt;a href="https://github.com/asalber/formulas-estadistica/raw/master/formulas-estadistica.pdf" target="_blank" rel="noopener">Fórmulas de Estadística y Probabilidad&lt;/a>&lt;/li>
&lt;li>
&lt;a href="https://github.com/asalber/statistics-cheatsheet/raw/master/statistics-formulas-excel.pdf" target="_blank" rel="noopener">Excel formulas&lt;/a>&lt;/li>
&lt;li>
&lt;a href="https://github.com/asalber/curso_estadistica/raw/master/tablas/tabla_normal_estandar.pdf" target="_blank" rel="noopener">Tabla de la distribución Normal estándar&lt;/a>&lt;/li>
&lt;li>
&lt;a href="https://github.com/asalber/curso_estadistica/raw/master/tablas/tabla_chi_cuadrado.pdf" target="_blank" rel="noopener">Tabla de la distribución Chi-cuadrado&lt;/a>&lt;/li>
&lt;li>
&lt;a href="https://github.com/asalber/curso_estadistica/raw/master/tablas/tabla_t_student.pdf" target="_blank" rel="noopener">Tabla de la distribución T de student&lt;/a>&lt;/li>
&lt;li>
&lt;a href="https://github.com/asalber/curso_estadistica/raw/master/tablas/tabla_f_fisher.pdf" target="_blank" rel="noopener">Tabla de la distribución F de Fisher&lt;/a>&lt;/li>
&lt;li>
&lt;a href="https://github.com/asalber/curso_estadistica/raw/master/tablas/tabla_intervalos_confianza.pdf" target="_blank" rel="noopener">Tabla de Intervalos de Confianza&lt;/a>&lt;/li>
&lt;li>
&lt;a href="https://github.com/asalber/curso_estadistica/raw/master/tablas/Tabla%20Resumen%20Contraste%20de%20Hip%C3%B3tesis.pdf" target="_blank" rel="noopener">Tabla de Contrastes de Hipótesis&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>Libro de Bioestadística Aplicada con SPSS</title><link>/docencia/spss/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/docencia/spss/</guid><description>&lt;p>&lt;img src="images/libro_bioestadistica_spss.jpg" alt="Libro Bioestadística Aplicada con SPSS">&lt;/p>
&lt;h2 id="resumen">Resumen&lt;/h2>
&lt;p>El análisis de datos en cualquier Ciencia Experimental o de la Salud es imprescindible para la compresión de los fenómenos biológicos, físicos o químicos.
Las nuevas tecnologías han hecho posible el desarrollo de programas capaces de recopilar, organizar y analizar enormes cantidades de datos con poco esfuerzo. SPSS es uno de los programas de análisis estadísticos más utilizados, sobre todo en el ámbito de las ciencias biosanitarias.
Este libro presenta las principales técnicas Estadísticas, tanto de Estadística Descriptiva como de Inferencia Estadística, aplicadas con SPSS a multitud de ejemplos del ámbito de las Ciencias de la Salud, desarrollados paso a paso.&lt;/p>
&lt;h2 id="tabla-de-contenidos">Tabla de contenidos&lt;/h2>
&lt;p>1 Introducción a SPSS&lt;br>
1.1 Introducción&lt;br>
1.2 Funciones básicas&lt;br>
1.2.1 Arranque&lt;br>
1.2.2 Introducción de datos&lt;br>
1.2.3 Guardar datos&lt;br>
1.2.4 Recuperar datos&lt;br>
1.2.5 Modificación de datos&lt;br>
1.2.6 Transformación y generación de datos&lt;br>
1.2.7 Recodificación de datos&lt;br>
1.2.8 Impresión&lt;br>
1.2.9 Salir del programa&lt;br>
1.2.10 Ayuda&lt;br>
1.3 Ejercicios resueltos&lt;br>
2 Distribuciones de Frecuencias y Gráficas&lt;br>
2.1 Fundamentos teóricos&lt;br>
2.1.1 Cálculo de frecuencias&lt;br>
2.1.2 Representaciones gráficas&lt;/p>
&lt;ul>
&lt;li>Diagrama de barras y polígono de frecuencias&lt;/li>
&lt;li>Histogramas&lt;/li>
&lt;li>Diagrama de sectores&lt;/li>
&lt;li>Diagrama de caja y datos atípicos&lt;/li>
&lt;/ul>
&lt;p>2.2 Ejercicios resueltos&lt;br>
2.3 Ejercicios propuestos&lt;br>
3 Estadísticos Muestrales&lt;br>
3.1 Fundamentos teóricos&lt;br>
3.1.1 Medidas de posición&lt;/p>
&lt;ul>
&lt;li>Media aritmética&lt;/li>
&lt;li>Mediana&lt;/li>
&lt;li>Moda&lt;/li>
&lt;li>Cuantiles&lt;/li>
&lt;/ul>
&lt;p>3.1.2 Medidas de dispersión&lt;/p>
&lt;ul>
&lt;li>Rango o Recorrido&lt;/li>
&lt;li>Rango intercuartílico&lt;/li>
&lt;li>Varianza&lt;/li>
&lt;li>Desviación típic&lt;/li>
&lt;li>Coeficiente de variación de Pearson&lt;/li>
&lt;li>Medidas de forma&lt;/li>
&lt;li>Coeficiente de asimetría de Fisher&lt;/li>
&lt;li>Coeficiente de apuntamiento o curtosis&lt;/li>
&lt;/ul>
&lt;p>3.1.4 Estadísticos por grupos&lt;br>
3.2 Ejercicios resueltos&lt;br>
3.3 Ejercicios propuestos&lt;br>
4 Regresión Lineal Simple y Correlación&lt;br>
4.1 Fundamentos teóricos&lt;br>
4.1.1 Regresión&lt;/p>
&lt;ul>
&lt;li>Rectas de regresión&lt;/li>
&lt;/ul>
&lt;p>4.1.2 Correlación&lt;/p>
&lt;ul>
&lt;li>Varianza residual&lt;/li>
&lt;li>Coeficiente de determinación&lt;/li>
&lt;li>Coeficiente de determinación lineal&lt;/li>
&lt;li>Coeficiente de correlación&lt;/li>
&lt;li>Fiabilidad de las predicciones&lt;/li>
&lt;/ul>
&lt;p>4.2 Ejercicios resueltos&lt;br>
4.3 Ejercicios propuestos&lt;br>
5 Regresión No Lineal&lt;br>
5.1 Fundamentos teóricos&lt;br>
5.2 Ejercicios resueltos&lt;br>
5.3 Ejercicios propuestos&lt;br>
6 Variables Aleatorias Discretas&lt;br>
6.1 Fundamentos teóricos&lt;br>
6.1.1 Variables aleatorias&lt;br>
6.1.2 Variables aleatorias discretas&lt;/p>
&lt;ul>
&lt;li>Función de probabilidad&lt;/li>
&lt;li>Función de distribución&lt;/li>
&lt;li>Estadísticos poblacionales&lt;/li>
&lt;/ul>
&lt;p>6.1.3 Variable Binomial&lt;br>
6.1.4 Variable de Poisson&lt;br>
6.2 Ejercicios resueltos&lt;br>
6.3 Ejercicios propuestos&lt;br>
7 Variables Aleatorias Continuas&lt;br>
7.1 Fundamentos teóricos&lt;br>
7.1.1 Variables aleatorias&lt;br>
7.1.2 Variables aleatorias continuas&lt;/p>
&lt;ul>
&lt;li>Función de densidad&lt;/li>
&lt;li>Función de distribución&lt;/li>
&lt;li>Estadísticos poblacionales&lt;/li>
&lt;/ul>
&lt;p>7.1.3 Distribución Uniforme Continua&lt;br>
7.1.4 Distribución Normal&lt;/p>
&lt;ul>
&lt;li>Distribución Chi-cuadrado&lt;/li>
&lt;/ul>
&lt;p>7.1.5 Distribución T de Student&lt;br>
7.1.6 Distribución F de Fisher-Snedecor&lt;br>
7.2 Ejercicios resueltos&lt;br>
7.3 Ejercicios propuestos&lt;br>
8 Intervalos de Confianza para Medias y Proporciones&lt;br>
8.1 Fundamentos teóricos&lt;br>
8.1.1 Inferencia estadística y estimación de parámetros&lt;br>
8.1.2 Intervalos de confianza&lt;br>
8.1.3 Intervalos de confianza para la media&lt;/p>
&lt;ul>
&lt;li>Intervalo de confianza para la media de una población normal con varianza conocida en muestras de cualquier tamaño&lt;/li>
&lt;li>Intervalo de confianza para la media de una población normal con varianza desconocida en muestras de cualquier tamaño&lt;/li>
&lt;li>Intervalo de confianza para la media de una población no normal, varianza conocida y muestras grandes&lt;/li>
&lt;li>Intervalo de confianza para la media de una población no normal, varianza desconocida y muestras grandes&lt;/li>
&lt;/ul>
&lt;p>8.1.4 Intervalos de confianza para una proporción poblacional&lt;br>
8.2 Ejercicios resueltos&lt;br>
8.3 Ejercicios propuestos&lt;br>
9 Intervalos de Confianza para Comparar Poblaciones&lt;br>
9.1 Fundamentos teóricos&lt;br>
9.1.1 Inferencia estadística aplicada a la comparación de poblaciones&lt;br>
9.1.2 Intervalos de confianza para la diferencia de medias de poblaciones independientes&lt;/p>
&lt;ul>
&lt;li>Intervalo de confianza para la diferencia de medias en poblaciones normales, con varianzas poblacionales conocidas, independientemente del tamaño de la muestra&lt;/li>
&lt;li>Intervalo de confianza para la diferencia de medias en poblaciones normales, con varianzas poblacionales desconocidas, independientemente del tamaño de la muestra&lt;/li>
&lt;li>Intervalo de confianza para la diferencia de medias en poblaciones no normales y muestras grandes&lt;/li>
&lt;/ul>
&lt;p>9.1.3 Intervalos de confianza para la media de la diferencia en poblaciones emparejadas&lt;br>
9.1.4 Intervalos de confianza para la diferencia de proporciones&lt;/p>
&lt;ul>
&lt;li>Intervalo de confianza para la razón de dos varianzas de poblaciones normales&lt;/li>
&lt;/ul>
&lt;p>9.2 Ejercicios resueltos&lt;br>
9.3 Ejercicios propuestos&lt;br>
10 Contraste de Hipótesis&lt;br>
10.1 Fundamentos teóricos&lt;br>
10.1.1Inferencia estadística y contrastes de hipótesis&lt;br>
10.1.2 Tipos de contrastes de hipótesis&lt;br>
10.1.3 Elementos de un contraste&lt;/p>
&lt;ul>
&lt;li>Hipótesis nula e hipótesis alternativa&lt;/li>
&lt;li>Errores en un contraste. Nivel de significación y potencia&lt;/li>
&lt;li>Estadístico del contraste y regiones de aceptación y rechazo&lt;/li>
&lt;li>El p-valor de un contraste&lt;/li>
&lt;/ul>
&lt;p>10.1.4 Contrastes para la media de una población&lt;/p>
&lt;ul>
&lt;li>Contraste para la media de una población normal con varianza conocida&lt;/li>
&lt;li>Contraste para la media de una población normal con varianza desconocida&lt;/li>
&lt;/ul>
&lt;p>10.1.5 Contrastes para una proporción de una población&lt;/p>
&lt;ul>
&lt;li>Contraste para la proporción en muestras grandes y distribuciones simétricas&lt;/li>
&lt;/ul>
&lt;p>10.1.6Contrastes para la varianza de una población&lt;/p>
&lt;ul>
&lt;li>Contraste para la varianza de una población normal&lt;/li>
&lt;/ul>
&lt;p>10.1.7 Contrastes para la comparación de medias poblacionales&lt;/p>
&lt;ul>
&lt;li>Contraste para la comparación de medias de poblaciones normales con varianzas conocidas&lt;/li>
&lt;li>Contraste para la comparación de medias de poblaciones normales con varianzas desconocidas&lt;/li>
&lt;/ul>
&lt;p>10.1.8 Contrastes para la comparación de proporciones poblacionales&lt;/p>
&lt;ul>
&lt;li>Contraste para la comparación de proporciones en muestras grandes y distribuciones simétricas&lt;/li>
&lt;/ul>
&lt;p>10.1.9Contrastes para la comparación de varianzas poblacionales&lt;/p>
&lt;ul>
&lt;li>Contraste para la comparación de varianzas de poblaciones normales&lt;/li>
&lt;/ul>
&lt;p>10.2 Ejercicios resueltos&lt;br>
10.3 Ejercicios propuestos&lt;br>
11 Análisis de la Varianza de un Factor&lt;br>
11.1 Fundamentos teóricos&lt;br>
11.1.1 El contraste de ANOVA&lt;/p>
&lt;ul>
&lt;li>Tabla de ANOVA&lt;/li>
&lt;/ul>
&lt;p>11.1.2 Test de comparaciones múltiples y por parejas&lt;br>
11.2 Ejercicios resueltos&lt;br>
11.3 Ejercicios propuestos&lt;br>
12 Contrastes de Hipótesis No Paramétricos&lt;br>
12.1 Fundamentos teóricos&lt;br>
12.1.1 Contrastes no paramétricos más habituales&lt;br>
12.1.2 Aleatoriedad de una muestra: Contraste de rachas&lt;br>
12.1.3 Contrastes de normalidad&lt;/p>
&lt;ul>
&lt;li>Estadísticos de asimetría y curtosis&lt;/li>
&lt;li>Contraste de Kolmogorov-Smirnov y corrección de Lilliefors&lt;/li>
&lt;li>Contraste de Shapiro-Wilk&lt;/li>
&lt;li>Gráficos Q-Q y P-P de comparación con la distribución normal&lt;/li>
&lt;/ul>
&lt;p>12.1.4 Contraste de la U de Mann-Whitney para la comparación de dos poblaciones independientes&lt;br>
12.1.5 Contraste de Wilcoxon para la comparación de dos poblaciones emparejadas&lt;br>
12.1.6 Contraste de Kruskal-Wallis para la comparación de varias poblaciones independientes&lt;br>
12.1.7 Contraste de Friedman para la comparación de medidas repetidas&lt;br>
12.1.8 Contraste de Levene para la comparación de varianzas&lt;br>
12.1.9 El coeficiente de correlación de Spearman&lt;br>
12.2 Ejercicios resueltos&lt;br>
12.3 Ejercicios propuestos&lt;br>
13 Contrastes Basados en el Estadístico Chi-cuadrado&lt;br>
13.1 Fundamentos teóricos&lt;br>
13.1.1 Contraste Chi-cuadrado de Pearson para ajuste de distribuciones&lt;br>
13.1.2 Contraste Chi-cuadrado en tablas de contingencia&lt;br>
13.1.3 Contraste exacto de Fisher&lt;br>
13.1.4 Contraste de McNemar para datos emparejados&lt;br>
13.2 Ejercicios Resueltos&lt;br>
13.3 Ejercicios propuestos&lt;br>
14 Análisis de Concordancia&lt;br>
14.1 Fundamentos teóricos&lt;br>
14.1.1 Introducción&lt;br>
14.1.2 Concordancia entre dos variables cuantitativas: Coeficiente de correlación intraclase&lt;br>
14.1.3 Concordancia entre dos variables cualitativas: Kappa de Cohen&lt;br>
14.1.4 Concordancia entre dos variables cualitativas ordinales: Kappa ponderado&lt;br>
14.2 Ejercicios resueltos&lt;br>
14.3 Ejercicios propuestos&lt;/p>
&lt;h2 id="autores">Autores&lt;/h2>
&lt;p>Santiago Angulo Díaz Parreño&lt;br>
José Miguel Cárdenas Rebollo&lt;br>
Anselomo Romero Limón&lt;br>
Alfredo Sánchez Alberca&lt;/p>
&lt;p>Los autores son profesores del Departamento de Matemática Aplicada y Estadística de la Universidad CEU San Pablo.
Imparten las asignaturas de Matemáticas y Estadística en las facultades de Farmacia y Medicina.
Son miembros de la Unidad de Bioestadística de esta universidad en la que han realizado multitud de trabajos de investigación aplicados a las Ciencias de la Salud.&lt;/p>
&lt;h2 id="capítulo-de-muestra">Capítulo de muestra&lt;/h2>
&lt;p>Descarga el siguiente capítulo de muestra para tener una idea del contenido del libro.&lt;/p>
&lt;ul>
&lt;li>
&lt;a href="capitulo_regresion.pdf">Regresión Lineal Simple y Correlación&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="dónde-adquirirlo">¿Dónde adquirirlo?&lt;/h2>
&lt;p>El libro puede adquirirse en la página web de
&lt;a href="https://www.ceuediciones.es/catalogo/libros/medicina/bioestadistica-aplicada-con-spss/" target="_blank" rel="noopener">CEU Ediciones&lt;/a>.&lt;/p></description></item><item><title>Tipos de estudios estadísticos</title><link>/docencia/r/estudios-estadisticos/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/docencia/r/estudios-estadisticos/</guid><description>&lt;p>El tipo de estudio estadístico más apropiado en cada caso depende de varios factores:&lt;/p>
&lt;ul>
&lt;li>El objetivo del estudio.&lt;/li>
&lt;li>El número de variables que intervienen.&lt;/li>
&lt;li>El tipo de las variables dependientes e independientes.&lt;/li>
&lt;li>La naturaleza de las observaciones (independientes o emparejadas).&lt;/li>
&lt;/ul>
&lt;p>A continuación se presentan los estudios estadísticos más habituales en función de estos factores. La siguiente tabla puede ayudar a identificar el más apropiado en cada caso.&lt;/p>
&lt;table width="1054" cellspacing="0" cellpadding="5" border="1">
&lt;tbody>
&lt;tr>
&lt;td bgcolor="#6d9eeb" width="95">
&lt;p>&lt;strong>Variables independientes&lt;/strong>&lt;/p>
&lt;/td>
&lt;td bgcolor="#6d9eeb" width="88">
&lt;p>&lt;strong>Variable dependiente&lt;/strong>&lt;/p>
&lt;/td>
&lt;td bgcolor="#6d9eeb" width="315">
&lt;p>&lt;strong>Objetivo&lt;/strong>&lt;/p>
&lt;/td>
&lt;td bgcolor="#6d9eeb" width="330">
&lt;p>&lt;strong>Ejemplo&lt;/strong>&lt;/p>
&lt;/td>
&lt;td bgcolor="#6d9eeb" width="174">
&lt;p>&lt;strong>Contraste&lt;/strong>&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td rowspan="6" width="95" height="14">
&lt;p>Ninguna&lt;br /> (Una poblaci&amp;oacute;n)&lt;/p>
&lt;/td>
&lt;td rowspan="2" width="88">
&lt;p>Cuantitativa&lt;/p>
&lt;/td>
&lt;td rowspan="2" width="315">
&lt;p>Contrastar la normalidad de una variable&lt;/p>
&lt;/td>
&lt;td rowspan="2" width="330">
&lt;p>Comprobar si la nota de un examen tiene distribuci&amp;oacute;n normal (forma de campana de Gauss)&lt;/p>
&lt;/td>
&lt;td width="174">
&lt;p>Komogorov-Smirnov&lt;br /> (requiere muestras grandes)&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td width="174">
&lt;p>Shapiro-Willks&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td width="88">
&lt;p>Cuantitativa normal&lt;/p>
&lt;/td>
&lt;td width="315">
&lt;p>Contrastar si la media poblacional de una variable tiene un valor determinado&lt;/p>
&lt;/td>
&lt;td width="330">
&lt;p>Comprobar si la nota media de un examen es 5&lt;/p>
&lt;/td>
&lt;td width="174">
&lt;p>Test T para la media de una poblaci&amp;oacute;n&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td width="88">
&lt;p>Cuantitativa o cualitativa ordinal&lt;/p>
&lt;/td>
&lt;td width="315">
&lt;p>Contrastar si la mediana poblacional de una variable tiene un valor determinado&lt;/p>
&lt;/td>
&lt;td width="330">
&lt;p>Comprobar si la calificaci&amp;oacute;n mediana de un examen es Aprobado&lt;/p>
&lt;/td>
&lt;td width="174">
&lt;p>Test para la mediana de una poblaci&amp;oacute;n&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td width="88">
&lt;p>Cualitativa (2 categor&amp;iacute;as)&lt;/p>
&lt;/td>
&lt;td width="315">
&lt;p>Contrastar si la proporci&amp;oacute;n poblacional de una de las categor&amp;iacute;as tiene un valor determinado&lt;/p>
&lt;/td>
&lt;td width="330">
&lt;p>Comprobar si la proporci&amp;oacute;n de aprobados es de la mitad (o que el porcentaje es 50%)&lt;/p>
&lt;/td>
&lt;td width="174">
&lt;p>Test Binomial&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td width="88">
&lt;p>Cualitativa&lt;/p>
&lt;/td>
&lt;td width="315">
&lt;p>Contrastar si las proporciones de cada una de las categor&amp;iacute;as tienen un valor determinado&lt;/p>
&lt;/td>
&lt;td width="330">
&lt;p>Comprobar si las proporciones de alumnos matriculados en ciencias, letras o mixtas son 0.5, 0.2 y 0.3 respectivamente&lt;/p>
&lt;/td>
&lt;td width="174">
&lt;p>Test Chi-cuadrado de bondad de ajuste&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td rowspan="7" width="95" height="13">
&lt;p>Una cualitativa con dos categor&amp;iacute;as independientes &lt;br /> (Dos poblaciones independientes)&lt;/p>
&lt;/td>
&lt;td rowspan="3" width="88">
&lt;p>Cuantitativa normal&lt;/p>
&lt;/td>
&lt;td width="315">
&lt;p>Contrastar si hay diferencias entre las medias la variable dependiente en dos poblaciones independientes&lt;/p>
&lt;/td>
&lt;td width="330">
&lt;p>Comprobar si el grupo de ma&amp;ntilde;ana y el grupo de tarde han tenido notas medias diferentes&lt;/p>
&lt;/td>
&lt;td width="174">
&lt;p>Test T para la comparaci&amp;oacute;n de medias de poblaciones independientes&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td width="315">
&lt;p>Contrastar si hay diferencias entre las varianzas de la variable dependiente en dos poblaciones independientes&lt;/p>
&lt;/td>
&lt;td width="330">
&lt;p>Comprobar si hay diferencias entre la variabilidad de las notas del grupo de ma&amp;ntilde;ana y el de tarde&lt;/p>
&lt;/td>
&lt;td width="174">
&lt;p>Test F de Fisher&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td width="315">
&lt;p>Contrastar si hay concordancia o acuerdo entre las dos variables&lt;/p>
&lt;/td>
&lt;td width="330">
&lt;p>Comprobar si hay concordancia o acuerdo entre las notas que ponen dos profesores distintos para los mismos ex&amp;aacute;menes&lt;/p>
&lt;/td>
&lt;td width="174">
&lt;p>Correlaci&amp;oacute;n intraclase&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td rowspan="2" width="88">
&lt;p>Cuantitativa o cualitativa ordinal&lt;/p>
&lt;/td>
&lt;td width="315">
&lt;p>Contrastar si hay diferencias entre las distribuciones de la variable dependiente en dos poblaciones independientes&lt;/p>
&lt;/td>
&lt;td width="330">
&lt;p>Comprobar si el grupo de ma&amp;ntilde;ana y el grupo de tarde han tenido calificaciones diferentes&lt;/p>
&lt;/td>
&lt;td width="174">
&lt;p>Test de la U de Mann-Whitney&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td width="315">
&lt;p>Contrastar si hay concordancia o acuerdo entre las dos variables&lt;/p>
&lt;/td>
&lt;td width="330">
&lt;p>Comprobar si hay concordancia o acuerdo entre las calificaciones que ponen dos profesores distintos para los mismos ex&amp;aacute;menes&lt;/p>
&lt;/td>
&lt;td width="174">
&lt;p>Kappa de Cohen&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td rowspan="2" width="88">
&lt;p>Cualitativa&lt;/p>
&lt;/td>
&lt;td width="315">
&lt;p>Contrastar si hay relaci&amp;oacute;n entre las dos variables o bien si hay diferencias entre las proporciones de las categor&amp;iacute;as de la variable dependiente en las dos poblaciones definidas por las categor&amp;iacute;as de la variable independiente&lt;/p>
&lt;/td>
&lt;td width="330">
&lt;p>Comprobar si existe relaci&amp;oacute;n entre los aprobados en una asignatura y el grupo al que pertenecen los alumnos, es decir, si la proporci&amp;oacute;n de aprobados es diferente en dos grupos distintos.&lt;/p>
&lt;/td>
&lt;td width="174">
&lt;p>Test Chi-cuadrado &lt;br /> (si no ha m&amp;aacute;s del 20% de frecuencias esperadas menores que 5)&lt;br /> Test exacto de Fisher&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td width="315">
&lt;p>Contrastar si hay concordancia o acuerdo entre las dos variables&lt;/p>
&lt;/td>
&lt;td width="330">
&lt;p>Comprobar si hay concordancia o acuerdo entre la valoraci&amp;oacute;n (aprobado o suspenso) que hacen dos profesores distintos para los mismos ex&amp;aacute;menes&lt;/p>
&lt;/td>
&lt;td width="174">
&lt;p>Kappa de Cohen&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td rowspan="3" width="95" height="14">
&lt;p>Una cualitativa con dos categor&amp;iacute;as relacionadas o pareadas&lt;br /> (Dos poblaciones relacionadas o pareadas)&lt;/p>
&lt;/td>
&lt;td width="88">
&lt;p>Cuantitativa normal&lt;/p>
&lt;/td>
&lt;td width="315">
&lt;p>Contrastar si hay diferencias entre las medias de la variable dependiente en dos poblaciones relacionadas o pareadas&lt;/p>
&lt;/td>
&lt;td width="330">
&lt;p>Comprobar si las notas medias de dos asignaturas cursadas por los mismos alumnos han sido diferentes o si las notas medias de un examen realizado al comienzo del curso (antes) y otro al final (despu&amp;eacute;s) de una misma asignatura han sido diferentes&lt;/p>
&lt;/td>
&lt;td width="174">
&lt;p>Test T para la comparaci&amp;oacute;n de medias de poblaciones relacionadas o pareadas&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td width="88">
&lt;p>Cuantitativa o cualitativa ordinal&lt;/p>
&lt;/td>
&lt;td width="315">
&lt;p>Contrastar si hay diferencias entre las distribuciones de la variable dependiente en dos poblaciones relacionadas o pareadas&lt;/p>
&lt;/td>
&lt;td width="330">
&lt;p>Comprobar si las calificaciones de dos asignaturas cursadas por los mismos alumnos han sido diferentes&lt;/p>
&lt;/td>
&lt;td width="174">
&lt;p>Test de Wilcoxon&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td width="88">
&lt;p>Cualitativa con dos categor&amp;iacute;as&lt;/p>
&lt;/td>
&lt;td width="315">
&lt;p>Contrastar si hay diferencias entre las proporciones de las categor&amp;iacute;as de la variable dependiente en dos poblaciones relacionadas o pareadas&lt;/p>
&lt;/td>
&lt;td width="330">
&lt;p>Comprobar si la proporci&amp;oacute;n o el porcentaje de aprobados en un examen es distinta al comienzo y al final del curso&lt;/p>
&lt;/td>
&lt;td width="174">
&lt;p>Test de McNemar&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td rowspan="4" width="95" height="14">
&lt;p>Una cualitativa con dos o m&amp;aacute;s categor&amp;iacute;as&lt;/p>
&lt;p>independientes&lt;br /> (Dos o m&amp;aacute;s poblaciones independientes)&lt;/p>
&lt;/td>
&lt;td width="88">
&lt;p>Cuantitativa normal y homogeneidad de varianzas&lt;/p>
&lt;/td>
&lt;td width="315">
&lt;p>Contrastar si hay diferencias entre las medias la variable dependiente en cada una de las poblaciones definidas por las categor&amp;iacute;as de la variable independiente&lt;/p>
&lt;/td>
&lt;td width="330">
&lt;p>Comprobar si existen diferencias entre las notas medias de tres grupos distintos de clase.&lt;/p>
&lt;/td>
&lt;td width="174">
&lt;p>An&amp;aacute;lisis de la Varianza de un factor (ANOVA)&lt;br /> Si hay diferencias &amp;gt; Test de Tukey o Bonferroni para la diferencia por pares&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td width="88">
&lt;p>Cuantitativa normal&lt;/p>
&lt;/td>
&lt;td width="315">
&lt;p>Contrastar si hay diferencias entre las varianzas de la variable dependiente en cada una de las poblaciones definidas por las categor&amp;iacute;as de la variable independiente&lt;/p>
&lt;/td>
&lt;td width="330">
&lt;p>Comprobar si la variabilidad de las notas de una asignatura es distinta en tres grupos diferentes de clase&lt;/p>
&lt;/td>
&lt;td width="174">
&lt;p>Prueba de Levene para la homogeneidad de varianzas&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td width="88">
&lt;p>Cuantitativa o cualitativa ordinal&lt;/p>
&lt;/td>
&lt;td width="315">
&lt;p>Contrastar si hay diferencias entre las distribuciones de la variable dependiente en cada una de las poblaciones definidas por las categor&amp;iacute;as de la variable independiente&lt;/p>
&lt;/td>
&lt;td width="330">
&lt;p>Comprobar si existen diferencias entre las calificaciones de tres grupos distintos de clase&lt;/p>
&lt;/td>
&lt;td width="174">
&lt;p>Test de Kruskal Wallis&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td width="88">
&lt;p>Cualitativa&lt;/p>
&lt;/td>
&lt;td width="315">
&lt;p>Contrastar si hay relaci&amp;oacute;n entre las dos variables o bien si hay diferencias entre las proporciones de las categor&amp;iacute;as de la variable dependiente en cada una de las poblaciones definidas por las categor&amp;iacute;as de la variable independiente&lt;/p>
&lt;/td>
&lt;td width="330">
&lt;p>Comprobar si existe relaci&amp;oacute;n entre los aprobados en una asignatura y el grupo al que pertenecen los alumnos, es decir, si la proporci&amp;oacute;n de aprobados es diferente en los distintos grupos.&lt;/p>
&lt;/td>
&lt;td width="174">
&lt;p>Test Chi-cuadrado &lt;br /> (si no ha m&amp;aacute;s del 20% de frecuencias esperadas menores que 5)&lt;br /> Test exacto de Fisher&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td rowspan="3" width="95" height="14">
&lt;p>Una cualitativa con dos o m&amp;aacute;s categor&amp;iacute;as relacionadas &lt;br /> (medidas repetidas)&lt;/p>
&lt;/td>
&lt;td width="88">
&lt;p>Cuantitativa normal&lt;/p>
&lt;/td>
&lt;td width="315">
&lt;p>Contrastar si hay diferencias entre las medias repetidas de la variable dependiente&lt;/p>
&lt;/td>
&lt;td width="330">
&lt;p>Comprobar si hay diferencias entre las notas que otorgan varios profesores a un mismo examen&lt;/p>
&lt;/td>
&lt;td width="174">
&lt;p>An&amp;aacute;lisis de la Varianza (ANOVA) de medidas repetidas de un factor&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td width="88">
&lt;p>Cuantitativa o cualitativa ordinal&lt;/p>
&lt;/td>
&lt;td width="315">
&lt;p>Contrastar si hay diferencias entre las medidas repetidas de la variable dependiente&lt;/p>
&lt;/td>
&lt;td width="330">
&lt;p>Comprobar si hay diferencias entre las calificaciones que otorgan varios profesores a un mismo examen&lt;/p>
&lt;/td>
&lt;td width="174">
&lt;p>Test de Friedman&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td width="88">
&lt;p>Cualitativa&lt;/p>
&lt;/td>
&lt;td width="315">
&lt;p>Contrastar si hay diferencias entre las valoraciones repetidas de la variable dependiente&lt;/p>
&lt;/td>
&lt;td width="330">
&lt;p>Comprobar si hay diferencias entre la valoraci&amp;oacute;n (aprobado o suspenso) que hacen varios profesores de un mismo examen&lt;/p>
&lt;/td>
&lt;td width="174">
&lt;p>Regresi&amp;oacute;n log&amp;iacute;stica de medidas repetidas&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td rowspan="4" width="95" height="13">
&lt;p>Una cuantitativa normal&lt;/p>
&lt;/td>
&lt;td rowspan="2" width="88">
&lt;p>Cuantitativa normal&lt;/p>
&lt;/td>
&lt;td width="315">
&lt;p>Contrastar si existe relaci&amp;oacute;n lineal entre las dos variables&lt;/p>
&lt;/td>
&lt;td width="330">
&lt;p>Comprobar si existe relaci&amp;oacute;n entre las notas de dos asignaturas&lt;/p>
&lt;/td>
&lt;td width="174">
&lt;p>Correlaci&amp;oacute;n de Pearson&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td width="315">
&lt;p>Construir un modelo predictivo que explique la variable dependiente en funci&amp;oacute;n de la independiente&lt;/p>
&lt;/td>
&lt;td width="330">
&lt;p>Construir el modelo (funci&amp;oacute;n de regresi&amp;oacute;n) que mejor explique la relaci&amp;oacute;n entre la nota de un examen y las horas dedicadas a su estudio&lt;/p>
&lt;/td>
&lt;td width="174">
&lt;p>Regresi&amp;oacute;n simple (lineal o no lineal)&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td width="88">
&lt;p>Cuantitativa o cualitativa ordinal&lt;/p>
&lt;/td>
&lt;td width="315">
&lt;p>Contrastar si existe relaci&amp;oacute;n lineal entre las dos variables&lt;/p>
&lt;/td>
&lt;td width="330">
&lt;p>Comprobar si existe relaci&amp;oacute;n entre las calificaciones de dos asignaturas&lt;/p>
&lt;/td>
&lt;td width="174">
&lt;p>Correlaci&amp;oacute;n de Spearman&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td width="88">
&lt;p>Cualitativa&lt;/p>
&lt;/td>
&lt;td width="315">
&lt;p>Construir un modelo predictivo que explique la variable dependiente en funci&amp;oacute;n de la independiente&lt;/p>
&lt;/td>
&lt;td width="330">
&lt;p>Construir el modelo (funci&amp;oacute;n log&amp;iacute;stica) que mejor explique la relaci&amp;oacute;n entre el resultado de un examen (aprobado o suspenso) y las horas dedicadas a su estudio&lt;/p>
&lt;/td>
&lt;td width="174">
&lt;p>Regresi&amp;oacute;n log&amp;iacute;stica simple&lt;/p>
&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>Los ejemplos de los distintos test que se presentan a continuación se han realizado a partir del siguiente conjunto de datos que contiene las notas y calificaciones de un curso. El fichero con los datos puede descargarse aquí para reproducir los estudios:
&lt;a href="datos/datos-curso.csv">datos-curso.csv&lt;/a>&lt;/p>
&lt;pre>&lt;code class="language-r">library(tidyverse)
&lt;/code>&lt;/pre>
&lt;h2 id="una-variable-cuantitativa">Una variable cuantitativa&lt;/h2>
&lt;h3 id="estudios-descriptivos">Estudios descriptivos&lt;/h3>
&lt;h4 id="estadísticos">Estadísticos&lt;/h4>
&lt;ul>
&lt;li>Tamaño muestral&lt;/li>
&lt;li>Media&lt;/li>
&lt;li>Desviación típica&lt;/li>
&lt;li>Mínimo, Máximo&lt;/li>
&lt;li>Cuartiles&lt;/li>
&lt;li>Coeficiente de asimetría&lt;/li>
&lt;li>Coeficiente de apuntamiento&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-r"># Tamaño muestral
nrow(df)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## [1] 120
&lt;/code>&lt;/pre>
&lt;pre>&lt;code class="language-r"># Media
mean(df$notaA, na.rm = TRUE)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## [1] 6.028333
&lt;/code>&lt;/pre>
&lt;pre>&lt;code class="language-r"># Desviación típica
sd(df$notaA, na.rm = TRUE)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## [1] 1.340524
&lt;/code>&lt;/pre>
&lt;pre>&lt;code class="language-r"># Min, max
min(df$notaA, na.rm = TRUE)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## [1] 2.5
&lt;/code>&lt;/pre>
&lt;pre>&lt;code class="language-r">max(df$notaA, na.rm = TRUE)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## [1] 9.3
&lt;/code>&lt;/pre>
&lt;pre>&lt;code class="language-r"># Cuartiles
quantile(df$notaA, c(0.25, 0.5, 0.75), na.rm = TRUE)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## 25% 50% 75%
## 5.100 5.900 6.825
&lt;/code>&lt;/pre>
&lt;pre>&lt;code class="language-r"># Coef. asimetría
library(moments)
skewness(df$notaA, na.rm = TRUE)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## [1] 0.1373915
&lt;/code>&lt;/pre>
&lt;pre>&lt;code class="language-r"># Coef. apuntamiento
kurtosis(df$notaA, na.rm = TRUE) - 3
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## [1] -0.102287
&lt;/code>&lt;/pre>
&lt;h4 id="gráficos">Gráficos&lt;/h4>
&lt;ul>
&lt;li>Diagrama de barras (variables discretas)&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-r">df %&amp;gt;% ggplot(aes(x = asinaturas.aprobadas)) +
geom_bar(fill=&amp;quot;#00BFC4&amp;quot;) +
# Cambio de escala del eje X
scale_x_discrete(limits=0:5)
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="img/one-quantitative-variable-bar-chart-1.svg" alt="">&amp;lt;!&amp;ndash; &amp;ndash;&amp;gt;&lt;/p>
&lt;ul>
&lt;li>Histograma&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-r">library(ggplot2)
# Límites de los intervalos
breaks = 0:10
# Histograma de las notasA
df %&amp;gt;% ggplot(aes(x = notaA)) +
geom_histogram(breaks = breaks, fill=&amp;quot;#00BFC4&amp;quot;) +
# Cambio de escala del eje X
scale_x_continuous(limits=c(0, 10), breaks = 0:10)
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="img/one-quantitative-variable-histogram-1.svg" alt="">&amp;lt;!&amp;ndash; &amp;ndash;&amp;gt;&lt;/p>
&lt;pre>&lt;code class="language-r"># Histograma de notasE
df %&amp;gt;% ggplot(aes(x = notaE)) +
geom_histogram(breaks = breaks, fill=&amp;quot;#00BFC4&amp;quot;) +
# Cambio de escala del eje X
scale_x_continuous(limits=c(0, 10), breaks = 0:10)
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="img/one-quantitative-variable-histogram-2.svg" alt="">&amp;lt;!&amp;ndash; &amp;ndash;&amp;gt;&lt;/p>
&lt;ul>
&lt;li>Diagrama de líneas&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-r"># Variables discretas
df %&amp;gt;% count(asinaturas.aprobadas) %&amp;gt;%
ggplot(aes(x = asinaturas.aprobadas, y = n)) +
geom_line(col=&amp;quot;#00BFC4&amp;quot;) +
# Cambio de escala del eje X
scale_x_discrete(limits=0:5)
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="img/one-quantitative-variable-line-chart-1.svg" alt="">&amp;lt;!&amp;ndash; &amp;ndash;&amp;gt;&lt;/p>
&lt;pre>&lt;code class="language-r"># Agrupación de datos en intervalos
df %&amp;gt;% ggplot(aes(x = notaA)) +
geom_freqpoly(breaks = breaks, col=&amp;quot;#00BFC4&amp;quot;) +
# Cambio de escala del eje X
scale_x_continuous(limits=c(0, 10), breaks = 0:10)
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="img/one-quantitative-variable-line-chart-2.svg" alt="">&amp;lt;!&amp;ndash; &amp;ndash;&amp;gt;&lt;/p>
&lt;ul>
&lt;li>Diagrama de caja y bigotes&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-r">df %&amp;gt;% ggplot(aes(x = notaA)) +
geom_boxplot(fill=&amp;quot;#00BFC4&amp;quot;) +
# Cambio de escala del eje X
scale_x_continuous(limits=c(0, 10), breaks = 0:10)
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="img/one-quantitative-variable-box-plot-1.svg" alt="">&amp;lt;!&amp;ndash; &amp;ndash;&amp;gt;&lt;/p>
&lt;h3 id="estudios-inferenciales">Estudios inferenciales&lt;/h3>
&lt;h4 id="test-de-normalidad-de-shapiro-wilk">Test de normalidad de Shapiro-Wilk&lt;/h4>
&lt;p>&lt;strong>Objetivo&lt;/strong>: Comprobar la normalidad de la distribución.&lt;/p>
&lt;p>&lt;strong>Hipótesis nula&lt;/strong>: La distribución es normal.&lt;/p>
&lt;pre>&lt;code class="language-r">shapiro.test(df$notaA)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>##
## Shapiro-Wilk normality test
##
## data: df$notaA
## W = 0.99424, p-value = 0.907
&lt;/code>&lt;/pre>
&lt;pre>&lt;code class="language-r">shapiro.test(df$notaE)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>##
## Shapiro-Wilk normality test
##
## data: df$notaE
## W = 0.92264, p-value = 4.065e-06
&lt;/code>&lt;/pre>
&lt;h4 id="test-t-para-la-media-de-una-población">Test t para la media de una población&lt;/h4>
&lt;p>&lt;strong>Objetivo&lt;/strong>: Estimar la media de una variable o compararla con un valor
dado &lt;em>μ&lt;/em>&lt;sub>0&lt;/sub>.&lt;/p>
&lt;p>&lt;strong>Requisitos&lt;/strong>:&lt;/p>
&lt;ul>
&lt;li>Una variable cuantitativa.&lt;/li>
&lt;li>Distribución normal o tamaño muestral ≥ 30.&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Hipótesis nula&lt;/strong>: La media de la población es igual a &lt;em>μ&lt;/em>&lt;sub>0&lt;/sub>.&lt;/p>
&lt;p>&lt;strong>Ejemplo&lt;/strong>: Comprobar si la nota media de un examen es diferente de 5.&lt;/p>
&lt;pre>&lt;code class="language-r">t.test(df$notaA, mu = 5, alternative = &amp;quot;two.sided&amp;quot;)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>##
## One Sample t-test
##
## data: df$notaA
## t = 8.4033, df = 119, p-value = 1.08e-13
## alternative hypothesis: true mean is not equal to 5
## 95 percent confidence interval:
## 5.786023 6.270643
## sample estimates:
## mean of x
## 6.028333
&lt;/code>&lt;/pre>
&lt;h2 id="una-variable-cualitativa">Una variable cualitativa&lt;/h2>
&lt;h3 id="estudios-descriptivos-1">Estudios descriptivos&lt;/h3>
&lt;h4 id="estadísticos-1">Estadísticos&lt;/h4>
&lt;ul>
&lt;li>Tamaños muestral&lt;/li>
&lt;li>Frecuencias muestrales&lt;/li>
&lt;li>Proporciones/porcentajes muestrales&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-r"># Tamaño muestral sin datos perdidos
length(na.omit(df$calificacionB))
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## [1] 115
&lt;/code>&lt;/pre>
&lt;pre>&lt;code class="language-r"># Frecuencias
table(df$calificacionB)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>##
## Aprobado Suspenso
## 98 17
&lt;/code>&lt;/pre>
&lt;pre>&lt;code class="language-r"># Proporciones
table(df$calificacionB) / length(na.omit(df$calificacionB))
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>##
## Aprobado Suspenso
## 0.8521739 0.1478261
&lt;/code>&lt;/pre>
&lt;pre>&lt;code class="language-r"># Porcentajes
table(df$calificacionB) / length(na.omit(df$calificacionB)) * 100
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>##
## Aprobado Suspenso
## 85.21739 14.78261
&lt;/code>&lt;/pre>
&lt;h4 id="gráficos-1">Gráficos&lt;/h4>
&lt;ul>
&lt;li>Diagrama de sectores&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-r">df %&amp;gt;% ggplot(aes(x = &amp;quot;&amp;quot;, fill = calificacionA)) +
geom_bar() +
# Cambiar a coordenadas polares
coord_polar(theta = &amp;quot;y&amp;quot;) +
# Eliminar ejes
theme_void()
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="img/piechart-1.svg" alt="">&amp;lt;!&amp;ndash; &amp;ndash;&amp;gt;&lt;/p>
&lt;h3 id="estudios-inferenciales-1">Estudios inferenciales&lt;/h3>
&lt;h4 id="test-binomial-para-una-proporción-de-una-población">Test binomial para una proporción de una población&lt;/h4>
&lt;p>&lt;strong>Objetivo&lt;/strong>: Estimar la propoción de una categoría en una población o
compararla con un valor &lt;em>p&lt;/em>&lt;sub>0&lt;/sub>.&lt;/p>
&lt;p>&lt;strong>Requisitos&lt;/strong>:&lt;/p>
&lt;ul>
&lt;li>One variable cualitativa&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Hipótesis nula&lt;/strong>: La proporción poblacional es igual a
&lt;em>p&lt;/em>&lt;sub>0&lt;/sub>.&lt;/p>
&lt;p>&lt;strong>Ejemplo&lt;/strong>: Comprobar si la proporción de aprobados es mayor de 0.5.&lt;/p>
&lt;pre>&lt;code class="language-r">freq &amp;lt;- table(df$calificacionA)[&amp;quot;Aprobado&amp;quot;]
binom.test(freq, n, p = 0.7, alternative = &amp;quot;greater&amp;quot;)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>##
## Exact binomial test
##
## data: freq and n
## number of successes = 94, number of trials = 120, p-value = 0.02657
## alternative hypothesis: true probability of success is greater than 0.7
## 95 percent confidence interval:
## 0.7123183 1.0000000
## sample estimates:
## probability of success
## 0.7833333
&lt;/code>&lt;/pre>
&lt;h4 id="test-z-para-la-proporción-de-una-población">Test Z para la proporción de una población&lt;/h4>
&lt;p>&lt;strong>Objetivo&lt;/strong>: Estimar la propoción de una categoría en una población o
compararla con un valor &lt;em>p&lt;/em>&lt;sub>0&lt;/sub>.&lt;/p>
&lt;p>&lt;strong>Requisitos&lt;/strong>:&lt;/p>
&lt;ul>
&lt;li>Una variable cualitativa&lt;/li>
&lt;li>Tamaño muestral &amp;gt;= 30&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Observación&lt;/strong>: Utiliza la aproximación normal de la distribución
Binomal.&lt;/p>
&lt;p>&lt;strong>Ejemplo&lt;/strong>: Comprobar si la proporción de aprobados es mayor de 0.5.&lt;/p>
&lt;pre>&lt;code class="language-r">freq &amp;lt;- table(df$calificacionA)[&amp;quot;Aprobado&amp;quot;]
prop.test(freq, n, p = 0.7, alternative = &amp;quot;greater&amp;quot;)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>##
## 1-sample proportions test with continuity correction
##
## data: freq out of n, null probability 0.7
## X-squared = 3.5813, df = 1, p-value = 0.02922
## alternative hypothesis: true p is greater than 0.7
## 95 percent confidence interval:
## 0.7111099 1.0000000
## sample estimates:
## p
## 0.7833333
&lt;/code>&lt;/pre>
&lt;h2 id="dos-variables-variable-dependiente-cuantitativa-y-variable-independiente-culitativa-con-dos-categorías-o-grupos">Dos variables: Variable dependiente cuantitativa y variable independiente culitativa con dos categorías o grupos&lt;/h2>
&lt;h3 id="estudios-descriptivos-2">Estudios descriptivos&lt;/h3>
&lt;h4 id="estadísticos-2">Estadísticos&lt;/h4>
&lt;ul>
&lt;li>Tamaño muestral de cada grupo&lt;/li>
&lt;li>Media de cada grupo&lt;/li>
&lt;li>Desviación típica de cada grupo&lt;/li>
&lt;li>Mínimo, Máximo de cada grupo&lt;/li>
&lt;li>Cuartiles de cada grupo&lt;/li>
&lt;li>Coeficiente de asimetría de cada grupo&lt;/li>
&lt;li>Coeficiente de apuntamiento de cada grupo&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-r"># Tamaño muestral de notaA según el sexo
df %&amp;gt;% group_by(sexo) %&amp;gt;% group_size()
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## [1] 71 49
&lt;/code>&lt;/pre>
&lt;pre>&lt;code class="language-r"># Media, Desviación típica, Mín, Máx, Cuartiles, Coef. Asimetría y Coef. Apuntamiento
library(moments)
df %&amp;gt;% group_by(sexo) %&amp;gt;% summarize(Media = mean(notaA, na.rm=TRUE), Des.Tip = sd(notaA, na.rm = TRUE), Mín = min(notaA), Máx = max(notaA), C1 = quantile(notaA, 0.25, na.rm = TRUE), C2 = quantile(notaA, 0.5, na.rm = TRUE), C3 = quantile(notaA, 0.75, na.rm = TRUE), Coef.Asimetría = skewness(notaA, na.rm = TRUE), Coef.Apuntamiento = kurtosis(notaA, na.rm = TRUE) - 3)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## # A tibble: 2 x 10
## sexo Media Des.Tip Mín Máx C1 C2 C3 Coef.Asimetría
## &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1 Hombre 6.12 1.23 3.5 9.3 5.3 6.1 6.85 0.249
## 2 Mujer 5.89 1.49 2.5 9.3 5 5.7 6.8 0.135
## # … with 1 more variable: Coef.Apuntamiento &amp;lt;dbl&amp;gt;
&lt;/code>&lt;/pre>
&lt;h4 id="gráficos-2">Gráficos&lt;/h4>
&lt;ul>
&lt;li>Diagrama de cajas y bigotes&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-r">df %&amp;gt;% ggplot(aes(x = sexo, y = notaA, fill = sexo)) +
geom_boxplot() +
# Cambio de escala del eje X
scale_y_continuous(limits=c(0, 10), breaks = 0:10)
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="img/quantiative-vs-qualitative-box-plot-1.svg" alt="">&amp;lt;!&amp;ndash; &amp;ndash;&amp;gt;&lt;/p>
&lt;ul>
&lt;li>Diagrama de violín&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-r">df %&amp;gt;% ggplot(aes(x = sexo, y = notaA, fill = sexo)) +
geom_violin() +
# Cambio de escala del eje X
scale_y_continuous(limits=c(0, 10), breaks = 0:10)
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="img/quantiative-vs-qualitative-viol%C3%ADn-plot-1.svg" alt="">&amp;lt;!&amp;ndash; &amp;ndash;&amp;gt;&lt;/p>
&lt;h3 id="estudios-inferenciales-2">Estudios inferenciales&lt;/h3>
&lt;h4 id="test-de-normalidad-de-shapiro-wilks">Test de normalidad de Shapiro-Wilks&lt;/h4>
&lt;p>&lt;strong>Objetivo&lt;/strong>: Comprobar la normalidad de la distribución de cada
población.&lt;/p>
&lt;p>&lt;strong>Hipótesis nula&lt;/strong>: La distribución es normal.&lt;/p>
&lt;pre>&lt;code class="language-r">df %&amp;gt;% group_by(sexo) %&amp;gt;%
summarise(`Estadístico W` = shapiro.test(notaA)$statistic, `p-valor` = shapiro.test(notaA)$p.value)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## # A tibble: 2 x 3
## sexo `Estadístico W` `p-valor`
## &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1 Hombre 0.990 0.872
## 2 Mujer 0.990 0.942
&lt;/code>&lt;/pre>
&lt;h4 id="test-f-de-fisher-de-comparación-de-varianzas-de-dos-poblaciones-independientes">Test F de Fisher de comparación de varianzas de dos poblaciones independientes&lt;/h4>
&lt;p>&lt;strong>Objetivo&lt;/strong>: Comparar las varianzas de dos poblaciones independientes.&lt;/p>
&lt;p>&lt;strong>Requisitos&lt;/strong>:&lt;/p>
&lt;ul>
&lt;li>Variable dependiente cuantitativa.&lt;/li>
&lt;li>Una variable independiente cualitativa con dos categorías
(poblaciones)&lt;/li>
&lt;li>Distribución normal de la variable dependiente en ambas poblaciones
o tamaños de las muestras de cada población ≥ 30.&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Hipótesis nula&lt;/strong>: La varianzas poblacionales son iguales (no existe
una diferencia significativa entre las medias poblacionales).&lt;/p>
&lt;p>&lt;strong>Ejemplo&lt;/strong>: Comprobar si diferencias signicativas entre las notas
medias de hombres y mujeres.&lt;/p>
&lt;pre>&lt;code class="language-r"># Test de comparación de varianzas
var.test(notaA ~ sexo, data = df)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>##
## F test to compare two variances
##
## data: notaA by sexo
## F = 0.6769, num df = 70, denom df = 48, p-value = 0.1347
## alternative hypothesis: true ratio of variances is not equal to 1
## 95 percent confidence interval:
## 0.3953421 1.1293155
## sample estimates:
## ratio of variances
## 0.6769032
&lt;/code>&lt;/pre>
&lt;h4 id="test-t-de-comparación-de-medias-de-dos-poblaciones-independientes">Test t de comparación de medias de dos poblaciones independientes&lt;/h4>
&lt;p>&lt;strong>Objetivo&lt;/strong>: Estimar la diferencia de medias en las dos poblaciones o
comprobar si hay diferencias significativas entre ellas.&lt;/p>
&lt;p>&lt;strong>Requisitos&lt;/strong>:&lt;/p>
&lt;ul>
&lt;li>Variable dependiente cuantitativa.&lt;/li>
&lt;li>Una variable independiente cualitativa con dos categorías
(poblaciones)&lt;/li>
&lt;li>Distribución normal de la variable dependiente en ambas poblaciones
o tamaños de las muestras de cada población ≥ 30.&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Hipótesis nula&lt;/strong>: La medias poblacionales son iguales (no existe una
diferencia significativa entre las medias poblacionales).&lt;/p>
&lt;p>&lt;strong>Observación&lt;/strong>: El resultado del test depende de si las varianzas
poblacionales son iguales o no.&lt;/p>
&lt;p>&lt;strong>Ejemplo&lt;/strong>: Comprobar si diferencias signicativas entre las notas
medias de hombres y mujeres.&lt;/p>
&lt;pre>&lt;code class="language-r"># Test de comparación de varianzas
var.test(notaA ~ sexo, data = df)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>##
## F test to compare two variances
##
## data: notaA by sexo
## F = 0.6769, num df = 70, denom df = 48, p-value = 0.1347
## alternative hypothesis: true ratio of variances is not equal to 1
## 95 percent confidence interval:
## 0.3953421 1.1293155
## sample estimates:
## ratio of variances
## 0.6769032
&lt;/code>&lt;/pre>
&lt;pre>&lt;code class="language-r"># Test de comparación de medias asumiendo varianzas iguales
t.test (notaA ~ sexo, data = df, alternative = &amp;quot;two.sided&amp;quot;, var.equal = FALSE)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>##
## Welch Two Sample t-test
##
## data: notaA by sexo
## t = 0.89364, df = 89.873, p-value = 0.3739
## alternative hypothesis: true difference in means between group Hombre and group Mujer is not equal to 0
## 95 percent confidence interval:
## -0.2821809 0.7435779
## sample estimates:
## mean in group Hombre mean in group Mujer
## 6.122535 5.891837
&lt;/code>&lt;/pre>
&lt;pre>&lt;code class="language-r"># Test de comparación de medias asumiendo varianzas iguales
t.test (notaA ~ sexo, data = df, alternative = &amp;quot;two.sided&amp;quot;, var.equal = TRUE)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>##
## Two Sample t-test
##
## data: notaA by sexo
## t = 0.92608, df = 118, p-value = 0.3563
## alternative hypothesis: true difference in means between group Hombre and group Mujer is not equal to 0
## 95 percent confidence interval:
## -0.262615 0.724012
## sample estimates:
## mean in group Hombre mean in group Mujer
## 6.122535 5.891837
&lt;/code>&lt;/pre>
&lt;ul>
&lt;li>Diagrama de medias&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-r">df %&amp;gt;% ggplot(aes(x = sexo, y = notaA, colour = sexo)) +
# Puntos de medias
stat_summary(fun=&amp;quot;mean&amp;quot;, size=3, geom=&amp;quot;point&amp;quot;, position=position_dodge(width=0.25)) +
# Intervalos de confianza para la media
stat_summary(fun.data = function(x) mean_cl_normal(x, conf.int=0.95), geom = &amp;quot;pointrange&amp;quot;, position=position_dodge(width=0.25))
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="img/quantitative-vs-qualitative-means-plot-1.svg" alt="">&amp;lt;!&amp;ndash; &amp;ndash;&amp;gt;&lt;/p>
&lt;h4 id="test-u-de-mann-whitney-de-comparación-de-dos-poblaciones-independientes-no-paramétrico">Test U de Mann-Whitney de comparación de dos poblaciones independientes (no paramétrico)&lt;/h4>
&lt;p>&lt;strong>Objetivo&lt;/strong>: Comprobar si hay diferencias significativas entre entre
dos poblaciones independientes.&lt;/p>
&lt;p>&lt;strong>Requisitos&lt;/strong>:&lt;/p>
&lt;ul>
&lt;li>Variable dependiente cuantitativa.&lt;/li>
&lt;li>Una variable independiente cualitativa con dos categorías
(poblaciones)&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Hipótesis nula&lt;/strong>: La medianas poblacionales son iguales (no existe una
diferencia significativa entre las medianas poblacionales).&lt;/p>
&lt;p>&lt;strong>Ejemplo&lt;/strong>: Comprobar si diferencias signicativas entre las notas de
hombres y mujeres.&lt;/p>
&lt;pre>&lt;code class="language-r"># Test de rangos U the Mann-Whitney
wilcox.test(notaA ~ sexo, data = df, alternative = &amp;quot;two.sided&amp;quot;)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>##
## Wilcoxon rank sum test with continuity correction
##
## data: notaA by sexo
## W = 1917, p-value = 0.3445
## alternative hypothesis: true location shift is not equal to 0
&lt;/code>&lt;/pre>
&lt;h2 id="dos-variables-variable-dependiente-cuantitativa-y-variable-independiente-culitativa-con-dos-categorías-o-grupos-pareados">Dos variables: Variable dependiente cuantitativa y variable independiente culitativa con dos categorías o grupos pareados&lt;/h2>
&lt;p>Dos grupos o poblaciones están pareadas o emparejadas cuando los dos
poblaciones contienen los mismos individuos, es decir, se trata en
realidadad de una única población, pero la variable dependiente se mide
dos veces en cada individuo (normalmente antes y después de la algún
suceso) y por tanto cada individuo tiene asociado un par de valores.&lt;/p>
&lt;p>Este estudio puede realizarse también creando una nueva variable a
partir de la resta de las dos mediciones y planteando un estudio de una
sola variable cuantitativa.&lt;/p>
&lt;p>&lt;strong>Ejemplo&lt;/strong>: Creación de la diferencia de notas de las asignaturas A y
B.&lt;/p>
&lt;pre>&lt;code class="language-r"># Creamos la variable diferencia = notaA - notaB
df &amp;lt;- df %&amp;gt;% mutate(diferencia = notaA - notaB)
&lt;/code>&lt;/pre>
&lt;h3 id="estudios-descriptivos-3">Estudios descriptivos&lt;/h3>
&lt;h4 id="estadísticos-3">Estadísticos&lt;/h4>
&lt;ul>
&lt;li>Tamaño muestral del grupo&lt;/li>
&lt;li>Media de la diferencia&lt;/li>
&lt;li>Desviación típica de la diferencia&lt;/li>
&lt;li>Mínimo, Máximo de la diferencia&lt;/li>
&lt;li>Cuartiles de la diferencia&lt;/li>
&lt;li>Coeficiente de asimetría de la diferencia&lt;/li>
&lt;li>Coeficiente de apuntamiento de la diferencia&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Ejemplo&lt;/strong>: Estadísticos descriptivos de la diferencia entre las notas
de las asignaturas A y B de un mismo grupo de alumnos.&lt;/p>
&lt;pre>&lt;code class="language-r"># Tamaño muestral de sin contar los datos perdidos
length(na.omit(df$diferencia))
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## [1] 115
&lt;/code>&lt;/pre>
&lt;pre>&lt;code class="language-r"># Media, Desviación típica, Mín, Máx, Cuartiles, Coef. Asimetría y Coef. Apuntamiento
library(moments)
df %&amp;gt;% summarize(Media = mean(diferencia, na.rm=TRUE), Des.Tip = sd(diferencia, na.rm = TRUE), Mín = min(diferencia, na.rm = TRUE), Máx = max(diferencia, na.rm = TRUE), C1 = quantile(diferencia, 0.25, na.rm = TRUE), C2 = quantile(diferencia, 0.5, na.rm = TRUE), C3 = quantile(diferencia, 0.75, na.rm = TRUE), Coef.Asimetría = skewness(diferencia, na.rm = TRUE), Coef.Apuntamiento = kurtosis(diferencia, na.rm = TRUE) - 3)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## # A tibble: 1 x 9
## Media Des.Tip Mín Máx C1 C2 C3 Coef.Asimetría Coef.Apuntamiento
## &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1 -0.882 0.900 -3.2 1.10 -1.5 -0.8 -0.300 -0.430 -0.137
&lt;/code>&lt;/pre>
&lt;h4 id="gráficos-3">Gráficos&lt;/h4>
&lt;ul>
&lt;li>Diagrama de cajas y bigotes&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-r">df %&amp;gt;% ggplot(aes(x = diferencia)) +
geom_boxplot(fill=&amp;quot;#00BFC4&amp;quot;)
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="img/quantiative-vs-qualitative-paired-box-plot-1.svg" alt="">&amp;lt;!&amp;ndash; &amp;ndash;&amp;gt;&lt;/p>
&lt;h3 id="estudios-inferenciales-3">Estudios inferenciales&lt;/h3>
&lt;h4 id="test-de-normalidad-de-shapiro-wilks-1">Test de normalidad de Shapiro-Wilks&lt;/h4>
&lt;p>&lt;strong>Objetivo&lt;/strong>: Comprobar la normalidad de la distribución de la
diferencia.&lt;/p>
&lt;p>&lt;strong>Hipótesis nula&lt;/strong>: La distribución es normal.&lt;/p>
&lt;p>&lt;strong>Ejemplo&lt;/strong>: Comprobar la normalidad de la diferencia entre las notas de
las asignaturas A y B de un mismo grupo de alumnos.&lt;/p>
&lt;pre>&lt;code class="language-r">df %&amp;gt;% summarise(`Estadístico W` = shapiro.test(diferencia)$statistic, `p-valor` = shapiro.test(diferencia)$p.value)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## # A tibble: 1 x 2
## `Estadístico W` `p-valor`
## &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1 0.979 0.0737
&lt;/code>&lt;/pre>
&lt;h4 id="test-t-de-comparación-de-medias-de-dos-poblaciones-pareadas">Test t de comparación de medias de dos poblaciones pareadas&lt;/h4>
&lt;p>&lt;strong>Objetivo&lt;/strong>: Estimar la media de la diferencia o compararla con un
valor dado &lt;em>μ&lt;/em>&lt;sub>0&lt;/sub>.&lt;/p>
&lt;p>&lt;strong>Requisitos&lt;/strong>:&lt;/p>
&lt;ul>
&lt;li>Variable dependiente cuantitativa.&lt;/li>
&lt;li>Una variable independiente cualitativa con dos categorías
(poblaciones) pareadas&lt;/li>
&lt;li>Distribución normal de la variable diferencia o tamaño muestral
≥ 30.&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Hipótesis nula&lt;/strong>: La medias poblacionales son iguales (no existe una
diferencia significativa entre las medias poblacionales).&lt;/p>
&lt;p>&lt;strong>Ejemplo&lt;/strong>: Comprobar si hay una diferencia signicativa entre las notas
medias de las asinaturas A y B, o lo que es lo mismo, comprobar si la
media de la diferencia de las notas de A y B es distinta de 0.&lt;/p>
&lt;pre>&lt;code class="language-r">t.test (notaA, notaB, data = df, alternative = &amp;quot;two.sided&amp;quot;, paired = TRUE)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>##
## Paired t-test
##
## data: notaA and notaB
## t = -10.618, df = 114, p-value &amp;lt; 2.2e-16
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
## -1.0515337 -0.7208695
## sample estimates:
## mean of the differences
## -0.8862016
&lt;/code>&lt;/pre>
&lt;ul>
&lt;li>Diagrama de medias&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-r">df %&amp;gt;% ggplot(aes(x=&amp;quot;&amp;quot;, y = diferencia)) +
# Puntos de medias
stat_summary(fun=&amp;quot;mean&amp;quot;, size=3, geom=&amp;quot;point&amp;quot;) +
# Intervalos de confianza para la media
stat_summary(fun.data = function(x) mean_cl_normal(x, conf.int=0.95), geom = &amp;quot;pointrange&amp;quot;, position=position_dodge(width=0.25))
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="img/quantitative-vs-qualitative-paired-means-plot-1.svg" alt="">&amp;lt;!&amp;ndash; &amp;ndash;&amp;gt;&lt;/p>
&lt;h4 id="test-wilcoxon-de-comparación-de-dos-poblaciones-pareadas-no-paramétrico">Test Wilcoxon de comparación de dos poblaciones pareadas (no paramétrico)&lt;/h4>
&lt;p>&lt;strong>Objetivo&lt;/strong>: Comparar las medianas de las dos poblaciones.&lt;/p>
&lt;p>&lt;strong>Requisitos&lt;/strong>:&lt;/p>
&lt;ul>
&lt;li>Variable dependiente cuantitativa.&lt;/li>
&lt;li>Una variable independiente cualitativa con dos categorías
(poblaciones) pareadas.&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Hipótesis nula&lt;/strong>: La medianas poblacionales son iguales (no existe una
diferencia significativa entre las medianas poblacionales).&lt;/p>
&lt;p>&lt;strong>Ejemplo&lt;/strong>: Comprobar si hay una diferencia signicativa entre las notas
de las asignaturas A y B.&lt;/p>
&lt;pre>&lt;code class="language-r">wilcox.test(notaA, notaB, data = df, alternative = &amp;quot;two.sided&amp;quot;, paired = TRUE)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>##
## Wilcoxon signed rank test with continuity correction
##
## data: notaA and notaB
## V = 466, p-value = 1.192e-15
## alternative hypothesis: true location shift is not equal to 0
&lt;/code>&lt;/pre>
&lt;h2 id="dos-variables-variable-dependiente-cuantitativa-y-variable-independiente-culitativa-con-más-de-dos-categorías-o-grupos">Dos variables: Variable dependiente cuantitativa y variable independiente culitativa con más de dos categorías o grupos&lt;/h2>
&lt;h3 id="estudios-descriptivos-4">Estudios descriptivos&lt;/h3>
&lt;h4 id="estadísticos-4">Estadísticos&lt;/h4>
&lt;ul>
&lt;li>Tamaño muestral de cada grupo&lt;/li>
&lt;li>Media de cada grupo&lt;/li>
&lt;li>Desviación típica de cada grupo&lt;/li>
&lt;li>Mínimo, Máximo de cada grupo&lt;/li>
&lt;li>Cuartiles de cada grupo&lt;/li>
&lt;li>Coeficiente de asimetría de cada grupo&lt;/li>
&lt;li>Coeficiente de apuntamiento de cada grupo&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-r"># Tamaño muestral de notaA según el grupo
df %&amp;gt;% group_by(grupo) %&amp;gt;% group_size()
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## [1] 38 35 47
&lt;/code>&lt;/pre>
&lt;pre>&lt;code class="language-r"># Media, Desviación típica, Mín, Máx, Cuartiles, Coef. Asimetría y Coef. Apuntamiento
library(moments)
df %&amp;gt;% group_by(grupo) %&amp;gt;% summarize(Media = mean(notaA, na.rm=TRUE), Des.Tip = sd(notaA, na.rm = TRUE), Mín = min(notaA, na.rm = TRUE), Máx = max(notaA, na.rm = TRUE), C1 = quantile(notaA, 0.25, na.rm = TRUE), C2 = quantile(notaA, 0.5, na.rm = TRUE), C3 = quantile(notaA, 0.75, na.rm = TRUE), Coef.Asimetría = skewness(notaA, na.rm = TRUE), Coef.Apuntamiento = kurtosis(notaA, na.rm = TRUE) - 3)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## # A tibble: 3 x 10
## grupo Media Des.Tip Mín Máx C1 C2 C3 Coef.Asimetría
## &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1 A 6.54 0.998 4.3 8.6 5.93 6.6 7.15 -0.250
## 2 B 6.96 1.23 3.5 9.3 6.2 6.8 7.7 -0.141
## 3 C 4.92 0.771 2.5 5.9 4.5 5.1 5.5 -1.06
## # … with 1 more variable: Coef.Apuntamiento &amp;lt;dbl&amp;gt;
&lt;/code>&lt;/pre>
&lt;h4 id="gráficos-4">Gráficos&lt;/h4>
&lt;ul>
&lt;li>Diagrama de cajas y bigotes&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-r">df %&amp;gt;% ggplot(aes(x = grupo, y = notaA, fill = grupo)) +
geom_boxplot() +
# Cambio de escala del eje X
scale_y_continuous(limits=c(0, 10), breaks = 0:10)
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="img/quantiative-vs-qualitative-more-two-box-plot-1.svg" alt="">&amp;lt;!&amp;ndash; &amp;ndash;&amp;gt;&lt;/p>
&lt;ul>
&lt;li>Diagrama de violín&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-r">df %&amp;gt;% ggplot(aes(x = grupo, y = notaA, fill = grupo)) +
geom_violin() +
# Cambio de escala del eje X
scale_y_continuous(limits=c(0, 10), breaks = 0:10)
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="img/quantiative-vs-qualitative-more-two-viol%C3%ADn-plot-1.svg" alt="">&amp;lt;!&amp;ndash; &amp;ndash;&amp;gt;&lt;/p>
&lt;h3 id="estudios-inferenciales-4">Estudios inferenciales&lt;/h3>
&lt;h4 id="test-de-normalidad-de-shapiro-wilks-2">Test de normalidad de Shapiro-Wilks&lt;/h4>
&lt;p>&lt;strong>Objetivo&lt;/strong>: Comprobar la normalidad de la distribución de cada
población.&lt;/p>
&lt;p>&lt;strong>Hipótesis nula&lt;/strong>: La distribución es normal.&lt;/p>
&lt;p>&lt;strong>Ejemplo&lt;/strong>: Comprobar la normalidad de las distribuciones de la nota A
en los grupos A, B y C.&lt;/p>
&lt;pre>&lt;code class="language-r">df %&amp;gt;% group_by(grupo) %&amp;gt;%
summarise(`Estadístico W` = shapiro.test(notaA)$statistic, `p-valor` = shapiro.test(notaA)$p.value)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## # A tibble: 3 x 3
## grupo `Estadístico W` `p-valor`
## &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1 A 0.984 0.840
## 2 B 0.963 0.277
## 3 C 0.918 0.00280
&lt;/code>&lt;/pre>
&lt;p>&lt;strong>Interpretación&lt;/strong>: La distribución de la nota A en los grupos A y B es
normal (p-valores &amp;gt; 0.05) pero no en el grupo C (p-valor &amp;lt; 0.05)&lt;/p>
&lt;p>&lt;strong>Ejemplo&lt;/strong>: Comprobar la normalidad de las distribuciones de la nota A
en los grupos A, B y C.&lt;/p>
&lt;pre>&lt;code class="language-r">df %&amp;gt;% group_by(grupo) %&amp;gt;%
summarise(`Estadístico W` = shapiro.test(notaC)$statistic, `p-valor` = shapiro.test(notaC)$p.value)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## # A tibble: 3 x 3
## grupo `Estadístico W` `p-valor`
## &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1 A 0.989 0.961
## 2 B 0.965 0.343
## 3 C 0.976 0.442
&lt;/code>&lt;/pre>
&lt;p>&lt;strong>Interpretación&lt;/strong>: La distribución de la nota C en los tres grupos es
normal (p-valores &amp;gt; 0.05).&lt;/p>
&lt;h4 id="test-de-levene-de-comparación-de-varianzas-de-dos-o-más-poblaciones-independientes">Test de Levene de comparación de varianzas de dos o más poblaciones independientes&lt;/h4>
&lt;p>&lt;strong>Objetivo&lt;/strong>: Comparar las varianzas de dos o más poblaciones
independientes.&lt;/p>
&lt;p>&lt;strong>Requisitos&lt;/strong>:&lt;/p>
&lt;ul>
&lt;li>Variable dependiente cuantitativa.&lt;/li>
&lt;li>Una variable independiente cualitativa con dos o más categorías
(poblaciones)&lt;/li>
&lt;li>Distribución normal de la variable dependiente en todas las
poblaciones o tamaños de las muestras de cada población ≥ 30.&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Hipótesis nula&lt;/strong>: La varianzas poblacionales son iguales (no existe
una diferencia significativa entre las medias poblacionales).&lt;/p>
&lt;p>&lt;strong>Ejemplo&lt;/strong>: Comprobar si diferencias signicativas entre las varianzas
de las notas de la asignatura C de los grupos A, B y C.&lt;/p>
&lt;pre>&lt;code class="language-r"># El test de Levene está disponible en el paquete car
library(car)
# Test de comparación de varianzas
leveneTest(notaC ~ grupo, data = df)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## Levene's Test for Homogeneity of Variance (center = median)
## Df F value Pr(&amp;gt;F)
## group 2 0.3186 0.7278
## 116
&lt;/code>&lt;/pre>
&lt;p>&lt;strong>Interpretación&lt;/strong>: No existe diferencia significativa entre las
varianzas de la nota C en los grupos A, B y C (p-valor &amp;gt; 0.05).&lt;/p>
&lt;h4 id="anova-de-un-factor-para-la-comparación-medias-de-más-de-dos-poblaciones-independientes">ANOVA de un factor para la comparación medias de más de dos poblaciones independientes&lt;/h4>
&lt;p>&lt;strong>Objetivo&lt;/strong>: Comprobar si hay diferencias significativas entre las
medias de más de dos poblaciones independientes.&lt;/p>
&lt;p>&lt;strong>Requisitos&lt;/strong>:&lt;/p>
&lt;ul>
&lt;li>Variable dependiente cuantitativa.&lt;/li>
&lt;li>Una variable independiente cualitativa con más de dos categorías
(poblaciones)-&lt;/li>
&lt;li>Distribución normal de la variable dependiente en todas las
poblaciones o tamaños de las muestras de cada población ≥ 30.&lt;/li>
&lt;li>Homogeneidad de varianzas en las poblaciones.&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Hipótesis nula&lt;/strong>: La medias poblacionales son iguales (no existe una
diferencia significativa entre las medias poblacionales).&lt;/p>
&lt;p>&lt;strong>Ejemplo&lt;/strong>: Comprobar si diferencias signicativas entre las notas
medias de la asignatura C de los grupos A, B y C.&lt;/p>
&lt;pre>&lt;code class="language-r"># Análisis de la varianza de un factor
summary(aov(notaC ~ grupo, data = df))
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## Df Sum Sq Mean Sq F value Pr(&amp;gt;F)
## grupo 2 80.69 40.34 20.05 3.32e-08 ***
## Residuals 116 233.41 2.01
## ---
## Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 1 observation deleted due to missingness
&lt;/code>&lt;/pre>
&lt;p>&lt;strong>Interpretación&lt;/strong>: Existen diferencias significativas entre las medias
de la nota C entre al menos dos grupos (p-valor=3.32e-08 &amp;lt; 0.05).&lt;/p>
&lt;p>&lt;strong>Observación&lt;/strong>: Cuando se detectan diferencias significativas entre las
medias de al menos dos grupos conviene realizar un test de comparación
múltiple por pares para ver entre qué poblaciones hay diferencias y
entre cuáles no. Los test más habituales de comparación por pares son el
de Tukey y el de Bonferroni.&lt;/p>
&lt;pre>&lt;code class="language-r"># Test de comparación múltiple de Tukey
TukeyHSD(aov(notaC ~ grupo, data = df))
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## Tukey multiple comparisons of means
## 95% family-wise confidence level
##
## Fit: aov(formula = notaC ~ grupo, data = df)
##
## $grupo
## diff lwr upr p adj
## B-A 0.4312693 -0.3637573 1.2262960 0.4048482
## C-A -1.4455767 -2.1802858 -0.7108676 0.0000241
## C-B -1.8768461 -2.6350758 -1.1186163 0.0000001
&lt;/code>&lt;/pre>
&lt;p>&lt;strong>Interpretación&lt;/strong>: No existe una diferencia significativa entre las
notas medias de la asignatura C de los grupos A y B (p-valor=0.4048 &amp;gt;
0.05), pero si existe una diferencia significativa entre las notas
medias de los grupos A y C (p-valor=0.00002 &amp;lt; 0.05) y también entre las
notas medias de los grupos B y C (p-valor=0.0000001 &amp;lt; 0.05).&lt;/p>
&lt;ul>
&lt;li>Diagrama de medias&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-r">df %&amp;gt;% ggplot(aes(x = grupo, y = notaC, colour = grupo)) +
# Puntos de medias
stat_summary(fun=&amp;quot;mean&amp;quot;, size=3, geom=&amp;quot;point&amp;quot;, position=position_dodge(width=0.25)) +
# Intervalos de confianza para la media
stat_summary(fun.data = function(x) mean_cl_normal(x, conf.int=0.95), geom = &amp;quot;pointrange&amp;quot;, position=position_dodge(width=0.25))
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="img/quantitative-vs-qualitative-more-two-means-plot-1.svg" alt="">&amp;lt;!&amp;ndash; &amp;ndash;&amp;gt;&lt;/p>
&lt;h4 id="test-kruskal-wallis-de-comparación-de-más-de-dos-poblaciones-independientes-no-paramétrico">Test Kruskal-Wallis de comparación de más de dos poblaciones independientes (no paramétrico)&lt;/h4>
&lt;p>&lt;strong>Objetivo&lt;/strong>: Comprobar si hay diferencias significativas entre entre
más de dos poblaciones independientes.&lt;/p>
&lt;p>&lt;strong>Requisitos&lt;/strong>:&lt;/p>
&lt;ul>
&lt;li>Variable dependiente cuantitativa.&lt;/li>
&lt;li>Una variable independiente cualitativa con más de dos categorías
(poblaciones)&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Hipótesis nula&lt;/strong>: La medianas poblacionales son iguales (no existe una
diferencia significativa entre las medianas poblacionales).&lt;/p>
&lt;p>&lt;strong>Ejemplo&lt;/strong>: Comprobar si diferencias signicativas entre las notas de la
asignatura A de los grupos A, B y C.&lt;/p>
&lt;pre>&lt;code class="language-r"># Test de Kruskal-Wallis
kruskal.test(notaA ~ grupo, data = df)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>##
## Kruskal-Wallis rank sum test
##
## data: notaA by grupo
## Kruskal-Wallis chi-squared = 62.218, df = 2, p-value = 3.087e-14
&lt;/code>&lt;/pre>
&lt;p>&lt;strong>Interpretación&lt;/strong>: Existen diferencias significativas entre las notas
de la asignatura A de al menos dos de los grupos.&lt;/p>
&lt;p>&lt;strong>Observación&lt;/strong>: Cuando se detectan diferencias significativas entre al
menos dos grupos conviene realizar un test de comparación múltiple por
pares para ver entre qué poblaciones hay diferencias y entre cuáles no.
El test más habitual es el de Wilcoxon.&lt;/p>
&lt;pre>&lt;code class="language-r"># Test de comparación múltiple de Wilcoxon
pairwise.wilcox.test(df$notaA, df$grupo, p.adjust.method = &amp;quot;BH&amp;quot;)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>##
## Pairwise comparisons using Wilcoxon rank sum test with continuity correction
##
## data: df$notaA and df$grupo
##
## A B
## B 0.19 -
## C 4.2e-10 1.3e-11
##
## P value adjustment method: BH
&lt;/code>&lt;/pre>
&lt;p>&lt;strong>Interpretación&lt;/strong>: No existe una diferencia significativa entre las
notas de la asignatura A de los grupos A y B (p-valor=0.19 &amp;gt; 0.05),
pero si existe una diferencia significativa entre las notas de los
grupos A y C (p-valor=4.2e-10 &amp;lt; 0.05) y también entre las notas de los
grupos B y C (p-valor=1.3e-11 &amp;lt; 0.05).&lt;/p></description></item></channel></rss>