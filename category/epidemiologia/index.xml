<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Epidemiología | Aprende con Alf</title><link>/category/epidemiologia/</link><atom:link href="/category/epidemiologia/index.xml" rel="self" type="application/rss+xml"/><description>Epidemiología</description><generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>es-es</language><lastBuildDate>Sun, 07 Nov 2021 00:00:00 +0000</lastBuildDate><image><url>/images/logo_hude38443eeb2faa5fa84365aba7d86a77_3514_300x300_fit_lanczos_3.png</url><title>Epidemiología</title><link>/category/epidemiologia/</link></image><item><title>Epidemiología</title><link>/docencia/estadistica/tutoriales/epidemiologia/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/docencia/estadistica/tutoriales/epidemiologia/</guid><description>&lt;h2 id="qué-es-la-epidemiología">¿Qué es la Epidemiología?&lt;/h2>
&lt;p>Epidemiología viene Griego: Epi (sobre), demos (gente) y logos (estudio), es decir, el estudio de lo que le ocurre a las poblaciones.&lt;/p>
&lt;blockquote>
&lt;p>En el ámbito de la salud pública, la &lt;strong>Epidemilogía&lt;/strong> es una rama de la Medicina que se encarga del estudio de la distribución y las causas de eventos relacionados con la salud (normalmente enfermedades) en las poblaciones, y la aplicación de este estudio para controlar problemas públicos de salud.&lt;/p>
&lt;/blockquote>
&lt;img src="img/detective.png" width=80% alt="Detective epidemiólogo">
&lt;p>Debido a la epidemia provocada por el coronavirus, la Epidemiología se ha convertido en una de las ramas de la medicina que más interés despiertan.&lt;/p>
&lt;p>&lt;img src="img/fernando-simon.jpg" alt="Fernando Simón">&lt;/p>
&lt;p>Sin embargo, antes de la COVID, la Epidemiología ya había servido en otros momentos históricos para solucionar o controlar algunos de los problemas de salud públicos más serios que ha enfrentado la humanidad.&lt;/p>
&lt;h3 id="algunos-descubrimientos-históricos">Algunos descubrimientos históricos&lt;/h3>
&lt;ul>
&lt;li>1854: John Snow determina que la causa de la epidemia de cólera que asolaba Lóndres era que el agua estaba contaminada con heces.&lt;/li>
&lt;li>1898: Ronald Ross averigua que el transmisor de la malaria es el el mosquito Anopheles.&lt;/li>
&lt;li>1950: Se descubre que fumar es el principal factor de riesgo de cáncer de pulmón.&lt;/li>
&lt;li>1954: Se valida la primera vacuna contra la poliomielitis (Jonas Salk’s).&lt;/li>
&lt;li>1970: Se observó que el ejercicio físico y una dieta sana reducían el riesgo de sufrir un infarto.&lt;/li>
&lt;li>1983: Robert Gallo, Luc Montagnier y Françoise Barré-Sinoussi identifican el virus que causa el SIDA. Poco después se se observó que el riesgo de contraer el HIV aumentaba con ciertas prácticas sexuales y con el consumo de algunos tipos de drogas.&lt;/li>
&lt;li>2020: Y llegó la COVID&amp;hellip;&lt;/li>
&lt;/ul>
&lt;p>En estos tiempos de pandemia un montón de términos técnicos de la Epidemiología se han convertido en lugares comunes gracias a los medios de comunicación.&lt;/p>
&lt;p>&lt;img src="img/wordcloud.png" alt="Términos epidemiología">&lt;/p>
&lt;p>Sin embargo, muchos de estos términos se utilizan de manera errónea, incluso por los propios medios de comunicación, y generan confusión para la población no experta. En este tutorial pretendo explicar los principales conceptos epidemiológicos usados en el control de enfermedades como la COVID e ilustrar su uso con ejemplos de aplicación.&lt;/p>
&lt;h2 id="índices-epidemiológicos">Índices epidemiológicos&lt;/h2>
&lt;p>&lt;strong>Riesgos&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>Prevalencia&lt;/li>
&lt;li>Incidencia&lt;/li>
&lt;li>Riesgo y Odds&lt;/li>
&lt;li>Riesgo/Odd relativo&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Test diagnósticos&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>Sensibilidad&lt;/li>
&lt;li>Especificidad&lt;/li>
&lt;li>Valores predictivos&lt;/li>
&lt;/ul>
&lt;p>Todos estos índices estan basados en el cálculo de probabilidades, por lo que comenzaremos introduciendo el concepto de probabilidad y sus principales propiedades.&lt;/p>
&lt;h2 id="el-concepto-de-probabilidad">El concepto de probabilidad&lt;/h2>
&lt;p>A lo largo de la historia ha habido diferentes intentos de definir matemáticamente el concepto de probabilidad. Quizá la más conocida y la primera que se enseña en las escuelas es la definición clásica de Laplace.&lt;/p>
&lt;div class="alert alert-def">
&lt;div>
&lt;strong>Definición clásica (Laplace)&lt;/strong> $$P(E)=\frac{|E|}{|\Omega|}=\frac{\mbox{Casos favorables a $E$}}{\mbox{Casos posibles}}$$
&lt;/div>
&lt;/div>
&lt;p>&lt;strong>Ejemplo&lt;/strong> Al tirar un dado equilibrado, la probabilidad de sacar un número par $E=\{2, 4, 6\}$ es
$$ P(E) = \frac{3}{6} = 0.5$$&lt;/p>
&lt;p>Sin embargo, esta definición tiene serios inconvenientes ya que, para poder usarla, todos los casos posibles de un experimento deben tener la misma probabilidad de ocurrir (&lt;em>equiprobabilidad&lt;/em>) y esto no suele ocurrir en la vida real (por ejemplo no todos los grupos sanguíneos tienen la misma probabilidad de ocurrir).&lt;/p>
&lt;p>Por este motivo, en el ámbito de las Ciencias es mucho más común utilizar la definición de probabilidad basada en el cálculo de frecuencias.&lt;/p>
&lt;div class="alert alert-def">
&lt;div>
&lt;strong>Definición frecuentista&lt;/strong> $$P(E)\approx f_E = \frac{n_E}{n}=\frac{\mbox{Frecuencia absoluta del evento}}{\mbox{Tamaño muestral}}$$
&lt;/div>
&lt;/div>
&lt;p>&lt;strong>Ejemplo&lt;/strong> Se ha aplicado un tratamiento a 100 personas y se han curado 75, entonces la probabilidad de curación del tratamiento es
$$P(E) = \frac{75}{100} = 0.75 \Rightarrow 75\%$$&lt;/p>
&lt;p>&lt;i class="fa fa-exclamation-triangle" style="color:#ff9900;">&lt;/i>Ojo, esta definición no permite calcular el valor exacto de la probabilidad de un suceso, tan solo una aproximación que será mejor cuanto mayor sea el tamaño de la muestra.&lt;/p>
&lt;h3 id="algunas-propiedades-de-la-probabilidad">Algunas propiedades de la probabilidad&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>Una probabilidad es un número real entre 0 y 1: $$0\leq P(E)\leq 1$$&lt;/p>
&lt;/li>
&lt;li>
&lt;p>La suma de las probabilidades de todos los casos posibles es 1: $$P(\Omega) = P(e_1) + P(e_2) + \cdots + P(e_n) = 1$$&lt;/p>
&lt;/li>
&lt;li>
&lt;p>La probabilidad de que ocurra lo contrario de un suceso es 1 menos la probabilidad del suceso: $$P(\overline E) = 1 - P(E)$$&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>De este modo, cuanto más probable es que ocurra un suceso, menos probable es que ocurra su contrario, y viceversa.&lt;/p>
&lt;h3 id="interpretación-de-una-probabilidad">Interpretación de una probabilidad&lt;/h3>
&lt;p>La probabilidad mide la verosimilitud de un suceso.&lt;/p>
&lt;p>De manera informal, se puede decir que la probabilidad mide la creencia o la confianza que tenemos en la ocurrencia de un suceso.&lt;/p>
&lt;ul>
&lt;li>$P(E) = 0 \Rightarrow$ Mínima verosimilitud&lt;/li>
&lt;li>$P(E) = 0.5 \Rightarrow$ Verosimilitud media (máxima incertidumbre)&lt;/li>
&lt;li>$P(E) = 1 \Rightarrow$ Máxima verosimilitud&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="img/balanza-probabilidad.png" alt="Balanza probabilidades">&lt;/p>
&lt;p>Aunque el concepto de probabilidad es el más extendido en aplicaciones que requieren cuantificar la incertidumbre sobre la ocurrencia de un suceso, existen otras formas de cuantificar esa incertidumbre como por ejemplo el &lt;em>odds&lt;/em>.&lt;/p>
&lt;h2 id="el-concepto-de-odds">El concepto de Odds&lt;/h2>
&lt;div class="alert alert-def">
&lt;div>
&lt;strong>Definición: Odds&lt;/strong> $$O(E)=\frac{\mbox{Nº casos con $E$}}{\mbox{Nº casos sin $E$}}=\frac{P(E)}{P(\overline E)}$$
&lt;/div>
&lt;/div>
&lt;p>&lt;strong>Ejemplo&lt;/strong> Se ha aplicado un tratamiento a 100 personas y se han curado 75, entonces el odds de curación del tratamiento es $$O(E) = \frac{75}{25} = 3$$&lt;/p>
&lt;p>&lt;i class="fa fa-exclamation-triangle" style="color:#ff9900;">&lt;/i> Un odds puede ser mayor que 1.&lt;/p>
&lt;h3 id="interpretación-de-un-odds">Interpretación de un Odds&lt;/h3>
&lt;p>Los odds también permiten cuantificar la verosimilitud de un suceso&amp;hellip;, pero en una escala diferente, ya que es una razón de probabilidades.&lt;/p>
&lt;ul>
&lt;li>$O(E) = 0 \Rightarrow$ Mínima verosimilitud&lt;/li>
&lt;li>$O(E) = 1 \Rightarrow$ Verosimilitud media (máxima incertidumbre)&lt;/li>
&lt;li>$O(E) = \infty \Rightarrow$ Máxima verosimilitud&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="img/balanza-odds.png" alt="Balanza probabilidades">&lt;/p>
&lt;h3 id="conversión-de-odds-en-probabilidades">Conversión de Odds en probabilidades&lt;/h3>
&lt;p>Es posible convertir un odds en una probabilidad aplicando la siguiente fórmula:&lt;/p>
&lt;p>$$ \frac{O(E)}{1 + O(E)} = \frac{\frac{P(E)}{P(\overline E)}}{1 + \frac{P(E)}{P(\overline E)}} = \frac{\frac{P(E)}{P(\overline E)}}{\frac{P(\overline E) + P(E)}{P(\overline E)}} = P(E)$$&lt;/p>
&lt;p>&lt;strong>Ejemplo&lt;/strong> Se ha aplicado un tratamiento a 100 personas y se han curado 75.
$$O(E) = \frac{75}{25} = 3 \Rightarrow P(E) = \frac{3}{1+3}=0.75$$&lt;/p>
&lt;h2 id="prevalencia">Prevalencia&lt;/h2>
&lt;div class="alert alert-def">
&lt;div>
&lt;strong>Definición: Prevalencia&lt;/strong>&lt;br>
La &lt;em>prevalencia&lt;/em> de una enfermedad $E$ es la proporción de personas que tienen la enfermedad en un momento concreto.
$$\mbox{Prevalencia}(E) = \frac{\mbox{Nº individuos afectados por $E$}}{\mbox{Tamaño poblacional}}$$
&lt;/div>
&lt;/div>
&lt;p>&lt;strong>Ejemplo&lt;/strong>. En una muestra de 1000 personas 150 tenían gripe. La prevalencia de la gripe es aproximadamente $$\frac{150}{1000}=0.15$$&lt;/p>
&lt;h2 id="incidencia-o-riesgo-absoluto">Incidencia o riesgo absoluto&lt;/h2>
&lt;div class="alert alert-def">
&lt;div>
&lt;strong>Definición: Incidencia&lt;/strong>&lt;br>
La &lt;em>incidencia&lt;/em> o &lt;em>riesgo absoluto&lt;/em> de una enfermedad $E$ es la proporción de nuevos casos durante un periodo determinado (por día, por semana, por mes, etc.)
$$R(E)=\frac{\mbox{Nº nuevos casos con $E$ en el periodo}}{\mbox{Tamaño población en riesgo al comienzo del periodo}}$$
&lt;/div>
&lt;/div>
&lt;p>&lt;strong>Ejemplo&lt;/strong>. Al comienzo del año se tomó una muestra de 1000 personas sin gripe y al finalizar el año 80 tuvieron gripe. La incidencia de la gripe ese año fue
$$ R(E) = \frac{80}{1000} = 0.08$$&lt;/p>
&lt;h3 id="prevalencia-vs-incidencia">Prevalencia vs Incidencia&lt;/h3>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>&lt;/th>
&lt;th style="text-align:center">Tiempo&lt;/th>
&lt;th style="text-align:center">Casos&lt;/th>
&lt;th style="text-align:center">Tipo estudio&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>Prevalencia&lt;/td>
&lt;td style="text-align:center">Puntual&lt;/td>
&lt;td style="text-align:center">Nuevos y existentes&lt;/td>
&lt;td style="text-align:center">Transversal&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Incidencia&lt;/td>
&lt;td style="text-align:center">Periodo&lt;/td>
&lt;td style="text-align:center">Solo nuevos&lt;/td>
&lt;td style="text-align:center">Longitudinal&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;ul>
&lt;li>La prevalencia muestra el número de personas afectadas (carga de la enfermedad).&lt;/li>
&lt;li>La incidencia muestra la evolución de la enfermedad y es más útil para detectar brotes y estudiar su causa.&lt;/li>
&lt;li>La incidencia depende solo de la contagiosidad de la enfermedad, mientras que la prevalencia depende también de la duración de la enfermedad y de lo agresiva que sea.&lt;/li>
&lt;/ul>
&lt;!-- $$ P(E) &lt; R(E) $$ -->
&lt;h3 id="algunas-consideraciones-en-el-caso-de-la-covid">Algunas consideraciones en el caso de la COVID&lt;/h3>
&lt;p>
&lt;a href="https://www.mscbs.gob.es/profesionales/saludPublica/ccayes/alertasActual/nCov/situacionActual.htm" target="_blank" rel="noopener">Datos del ministerio de sanidad&lt;/a>&lt;/p>
&lt;p>La incidencia de la COVID se suele dar sobre un periodo de dos semanas (14 días) aunque no siempre.&lt;/p>
&lt;p>Los datos son poco precisos y subestiman el riesgo de la COVID:&lt;/p>
&lt;ul>
&lt;li>Muchos asintomáticos no son detectados.&lt;/li>
&lt;li>La detección de casos es mediante test diagnósticos que tienen un margen de error (falsos positivos y falsos negativos).&lt;/li>
&lt;li>Se calcula dividiendo por el tamaño de la población (nuevos casos por cada 100000 habitantes) pero habría que dividir por el tamaño de la población en riesgo (sin contar ya infectados o inmunizados).&lt;/li>
&lt;/ul>
&lt;h2 id="comparación-de-riesgos">Comparación de riesgos&lt;/h2>
&lt;p>Tanto la prevalencia como la incidencia permiten estudiar la magnitud y la evolución de una enfermedad pero no permiten analizar las posibles causas. Cuando se quiere investigar si la exposición a un determinado factor puede influir en el desarrollo de una enfermedad hay que comparar los riesgos en dos grupos:&lt;/p>
&lt;ul>
&lt;li>Grupo tratamiento $T$: Individuos expuestos a un factor.&lt;/li>
&lt;li>Grupo control $C$: Individuos no expuestos al factor.&lt;/li>
&lt;/ul>
&lt;p>$$
\begin{array}{|l|cc|}
\hline
&amp;amp; E &amp;amp; \overline E\newline
\hline
T &amp;amp; a &amp;amp; b\newline
C &amp;amp; c &amp;amp; d\newline
\hline
\end{array}
$$&lt;/p>
&lt;h2 id="riesgo-relativo">Riesgo relativo&lt;/h2>
&lt;div class="alert alert-def">
&lt;div>
&lt;strong>Definición: Riesgo relativo&lt;/strong>
$$RR(E)=\frac{\mbox{Riesgo grupo tratamiento}}{\mbox{Riesgo grupo control}}=\frac{R_T(E)}{R_C(E)}=\frac{a/(a+b)}{c/(c+d)}$$
&lt;/div>
&lt;/div>
&lt;p>&lt;strong>Ejemplo&lt;/strong>.&lt;/p>
&lt;p>$$
\begin{array}{|l|cc|}
\hline
&amp;amp; \mbox{Gripe } G &amp;amp; \mbox{No gripe }\overline E\newline
\hline
\mbox{Vacunados } T &amp;amp; 20 &amp;amp; 480 \newline
\mbox{No vacunados } C &amp;amp; 80 &amp;amp; 420 \newline
\hline
\end{array}
$$&lt;/p>
&lt;p>$$RR(G) = \frac{20/(20+480)}{80/(80+420)} = 0.25$$&lt;/p>
&lt;h3 id="interpretación-del-riesgo-relativo">Interpretación del riesgo relativo&lt;/h3>
&lt;ul>
&lt;li>$RR=1$ $\Rightarrow$ No hay asociación entre el suceso y la exposición al factor.&lt;/li>
&lt;li>$RR&amp;lt;1$ $\Rightarrow$ La exposición al factor disminuye el riesgo del suceso.&lt;/li>
&lt;li>$RR&amp;gt;1$ $\Rightarrow$ La exposición al factor aumenta el riesgo del suceso.&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="img/escala-riesgo-relativo.png" alt="Interpretación riesgo relativo">&lt;/p>
&lt;h2 id="odds-ratio">Odds ratio&lt;/h2>
&lt;p>Del mismo modo que se pueden comparar los riesgos en los grupos tratamiento y control, se pueden comparar también los odds.&lt;/p>
&lt;div class="alert alert-def">
&lt;div>
&lt;strong>Definición: Odds ratio&lt;/strong>
$$OR(E)=\frac{\mbox{Odds grupo tratamiento}}{\mbox{Odds grupo control}}=\frac{O_T(E)}{O_C(E)}=\frac{a/b}{c/d}=\frac{ad}{bc}$$
&lt;/div>
&lt;/div>
&lt;p>&lt;strong>Ejemplo&lt;/strong>.&lt;/p>
&lt;p>$$
\begin{array}{|l|cc|}
\hline
&amp;amp; \mbox{Gripe } G &amp;amp; \mbox{No gripe }\overline E\newline
\hline
\mbox{Vacunados } T &amp;amp; 20 &amp;amp; 480 \newline
\mbox{No vacunados } C &amp;amp; 80 &amp;amp; 420 \newline
\hline
\end{array}
$$&lt;/p>
&lt;p>$$OR(G) = \frac{20/480}{80/420} = 0.22$$&lt;/p>
&lt;h3 id="interpretación-del-odds-ratio">Interpretación del odds ratio&lt;/h3>
&lt;ul>
&lt;li>$OR=1$ $\Rightarrow$ No existe asociación entre el suceso y la exposición al factor.&lt;/li>
&lt;li>$OR&amp;lt;1$ $\Rightarrow$ La exposición al factor disminuye el riesgo del suceso.&lt;/li>
&lt;li>$OR&amp;gt;1$ $\Rightarrow$ La exposición al factor aumenta el riesgo del suceso.&lt;/li>
&lt;/ul>
&lt;h3 id="riesgo-relativo-vs-odds-ratio">Riesgo relativo vs odds ratio&lt;/h3>
&lt;p>El riesgo relativo es una comparación de probabilidades pero depende de la incidencia de la enfermedad.&lt;/p>
&lt;p>La interpretación del odds ratio es más enrevesada porque es contrafactual, ya que da cuántas veces es más frecuente el suceso en el grupo tratamiento en comparación con el control, asumiendo que en el
grupo control es tan frecuente que ocurra el suceso como que no. Su ventaja es que no depende de la incidencia de la enfermedad.&lt;/p>
&lt;p>&lt;strong>Ejemplo&lt;/strong>. Para estudiar la asociación entre fumar y el cáncer de pulmón se han tomado dos muestras, la segunda con el doble de pacientes sanos que la primera.&lt;/p>
&lt;p>$$
\begin{array}{|l|cc|}
\hline
\textbf{Muestra 1} &amp;amp; \mbox{Cáncer } E &amp;amp; \mbox{No cáncer }\overline E\newline
\hline
\mbox{Fumadores } &amp;amp; 60 &amp;amp; 80 \newline
\mbox{No fumadores } C &amp;amp; 40 &amp;amp; 320 \newline
\hline
\end{array}
$$&lt;/p>
&lt;p>$$
\begin{aligned}
RR(E) &amp;amp;= \frac{60/(60+80)}{40/(40+320)} = 3.86
\newline
OR(E) &amp;amp;= \frac{60/80}{40/320} = 6
\end{aligned}
$$&lt;/p>
&lt;p>$$
\begin{array}{|l|cc|}
\hline
\textbf{Muestra 2} &amp;amp; \mbox{Cáncer } E &amp;amp; \mbox{No cáncer }\overline E\newline
\hline
\mbox{Fumadores } &amp;amp; 60 &amp;amp; 160 \newline
\mbox{No fumadores } C &amp;amp; 40 &amp;amp; 640 \newline
\hline
\end{array}
$$&lt;/p>
&lt;p>$$
\begin{aligned}
RR(E) &amp;amp;= \frac{60/(60+160)}{40/(40+640)} = 4.64
\newline
OR(E) &amp;amp;= \frac{60/160}{40/640} = 6
\end{aligned}
$$&lt;/p>
&lt;h3 id="aplicación-a-la-covid">Aplicación a la COVID&lt;/h3>
&lt;ul>
&lt;li>
&lt;a href="https://www.npr.org/sections/coronavirus-live-updates/2020/03/22/819846180/study-calculates-just-how-much-age-medical-conditions-raise-odds-of-severe-covid?t=1614095513052" target="_blank" rel="noopener">La edad aumenta la gravedad&lt;/a>&lt;/li>
&lt;li>
&lt;a href="https://www.aarp.org/espanol/salud/enfermedades-y-tratamientos/info-2020/tipo-de-sangre-y-riesgo-de-covid.html" target="_blank" rel="noopener">El riesgo de infección depende del grupo sanguíneo&lt;/a>&lt;/li>
&lt;li>
&lt;a href="https://medicalxpress.com/news/2021-01-vitamin-d-deficiency-covid-.html" target="_blank" rel="noopener">El déficit de vitamina D aumenta el riesgo de infección&lt;/a>&lt;/li>
&lt;li>
&lt;a href="https://www.sciencedaily.com/releases/2021/02/210209083524.htm" target="_blank" rel="noopener">Las personas con demencia tienen mayor riesgo de infectase&lt;/a>&lt;/li>
&lt;li>
&lt;a href="https://www.nejm.org/doi/full/10.1056/NEJMoa2007764" target="_blank" rel="noopener">El Remdesivir acelera la recuperación&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="tests-diagnósticos">Tests diagnósticos&lt;/h2>
&lt;p>Otra aplicación de la Epidemiología basado en el cálculo de probabilidades son los &lt;em>test diagnósticos&lt;/em>.&lt;/p>
&lt;blockquote>
&lt;p>Un test diagnóstico es un test usado para diagnosticar una enfermedad o descartarla.&lt;/p>
&lt;/blockquote>
&lt;p>Normalmente producen dos resultados: positivo (+) a favor de la enfermedad y negativo (-) en contra de ella.&lt;/p>
&lt;p>$$
\begin{array}{|l|cc|}
\hline
\mbox{Test} &amp;amp; E &amp;amp; \overline E\newline
\hline
\mbox{Positivo }+ &amp;amp; \color{green}{\mbox{Verdadero positivo }VP} &amp;amp; \color{red}{\mbox{Falso positivo }FP} \newline
\mbox{Negativo }- &amp;amp; \color{red}{\mbox{Falso negativo }FN} &amp;amp; \color{green}{\mbox{Verdadero negativo }VN}\newline
\hline
\end{array}
$$&lt;/p>
&lt;h2 id="sensibilidad-y-especificidad-de-un-test">Sensibilidad y especificidad de un test&lt;/h2>
&lt;p>La fiabilidad de un test diagnóstico depende de las siguientes probabilidades.&lt;/p>
&lt;div class="alert alert-def">
&lt;div>
&lt;strong>Definición: Sensibilidad&lt;/strong>&lt;br>
La &lt;em>sensibilidad&lt;/em> de un test diagnóstico es la proporción de resultados positivos del test en personas con la enfermedad,
$$P(+|E)=\frac{VP}{VP+FN}$$
&lt;/div>
&lt;/div>
&lt;div class="alert alert-def">
&lt;div>
&lt;strong>Definición: Especificidad&lt;/strong>&lt;br>
La &lt;em>especificidad&lt;/em> de un test diagnóstico es la proporción de resultados negativos del test en personas sin la enfermedad,
$$P(-|\overline{E})=\frac{VN}{VN+FP}$$
&lt;/div>
&lt;/div>
&lt;p>&lt;strong>Ejemplo&lt;/strong>. Un test de antígenos para detectar el SARS-COV-2 tiene una sensibilidad del 70% y una especificidad del 95%.&lt;/p>
&lt;ul>
&lt;li>Si aplicamos el test a 100 enfermos dará 70 positivos y 30 negativos.&lt;/li>
&lt;li>Si aplicamos el test a 100 sanos dará 95 negativos y 5 positivos.&lt;/li>
&lt;/ul>
&lt;p>La fiabilidad del test depende también de la prevalencia de la enfermedad.&lt;/p>
&lt;p>&lt;strong>Ejemplo&lt;/strong>. Utilizando el test del ejemplo anterior en una población de 1000 personas y suponiendo una prevalencia del 1% se tiene&lt;/p>
&lt;p>$$
\begin{array}{|l|cc|}
\hline
\mbox{Test} &amp;amp; E &amp;amp; \overline E\newline
\hline
\mbox{Positivo }+ &amp;amp; 7 &amp;amp; 50 \newline
\mbox{Negativo }- &amp;amp; 3 &amp;amp; 940\newline
\hline
\end{array}
$$&lt;/p>
&lt;p>&lt;img src="img/resultados-test0.01-0.7-0.95.svg" alt="Resultados de un test diagnóstico con una sensibilidad del 70%, una especidficidad del 95% y una prevalencia del 1%">&lt;/p>
&lt;p>Mientras que si la prevalencia es del 10% se tiene&lt;/p>
&lt;p>$$
\begin{array}{|l|cc|}
\hline
\mbox{Test} &amp;amp; E &amp;amp; \overline E\newline
\hline
\mbox{Positivo }+ &amp;amp; 70 &amp;amp; 45 \newline
\mbox{Negativo }- &amp;amp; 30 &amp;amp; 855\newline
\hline
\end{array}
$$&lt;/p>
&lt;p>&lt;img src="img/resultados-test0.1-0.7-0.95.svg" alt="Resultados de un test diagnóstico con una sensibilidad del 70%, una especidficidad del 95% y una prevalencia del 10%">&lt;/p>
&lt;p>Para ver los resultados de un test diagnóstico en función de la prevalencia, la sensibilidad y la especificidad se puede utilizar esta
&lt;a href="http://nube.aprendeconalf.es/shiny/diagnostic-test/" target="_blank" rel="noopener">aplicación para test diagnósticos&lt;/a>&lt;/p>
&lt;h3 id="cuándo-usar-un-test-más-sensible-o-más-específico">Cuándo usar un test más sensible o más específico&lt;/h3>
&lt;p>Una mayor sensibilidad aumenta el número de verdaderos positivos y disminuye el número de falsos negativos, mientras que una mayor especificidad aumenta el número de verdaderos negativos y disminuye el número de falsos positivos. Por tanto, utilizaremos un test más sensible cuando:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>La enfermedad es grave o muy contagiosa y es importante detectarla.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>La enfermedad es curable.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Los falsos positivos no provocan traumas serios.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>Y utilizaremos un test más específico cuando:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>La enfermedad es importante pero difícil o imposible de curar.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Los falsos positivos pueden provocar traumas serios.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>El tratamiento de los falsos positivos puede tener graves consecuencias.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>Tanto la sensibilidad como la especificidad son indicadores de la fiabilidad de un test a priori, es decir, antes de aplicar el test. Una vez que el test se ha aplicado y se conoce su resultado, a la hora de diagnosticar la enfermedad o rechazarla, es mejor utilizar los &lt;em>valores predictivos&lt;/em>.&lt;/p>
&lt;h2 id="valores-predictivos-de-un-test">Valores predictivos de un test&lt;/h2>
&lt;div class="alert alert-def">
&lt;div>
&lt;strong>Definición: Valor predictivo positivo&lt;/strong>&lt;br>
El &lt;em>valor predictivo positivo&lt;/em> de un test diagnóstico es la proporción de personas con la enfermedad entre las personas con resultado positivo en el test,
$$P(E|+) = \frac{VP}{VP+FP}$$
&lt;/div>
&lt;/div>
&lt;div class="alert alert-def">
&lt;div>
&lt;strong>Definición: Valor predictivo negativo&lt;/strong>&lt;br>
El &lt;em>valor predictivo negativo&lt;/em> de un test diagnóstico es la proporción de personas sin la enfermedad entre las personas con resultado negativo en el test,
$$P(\overline{E}|-) = \frac{VN}{VN+FN}$$
&lt;/div>
&lt;/div>
&lt;p>&lt;strong>Ejemplo&lt;/strong>. Siguiendo con el ejemplo anterior y suponiendo una prevalencia del 1%, se tiene&lt;/p>
&lt;p>$$
\begin{array}{|l|cc|}
\hline
\mbox{Test} &amp;amp; E &amp;amp; \overline E\newline
\hline
\mbox{Positivo }+ &amp;amp; 7 &amp;amp; 50 \newline
\mbox{Negativo }- &amp;amp; 3 &amp;amp; 940\newline
\hline
\end{array}
$$&lt;/p>
&lt;p>&lt;img src="img/resultados-test0.01-0.7-0.95.svg" alt="Resultados de un test diagnóstico con una sensibilidad del 70%, una especidficidad del 95% y una prevalencia del 1%">&lt;/p>
&lt;p>Mientras que si la prevalencia es del 10% se tiene&lt;/p>
&lt;p>$$
\begin{array}{|l|cc|}
\hline
\mbox{Test} &amp;amp; E &amp;amp; \overline E\newline
\hline
\mbox{Positivo }+ &amp;amp; 70 &amp;amp; 45 \newline
\mbox{Negativo }- &amp;amp; 30 &amp;amp; 855\newline
\hline
\end{array}
$$&lt;/p>
&lt;p>$$VPP = \frac{7}{7+50} = 0.123$$
$$VPN = \frac{940}{3+940} = 0.997$$&lt;/p>
&lt;p>Mientras que si la prevalencia es del 10% se tiene&lt;/p>
&lt;p>$$
\begin{array}{|l|cc|}
\hline
\mbox{Test} &amp;amp; E &amp;amp; \overline E\newline
\hline
\mbox{Positivo }+ &amp;amp; 70 &amp;amp; 45 \newline
\mbox{Negativo }- &amp;amp; 30 &amp;amp; 855\newline
\hline
\end{array}
$$&lt;/p>
&lt;p>$$VPP = \frac{70}{70+45} = 0.609$$
$$VPN = \frac{855}{30+855} = 0.966$$&lt;/p>
&lt;h3 id="interpretación-de-los-valores-predictivos">Interpretación de los valores predictivos&lt;/h3>
&lt;p>$$
\begin{array}{rcl}
VPP&amp;gt;0.5 &amp;amp; \Rightarrow &amp;amp; \mbox{Diagnosticar la enfermedad}\newline
VPN&amp;gt;0.5 &amp;amp; \Rightarrow &amp;amp; \mbox{Descartar la enfermedad}
\end{array}
$$&lt;/p>
&lt;h2 id="curva-roc">Curva ROC&lt;/h2>
&lt;p>En los test diagnósticos basado en la medición de una variable cuantitativa (como por ejemplo los test de antígenos para la COVID) la sensibilidad y la especificidad dependen el umbral fijado para dar un positivo.&lt;/p>
&lt;p>Para evaluar la fiabilidad de estos tests se suele utilizar la &lt;em>curva ROC&lt;/em>.&lt;/p>
&lt;div class="alert alert-def">
&lt;div>
&lt;strong>Definición: Curva ROC&lt;/strong>&lt;br>
La curva ROC (Receiver Operating Characteristic) de un test diagnóstico es la curva que resulta de representar la razón de verdaderos positivos (sensibilidad) frente a la razón de falsos positivos (1-especificidad) para los diferentes umbrales de positivo del test.
&lt;/div>
&lt;/div>
&lt;p>&lt;img src="img/curva-roc.png" alt="Curva ROC">&lt;/p>
&lt;h3 id="interpretación-de-la-curva-roc">Interpretación de la curva ROC&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>El mejor test es el que que se sitúa en la esquina superior izquierda de el espacio (sensibilidad 1 y especificidad 1).&lt;/p>
&lt;/li>
&lt;li>
&lt;p>La diagonal representa un test con un diagnóstico aleatorio.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Para evaluar la fiabilidad de un test diagnóstico independientemente del umbral de positivos se suele medir el area bajo la curva ROC, también conocida como &lt;em>AUC&lt;/em> (&lt;em>area under the curve&lt;/em>). Según del valor de la AUC, se tiene&lt;/p>
&lt;/li>
&lt;li>
&lt;p>0.5: Diagnóstico aleatorio.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>[0.5, 0.6): Test malo.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>[0.6, 0.75): Test regular.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>[0.75, 0.9): Test bueno.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>[0.9, 0.97): Test muy bueno.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>[0.97, 1): Test excelente.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h3 id="aplicaciones-a-la-covid">Aplicaciones a la COVID&lt;/h3>
&lt;ul>
&lt;li>
&lt;a href="https://www.rcpjournals.org/content/clinmedicine/20/6/e209" target="_blank" rel="noopener">Fiabilidad del diagnóstico por PCR&lt;/a>&lt;/li>
&lt;li>
&lt;a href="https://www.cdc.gov/mmwr/volumes/69/wr/mm695152a3.htm" target="_blank" rel="noopener">Fiabilidad del diagnóstico por el test de antígenos&lt;/a>&lt;/li>
&lt;li>
&lt;a href="https://academic.oup.com/ajcp/article/154/5/575/5898531" target="_blank" rel="noopener">Comparativa de test&lt;/a>&lt;/li>
&lt;li>
&lt;a href="https://www.dosfarma.com/salud/test-analisis/test-antigenos-covid/" target="_blank" rel="noopener">Test comerciales&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>Los test de antígenos son más rápidos que las PCR pero son menos fiables.&lt;/p>
&lt;p>Por un lado son menos sensibles que una prueba de PCR debido a que se se requiere una mayor cantidad de virus en las mucosas nasales o bucales para que se muestre un resultado positivo. Eso limita su efectividad cuando las personas llevan poco tiempo infectadas y el virus está empezando a reproducirse.&lt;/p>
&lt;p>Por otro lado también son menos específicos que la PCR, y por tanto, producen más falsos positivos.&lt;/p>
&lt;h2 id="referencias">Referencias&lt;/h2>
&lt;ul>
&lt;li>
&lt;a href="http://matematicas.uclm.es/cemat/covid19/" target="_blank" rel="noopener">Acción matemática contra el coronavirus&lt;/a>&lt;/li>
&lt;li>
&lt;a href="https://www.repidemicsconsortium.org/" target="_blank" rel="noopener">R Epidemic Consortium (RECON)&lt;/a>&lt;/li>
&lt;li>
&lt;a href="https://cran.r-project.org/doc/contrib/Epicalc_Book.pdf" target="_blank" rel="noopener">Analysis of epidemiological data using R and Epicalc&lt;/a>&lt;/li>
&lt;li>
&lt;a href="https://statsandr.com/blog/top-r-resources-on-covid-19-coronavirus/#coronavirus" target="_blank" rel="noopener">R resources about COVID-19&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>Probabilidad</title><link>/docencia/estadistica/manual/probabilidad/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/docencia/estadistica/manual/probabilidad/</guid><description>&lt;p>La estadística descriptiva permite describir el comportamiento y las relaciones entre las variables en la muestra, pero no permite sacar conclusiones sobre el resto de la población.&lt;/p>
&lt;p>Ha llegado el momento de dar el salto de la muestra a la población y pasar de la estadística descriptiva a la inferencia estadística, y el puente que lo permite es la &lt;strong>Teoría de la Probabilidad&lt;/strong>.&lt;/p>
&lt;p>Hay que tener en cuenta que el conocimiento que se puede obtener de la población a partir de la muestra es limitado, y que para obtener conclusiones válidas para la población la muestra debe ser
representativa de esta. Por esta razón, para garantizar la representatividad de la muestra, esta debe extraerse &lt;em>aleatoriamente&lt;/em>, es decir, al &lt;em>azar&lt;/em>.&lt;/p>
&lt;p>La teoría de la probabilidad precisamente se encarga de controlar ese azar para saber hasta qué punto son fiables las conclusiones obtenidas a partir de una muestra.&lt;/p>
&lt;h2 id="experimentos-y-sucesos-aleatorios">Experimentos y sucesos aleatorios&lt;/h2>
&lt;h3 id="experimentos-aleatorios">Experimentos aleatorios&lt;/h3>
&lt;p>El estudio de una característica en una población se realiza a través de experimentos aleatorios.&lt;/p>
&lt;div class="alert alert-def">
&lt;div>
&lt;p>&lt;strong>Definición - Experimento aleatorio&lt;/strong>. Un &lt;em>experimento aleatorio&lt;/em> es un experimento que cumple dos condiciones:&lt;/p>
&lt;ol>
&lt;li>El conjunto de posibles resultados es conocido.&lt;/li>
&lt;li>No se puede predecir con absoluta certeza el resultado del experimento.&lt;/li>
&lt;/ol>
&lt;/div>
&lt;/div>
&lt;p>&lt;strong>Ejemplo&lt;/strong>. Un ejemplo típico de experimentos aleatorios son los juegos
de azar. El lanzamiento de un dado, por ejemplo, es un experimento
aleatorio ya que:&lt;/p>
&lt;ul>
&lt;li>Se conoce el conjunto posibles de resultados $\{1,2,3,4,5,6\}$.&lt;/li>
&lt;li>Antes de lanzar el dado, es imposible predecir con absoluta certeza el valor que saldrá.&lt;/li>
&lt;/ul>
&lt;p>Otro ejemplo de experimento aleatorio sería la selección de un individuo de una población al azar y la determinación de su grupo sanguíneo.&lt;/p>
&lt;p>En general, la obtención de cualquier muestra mediante procedimientos aleatorios será un experimento
aleatorio.&lt;/p>
&lt;h3 id="espacio-muestral">Espacio muestral&lt;/h3>
&lt;div class="alert alert-def">
&lt;div>
&lt;strong>Definición - Espacio muestral&lt;/strong>. Al conjunto $\Omega$ de todos los posibles resultados de un
experimento aleatorio se le llama &lt;em>espacio muestral&lt;/em>.
&lt;/div>
&lt;/div>
&lt;p>Algunos ejemplos de espacios muestrales son:&lt;/p>
&lt;ul>
&lt;li>Lanzamiento de una moneda: $\Omega=\{c,x\}$.&lt;/li>
&lt;li>Lanzamiento de un dado: $\Omega=\{1,2,3,4,5,6\}$.&lt;/li>
&lt;li>Grupo sanguíneo de un individuo seleccionado al azar:
$\Omega=\{\mbox{A},\mbox{B},\mbox{AB},\mbox{0}\}$.&lt;/li>
&lt;li>Estatura de un individuo seleccionado al azar:
$\Omega=\mathbb{R}^+$.&lt;/li>
&lt;/ul>
&lt;h3 id="diagrama-de-árbol">Diagrama de árbol&lt;/h3>
&lt;p>En experimentos donde se mide más de una variable, la determinación del espacio muestral puede resultar compleja. En tales casos es recomendable utilizar un para construir el espacio muestral.&lt;/p>
&lt;p>En un diagrama de árbol cada variable se representa en un nivel del árbol y cada posible valor de la variable como una rama.&lt;/p>
&lt;p>&lt;strong>Ejemplo&lt;/strong> El siguiente diagrama de árbol representa el espacio muestral de un experimento aleatorio en el que se mide el sexo y el grupo sanguineo de un individuo al azar.&lt;/p>
&lt;img src="../img/probabilidad/espacio_muestral.svg" alt="Diagrama de árbol del espacio muestral del sexo y el grupo sanguineo" width="500">
&lt;h3 id="sucesos-aleatorios">Sucesos aleatorios&lt;/h3>
&lt;div class="alert alert-def">
&lt;div>
&lt;strong>Definición - Suceso aleatorio&lt;/strong>. Un &lt;em>suceso aleatorio&lt;/em> es cualquier subconjunto del espacio muestral $\Omega$ de un experimento aleatorio.
&lt;/div>
&lt;/div>
&lt;p>Existen distintos tipos de sucesos:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Suceso imposible&lt;/strong>: Es el suceso vacío $\emptyset$. Este suceso nunca ocurre.&lt;/li>
&lt;li>&lt;strong>Sucesos elementales&lt;/strong>: Son los sucesos formados por un solo elemento.&lt;/li>
&lt;li>&lt;strong>Sucesos compuestos&lt;/strong>: Son los sucesos formados por dos o más elementos.&lt;/li>
&lt;li>&lt;strong>Suceso seguro&lt;/strong>: Es el suceso que contiene el propio espacio muestral $\Omega$. Este suceso siempre ocurre.&lt;/li>
&lt;/ul>
&lt;h2 id="teoría-de-conjuntos">Teoría de conjuntos&lt;/h2>
&lt;h3 id="espacio-de-sucesos">Espacio de sucesos&lt;/h3>
&lt;div class="alert alert-def">
&lt;div>
&lt;strong>Definición - Espacio de sucesos&lt;/strong>. Dado un espacio muestral $\Omega$ de un experimento aleatorio, el conjunto formado por todos los posibles sucesos de $\Omega$ se llama &lt;em>espacio de sucesos de $\Omega$&lt;/em> y se denota $\mathcal{P}(\Omega)$.
&lt;/div>
&lt;/div>
&lt;p>&lt;strong>Ejemplo&lt;/strong>. Dado el espacio muestral $\Omega=\{a,b,c\}$, su espacio de sucesos es&lt;/p>
&lt;p>$$\mathcal{P}(\Omega)=\left\{\emptyset, \{a\},\{b\},\{c\},\{a,b\},\{a,c\},\{b,c\},\{a,b,c\}\right\}$$&lt;/p>
&lt;h3 id="operaciones-entre-sucesos">Operaciones entre sucesos&lt;/h3>
&lt;p>Puesto que los sucesos son conjuntos, por medio de la teoría de
conjuntos se pueden definir las siguientes operaciones entre sucesos:&lt;/p>
&lt;ul>
&lt;li>Unión.&lt;/li>
&lt;li>Intersección.&lt;/li>
&lt;li>Complementario.&lt;/li>
&lt;li>Diferencia.&lt;/li>
&lt;/ul>
&lt;h3 id="unión-de-sucesos">Unión de sucesos&lt;/h3>
&lt;div class="alert alert-def">
&lt;div>
&lt;p>&lt;strong>Definición - Suceso unión&lt;/strong>. Dados dos sucesos $A,B\subseteq \Omega$, se llama &lt;em>suceso unión&lt;/em> de $A$ y $B$, y se denota $A\cup B$, al suceso formado por los elementos de $A$ junto a los elementos de $B$, es decir,&lt;/p>
&lt;p>$$A\cup B = \{x\,|\, x\in A\textrm{ o }x\in B\}.$$&lt;/p>
&lt;/div>
&lt;/div>
&lt;img src="../img/probabilidad/union.svg" alt="Union de dos sucesos" width="300">
&lt;p>El suceso unión $A\cup B$ ocurre siempre que ocurre $A$ &lt;span style="color:red;">o&lt;/span> $B$.&lt;/p>
&lt;h3 id="intersección-de-sucesos">Intersección de sucesos&lt;/h3>
&lt;div class="alert alert-def">
&lt;div>
&lt;p>&lt;strong>Definición - Suceso intersección&lt;/strong>. Dados dos sucesos $A,B\subseteq \Omega$, se llama &lt;em>suceso intersección&lt;/em> de $A$ y $B$, y se denota $A\cap B$, al suceso formado por los elementos comunes de $A$ y $B$, es decir,&lt;/p>
&lt;p>$$A\cap B = \{x\,|\, x\in A\textrm{ y }x\in B\}.$$&lt;/p>
&lt;/div>
&lt;/div>
&lt;img src="../img/probabilidad/interseccion.svg" alt="Intersección de dos sucesos" width="300">
&lt;p>El suceso intersección $A\cap B$ ocurre siempre que ocurren $A$ &lt;span style="color:red;">y&lt;/span> $B$.&lt;/p>
&lt;p>Diremos que dos sucesos son &lt;strong>incompatibles&lt;/strong> si su intersección es vacía.&lt;/p>
&lt;h3 id="contrario-de-un-suceso">Contrario de un suceso&lt;/h3>
&lt;div class="alert alert-def">
&lt;div>
&lt;p>&lt;strong>Definición - Suceso contrario&lt;/strong>. Dado suceso $A\subseteq \Omega$, se llama &lt;em>suceso contrario o complementario&lt;/em> de $A$, y se denota $\overline A$, al suceso formado por los elementos de $\Omega$ que no pertenecen a $A$, es decir,&lt;/p>
&lt;p>$$\overline A = \{x\,|\, x\not\in A\}.$$&lt;/p>
&lt;/div>
&lt;/div>
&lt;img src="../img/probabilidad/contrario.svg" alt="Contrario de un suceso" width="300">
&lt;p>El suceso contrario $\overline A$ ocurre siempre que &lt;span style="color:red;">no&lt;/span> ocurre $A$.&lt;/p>
&lt;h3 id="diferencia-de-sucesos">Diferencia de sucesos&lt;/h3>
&lt;div class="alert alert-def">
&lt;div>
&lt;p>&lt;strong>Definición - Suceso diferencia&lt;/strong>. Dados dos sucesos $A,B\subseteq \Omega$, se llama &lt;em>suceso diferencia&lt;/em> de $A$ y $B$, y se denota $A-B$, al suceso formado por los elementos de $A$ que no pertenecen a $B$, es decir,&lt;/p>
&lt;p>$$A-B = \{x\,|\, x\in A\mbox{ y }x\not\in B\} = A \cap \overline B.$$&lt;/p>
&lt;/div>
&lt;/div>
&lt;img src="../img/probabilidad/diferencia.svg" alt="Diferencia de sucesos" width="300">
&lt;p>El suceso diferencia $A-B$ ocurre siempre que ocurre $A$ pero no ocurre $B$, y también puede expresarse como $A\cap \bar B$.&lt;/p>
&lt;p>&lt;strong>Ejemplo&lt;/strong>. Dado el espacio muestral correspondiente al lanzamiento de un dado
$\Omega=\{1,2,3,4,5,6\}$ y los sucesos $A=\{2,4,6\}$ y $B=\{1,2,3,4\}$,&lt;/p>
&lt;ul>
&lt;li>La unión de $A$ y $B$ es $A\cup B=\{1,2,3,4,6\}$.&lt;/li>
&lt;li>La intersección de $A$ y $B$ es $A\cap B=\{2,4\}$.&lt;/li>
&lt;li>El contrario de $A$ es $\overline A=\{1,3,5\}$.&lt;/li>
&lt;li>Los eventos $A$ y $\overline A$ son incompatibles.&lt;/li>
&lt;li>La diferencia de $A$ y $B$ es $A-B=\{6\}$, y la diferencia de $B$ y $A$ es $B-A=\{1,3\}$.&lt;/li>
&lt;/ul>
&lt;h3 id="álgebra-de-sucesos">Álgebra de sucesos&lt;/h3>
&lt;p>Dados los sucesos $A,B,C\in \mathcal{P}(\Omega)$, se cumplen las
siguientes propiedades:&lt;/p>
&lt;ol>
&lt;li>$A\cup A=A$, $A\cap A=A$ (idempotencia).&lt;/li>
&lt;li>$A\cup B=B\cup A$, $A\cap B = B\cap A$ (conmutativa).&lt;/li>
&lt;li>$(A\cup B)\cup C = A\cup (B\cup C)$, $(A\cap B)\cap C = A\cap (B\cap C)$ (asociativa).&lt;/li>
&lt;li>$(A\cup B)\cap C = (A\cap C)\cup (B\cap C)$, $(A\cap B)\cup C = (A\cup C)\cap (B\cup C)$ (distributiva).&lt;/li>
&lt;li>$A\cup \emptyset=A$, $A\cap E=A$ (elemento neutro).&lt;/li>
&lt;li>$A\cup E=E$, $A\cap \emptyset=\emptyset$ (elemento absorbente).&lt;/li>
&lt;li>$A\cup \overline A = E$, $A\cap \overline A= \emptyset$ (elemento simétrico complementario).&lt;/li>
&lt;li>$\overline{\overline A} = A$ (doble contrario).&lt;/li>
&lt;li>$\overline{A\cup B} = \overline A\cap \overline B$, $\overline{A\cap B} = \overline A\cup \overline B$ (leyes de Morgan).&lt;/li>
&lt;li>$A\cap B\subseteq A\cup B$.&lt;/li>
&lt;/ol>
&lt;h2 id="definición-de-probabilidad">Definición de probabilidad&lt;/h2>
&lt;h3 id="definición-clásica-de-probabilidad">Definición clásica de probabilidad&lt;/h3>
&lt;div class="alert alert-def">
&lt;div>
&lt;p>Dado un espacio muestral $\Omega$ de un experimento aleatorio donde todos los elementos de $\Omega$ son equiprobables, la &lt;em>probabilidad&lt;/em> de un suceso $A\subseteq \Omega$ es el cociente entre el número de elementos de $A$ y el número de elementos de $\Omega$&lt;/p>
&lt;p>$$P(A) = \frac{|A|}{|\Omega|} = \frac{\mbox{nº casos favorables a A}}{\mbox{nº casos posibles}}$$&lt;/p>
&lt;/div>
&lt;/div>
&lt;p>Esta definición es ampliamente utilizada, aunque tiene importantes
restricciones:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Es necesario que todos los elementos del espacio muestral tengan la
misma probabilidad de ocurrir (&lt;em>equiprobabilidad&lt;/em>).&lt;/p>
&lt;/li>
&lt;li>
&lt;p>No puede utilizarse con espacios muestrales infinitos, o de los que
no se conoce el número de casos posibles.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>&lt;span class="alert">&lt;em>¡Ojo! Esto no se cumple en muchos experimentos
aleatorios reales.&lt;/em>&lt;/span>&lt;/p>
&lt;p>&lt;strong>Ejemplo&lt;/strong>. Dado el espacio muestral correspondiente al lanzamiento de un dado $\Omega=\{1,2,3,4,5,6\}$ y el suceso $A=\{2,4,6\}$, la probabilidad de $A$ es&lt;/p>
&lt;p>$$P(A) = \frac{|A|}{|\Omega|} = \frac{3}{6} = 0.5.$$&lt;/p>
&lt;p>Sin embargo, si se considera el espacio muestral correspondiente a observar el grupo sanguíneo de un individuo al azar, $\Omega=\{O,A,B,AB\}$, no se puede usar la definición clásica de probabilidad para calcular la probabilidad de que tenga grupo sanguíneo $A$,&lt;/p>
&lt;p>$$P(A) \neq \frac{|A|}{|\Omega|} = \frac{1}{4} = 0.25,$$&lt;/p>
&lt;p>ya que los grupos sanguíneos no son igualmente probables en las poblaciones humanas.&lt;/p>
&lt;h3 id="definición-frecuentista-de-probabilidad">Definición frecuentista de probabilidad&lt;/h3>
&lt;div class="alert alert-theo">
&lt;div>
&lt;strong>Teorema - Ley de los grandes números&lt;/strong>.Cuando un experimento aleatorio se repite un gran número de veces, las frecuencias relativas de los sucesos del experimento tienden a estabilizarse en torno a cierto número, que es precisamente su probabilidad.
&lt;/div>
&lt;/div>
&lt;p>De acuerdo al teorema anterior, podemos dar la siguiente definición&lt;/p>
&lt;div class="alert alert-def">
&lt;div>
&lt;p>&lt;strong>Definición - Probabilidad frecuentista&lt;/strong>. Dado un espacio muestral $\Omega$ de un experimento aleatorio
reproducible, la &lt;em>probabilidad&lt;/em> de un suceso $A\subseteq \Omega$ es la frecuencia relativa del suceso $A$ en infinitas repeticiones del experimento&lt;/p>
&lt;p>$$P(A) = lim_{n\rightarrow \infty}\frac{n_{A}}{n}$$&lt;/p>
&lt;/div>
&lt;/div>
&lt;p>Aunque esta definición es muy útil en experimentos científicos reproducibles, también tiene serios inconvenientes, ya que&lt;/p>
&lt;ul>
&lt;li>Sólo se calcula una aproximación de la probabilidad real.&lt;/li>
&lt;li>La repetición del experimento debe ser en las mismas condiciones.&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Ejemplo&lt;/strong>. Dado el espacio muestral correspondiente al lanzamiento de una moneda $\Omega=\{C,X\}$, si después de lanzar la moneda 100 veces obtenemos 54 caras, entonces la probabilidad de $C$ es aproximadamente&lt;/p>
&lt;p>$$P(C) = \frac{n_C}{n} = \frac{54}{100} = 0.54.$$&lt;/p>
&lt;p>Si se considera el espacio muestral correspondiente a observar el grupo sanguíneo de un individuo al azar, $\Omega=\{O,A,B,AB\}$, si se toma una muestra aleatoria de 1000 personas y se observa que 412 tienen grupo sanguíneo $A$, entonces la probabilidad del grupo sanguíneo $A$ es aproximadamente&lt;/p>
&lt;p>$$P(A) = \frac{n_A}{n} = \frac{412}{1000} = 0.412.$$&lt;/p>
&lt;h3 id="definición-axiomática-de-probabilidad">Definición axiomática de probabilidad&lt;/h3>
&lt;div class="alert alert-def">
&lt;div>
&lt;p>&lt;strong>Definición - Probabilidad (Kolmogórov)&lt;/strong>.Dado un espacio muestral $\Omega$ de un experimento aleatorio, una función de &lt;em>probabilidad&lt;/em> es una aplicación que asocia a cada suceso $A\subseteq \Omega$ un número real $P(A)$, conocido como probabilidad de $A$, que cumple los siguientes axiomas:&lt;/p>
&lt;ol>
&lt;li>
&lt;p>La probabilidad de un suceso cualquiera es positiva o nula,
$$P(A)\geq 0.$$&lt;/p>
&lt;/li>
&lt;li>
&lt;p>La probabilidad del suceso seguro es igual a la unidad,
$$P(\Omega)=1.$$&lt;/p>
&lt;/li>
&lt;li>
&lt;p>La probabilidad de la unión de dos sucesos incompatibles
($A\cap B=\emptyset$) es igual a la suma de las probabilidades de
cada uno de ellos,
$$P(A\cup B) = P(A)+P(B).$$&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;/div>
&lt;h3 id="consecuencias-de-los-axiomas-de-probabilidad">Consecuencias de los axiomas de probabilidad&lt;/h3>
&lt;p>A partir de los axiomas de la definición de probabilidad se pueden
deducir los siguientes resultados:&lt;/p>
&lt;ol>
&lt;li>
&lt;p>$P(\overline A) = 1-P(A)$.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>$P(\emptyset)= 0$.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Si $A\subseteq B$ entonces $P(A)\leq P(B)$.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>$P(A) \leq 1$.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Si $A$ y $B$ son sucesos compatibles, es decir, su intersección no es vacía, entonces&lt;/p>
&lt;p>$$P(A\cup B)= P(A) + P(B) - P(A\cap B).$$&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Si el suceso $A$ está compuesto por los sucesos elementales
$e_1,e_2,&amp;hellip;,e_n$, entonces&lt;/p>
&lt;p>$$P(A)=\sum_{i=1}^n P(e_i).$$&lt;/p>
&lt;/li>
&lt;/ol>
&lt;div class="spoiler " >
&lt;p>
&lt;a class="btn btn-primary" data-toggle="collapse" href="#spoiler-12" role="button" aria-expanded="false" aria-controls="spoiler-12">
Demostración
&lt;/a>
&lt;/p>
&lt;div class="collapse card " id="spoiler-12">
&lt;div class="card-body">
&lt;ol>
&lt;li>
&lt;p>$\overline A = \Omega \Rightarrow P(A\cup \overline A) = P(\Omega) \Rightarrow P(A)+P(\overline A) = 1 \Rightarrow P(\overline A)=1-P(A)$.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>$\emptyset = \overline \Omega \Rightarrow P(\emptyset) = P(\overline \Omega) = 1-P(\Omega) = 1-1 = 0.$&lt;/p>
&lt;/li>
&lt;li>
&lt;p>$B = A\cup (B-A)$. Como $A$ y $B-A$ son incompatibles, $P(B) = P(A\cup (B-A)) = P(A)+P(B-A) \geq P(A).$&lt;/p>
&lt;p>Si pensamos en probabilidades como áreas, es fácil de ver gráficamente,
&lt;img src="../img/probabilidad/probabilidad_inclusion.svg" alt="Probabilidad de un suceso incluido en otro" width="300">&lt;/p>
&lt;/li>
&lt;li>
&lt;p>$A\subseteq \Omega \Rightarrow P(A)\leq P(\Omega)=1.$&lt;/p>
&lt;/li>
&lt;li>
&lt;p>$A=(A-B)\cup (A\cap B)$. Como $A-B$ y $A\cap B$ son incompatibles, $P(A)=P(A-B)+P(A\cap B) \Rightarrow P(A-B)=P(A)-P(A\cap B)$.&lt;/p>
&lt;p>Si pensamos en probabilidades como áreas, es fácil de ver gráficamente,&lt;/p>
&lt;img src="../img/probabilidad/probabilidad_diferencia.svg" alt="Probabilidad de la diferencia de dos sucesos" width="300">
&lt;/li>
&lt;li>
&lt;p>$A\cup B= (A-B) \cup (B-A) \cup (A\cap B)$. Como $A-B$, $B-A$ y $A\cap B$ son incompatibles, $P(A\cup
B)=P(A-B)+P(B-A)+P(A\cap B) = P(A)-P(A\cap B)+P(B)-P(A\cap B)+P(A\cap B)= P(A)+P(B)-P(A\cup B)$.&lt;/p>
&lt;p>Si pensamos en probabilidades como áreas, es fácil de ver gráficamente,&lt;/p>
&lt;img src="../img/probabilidad/probabilidad_union.svg" alt="Probabilidad de la unión de dos sucesos" width="300">
&lt;/li>
&lt;li>
&lt;p>$A=\{e_1,\cdots,e_n\} = \{e_1\}\cup \cdots \cup \{e_n\} \Rightarrow$ $P(A)=P(\{e_1\}\cup \cdots \cup \{e_n\}) = P(\{e_1\})+ \cdots P(\{e_n\}).$&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;h3 id="interpretación-de-la-probabilidad">Interpretación de la probabilidad&lt;/h3>
&lt;p>Como ha quedado claro en los axiomas anteriores, la probabilidad de un evento $A$ es un número real $P(A)$ que está siempre entre 0 y 1.&lt;/p>
&lt;p>En cierto modo, este número expresa la verosimilitud del evento, es decir, la confianza que hay en que ocurra $A$ en el experimento. Por tanto, también nos da una medida de la incertidumbre sobre el suceso.&lt;/p>
&lt;ul>
&lt;li>
&lt;p>La mayor incertidumbre corresponde a $P(A)=0.5$ (Es tan probable que ocurra $A$ como que no ocurra).&lt;/p>
&lt;/li>
&lt;li>
&lt;p>La menor incertidumbre corresponde a $P(A)=1$ ($A$ sucederá con absoluta certeza) y $P(A)=0$ ($A$ no sucederá con absoluta certeza).&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>Cuando $P(A)$ está más próximo a 0 que a 1, la confianza en que no ocurra $A$ es mayor que la de que ocurra $A$. Por el contrario, cuando $P(A)$ está más próximo a 1 que a 0, la confianza en que ocurra
$A$ es mayor que la de que no ocurra $A$.&lt;/p>
&lt;h2 id="probabilidad-condicionada">Probabilidad condicionada&lt;/h2>
&lt;h3 id="experimentos-condicionados">Experimentos condicionados&lt;/h3>
&lt;p>En algunas ocasiones, es posible que tengamos alguna información sobre el experimento antes de su realización. Habitualmente esa información se da en forma de un suceso $B$ del mismo espacio muestral que sabemos que es cierto antes de realizar el experimento.&lt;/p>
&lt;p>En tal caso se dice que el suceso $B$ es un suceso &lt;em>condicionante&lt;/em>, y la probabilidad de otro suceso $A$ se conoce como y se expresa $$P(A|B).$$&lt;/p>
&lt;p>Esto debe leerse como &lt;em>probabilidad de $A$ dado $B$&lt;/em> o &lt;em>probabilidad de $A$ bajo la condición de $B$&lt;/em>.&lt;/p>
&lt;p>Los condicionantes suelen cambiar el espacio muestral del experimento y por tanto las probabilidades de sus sucesos.&lt;/p>
&lt;p>&lt;strong>Ejemplo&lt;/strong>. Supongamos que tenemos una muestra de 100 hombres y 100 mujeres con las siguientes frecuencias&lt;/p>
&lt;p>$$
\begin{array}{|c|c|c|}
\hline
&amp;amp; \mbox{No fumadores} &amp;amp; \mbox{Fumadores} \newline
\hline
\mbox{Mujeres} &amp;amp; 80 &amp;amp; 20 \newline
\hline
\mbox{Hombres} &amp;amp; 60 &amp;amp; 40 \newline
\hline
\end{array}
$$&lt;/p>
&lt;p>Entonces, usando la definición frecuentista de probabilidad, la probabilidad de que una persona elegida al azar sea fumadora es&lt;/p>
&lt;p>$$P(\mbox{Fumadora})= \frac{60}{200}=0.3.$$&lt;/p>
&lt;p>Sin embargo, si se sabe que la persona elegida es mujer, entonces la muestra se reduce a la primera fila, y la probabilidad de ser fumadora es&lt;/p>
&lt;p>$$P(\mbox{Fumadora}|\mbox{Mujer})=\frac{20}{100}=0.2.$$&lt;/p>
&lt;h3 id="probabilidad-condicionada-1">Probabilidad condicionada&lt;/h3>
&lt;div class="alert alert-def">
&lt;div>
&lt;p>&lt;strong>Definición - Probabilidad condicionada&lt;/strong>. Dado un espacio muestral $\Omega$ de un experimento aleatorio, y dos dos sucesos $A,B\subseteq \Omega$, la probabilidad de $A$ &lt;em>condicionada&lt;/em> por $B$ es&lt;/p>
&lt;p>$$P(A|B) = \frac{P(A\cap B)}{P(B)},$$&lt;/p>
&lt;p>siempre y cuando, $P(B)\neq 0$.&lt;/p>
&lt;/div>
&lt;/div>
&lt;p>Esta definición permite calcular probabilidades sin tener que alterar el espacio muestral original del experimento.&lt;/p>
&lt;p>&lt;strong>Ejemplo&lt;/strong>. En el ejemplo anterior&lt;/p>
&lt;p>$$P(\mbox{Fumadora}|\mbox{Mujer})= \frac{P(\mbox{Fumadora}\cap \mbox{Mujer})}{P(\mbox{Mujer})} = \frac{20/200}{100/200}=\frac{20}{100}=0.2.$$&lt;/p>
&lt;h3 id="probabilidad-del-suceso-intersección">Probabilidad del suceso intersección&lt;/h3>
&lt;p>A partir de la definición de probabilidad condicionada es posible obtener la fórmula para calcular la probabilidad de la intersección de dos sucesos.&lt;/p>
&lt;p>$$P(A\cap B) = P(A)P(B|A) = P(B)P(A|B).$$&lt;/p>
&lt;p>&lt;strong>Ejemplo&lt;/strong>. En una población hay un 30% de fumadores y se sabe que el 40% de los fumadores tiene cáncer de pulmón. La probabilidad de que una persona elegida al azar sea fumadora y tenga cáncer de pulmón es&lt;/p>
&lt;p>$$P(\mbox{Fumadora}\cap \mbox{Cáncer})= P(\mbox{Fumadora})P(\mbox{Cáncer}|\mbox{Fumadora}) = 0.3\times 0.4 = 0.12.$$&lt;/p>
&lt;h3 id="independencia-de-sucesos">Independencia de sucesos&lt;/h3>
&lt;p>En ocasiones, la ocurrencia del suceso condicionante no cambia la
probabilidad original del suceso principal.&lt;/p>
&lt;div class="alert alert-def">
&lt;div>
&lt;p>&lt;strong>Definición - Sucesos independientes&lt;/strong>. Dado un espacio muestral $\Omega$ de un experimento aleatorio, dos
sucesos $A,B\subseteq \Omega$ son &lt;em>independientes&lt;/em> si la probabilidad de $A$ no se ve alterada al condicionar por $B$, y viceversa, es decir,&lt;/p>
&lt;p>$$P(A|B) = P(A) \quad \mbox{and} \quad P(B|A)=P(B),$$&lt;/p>
&lt;p>si $P(A)\neq 0$ y $P(B)\neq 0$.&lt;/p>
&lt;/div>
&lt;/div>
&lt;p>Esto significa que la ocurrencia de uno evento no aporta información relevante para cambiar la incertidumbre sobre el otro.&lt;/p>
&lt;p>Cuando dos eventos son independientes, la probabilidad de su intersección es igual al producto de sus probabilidades,&lt;/p>
&lt;p>$$P(A\cap B) = P(A)P(B).$$&lt;/p>
&lt;h2 id="espacio-probabilístico">Espacio probabilístico&lt;/h2>
&lt;div class="alert alert-def">
&lt;div>
&lt;p>&lt;strong>Definición - Espacio probabilístico&lt;/strong>. Un &lt;em>espacio probabilístico&lt;/em> de un experimento aleatorio es una terna $(\Omega,\mathcal{F},P)$ donde&lt;/p>
&lt;ul>
&lt;li>$\Omega$ es el espacio muestral del experimento.&lt;/li>
&lt;li>$\mathcal{F}$ es un un conjunto de sucesos del experimento.&lt;/li>
&lt;li>$P$ es una función de probabilidad.&lt;/li>
&lt;/ul>
&lt;/div>
&lt;/div>
&lt;p>Si conocemos la probabilidad de todos los elementos de $\Omega$, entonces podemos calcular la probabilidad de cualquier suceso en $\mathcal{F}$ y se puede construir fácilmente el espacio probabilístico.&lt;/p>
&lt;h3 id="construcción-del-espacio-probabilístico">Construcción del espacio probabilístico&lt;/h3>
&lt;p>Para determinar la probabilidad de cada suceso elemental se puede utilizar un diagrama de árbol, mediante las siguientes reglas:&lt;/p>
&lt;ol>
&lt;li>
&lt;p>Para cada nodo del árbol, etiquetar la rama que conduce hasta él con la probabilidad de que la variable en ese nivel tome el valor del nodo, condicionada por los sucesos correspondientes a sus nodos
antecesores en el árbol.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>La probabilidad de cada suceso elemental en las hojas del árbol es el producto de las probabilidades de las ramas que van desde la raíz a la hoja del árbol.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;img src="../img/probabilidad/espacio_probabilistico.svg" alt="Diagrama de árbol de un espacio probabilístico" width="600">
&lt;h3 id="árboles-de-probabilidad-con-variables-dependientes">Árboles de probabilidad con variables dependientes&lt;/h3>
&lt;p>&lt;strong>Ejemplo&lt;/strong>. Sea una población en la que el 30% de las personas fuman, y que la incidencia del cáncer de pulmón en fumadores es del 40% mientras que en los no fumadores es del 10%.&lt;/p>
&lt;p>El espacio probabilístico del experimento aleatorio que consiste en elegir una persona al azar y medir las variables Fumar y Cáncer de pulmón se muestra a continuación.&lt;/p>
&lt;img src="../img/probabilidad/espacio_probabilistico_fumar_cancer.svg" alt="Diagrama de árbol del espacio probabilístico de fumar y tener cáncer de pulmón" width="550">
&lt;h3 id="árboles-de-probabilidad-con-variables-independientes">Árboles de probabilidad con variables independientes&lt;/h3>
&lt;p>&lt;strong>Ejemplo&lt;/strong> El árbol de probabilidad asociado al experimento aleatorio que consiste en el lanzamiento de dos monedas se muestra a continuación.&lt;/p>
&lt;img src="../img/probabilidad/espacio_probabilistico_monedas.svg" alt="Diágrama de árbol del espacio probabilístico del lanzamiento de dos monedas" width="550">
&lt;h3 id="árboles-de-probabilidad-con-variables-independientes-1">Árboles de probabilidad con variables independientes&lt;/h3>
&lt;p>&lt;strong>Ejemplo&lt;/strong>. Dada una población en la que hay un 40% de hombres y un 60% de mujeres, el experimento aleatorio que consiste en tomar una muestra aleatoria de tres personas tiene el árbol de probabilidad que se muestra a continuación.&lt;/p>
&lt;img src="../img/probabilidad/espacio_probabilistico_muestra.svg" alt="Diagrama de árbol del espacio probabilístico del sexo de tres individuos elegidos al azar" width="600">
&lt;h2 id="teorema-de-la-probabilidad-total">Teorema de la probabilidad total&lt;/h2>
&lt;h3 id="sistema-completo-de-sucesos">Sistema completo de sucesos&lt;/h3>
&lt;p>Una colección de sucesos $A_1,A_2,\ldots,A_n$ de un mismo espacio muestral $\Omega$ es un &lt;em>sistema completo&lt;/em> si cumple las siguientes condiciones:&lt;/p>
&lt;ol>
&lt;li>
&lt;p>La unión de todos es el espacio muestral:
$A_1\cup \cdots\cup A_n =\Omega$.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Son incompatibles dos a dos: $A_i\cap A_j = \emptyset$
$\forall i\neq j$.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;img src="../img/probabilidad/particion_espacio_muestral.svg" alt="Partición del espacio muestral en un sistema completo de sucesos" width="300">
&lt;p>En realidad un sistema completo de sucesos es una partición del espacio muestral de acuerdo a algún atributo, como por ejemplo el sexo o el grupo sanguíneo.&lt;/p>
&lt;h3 id="teorema-de-la-probabilidad-total-1">Teorema de la probabilidad total&lt;/h3>
&lt;p>Conocer las probabilidades de un determinado suceso en cada una de las partes de un sistema completo puede ser útil para calcular su probabilidad.&lt;/p>
&lt;div class="alert alert-def">
&lt;div>
&lt;p>&lt;strong>Definición - Teorema de la probabilidad total&lt;/strong>. Dado un sistema completo de sucesos $A_1,\ldots,A_n$ y un suceso $B$ de un espacio muestral $\Omega$, la probabilidad de cualquier suceso $B$ del espacio muestral se puede calcular mediante la fórmula&lt;/p>
&lt;p>$$P(B) = \sum_{i=1}^n P(A_i\cap B) = \sum_{i=1}^n P(A_i)P(B|A_i).$$&lt;/p>
&lt;/div>
&lt;/div>
&lt;div class="spoiler " >
&lt;p>
&lt;a class="btn btn-primary" data-toggle="collapse" href="#spoiler-17" role="button" aria-expanded="false" aria-controls="spoiler-17">
Demostración
&lt;/a>
&lt;/p>
&lt;div class="collapse card " id="spoiler-17">
&lt;div class="card-body">
&lt;p>La demostración del teorema es sencilla, ya que al ser $A_1,\ldots,A_n$ un sistema completo tenemos&lt;/p>
&lt;p>$$B = B\cap E = B\cap (A_1\cup \cdots \cup A_n) = (B\cap A_1)\cup \cdots \cup (B\cap A_n)$$&lt;/p>
&lt;p>y como estos sucesos son incompatibles entre sí, se tiene&lt;/p>
&lt;p>$$
\begin{aligned}
P(B) &amp;amp;= P((B\cap A_1)\cup \cdots \cup (B\cap A_n)) = P(B\cap A_1)+\cdots + P(B\cap A_n) =\newline
&amp;amp;= P(A_1)P(B/A_1)+\cdots + P(A_n)P(B/A_n) = \sum_{i=1}^n P(A_i)P(B/A_i).
\end{aligned}
$$&lt;/p>
&lt;img src="../img/probabilidad/probabilidad_total.svg" alt="Teorema de la probabilidad total" width="400">
&lt;/div>
&lt;/div>
&lt;/div>
&lt;p>&lt;strong>Ejemplo&lt;/strong>. Un determinado síntoma $S$ puede ser originado por una enfermedad $E$ pero también lo pueden presentar las personas sin la enfermedad.
Sabemos que la prevalencia de la enfermedad $E$ es $0.2$. Además, se sabe que el $90%$ de las personas con la enfermedad presentan el síntoma, mientras que sólo el $40%$ de las personas sin la enfermedad lo presentan. Si se toma una persona al azar de la población, &lt;em>¿qué probabilidad hay de que tenga el síntoma?&lt;/em>&lt;/p>
&lt;p>Para responder a la pregunta se puede aplicar el teorema de la probabilidad total usando el sistema completo $\{E,\overline{E}\}$:&lt;/p>
&lt;p>$$P(S) = P(E)P(S|E)+P(\overline E)P(S|\overline E) = 0.2\cdot 0.9 + 0.8\cdot 0.4 = 0.5.$$&lt;/p>
&lt;p>Es decir, la mitad de la población tendrá el síntoma.&lt;/p>
&lt;p>&lt;em>¡En el fondo se trata de una media ponderada de probabilidades!&lt;/em>&lt;/p>
&lt;p>La respuesta a la pregunta anterior es evidente a la luz del árbol de probabilidad del espacio probabilístico del experimento.&lt;/p>
&lt;img src="../img/probabilidad/espacio_probabilistico_total.svg" alt="Aplicación del teorema de la probabilidad total en un espacio probabilístico" width="600">
&lt;p>$$
\begin{aligned}
P(S) &amp;amp;= P(E,S) + P(\overline E,S) = P(E)P(S|E)+P(\overline E)P(S|\overline E)\newline
&amp;amp; = 0.2\cdot 0.9+ 0.8\cdot 0.4 = 0.18 + 0.32 = 0.5.
\end{aligned}
$$&lt;/p>
&lt;h2 id="teorema-de-bayes">Teorema de Bayes&lt;/h2>
&lt;p>Los sucesos de un sistema completo de sucesos $A_1,\cdots,A_n$ también pueden verse como las distintas hipótesis ante un determinado hecho $B$.&lt;/p>
&lt;p>En estas condiciones resulta útil poder calcular las probabilidades a posteriori $P(A_i|B)$ de cada una de las hipótesis.&lt;/p>
&lt;div class="alert alert-def">
&lt;div>
&lt;p>&lt;strong>Definición - Teorema de Bayes&lt;/strong>. Dado un sistema completo de sucesos $A_1,\ldots,A_n$ y un suceso $B$
de un espacio muestral $\Omega$ y otro suceso $B$ del mismo espacio muestral, la probabilidad de cada suceso $A_i$ $i=1,\ldots,n$ condicionada por $B$ puede calcularse con la siguiente fórmula&lt;/p>
&lt;p>$$P(A_i|B) = \frac{P(A_i\cap B)}{P(B)} = \frac{P(A_i)P(B|A_i)}{\sum_{i=1}^n P(A_i)P(B|A_i)}.$$&lt;/p>
&lt;/div>
&lt;/div>
&lt;p>&lt;strong>Ejemplo&lt;/strong>. En el ejemplo anterior, una pregunta más interesante es qué diagnosticar a una persona que presenta el síntoma.&lt;/p>
&lt;p>En este caso se puede interpretar $E$ y $\overline{E}$ como las dos posibles hipótesis para el síntoma $S$. Las probabilidades a priori para ellas son $P(E)=0.2$ y $P(\overline E)=0.8$. Esto quiere decir que si no se dispone de información sobre el síntoma, el diagnóstico será que la persona no tiene la enfermedad.&lt;/p>
&lt;p>Sin embargo, si al reconocer a la persona se observa que presenta el síntoma, dicha información condiciona a las hipótesis, y para decidir entre ellas es necesario calcular sus probabilidades a posteriori, es
decir, $P(E|S)$ y P(\overline{E}|S)$.&lt;/p>
&lt;p>Para calcular las probabilidades a posteriori se puede utilizar el teorema de Bayes:&lt;/p>
&lt;p>$$
\begin{aligned}
P(E|S) &amp;amp;= \frac{P(E)P(S|E)}{P(E)P(S|E)+P(\overline{E})P(S|\overline{E})} = \frac{0.2\cdot 0.9}{0.2\cdot 0.9 + 0.8\cdot 0.4} = \frac{0.18}{0.5}=0.36,\newline
P(\overline{E}|S) &amp;amp;= \frac{P(\overline{E})P(S|\overline{E})}{P(E)P(S|E)+P(\overline{E})P(S|\overline{E})} = \frac{0.8\cdot 0.4}{0.2\cdot 0.9 + 0.8\cdot 0.4} = \frac{0.32}{0.5}=0.64.
\end{aligned}
$$&lt;/p>
&lt;p>Como se puede ver la probabilidad de tener la enfermedad ha aumentado.
No obstante, la probabilidad de no tener la enfermedad sigue siendo mayor que la de tenerla, y por esta razón el diagnóstico seguirá siendo que no tiene la enfermedad.&lt;/p>
&lt;p>En este caso se dice que el síntoma $S$ &lt;em>no es determinante&lt;/em> a la hora de diagnosticar la enfermedad.&lt;/p>
&lt;h2 id="epidemiología">Epidemiología&lt;/h2>
&lt;p>Una de las ramas de la Medicina que hace un mayor uso de la probabilidad es la , que estudia la distribución y las causas de las enfermedades en las poblaciones, identificando factores de riesgos para las enfermedades de cara a la atención médica preventiva.&lt;/p>
&lt;p>En Epidemiología interesa la frecuencia de un &lt;em>suceso médico&lt;/em> $E$ (típicamente una enfermedad como la gripe, un factor de riesgo como fumar o un factor de protección como vacunarse) que se mide mediante una
variable nominal con dos categorías (ocurrencia o no del suceso).&lt;/p>
&lt;p>Hay diferentes medidas relativas a la frecuencia de un suceso médico. Las más importantes son:&lt;/p>
&lt;ul>
&lt;li>Prevalencia&lt;/li>
&lt;li>Incidencia&lt;/li>
&lt;li>Riesgo relativo&lt;/li>
&lt;li>Odds ratio&lt;/li>
&lt;/ul>
&lt;h3 id="prevalencia">Prevalencia&lt;/h3>
&lt;div class="alert alert-def">
&lt;div>
&lt;p>&lt;strong>Definición - Prevalencia&lt;/strong>. La &lt;em>prevalencia&lt;/em> de un suceso médico $E$ es la proporción de una población que está afectada por el suceso.&lt;/p>
&lt;p>$$\mbox{Prevalencia}(E) = \frac{\mbox{Nº individuos afectados por $E$}}{\mbox{Tamaño poblacional}}$$&lt;/p>
&lt;/div>
&lt;/div>
&lt;p>A menudo, la prevalencia se estima mediante una muestra como la frecuencia relativa de los individuos afectados por el suceso en la muestra. Es también común expresarla esta frecuencia como un porcentaje.&lt;/p>
&lt;p>&lt;strong>Ejemplo&lt;/strong>. Para estimar la prevalencia de la gripe se estudió una muestra de 1000 personas de las que 150 presentaron gripe. Así, la prevalencia de la gripe es aproximadamente 150/1000=0.15, es decir, un
15%.&lt;/p>
&lt;h3 id="incidencia">Incidencia&lt;/h3>
&lt;p>La mide la probabilidad de ocurrencia de un suceso médico en una población durante un periodo de tiempo específico. La incidencia puede medirse como una proporción acumulada o como una tasa.&lt;/p>
&lt;div class="alert alert-def">
&lt;div>
&lt;p>&lt;strong>Definición - Incidencia acumulada&lt;/strong>. La &lt;em>incidencia acumulada&lt;/em> de un suceso médico $E$ es la proporción de individuos que experimentaron el evento en un periodo de tiempo, es decir, el número de nuevos casos afectados por el evento en el periodo de tiempo, divido por el tamaño de la población inicialmente en riesgo de verse afectada.&lt;/p>
&lt;p>$$R(E)=\frac{\mbox{Nº de nuevos casos con $E$}}{\mbox{Tamaño de la población en riesgo}}$$&lt;/p>
&lt;/div>
&lt;/div>
&lt;p>&lt;strong>Ejemplo&lt;/strong>. Una población contenía inicialmente $1000$ personas sin gripe y después de dos años se observó que 160 de ellas sufrieron gripe. La incidencia acumulada de la gripe es 160 casos pro 1000 personas por dos años, es decir, 16% en dos años.&lt;/p>
&lt;h3 id="tasa-de-incidencia-o-riesgo-absoluto">Tasa de incidencia o Riesgo absoluto&lt;/h3>
&lt;div class="alert alert-def">
&lt;div>
&lt;p>&lt;strong>Definición - Riesgo absoluto&lt;/strong>.La &lt;em>tasa de incidencia&lt;/em> o &lt;em>riesgo absoluto&lt;/em> de un suceso médico $E$ es el número de nuevos casos afectados por el evento divido por la población en riesgo y por el número de unidades temporales del periodo considerado.&lt;/p>
&lt;p>$$R(E)=\frac{\mbox{Nº nuevos casos con $E$}}{\mbox{Tamaño población en riesgo}\times \mbox{Nº unidades de tiempo}}$$&lt;/p>
&lt;/div>
&lt;/div>
&lt;p>&lt;strong>Ejemplo&lt;/strong>. Una población contenía inicialmente $1000$ personas sin gripe y después de dos años se observó que 160 de ellas sufrieron gripe. Si se considera el año como intervalo de tiempo, la tasa de incidencia de la gripe es 160 casos dividida por 1000 personas y por dos años, es decir, 80 casos por 1000 personas-año o 8% de personas al año.&lt;/p>
&lt;h3 id="prevalencia-vs-incidencia">Prevalencia vs Incidencia&lt;/h3>
&lt;p>La prevalencia no debe confundirse con la incidencia. La prevalencia indica cómo de extendido está el suceso médico en una población, sin preocuparse por cuándo los sujetos se han expuesto al riesgo o durante
cuánto tiempo, mientras que la incidencia se fija en el riesgo de verse afectado por el suceso en un periodo concreto de tiempo.&lt;/p>
&lt;p>Así, la prevalencia se calcula en estudios transversales en un momento temporal puntual, mientras que para medir la incidencia se necesita un estudio longitudinal que permita observar a los individuos durante un
periodo de tiempo.&lt;/p>
&lt;p>La incidencia es más útil cuando se pretende entender la causalidad del suceso: por ejemplo, si la incidencia de una enfermedad en una población aumenta, seguramente hay un factor de riesgo que lo está promoviendo.&lt;/p>
&lt;p>Cuando la tasa de incidencia es aproximadamente constante en la duración del suceso, la prevalencia es aproximadamente el producto de la incidencia por la duración media del suceso, es decir,&lt;/p>
&lt;p>$$ \mbox{Prevalencia} = \mbox{Incidencia} \times \mbox{duración}$$&lt;/p>
&lt;h3 id="comparación-de-riesgos">Comparación de riesgos&lt;/h3>
&lt;p>Para determinar si un factor o característica está asociada con el suceso médico es necesario comparar el riesgo del suceso en dos poblaciones, una expuesta al factor y la otra no. El grupo expuesto al factor se conoce como &lt;em>grupo tratamiento&lt;/em> o &lt;em>grupo experimental&lt;/em> $T$ y el grupo no expuesto como &lt;em>grupo control&lt;/em> $C$.&lt;/p>
&lt;p>Habitualmente los casos observados para cada grupo se representan en una tabla de 2$\times$2 como la siguiente:&lt;/p>
&lt;table>
&lt;thead>
&lt;tr class="header">
&lt;th style="text-align: left;">&lt;/th>
&lt;th style="text-align: center;">Suceso $E$&lt;/th>
&lt;th style="text-align: center;">No suceso $\overline E$&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr class="odd">
&lt;td style="text-align: left;">Grupo tratamiento $T$&lt;/td>
&lt;td style="text-align: center;">$a$&lt;/td>
&lt;td style="text-align: center;">$b$&lt;/td>
&lt;/tr>
&lt;tr class="even">
&lt;td style="text-align: left;">Grupo control $C$&lt;/td>
&lt;td style="text-align: center;">$c$&lt;/td>
&lt;td style="text-align: center;">$d$&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h3 id="riesgo-atribuible-o-diferencia-de-riesgos-ra">Riesgo atribuible o diferencia de riesgos $RA$&lt;/h3>
&lt;div class="alert alert-def">
&lt;div>
&lt;p>&lt;strong>Definición - Riesgo atribuible&lt;/strong>. El &lt;em>riesgo atribuible&lt;/em> o &lt;em>diferencia de riesgo&lt;/em> de un suceso médico
$E$ para los individuos expuestos a un factor es la diferencia entre los riesgos absolutos de los grupos tratamiento y control.&lt;/p>
&lt;p>$$RA(E)=R_T(E)-R_C(E)=\frac{a}{a+b}-\frac{c}{c+d}.$$&lt;/p>
&lt;/div>
&lt;/div>
&lt;p>El riesgo atribuible es el riesgo de un suceso que es debido específicamente al factor de interés.&lt;/p>
&lt;p>Obsérvese que el riesgo atribuible puede ser positivo, cuando el riesgo del grupo tratamiento es mayor que el del grupo control, o negativo, de lo contrario.&lt;/p>
&lt;p>&lt;strong>Ejemplo&lt;/strong>. Para determinar la efectividad de una vacuna contra la gripe, una muestra de 1000 personas sin gripe fueron seleccionadas al comienzo del año. La mitad de ellas fueron vacunadas (grupo tratamiento) y la otra mitad recibieron un placebo (grupo control). La tabla siguiente resume los resultados al final del año.&lt;/p>
&lt;table>
&lt;thead>
&lt;tr class="header">
&lt;th style="text-align: left;">&lt;/th>
&lt;th style="text-align: center;">Gripe $E$&lt;/th>
&lt;th style="text-align: center;">No gripe $\overline E$&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr class="odd">
&lt;td style="text-align: left;">Grupo tratamiento (vacunados)&lt;/td>
&lt;td style="text-align: center;">20&lt;/td>
&lt;td style="text-align: center;">480&lt;/td>
&lt;/tr>
&lt;tr class="even">
&lt;td style="text-align: left;">Grupo control (No vacunados)&lt;/td>
&lt;td style="text-align: center;">80&lt;/td>
&lt;td style="text-align: center;">420&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>El riesgo atribuible de contraer la gripe cuando se es vacunado es&lt;/p>
&lt;p>$$AR(D) = \frac{20}{20+480}-\frac{80}{80+420} = -0.12.$$&lt;/p>
&lt;p>Esto quiere decir que el riesgo de contraer la gripe es un 12% menor en vacunados
que en no vacunados.&lt;/p>
&lt;h3 id="riesgo-relativo-rr">Riesgo relativo $RR$&lt;/h3>
&lt;div class="alert alert-def">
&lt;div>
&lt;p>&lt;strong>Definición - Teorema de Bayes&lt;/strong>. El &lt;em>riesgo relativo&lt;/em> de un suceso médico $E$ para los individuos expuestos a un factor es el cociente entre las proporciones de individuos afectados por el suceso en un periodo de tiempo de los grupos tratamiento y control. Es decir, el cociente entre las incidencias de
grupo tratamiento y el grupo control.&lt;/p>
&lt;p>$$RR(D)=\frac{\mbox{Riesgo grupo tratamiento}}{\mbox{Riesgo grupo control}}=\frac{R_T(E)}{R_C(E)}=\frac{a/(a+b)}{c/(c+d)}$$&lt;/p>
&lt;/div>
&lt;/div>
&lt;p>El riesgo relativo compara el riesgo de desarrollar un suceso médico entre el grupo tratamiento y el grupo control.&lt;/p>
&lt;ul>
&lt;li>$RR=1$ $\Rightarrow$ No hay asociación entre el suceso y la exposición al factor.&lt;/li>
&lt;li>$RR&amp;lt;1$ $\Rightarrow$ La exposición al factor disminuye el riesgo del suceso.&lt;/li>
&lt;li>$RR&amp;gt;1$ $\Rightarrow$ La exposición al factor aumenta el riesgo del suceso.&lt;/li>
&lt;/ul>
&lt;p>Cuanto más lejos de 1, más fuerte es la asociación.&lt;/p>
&lt;p>&lt;strong>Ejemplo&lt;/strong>. Para determinar la efectividad de una vacuna contra la gripe, una muestra de 1000 personas sin gripe fueron seleccionadas al comienzo del año. La mitad de ellas fueron vacunadas (grupo tratamiento) y la otra mitad recibieron un placebo (grupo control). La tabla siguiente resume los resultados al final del año.&lt;/p>
&lt;table>
&lt;thead>
&lt;tr class="header">
&lt;th style="text-align: left;">&lt;/th>
&lt;th style="text-align: center;">Gripe $E$&lt;/th>
&lt;th style="text-align: center;">No gripe $\overline E$&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr class="odd">
&lt;td style="text-align: left;">Grupo tratamiento (vacunados)&lt;/td>
&lt;td style="text-align: center;">20&lt;/td>
&lt;td style="text-align: center;">480&lt;/td>
&lt;/tr>
&lt;tr class="even">
&lt;td style="text-align: left;">Grupo control (No vacunados)&lt;/td>
&lt;td style="text-align: center;">80&lt;/td>
&lt;td style="text-align: center;">420&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>El riesgo relativo de contraer la gripe cuando se es vacunado es&lt;/p>
&lt;p>$$RR(D) = \frac{20/(20+480)}{80/(80+420)} = 0.25.$$&lt;/p>
&lt;p>Así, la probabilidad de contraer la gripe en los individuos vacunados fue la cuarta parte de
la de contraerla en el caso de no haberse vacunado, es decir, la vacuna reduce el riesgo de gripe un 75%.&lt;/p>
&lt;h3 id="odds">Odds&lt;/h3>
&lt;p>Una forma alternativa de medir el riesgo de un suceso médico es el &lt;em>odds&lt;/em>.&lt;/p>
&lt;p>El &lt;em>odds&lt;/em> de un suceso médico $E$ en una población es el cociente entre el número de individuos que adquirieron el suceso y los que no en un periodo de tiempo.&lt;/p>
&lt;p>$$ODDS(E)=\frac{\mbox{Nº nuevos casos con $E$}}{\mbox{Nº casos sin $E$}}=\frac{P(E)}{P(\overline E)}$$&lt;/p>
&lt;p>A diferencia de la incidencia, que es una proporción menor o igual que 1, el odds puede ser mayor que 1. No obstante es posible convertir el odds en una probabilidad con al fórmula&lt;/p>
&lt;p>$$P(E) = \frac{ODDS(E)}{ODDS(E)+1}$$&lt;/p>
&lt;p>&lt;strong>Ejemplo&lt;/strong> Una población contenía inicialmente $1000$ personas sin gripe. Después de un año 160 de ellas tuvieron gripe. Entonces el odds de la gripe es 160/840.&lt;/p>
&lt;p>Obsérvese que la incidencia es 160/1000.&lt;/p>
&lt;h3 id="odds-ratio-or">Odds ratio $OR$&lt;/h3>
&lt;div class="alert alert-def">
&lt;div>
&lt;p>&lt;strong>Definición - Odds ratio&lt;/strong>. El &lt;em>odds ratio&lt;/em> o la &lt;em>oportunidad relativa&lt;/em> de un suceso médico $E$
para los individuos expuestos a un factor es el cociente entre los odds del sucesos de los grupos tratamiento y control.&lt;/p>
&lt;p>$$OR(E)=\frac{\mbox{Odds en grupo tratamiento}}{\mbox{Odds en grupo control}}=\frac{a/b}{c/d}=\frac{ad}{bc}$$&lt;/p>
&lt;/div>
&lt;/div>
&lt;p>El odds ratio compara los odds de un suceso médico entre el grupo tratamiento y control. La interpretación es similar a la del riesgo relativo:&lt;/p>
&lt;ul>
&lt;li>$OR=1$ $\Rightarrow$ No existe asociación entre el suceso y la exposición al factor.&lt;/li>
&lt;li>$OR&amp;lt;1$ $\Rightarrow$ La exposición al factor disminuye el riesgo del suceso.&lt;/li>
&lt;li>$OR&amp;gt;1$ $\Rightarrow$ La exposición al factor aumenta el riesgo del suceso.&lt;/li>
&lt;/ul>
&lt;p>Cuanto más lejos de 1, más fuerte es la asociación.&lt;/p>
&lt;p>&lt;strong>Ejemplo&lt;/strong>. Para determinar la efectividad de una vacuna contra la gripe, una muestra de 1000 personas sin gripe fueron seleccionadas al comienzo del año. La mitad de ellas fueron vacunadas (grupo tratamiento) y la otra mitad recibieron un placebo (grupo control). La tabla siguiente resume los resultados al final del año.&lt;/p>
&lt;table>
&lt;thead>
&lt;tr class="header">
&lt;th style="text-align: left;">&lt;/th>
&lt;th style="text-align: center;">Gripe $E$&lt;/th>
&lt;th style="text-align: center;">No gripe $\overline E$&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr class="odd">
&lt;td style="text-align: left;">Grupo tratamiento (vacunados)&lt;/td>
&lt;td style="text-align: center;">20&lt;/td>
&lt;td style="text-align: center;">480&lt;/td>
&lt;/tr>
&lt;tr class="even">
&lt;td style="text-align: left;">Grupo control (No vacunados)&lt;/td>
&lt;td style="text-align: center;">80&lt;/td>
&lt;td style="text-align: center;">420&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>El odds ratio de sufrir la gripe para los individuos vacunados es&lt;/p>
&lt;p>$$OR(D) = \frac{20/480}{80/420} = 0.21875.$$&lt;/p>
&lt;p>Esto quiere decir que el odds de sufrir la gripe frente a no sufrirla en los vacunados es casi un quinto del de los no vacunados, es decir, que aproximadamente por cada 22 personas vacunadas con gripe habrá 100 personas no vacunadas con gripe.&lt;/p>
&lt;h3 id="riesgo-relativo-vs-odds-ratio">Riesgo relativo vs Odds ratio&lt;/h3>
&lt;p>El riesgo relativo y el odds ratio son dos medidas de asociación pero su interpretación es ligeramente diferente. Mientras que el riesgo relativo expresa una comparación de riesgos entre los grupos tratamiento y control, el odds ratio expresa una comparación de odds, que no es lo mismo que el riesgo. Así, un odds ratio de 2 &lt;em>no&lt;/em> significa que el grupo tratamiento tiene el doble de riesgo de adquirir el suceso.&lt;/p>
&lt;p>La interpretación del odds ratio es un poco más enrevesada porque es contrafactual, y nos da cuántas veces es más frecuente el suceso en el grupo tratamiento en comparación con el control, asumiendo que en el
grupo control es tan frecuente que ocurra el suceso como que no.&lt;/p>
&lt;p>La ventaja del odds ratio es que no depende de la prevalencia o la incidencia del suceso, y debe usarse siempre que el número de individuos que presenta el suceso se selecciona arbitrariamente en ambos grupos,
como ocurre en los estudios casos-control.&lt;/p>
&lt;p>&lt;strong>Ejemplo&lt;/strong>. Para determinar la asociación entre el cáncer de pulmón y fumar se tomaron dos muestras (la segunda con el doble de individuos sin cáncer) obteniendo los siguientes resultados:&lt;/p>
&lt;p>&lt;strong>Sample 1&lt;/strong>&lt;/p>
&lt;table>
&lt;thead>
&lt;tr class="header">
&lt;th style="text-align: left;">&lt;/th>
&lt;th style="text-align: center;">Cáncer&lt;/th>
&lt;th style="text-align: center;">No cáncer&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr class="odd">
&lt;td style="text-align: left;">Fumadores&lt;/td>
&lt;td style="text-align: center;">60&lt;/td>
&lt;td style="text-align: center;">80&lt;/td>
&lt;/tr>
&lt;tr class="even">
&lt;td style="text-align: left;">No fumadores&lt;/td>
&lt;td style="text-align: center;">40&lt;/td>
&lt;td style="text-align: center;">320&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>$$
\begin{aligned}
RR(D) &amp;amp;= \frac{60/(60+80)}{40/(40+320)} = 3.86.\newline
OR(D) &amp;amp;= \frac{60/80}{40/320} = 6.
\end{aligned}
$$&lt;/p>
&lt;p>&lt;strong>Sample 2&lt;/strong>&lt;/p>
&lt;table>
&lt;thead>
&lt;tr class="header">
&lt;th style="text-align: left;">&lt;/th>
&lt;th style="text-align: center;">Cáncer&lt;/th>
&lt;th style="text-align: center;">No cáncer&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr class="odd">
&lt;td style="text-align: left;">Fumadores&lt;/td>
&lt;td style="text-align: center;">60&lt;/td>
&lt;td style="text-align: center;">160&lt;/td>
&lt;/tr>
&lt;tr class="even">
&lt;td style="text-align: left;">No fumadores&lt;/td>
&lt;td style="text-align: center;">40&lt;/td>
&lt;td style="text-align: center;">640&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>$$
\begin{aligned}
RR(D) &amp;amp;= \frac{60/(60+160)}{40/(40+640)} = 4.64.\newline
OR(D) &amp;amp;= \frac{60/160}{40/640} = 6.
\end{aligned}
$$&lt;/p>
&lt;p>Así, cuando cambia la incidencia o prevalencia de un suceso (cáncer de pulmón) el riesgo relativo cambia, mientras que el odds ratio no.&lt;/p>
&lt;h3 id="riesgo-relativo-vs-odds-ratio-1">Riesgo relativo vs Odds ratio&lt;/h3>
&lt;p>La relación entre el riesgo relativo y el odds ratio viene dada por la siguiente fórmula&lt;/p>
&lt;p>$$RR = \frac{OR}{1-R_0+R_0\cdot OR} = OR \frac{1-R_1}{1-R_0},$$&lt;/p>
&lt;p>donde $R_C$ and $R_T$ son la prevalencia o la incidencia en los grupos control y tratamiento respectivamente.&lt;/p>
&lt;p>El odds ratio siempre sobrestima el riesgo relativo cuando este es mayor que 1 y lo subestima cuando es menor que 1. No obstante, con sucesos médicos raros (con una prevalencia o incidencia baja) el riesgo
relativo y el odds ratio son casi iguales.&lt;/p>
&lt;img src="../img/probabilidad/odds_ratio_vs_riesgo_relativo.svg" alt="Odss ratio versus riesgo relativo" width="600">
&lt;h2 id="tests-diagnósticos">Tests diagnósticos&lt;/h2>
&lt;p>En Epidemiología es común el uso de test para diagnosticar enfermedades.&lt;/p>
&lt;p>Generalmente estos test no son totalmente fiables, sino que hay cierta probabilidad de acierto o fallo en el diagnóstico, que suele representarse en la siguiente tabla:&lt;/p>
&lt;table>
&lt;thead>
&lt;tr class="header">
&lt;th style="text-align: left;">&lt;/th>
&lt;th style="text-align: center;">Presencia enfermedad $E$&lt;/th>
&lt;th style="text-align: center;">Ausencia enfermedad $\overline E$&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr class="odd">
&lt;td style="text-align: left;">Test positivo $+$&lt;/td>
&lt;td style="text-align: center;">&lt;span style="color: green">Verdadero positivo &lt;/span>$VP$&lt;/td>
&lt;td style="text-align: center;">&lt;span style="color: red">Falso positivo &lt;/span>$FP$&lt;/td>
&lt;/tr>
&lt;tr class="even">
&lt;td style="text-align: left;">Test negativo $−$&lt;/td>
&lt;td style="text-align: left;">&lt;span style="color: red">Falso negativo &lt;/span>$FN$&lt;/td>
&lt;td style="text-align: left;">&lt;span style="color: green">Verdadero Negativo &lt;/span>$VN$&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h3 id="sensibilidad-y-especificidad-de-un-test-diagnóstico">Sensibilidad y especificidad de un test diagnóstico&lt;/h3>
&lt;p>La fiabilidad de un test diagnóstico depende de las siguientes probabilidades.&lt;/p>
&lt;div class="alert alert-def">
&lt;div>
&lt;p>&lt;strong>Definición - Sensibilidad&lt;/strong>. La &lt;em>sensibilidad&lt;/em> de un test diagnóstico es la proporción de resultados positivos del test en personas con la enfermedad,&lt;/p>
&lt;p>$$P(+|E)=\frac{VP}{VP+FN}$$&lt;/p>
&lt;/div>
&lt;/div>
&lt;div class="alert alert-def">
&lt;div>
&lt;p>&lt;strong>Definición - Especificidad&lt;/strong>. La &lt;em>especificidad&lt;/em> de un test diagnóstico es la proporción de resultados
negativos del test en personas sin la enfermedad,&lt;/p>
&lt;p>$$P(-|\overline{E})=\frac{VN}{VN+FP}$$&lt;/p>
&lt;/div>
&lt;/div>
&lt;p>Normalmente existe un balance entre la sensibilidad y la especificidad.&lt;/p>
&lt;p>Un test con una alta sensibilidad detectará la enfermedad en la mayoría de las personas enfermas, pero también dará más falsos positivos que un test menos sensible. De este modo, un resultado positivo en un test con una gran sensibilidad no es muy útil para confirmar la enfermedad, pero un resultado negativo es útil para descartar la enfermedad, ya que raramente da resultados negativos en personas con la enfermedad.&lt;/p>
&lt;p>Por otro lado, un test con una alta especificidad descartará la enfermedad en la mayoría de las personas sin la enfermedad, pero también producirá más falsos negativos que un test menos específico. Así, un
resultado negativo en un test con una gran especificidad no es útil para descartar la enfermedad, pero un resultado positivo es muy útil para confirmar la enfermedad, ya que raramente da resultados positivos en
personas sin la enfermedad.&lt;/p>
&lt;p>Decidir entre un test con una gran sensibilidad o un test con una gran especificidad depende del tipo de enfermedad y el objetivo del test. En general, utilizaremos un test sensible cuando:&lt;/p>
&lt;ul>
&lt;li>La enfermedad es grave y es importante detectarla.&lt;/li>
&lt;li>La enfermedad es curable.&lt;/li>
&lt;li>Los falsos positivos no provocan traumas serios.&lt;/li>
&lt;/ul>
&lt;p>Y utilizaremos un test específico cuando:&lt;/p>
&lt;ul>
&lt;li>La enfermedad es importante pero difícil o imposible de curar.&lt;/li>
&lt;li>Los falsos positivos pueden provocar traumas serios.&lt;/li>
&lt;li>El tratamiento de los falsos positivos puede tener graves consecuencias.&lt;/li>
&lt;/ul>
&lt;h3 id="valores-predictivos-de-un-test-diagnóstico">Valores predictivos de un test diagnóstico&lt;/h3>
&lt;p>Pero el aspecto más importante de un test diagnóstico es su poder predictivo, que se mide con las siguientes probabilidades a posteriori.&lt;/p>
&lt;div class="alert alert-def">
&lt;div>
&lt;p>&lt;strong>Definición - Valor predictivo positivo&lt;/strong>. El &lt;em>valor predictivo positivo&lt;/em> de un test diagnóstico es la proporción de personas con la enfermedad entre las personas con resultado positivo
en el test,&lt;/p>
&lt;p>$$P(E|+) = \frac{VP}{VP+FP}$$&lt;/p>
&lt;/div>
&lt;/div>
&lt;div class="alert alert-def">
&lt;div>
&lt;p>&lt;strong>Definición - Valor predictivo negativo&lt;/strong>. El &lt;em>valor predictivo negativo&lt;/em> de un test diagnóstico es la proporción de personas sin la enfermedad entre las personas con resultado negativo en el test,&lt;/p>
&lt;p>$$P(\overline{E}|-) = \frac{VN}{VN+FN}$$&lt;/p>
&lt;/div>
&lt;/div>
&lt;p>Los valores predictivos positivo y negativo permiten confirmar o descartar la enfermedad, respectivamente, si alcanzan al menos el umbral de $0.5$.&lt;/p>
&lt;p>$$
\begin{array}{rcl}
VPP&amp;gt;0.5 &amp;amp; \Rightarrow &amp;amp; \mbox{Diagnosticar la enfermedad}\newline
VPN&amp;gt;0.5 &amp;amp; \Rightarrow &amp;amp; \mbox{Diagnosticar la no enfermedad}
\end{array}
$$&lt;/p>
&lt;p>No obstante, estas probabilidades dependen de la proporción de personas con la enfermedad en la población $P(E)$ que se conoce como de la enfermedad. Pueden calcularse a partir de la sensibilidad y la especificidad del test diagnóstico usando el teorema de Bayes.&lt;/p>
&lt;p>$$
\begin{aligned}
VPP=P(E|+) &amp;amp;= \frac{P(E)P(+|E)}{P(E)P(+|E)+P(\overline{E})P(+|\overline{E})}\newline
VPN=P(\overline{E}|-) &amp;amp;= \frac{P(\overline{E})P(-|\overline{E})}{P(E)P(-|E)+P(\overline{E})P(-|\overline{E})}
\end{aligned}
$$&lt;/p>
&lt;p>Así, con enfermedades frecuentes, el valor predictivo positivo aumenta, y con enfermedades raras, el valor predictivo negativo aumenta.&lt;/p>
&lt;p>&lt;strong>Ejemplo&lt;/strong> Un test diagnóstico para la gripe se ha aplicado a una muestra aleatoria de 1000 personas. Los resultados aparecen resumidos en la siguiente
tabla.&lt;/p>
&lt;table>
&lt;thead>
&lt;tr class="header">
&lt;th style="text-align: left;">&lt;/th>
&lt;th style="text-align: center;">Presencia de gripe $E$&lt;/th>
&lt;th style="text-align: center;">Ausencia de gripe $\overline E$&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr class="odd">
&lt;td style="text-align: left;">Test $+$&lt;/td>
&lt;td style="text-align: center;">95&lt;/td>
&lt;td style="text-align: center;">90&lt;/td>
&lt;/tr>
&lt;tr class="even">
&lt;td style="text-align: left;">Test $−$&lt;/td>
&lt;td style="text-align: center;">5&lt;/td>
&lt;td style="text-align: center;">810&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>Según esta muestra, la prevalencia de la gripe puede estimarse como&lt;/p>
&lt;p>$$P(E) = \frac{95+5}{1000} = 0.1.$$&lt;/p>
&lt;p>La sensibilidad del test diagnóstico es&lt;/p>
&lt;p>$$P(+|E) = \frac{95}{95+5}= 0.95.$$&lt;/p>
&lt;p>Y la especificidad es&lt;/p>
&lt;p>$$P(-|\overline{E}) = \frac{810}{90+810}=0.9.$$&lt;/p>
&lt;p>El valor predictivo positivo del test es&lt;/p>
&lt;p>$$VPP = P(E|+) = \frac{95}{95+90} = 0.5135.$$&lt;/p>
&lt;p>Como este valor es mayor que $0.5$, eso significa que se diagnosticará la gripe si el resultado del test es positivo. No obstante, la confianza en el diagnóstico será baja, ya que el valor es poco mayor que $0.5$.&lt;/p>
&lt;p>Por otro lado, el valor predictivo negativo es&lt;/p>
&lt;p>$$VPN = P(\overline{E}|-) = \frac{810}{5+810} = 0.9939.$$&lt;/p>
&lt;p>Como este valor es casi 1, eso significa que es casi seguro que no se tiene la gripe cuando el resultado del test es negativo.&lt;/p>
&lt;p>Así, se puede concluir que este test es muy potente para descartar la gripe, pero no lo est tanto para confirmarla.&lt;/p>
&lt;h3 id="razón-de-verosimilitud-de-un-test-diagnóstico">Razón de verosimilitud de un test diagnóstico&lt;/h3>
&lt;p>La siguientes medidas también se derivan de la sensibilidad y la especificidad de un test diagnóstico.&lt;/p>
&lt;div class="alert alert-def">
&lt;div>
&lt;p>&lt;strong>Definición - Razón de verosimilitud positiva&lt;/strong>. La &lt;em>razón de verosimilitud positiva&lt;/em> de un test diagnóstico es el cociente entre la probabilidad de un resultado positivo en personas con
la enfermedad y personas sin la enfermedad, respectivamente.&lt;/p>
&lt;p>$$RV+=\frac{P(+|E)}{P(+|\overline{E})} = \frac{\mbox{Sensibilidad}}{1-\mbox{Especificidad}}$$&lt;/p>
&lt;/div>
&lt;/div>
&lt;div class="alert alert-def">
&lt;div>
&lt;p>&lt;strong>Definición - Razón de verosimilitud negativa&lt;/strong>. La &lt;em>razón de verosimilitud negativa&lt;/em> de un test diagnóstico es el cociente entre la probabilidad de un resultado negativo en personas con la enfermedad y personas sin la enfermedad, respectivamente.&lt;/p>
&lt;p>$$RV-=\frac{P(-|E)}{P(-|\overline{E})} = \frac{1-\mbox{Sensibilidad}}{\mbox{Especificidad}}$$&lt;/p>
&lt;/div>
&lt;/div>
&lt;p>La razón de verosimilitud positiva puede interpretarse como el número de veces que un resultado positivo es más probable en personas con la enfermedad que en personas sin la enfermedad.&lt;/p>
&lt;p>Por otro lado, la razón de verosimilitud negativa puede interpretarse como el número de veces que un resultado negativo es más probable en personas con la enfermedad que en personas sin la enfermedad.&lt;/p>
&lt;p>Las probabilidades a posteriori pueden calculares a partir de las probabilidades a priori usando las razones de verosimilitud&lt;/p>
&lt;p>$$P(E|+) = \frac{P(E)P(+|E)}{P(E)P(+|E)+P(\overline{E})P(+|\overline{E})} = \frac{P(E)RV+}{1-P(E)+P(E)RV+}$$&lt;/p>
&lt;p>Así,&lt;/p>
&lt;ul>
&lt;li>Una razón de verosimilitud positiva mayor que 1 aumenta la probabilidad de la enfermedad.&lt;/li>
&lt;li>Una razón de verosimilitud positiva menor que 1 disminuye la probabilidad de la enfermedad.&lt;/li>
&lt;li>Una razón de verosimilitud 1 no cambia la probabilidad a priori de la de tener la enfermedad.&lt;/li>
&lt;/ul>
&lt;img src="../img/probabilidad/razon_verosimilitud.svg" alt="Razón de verosimilitud" width="600"></description></item><item><title>Ejercicios de Tests Diagnósticos</title><link>/docencia/estadistica/ejercicios/tests-diagnosticos/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/docencia/estadistica/ejercicios/tests-diagnosticos/</guid><description>&lt;h2 id="ejercicio-1">Ejercicio 1&lt;/h2>
&lt;p>Titulación: Farmacia, Medicina&lt;/p>
&lt;p>Para detectar el parásito del paludismo existe un test de respuesta inmediata que produce un 2 % de falsos
positivos y un 4 % de falsos negativos.
En una determinada región de África se sabe que hay un 32 % de personas con paludismo.
Se pide:&lt;/p>
&lt;ol>
&lt;li>¿Cuál es la probabilidad de que el test de un diagnóstico acertado?&lt;/li>
&lt;li>¿Cuál es el poder predictivo negativo del test?&lt;/li>
&lt;li>¿Cuánto debería valer la sensibilidad del test para que el poder predictivo negativo fuese de al menos el 99 %?&lt;/li>
&lt;/ol>
&lt;p>&lt;strong>SOLUCIÓN&lt;/strong>&lt;/p>
&lt;iframe src="http://www.slideshare.net/slideshow/embed_code/35218906" width="640" height="449" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" style="border:1px solid #CCC; border-width:1px 1px 0; margin-bottom:5px; max-width: 100%;" allowfullscreen> &lt;/iframe>
&lt;iframe src="//www.youtube.com/embed/Py7ciwGGvqg" width="640" height="360" frameborder="0"> &lt;/iframe></description></item><item><title>Epidemiología para tiempos de pandemia</title><link>/post/epidemiologia-tiempos-pandemias/</link><pubDate>Sun, 07 Nov 2021 00:00:00 +0000</pubDate><guid>/post/epidemiologia-tiempos-pandemias/</guid><description>&lt;p>Debido a la epidemia provocada por el coronavirus, la Epidemiología se ha convertido en una de las ramas de la medicina que más interés despiertan.&lt;/p>
&lt;p>En estos tiempos de pandemia un montón de términos técnicos de la Epidemiología se han convertido en lugares comunes gracias a los medios de comunicación. Sin embargo, muchos de estos términos se utilizan de manera errónea, incluso por los propios medios de comunicación, y generan confusión para la población no experta.&lt;/p>
&lt;p>Por ello, y con motivo de la
&lt;a href="http://www.madrimasd.org/semanacienciaeinnovacion/" target="_blank" rel="noopener">Semana de la Ciencia y la Innovación de Madrid 2021&lt;/a>, he preparado un tutorial para explicar al público en general los principales conceptos epidemiológicos usados en el control de enfermedades como la COVID e ilustrar su uso con ejemplos de aplicación.&lt;/p>
&lt;p>Podéis acceder a él en el siguiente enlace:
&lt;a href="/docencia/estadistica/tutoriales/epidemiologia/#valores-predictivos-de-un-test">Tutorial de Epidemiología&lt;/a>&lt;/p></description></item></channel></rss>